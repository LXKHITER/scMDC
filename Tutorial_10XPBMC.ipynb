{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial of scMDC on 10X PBMC CITE-seq data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial was implemented on MacBook pro 2018 with CPU\n",
    "\n",
    "1. Build the scMDC model and load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiantian/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:21: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Autoencoder: Successfully preprocessed 1000 genes and 6661 cells.\n",
      "### Autoencoder: Successfully preprocessed 14 genes and 6661 cells.\n",
      "(6661, 1000)\n",
      "(6661, 14)\n",
      "(6661, 14)\n",
      "(6661, 14)\n",
      "(6661,)\n",
      "scMultiCluster(\n",
      "  (encoder1): Sequential(\n",
      "    (0): Linear(in_features=1000, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=32, out_features=12, bias=True)\n",
      "  )\n",
      "  (decoder1): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=32, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=32, out_features=64, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      "  (encoder2): Sequential(\n",
      "    (0): Linear(in_features=14, out_features=8, bias=True)\n",
      "  )\n",
      "  (decoder2): Sequential()\n",
      "  (latent_enc): Sequential(\n",
      "    (0): Linear(in_features=20, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=16, bias=True)\n",
      "  )\n",
      "  (latent_dec): Sequential(\n",
      "    (0): Linear(in_features=16, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=20, bias=True)\n",
      "  )\n",
      "  (dec_mean1): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1000, bias=True)\n",
      "    (1): MeanAct()\n",
      "  )\n",
      "  (dec_disp1): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1000, bias=True)\n",
      "    (1): DispAct()\n",
      "  )\n",
      "  (dec_mean2): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=14, bias=True)\n",
      "    (1): MeanAct()\n",
      "  )\n",
      "  (dec_disp2): Sequential(\n",
      "    (0): Linear(in_features=8, out_features=14, bias=True)\n",
      "    (1): DispAct()\n",
      "  )\n",
      "  (dec_pi1): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1000, bias=True)\n",
      "    (1): Sigmoid()\n",
      "  )\n",
      "  (zinb_loss): ZINBLoss()\n",
      "  (NBLoss): NBLoss()\n",
      "  (mse): MSELoss()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "import math, os\n",
    "from sklearn import metrics\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from scMDC import scMultiCluster\n",
    "import numpy as np\n",
    "import collections\n",
    "import h5py\n",
    "import scanpy as sc\n",
    "from preprocess import read_dataset, normalize\n",
    "from utils import cluster_acc, GetCluster\n",
    "\n",
    "\n",
    "data_mat = h5py.File('10XPBMC_filtered_1000G.H5')\n",
    "x1 = np.array(data_mat['X1'])\n",
    "x2 = np.array(data_mat['X2'])\n",
    "y = np.array(data_mat['Y'])\n",
    "data_mat.close()\n",
    "\n",
    "# preprocessing CITE-seq read counts matrix\n",
    "adata1 = sc.AnnData(x1)\n",
    "adata1.obs['Group'] = y\n",
    "\n",
    "adata1 = read_dataset(adata1,\n",
    "                    transpose=False,\n",
    "                    test_split=False,\n",
    "                    copy=True)\n",
    "\n",
    "adata1 = normalize(adata1,\n",
    "                    size_factors=True,\n",
    "                    normalize_input=True,\n",
    "                    logtrans_input=True)\n",
    "\n",
    "adata2 = sc.AnnData(x2)\n",
    "adata2.obs['Group'] = y\n",
    "adata2 = read_dataset(adata2,\n",
    "                    transpose=False,\n",
    "                    test_split=False,\n",
    "                    copy=True)\n",
    "\n",
    "adata2 = normalize(adata2,\n",
    "                    size_factors=True,\n",
    "                    normalize_input=True,\n",
    "                    logtrans_input=True)\n",
    "\n",
    "input_size1 = adata1.n_vars\n",
    "input_size2 = adata2.n_vars\n",
    "\n",
    "print(adata1.X.shape)\n",
    "print(adata2.raw.X.shape)\n",
    "print(x2.shape)\n",
    "print(adata2.X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "encodeLayer1 = list(map(int, [64,32,12]))\n",
    "decodeLayer1 = encodeLayer1[::-1]\n",
    "encodeLayer2 = list(map(int, [8]))\n",
    "if len(encodeLayer2) >1:\n",
    "    decodeLayer2 = encodeLayer2[::-1]\n",
    "else:\n",
    "    decodeLayer2 = encodeLayer2\n",
    "    \n",
    "encodeLayer3 = list(map(int, [64,16]))\n",
    "if len(encodeLayer3) >1:\n",
    "    decodeLayer3 = encodeLayer3[::-1]\n",
    "else:\n",
    "    decodeLayer3 = encodeLayer3\n",
    "    \n",
    "model = scMultiCluster(input_dim1=input_size1, input_dim2=input_size2,\n",
    "                    zencode_dim=encodeLayer3, zdecode_dim=decodeLayer3, \n",
    "                    encodeLayer1=encodeLayer1, decodeLayer1=decodeLayer1, encodeLayer2=encodeLayer2, decodeLayer2=decodeLayer2,\n",
    "                    sigma1=2.5, sigma2=0, gamma1=0.1, gamma2=0.1, gamma3=.0001, cutoff = 0.5)\n",
    "\n",
    "print(str(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Pretrainging state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretraining stage\n",
      "Pretrain epoch [1/1], ZINB loss:0.7685, NB loss:244.6999\n",
      "Pretrain epoch [2/1], ZINB loss:0.7862, NB loss:237.7955\n",
      "Pretrain epoch [3/1], ZINB loss:0.7567, NB loss:231.7954\n",
      "Pretrain epoch [4/1], ZINB loss:0.6953, NB loss:220.0811\n",
      "Pretrain epoch [5/1], ZINB loss:0.6515, NB loss:213.8475\n",
      "Pretrain epoch [6/1], ZINB loss:0.6197, NB loss:208.9973\n",
      "Pretrain epoch [7/1], ZINB loss:0.5906, NB loss:199.4105\n",
      "Pretrain epoch [8/1], ZINB loss:0.5331, NB loss:189.3931\n",
      "Pretrain epoch [9/1], ZINB loss:0.5357, NB loss:187.7750\n",
      "Pretrain epoch [10/1], ZINB loss:0.5405, NB loss:179.2274\n",
      "Pretrain epoch [11/1], ZINB loss:0.5366, NB loss:173.3947\n",
      "Pretrain epoch [12/1], ZINB loss:0.5040, NB loss:169.4115\n",
      "Pretrain epoch [13/1], ZINB loss:0.5066, NB loss:165.8712\n",
      "Pretrain epoch [14/1], ZINB loss:0.4927, NB loss:156.6874\n",
      "Pretrain epoch [15/1], ZINB loss:0.4952, NB loss:159.2221\n",
      "Pretrain epoch [16/1], ZINB loss:0.4942, NB loss:151.8865\n",
      "Pretrain epoch [17/1], ZINB loss:0.4868, NB loss:149.1227\n",
      "Pretrain epoch [18/1], ZINB loss:0.4858, NB loss:138.0013\n",
      "Pretrain epoch [19/1], ZINB loss:0.5080, NB loss:133.5911\n",
      "Pretrain epoch [20/1], ZINB loss:0.4941, NB loss:133.5487\n",
      "Pretrain epoch [21/1], ZINB loss:0.4879, NB loss:128.9355\n",
      "Pretrain epoch [22/1], ZINB loss:0.4857, NB loss:125.2915\n",
      "Pretrain epoch [23/1], ZINB loss:0.4360, NB loss:127.4185\n",
      "Pretrain epoch [24/1], ZINB loss:0.4604, NB loss:114.9582\n",
      "Pretrain epoch [25/1], ZINB loss:0.4851, NB loss:112.6361\n",
      "Pretrain epoch [26/1], ZINB loss:0.4496, NB loss:112.8178\n",
      "Pretrain epoch [27/1], ZINB loss:0.3428, NB loss:94.5976\n",
      "Pretrain epoch [1/2], ZINB loss:0.4692, NB loss:108.1890\n",
      "Pretrain epoch [2/2], ZINB loss:0.4616, NB loss:94.8150\n",
      "Pretrain epoch [3/2], ZINB loss:0.4530, NB loss:93.8685\n",
      "Pretrain epoch [4/2], ZINB loss:0.4362, NB loss:88.3841\n",
      "Pretrain epoch [5/2], ZINB loss:0.4416, NB loss:84.7844\n",
      "Pretrain epoch [6/2], ZINB loss:0.4314, NB loss:82.3135\n",
      "Pretrain epoch [7/2], ZINB loss:0.4428, NB loss:77.9764\n",
      "Pretrain epoch [8/2], ZINB loss:0.4481, NB loss:77.8967\n",
      "Pretrain epoch [9/2], ZINB loss:0.4714, NB loss:76.5800\n",
      "Pretrain epoch [10/2], ZINB loss:0.4543, NB loss:74.7313\n",
      "Pretrain epoch [11/2], ZINB loss:0.4355, NB loss:73.5911\n",
      "Pretrain epoch [12/2], ZINB loss:0.4487, NB loss:67.5776\n",
      "Pretrain epoch [13/2], ZINB loss:0.4170, NB loss:64.3059\n",
      "Pretrain epoch [14/2], ZINB loss:0.4210, NB loss:62.5404\n",
      "Pretrain epoch [15/2], ZINB loss:0.4214, NB loss:62.4823\n",
      "Pretrain epoch [16/2], ZINB loss:0.4203, NB loss:59.6742\n",
      "Pretrain epoch [17/2], ZINB loss:0.4483, NB loss:56.6934\n",
      "Pretrain epoch [18/2], ZINB loss:0.4506, NB loss:58.2377\n",
      "Pretrain epoch [19/2], ZINB loss:0.4195, NB loss:53.5119\n",
      "Pretrain epoch [20/2], ZINB loss:0.4246, NB loss:55.7931\n",
      "Pretrain epoch [21/2], ZINB loss:0.4201, NB loss:51.8666\n",
      "Pretrain epoch [22/2], ZINB loss:0.4547, NB loss:50.4104\n",
      "Pretrain epoch [23/2], ZINB loss:0.4475, NB loss:51.0669\n",
      "Pretrain epoch [24/2], ZINB loss:0.4407, NB loss:45.0048\n",
      "Pretrain epoch [25/2], ZINB loss:0.4475, NB loss:46.4137\n",
      "Pretrain epoch [26/2], ZINB loss:0.4365, NB loss:42.2914\n",
      "Pretrain epoch [27/2], ZINB loss:0.5035, NB loss:47.7852\n",
      "Pretrain epoch [1/3], ZINB loss:0.4216, NB loss:41.0028\n",
      "Pretrain epoch [2/3], ZINB loss:0.4235, NB loss:39.5738\n",
      "Pretrain epoch [3/3], ZINB loss:0.4729, NB loss:38.5103\n",
      "Pretrain epoch [4/3], ZINB loss:0.4408, NB loss:35.0564\n",
      "Pretrain epoch [5/3], ZINB loss:0.4345, NB loss:34.4393\n",
      "Pretrain epoch [6/3], ZINB loss:0.4301, NB loss:34.2608\n",
      "Pretrain epoch [7/3], ZINB loss:0.4381, NB loss:34.8195\n",
      "Pretrain epoch [8/3], ZINB loss:0.4258, NB loss:33.4592\n",
      "Pretrain epoch [9/3], ZINB loss:0.4195, NB loss:32.3059\n",
      "Pretrain epoch [10/3], ZINB loss:0.4207, NB loss:32.7371\n",
      "Pretrain epoch [11/3], ZINB loss:0.4135, NB loss:31.0905\n",
      "Pretrain epoch [12/3], ZINB loss:0.4202, NB loss:29.0008\n",
      "Pretrain epoch [13/3], ZINB loss:0.4069, NB loss:28.4139\n",
      "Pretrain epoch [14/3], ZINB loss:0.4280, NB loss:30.0516\n",
      "Pretrain epoch [15/3], ZINB loss:0.4187, NB loss:27.2065\n",
      "Pretrain epoch [16/3], ZINB loss:0.4427, NB loss:26.3370\n",
      "Pretrain epoch [17/3], ZINB loss:0.4430, NB loss:26.6429\n",
      "Pretrain epoch [18/3], ZINB loss:0.4197, NB loss:26.1555\n",
      "Pretrain epoch [19/3], ZINB loss:0.4240, NB loss:26.0600\n",
      "Pretrain epoch [20/3], ZINB loss:0.4116, NB loss:24.5343\n",
      "Pretrain epoch [21/3], ZINB loss:0.4178, NB loss:24.6355\n",
      "Pretrain epoch [22/3], ZINB loss:0.4028, NB loss:24.2206\n",
      "Pretrain epoch [23/3], ZINB loss:0.4222, NB loss:24.6312\n",
      "Pretrain epoch [24/3], ZINB loss:0.3954, NB loss:22.3121\n",
      "Pretrain epoch [25/3], ZINB loss:0.4262, NB loss:22.4278\n",
      "Pretrain epoch [26/3], ZINB loss:0.4389, NB loss:23.2360\n",
      "Pretrain epoch [27/3], ZINB loss:0.4839, NB loss:23.1550\n",
      "Pretrain epoch [1/4], ZINB loss:0.4401, NB loss:21.1741\n",
      "Pretrain epoch [2/4], ZINB loss:0.4008, NB loss:20.5283\n",
      "Pretrain epoch [3/4], ZINB loss:0.4336, NB loss:21.1107\n",
      "Pretrain epoch [4/4], ZINB loss:0.4157, NB loss:20.6089\n",
      "Pretrain epoch [5/4], ZINB loss:0.4160, NB loss:19.9697\n",
      "Pretrain epoch [6/4], ZINB loss:0.4147, NB loss:19.8253\n",
      "Pretrain epoch [7/4], ZINB loss:0.4048, NB loss:19.0109\n",
      "Pretrain epoch [8/4], ZINB loss:0.4358, NB loss:19.7417\n",
      "Pretrain epoch [9/4], ZINB loss:0.4310, NB loss:18.4987\n",
      "Pretrain epoch [10/4], ZINB loss:0.3870, NB loss:18.5859\n",
      "Pretrain epoch [11/4], ZINB loss:0.4281, NB loss:19.1682\n",
      "Pretrain epoch [12/4], ZINB loss:0.4023, NB loss:17.9768\n",
      "Pretrain epoch [13/4], ZINB loss:0.4194, NB loss:17.5498\n",
      "Pretrain epoch [14/4], ZINB loss:0.4077, NB loss:17.2193\n",
      "Pretrain epoch [15/4], ZINB loss:0.4209, NB loss:17.2990\n",
      "Pretrain epoch [16/4], ZINB loss:0.4375, NB loss:18.2280\n",
      "Pretrain epoch [17/4], ZINB loss:0.4155, NB loss:16.6745\n",
      "Pretrain epoch [18/4], ZINB loss:0.4329, NB loss:16.1271\n",
      "Pretrain epoch [19/4], ZINB loss:0.4178, NB loss:16.3051\n",
      "Pretrain epoch [20/4], ZINB loss:0.4125, NB loss:16.1309\n",
      "Pretrain epoch [21/4], ZINB loss:0.4144, NB loss:15.9078\n",
      "Pretrain epoch [22/4], ZINB loss:0.4095, NB loss:15.8476\n",
      "Pretrain epoch [23/4], ZINB loss:0.3943, NB loss:15.5478\n",
      "Pretrain epoch [24/4], ZINB loss:0.3945, NB loss:15.8568\n",
      "Pretrain epoch [25/4], ZINB loss:0.4026, NB loss:15.1079\n",
      "Pretrain epoch [26/4], ZINB loss:0.3972, NB loss:15.5948\n",
      "Pretrain epoch [27/4], ZINB loss:0.4032, NB loss:18.0099\n",
      "Pretrain epoch [1/5], ZINB loss:0.4153, NB loss:15.6016\n",
      "Pretrain epoch [2/5], ZINB loss:0.4118, NB loss:14.6243\n",
      "Pretrain epoch [3/5], ZINB loss:0.4193, NB loss:14.6052\n",
      "Pretrain epoch [4/5], ZINB loss:0.4200, NB loss:14.2306\n",
      "Pretrain epoch [5/5], ZINB loss:0.4036, NB loss:14.1492\n",
      "Pretrain epoch [6/5], ZINB loss:0.4230, NB loss:14.8159\n",
      "Pretrain epoch [7/5], ZINB loss:0.4024, NB loss:14.0522\n",
      "Pretrain epoch [8/5], ZINB loss:0.4097, NB loss:13.7086\n",
      "Pretrain epoch [9/5], ZINB loss:0.3902, NB loss:13.7691\n",
      "Pretrain epoch [10/5], ZINB loss:0.4226, NB loss:14.2099\n",
      "Pretrain epoch [11/5], ZINB loss:0.4026, NB loss:13.6032\n",
      "Pretrain epoch [12/5], ZINB loss:0.4027, NB loss:13.8766\n",
      "Pretrain epoch [13/5], ZINB loss:0.3918, NB loss:13.4140\n",
      "Pretrain epoch [14/5], ZINB loss:0.3938, NB loss:13.4561\n",
      "Pretrain epoch [15/5], ZINB loss:0.4009, NB loss:13.3208\n",
      "Pretrain epoch [16/5], ZINB loss:0.4290, NB loss:13.2711\n",
      "Pretrain epoch [17/5], ZINB loss:0.4269, NB loss:12.9512\n",
      "Pretrain epoch [18/5], ZINB loss:0.4401, NB loss:12.8405\n",
      "Pretrain epoch [19/5], ZINB loss:0.4104, NB loss:12.9109\n",
      "Pretrain epoch [20/5], ZINB loss:0.4022, NB loss:12.8033\n",
      "Pretrain epoch [21/5], ZINB loss:0.4206, NB loss:12.8338\n",
      "Pretrain epoch [22/5], ZINB loss:0.4294, NB loss:12.6248\n",
      "Pretrain epoch [23/5], ZINB loss:0.4202, NB loss:13.0084\n",
      "Pretrain epoch [24/5], ZINB loss:0.4145, NB loss:12.0278\n",
      "Pretrain epoch [25/5], ZINB loss:0.3966, NB loss:12.1924\n",
      "Pretrain epoch [26/5], ZINB loss:0.4038, NB loss:12.3986\n",
      "Pretrain epoch [27/5], ZINB loss:0.4213, NB loss:12.0498\n",
      "Pretrain epoch [1/6], ZINB loss:0.4004, NB loss:11.8821\n",
      "Pretrain epoch [2/6], ZINB loss:0.4117, NB loss:12.0744\n",
      "Pretrain epoch [3/6], ZINB loss:0.4391, NB loss:11.6388\n",
      "Pretrain epoch [4/6], ZINB loss:0.3869, NB loss:11.7197\n",
      "Pretrain epoch [5/6], ZINB loss:0.4073, NB loss:11.7781\n",
      "Pretrain epoch [6/6], ZINB loss:0.4091, NB loss:11.9107\n",
      "Pretrain epoch [7/6], ZINB loss:0.4119, NB loss:11.5784\n",
      "Pretrain epoch [8/6], ZINB loss:0.4041, NB loss:11.7497\n",
      "Pretrain epoch [9/6], ZINB loss:0.4025, NB loss:11.4895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [10/6], ZINB loss:0.4229, NB loss:11.5235\n",
      "Pretrain epoch [11/6], ZINB loss:0.4191, NB loss:11.5939\n",
      "Pretrain epoch [12/6], ZINB loss:0.4123, NB loss:11.5202\n",
      "Pretrain epoch [13/6], ZINB loss:0.4213, NB loss:11.1892\n",
      "Pretrain epoch [14/6], ZINB loss:0.4002, NB loss:11.3524\n",
      "Pretrain epoch [15/6], ZINB loss:0.4062, NB loss:11.1018\n",
      "Pretrain epoch [16/6], ZINB loss:0.4213, NB loss:11.2628\n",
      "Pretrain epoch [17/6], ZINB loss:0.3971, NB loss:10.9121\n",
      "Pretrain epoch [18/6], ZINB loss:0.4123, NB loss:10.7550\n",
      "Pretrain epoch [19/6], ZINB loss:0.4089, NB loss:10.6411\n",
      "Pretrain epoch [20/6], ZINB loss:0.4258, NB loss:10.6300\n",
      "Pretrain epoch [21/6], ZINB loss:0.3789, NB loss:10.8499\n",
      "Pretrain epoch [22/6], ZINB loss:0.4172, NB loss:10.4883\n",
      "Pretrain epoch [23/6], ZINB loss:0.4080, NB loss:10.5355\n",
      "Pretrain epoch [24/6], ZINB loss:0.4435, NB loss:10.8180\n",
      "Pretrain epoch [25/6], ZINB loss:0.3984, NB loss:10.2904\n",
      "Pretrain epoch [26/6], ZINB loss:0.3886, NB loss:10.5180\n",
      "Pretrain epoch [27/6], ZINB loss:0.4086, NB loss:10.8517\n",
      "Pretrain epoch [1/7], ZINB loss:0.3922, NB loss:10.2927\n",
      "Pretrain epoch [2/7], ZINB loss:0.4062, NB loss:10.4427\n",
      "Pretrain epoch [3/7], ZINB loss:0.4151, NB loss:10.2734\n",
      "Pretrain epoch [4/7], ZINB loss:0.3982, NB loss:10.5386\n",
      "Pretrain epoch [5/7], ZINB loss:0.3959, NB loss:10.2423\n",
      "Pretrain epoch [6/7], ZINB loss:0.4118, NB loss:10.1915\n",
      "Pretrain epoch [7/7], ZINB loss:0.3951, NB loss:10.0479\n",
      "Pretrain epoch [8/7], ZINB loss:0.4086, NB loss:9.9889\n",
      "Pretrain epoch [9/7], ZINB loss:0.4022, NB loss:9.9897\n",
      "Pretrain epoch [10/7], ZINB loss:0.4083, NB loss:9.8390\n",
      "Pretrain epoch [11/7], ZINB loss:0.3874, NB loss:9.8131\n",
      "Pretrain epoch [12/7], ZINB loss:0.4119, NB loss:9.6747\n",
      "Pretrain epoch [13/7], ZINB loss:0.4277, NB loss:9.7353\n",
      "Pretrain epoch [14/7], ZINB loss:0.4169, NB loss:9.8932\n",
      "Pretrain epoch [15/7], ZINB loss:0.4022, NB loss:9.7851\n",
      "Pretrain epoch [16/7], ZINB loss:0.4100, NB loss:9.5381\n",
      "Pretrain epoch [17/7], ZINB loss:0.3931, NB loss:9.6673\n",
      "Pretrain epoch [18/7], ZINB loss:0.4248, NB loss:9.5637\n",
      "Pretrain epoch [19/7], ZINB loss:0.4102, NB loss:9.6073\n",
      "Pretrain epoch [20/7], ZINB loss:0.4021, NB loss:9.6304\n",
      "Pretrain epoch [21/7], ZINB loss:0.3976, NB loss:9.6746\n",
      "Pretrain epoch [22/7], ZINB loss:0.3930, NB loss:9.2883\n",
      "Pretrain epoch [23/7], ZINB loss:0.4443, NB loss:9.5614\n",
      "Pretrain epoch [24/7], ZINB loss:0.4202, NB loss:9.4636\n",
      "Pretrain epoch [25/7], ZINB loss:0.3981, NB loss:9.5527\n",
      "Pretrain epoch [26/7], ZINB loss:0.4146, NB loss:9.3276\n",
      "Pretrain epoch [27/7], ZINB loss:0.3825, NB loss:9.2721\n",
      "Pretrain epoch [1/8], ZINB loss:0.3900, NB loss:9.3099\n",
      "Pretrain epoch [2/8], ZINB loss:0.4024, NB loss:9.1013\n",
      "Pretrain epoch [3/8], ZINB loss:0.4229, NB loss:9.3106\n",
      "Pretrain epoch [4/8], ZINB loss:0.4071, NB loss:9.0442\n",
      "Pretrain epoch [5/8], ZINB loss:0.4223, NB loss:9.0696\n",
      "Pretrain epoch [6/8], ZINB loss:0.4260, NB loss:9.1291\n",
      "Pretrain epoch [7/8], ZINB loss:0.3995, NB loss:9.1786\n",
      "Pretrain epoch [8/8], ZINB loss:0.4199, NB loss:9.1944\n",
      "Pretrain epoch [9/8], ZINB loss:0.3999, NB loss:9.0634\n",
      "Pretrain epoch [10/8], ZINB loss:0.3993, NB loss:9.1251\n",
      "Pretrain epoch [11/8], ZINB loss:0.3981, NB loss:8.9054\n",
      "Pretrain epoch [12/8], ZINB loss:0.3968, NB loss:8.9951\n",
      "Pretrain epoch [13/8], ZINB loss:0.4026, NB loss:8.7875\n",
      "Pretrain epoch [14/8], ZINB loss:0.4173, NB loss:8.7888\n",
      "Pretrain epoch [15/8], ZINB loss:0.4133, NB loss:8.9447\n",
      "Pretrain epoch [16/8], ZINB loss:0.4248, NB loss:8.8791\n",
      "Pretrain epoch [17/8], ZINB loss:0.3952, NB loss:8.8771\n",
      "Pretrain epoch [18/8], ZINB loss:0.4046, NB loss:8.8153\n",
      "Pretrain epoch [19/8], ZINB loss:0.4086, NB loss:8.8321\n",
      "Pretrain epoch [20/8], ZINB loss:0.3962, NB loss:8.8407\n",
      "Pretrain epoch [21/8], ZINB loss:0.4069, NB loss:8.7467\n",
      "Pretrain epoch [22/8], ZINB loss:0.4004, NB loss:8.7476\n",
      "Pretrain epoch [23/8], ZINB loss:0.4042, NB loss:8.6200\n",
      "Pretrain epoch [24/8], ZINB loss:0.4050, NB loss:8.6019\n",
      "Pretrain epoch [25/8], ZINB loss:0.4081, NB loss:8.4952\n",
      "Pretrain epoch [26/8], ZINB loss:0.3810, NB loss:8.6267\n",
      "Pretrain epoch [27/8], ZINB loss:0.6398, NB loss:8.1270\n",
      "Pretrain epoch [1/9], ZINB loss:0.3954, NB loss:8.5367\n",
      "Pretrain epoch [2/9], ZINB loss:0.4202, NB loss:8.8177\n",
      "Pretrain epoch [3/9], ZINB loss:0.4156, NB loss:8.5193\n",
      "Pretrain epoch [4/9], ZINB loss:0.4191, NB loss:8.4224\n",
      "Pretrain epoch [5/9], ZINB loss:0.4473, NB loss:8.3813\n",
      "Pretrain epoch [6/9], ZINB loss:0.4146, NB loss:8.3566\n",
      "Pretrain epoch [7/9], ZINB loss:0.4059, NB loss:8.4258\n",
      "Pretrain epoch [8/9], ZINB loss:0.4065, NB loss:8.4509\n",
      "Pretrain epoch [9/9], ZINB loss:0.4201, NB loss:8.3936\n",
      "Pretrain epoch [10/9], ZINB loss:0.3956, NB loss:8.4600\n",
      "Pretrain epoch [11/9], ZINB loss:0.4067, NB loss:8.2584\n",
      "Pretrain epoch [12/9], ZINB loss:0.4081, NB loss:8.3095\n",
      "Pretrain epoch [13/9], ZINB loss:0.4247, NB loss:8.2458\n",
      "Pretrain epoch [14/9], ZINB loss:0.4058, NB loss:8.2737\n",
      "Pretrain epoch [15/9], ZINB loss:0.4164, NB loss:8.3232\n",
      "Pretrain epoch [16/9], ZINB loss:0.4162, NB loss:8.2564\n",
      "Pretrain epoch [17/9], ZINB loss:0.4202, NB loss:8.2017\n",
      "Pretrain epoch [18/9], ZINB loss:0.3968, NB loss:8.1068\n",
      "Pretrain epoch [19/9], ZINB loss:0.4037, NB loss:8.2136\n",
      "Pretrain epoch [20/9], ZINB loss:0.4004, NB loss:8.1370\n",
      "Pretrain epoch [21/9], ZINB loss:0.4108, NB loss:8.1953\n",
      "Pretrain epoch [22/9], ZINB loss:0.4032, NB loss:8.1223\n",
      "Pretrain epoch [23/9], ZINB loss:0.3926, NB loss:8.0779\n",
      "Pretrain epoch [24/9], ZINB loss:0.3971, NB loss:8.1214\n",
      "Pretrain epoch [25/9], ZINB loss:0.4148, NB loss:8.0724\n",
      "Pretrain epoch [26/9], ZINB loss:0.4096, NB loss:8.0298\n",
      "Pretrain epoch [27/9], ZINB loss:0.3553, NB loss:8.8517\n",
      "Pretrain epoch [1/10], ZINB loss:0.3958, NB loss:8.0276\n",
      "Pretrain epoch [2/10], ZINB loss:0.4268, NB loss:7.9653\n",
      "Pretrain epoch [3/10], ZINB loss:0.3874, NB loss:7.9436\n",
      "Pretrain epoch [4/10], ZINB loss:0.3944, NB loss:7.9765\n",
      "Pretrain epoch [5/10], ZINB loss:0.4203, NB loss:8.0133\n",
      "Pretrain epoch [6/10], ZINB loss:0.4050, NB loss:7.9484\n",
      "Pretrain epoch [7/10], ZINB loss:0.4205, NB loss:7.9291\n",
      "Pretrain epoch [8/10], ZINB loss:0.4111, NB loss:7.8816\n",
      "Pretrain epoch [9/10], ZINB loss:0.4224, NB loss:7.9757\n",
      "Pretrain epoch [10/10], ZINB loss:0.4162, NB loss:7.9288\n",
      "Pretrain epoch [11/10], ZINB loss:0.3847, NB loss:7.8841\n",
      "Pretrain epoch [12/10], ZINB loss:0.3971, NB loss:7.8294\n",
      "Pretrain epoch [13/10], ZINB loss:0.4066, NB loss:7.8703\n",
      "Pretrain epoch [14/10], ZINB loss:0.4033, NB loss:7.9019\n",
      "Pretrain epoch [15/10], ZINB loss:0.3866, NB loss:7.8235\n",
      "Pretrain epoch [16/10], ZINB loss:0.4100, NB loss:7.7892\n",
      "Pretrain epoch [17/10], ZINB loss:0.3902, NB loss:7.7973\n",
      "Pretrain epoch [18/10], ZINB loss:0.4058, NB loss:7.7714\n",
      "Pretrain epoch [19/10], ZINB loss:0.3984, NB loss:7.7696\n",
      "Pretrain epoch [20/10], ZINB loss:0.3935, NB loss:7.7032\n",
      "Pretrain epoch [21/10], ZINB loss:0.4061, NB loss:7.8025\n",
      "Pretrain epoch [22/10], ZINB loss:0.4210, NB loss:7.7271\n",
      "Pretrain epoch [23/10], ZINB loss:0.4106, NB loss:7.6409\n",
      "Pretrain epoch [24/10], ZINB loss:0.4064, NB loss:7.7514\n",
      "Pretrain epoch [25/10], ZINB loss:0.3996, NB loss:7.6709\n",
      "Pretrain epoch [26/10], ZINB loss:0.4042, NB loss:7.6793\n",
      "Pretrain epoch [27/10], ZINB loss:0.4970, NB loss:7.9509\n",
      "Pretrain epoch [1/11], ZINB loss:0.4082, NB loss:7.6293\n",
      "Pretrain epoch [2/11], ZINB loss:0.4117, NB loss:7.6731\n",
      "Pretrain epoch [3/11], ZINB loss:0.4133, NB loss:7.6438\n",
      "Pretrain epoch [4/11], ZINB loss:0.4044, NB loss:7.6484\n",
      "Pretrain epoch [5/11], ZINB loss:0.4024, NB loss:7.5866\n",
      "Pretrain epoch [6/11], ZINB loss:0.4167, NB loss:7.5546\n",
      "Pretrain epoch [7/11], ZINB loss:0.4167, NB loss:7.6452\n",
      "Pretrain epoch [8/11], ZINB loss:0.3974, NB loss:7.5503\n",
      "Pretrain epoch [9/11], ZINB loss:0.3933, NB loss:7.5198\n",
      "Pretrain epoch [10/11], ZINB loss:0.4152, NB loss:7.5736\n",
      "Pretrain epoch [11/11], ZINB loss:0.4022, NB loss:7.4966\n",
      "Pretrain epoch [12/11], ZINB loss:0.3990, NB loss:7.5380\n",
      "Pretrain epoch [13/11], ZINB loss:0.3757, NB loss:7.5003\n",
      "Pretrain epoch [14/11], ZINB loss:0.4073, NB loss:7.5412\n",
      "Pretrain epoch [15/11], ZINB loss:0.3978, NB loss:7.4462\n",
      "Pretrain epoch [16/11], ZINB loss:0.3984, NB loss:7.4889\n",
      "Pretrain epoch [17/11], ZINB loss:0.4040, NB loss:7.4201\n",
      "Pretrain epoch [18/11], ZINB loss:0.4124, NB loss:7.4930\n",
      "Pretrain epoch [19/11], ZINB loss:0.4000, NB loss:7.4803\n",
      "Pretrain epoch [20/11], ZINB loss:0.4023, NB loss:7.5435\n",
      "Pretrain epoch [21/11], ZINB loss:0.4087, NB loss:7.3880\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [22/11], ZINB loss:0.4008, NB loss:7.4223\n",
      "Pretrain epoch [23/11], ZINB loss:0.4104, NB loss:7.4230\n",
      "Pretrain epoch [24/11], ZINB loss:0.3976, NB loss:7.3854\n",
      "Pretrain epoch [25/11], ZINB loss:0.3898, NB loss:7.3617\n",
      "Pretrain epoch [26/11], ZINB loss:0.4104, NB loss:7.3753\n",
      "Pretrain epoch [27/11], ZINB loss:0.4379, NB loss:7.7270\n",
      "Pretrain epoch [1/12], ZINB loss:0.4142, NB loss:7.2982\n",
      "Pretrain epoch [2/12], ZINB loss:0.4221, NB loss:7.3532\n",
      "Pretrain epoch [3/12], ZINB loss:0.3929, NB loss:7.3227\n",
      "Pretrain epoch [4/12], ZINB loss:0.4079, NB loss:7.2940\n",
      "Pretrain epoch [5/12], ZINB loss:0.4028, NB loss:7.3548\n",
      "Pretrain epoch [6/12], ZINB loss:0.3911, NB loss:7.3018\n",
      "Pretrain epoch [7/12], ZINB loss:0.4070, NB loss:7.3199\n",
      "Pretrain epoch [8/12], ZINB loss:0.3897, NB loss:7.3123\n",
      "Pretrain epoch [9/12], ZINB loss:0.4108, NB loss:7.3426\n",
      "Pretrain epoch [10/12], ZINB loss:0.3879, NB loss:7.2869\n",
      "Pretrain epoch [11/12], ZINB loss:0.4183, NB loss:7.3355\n",
      "Pretrain epoch [12/12], ZINB loss:0.3913, NB loss:7.2686\n",
      "Pretrain epoch [13/12], ZINB loss:0.3930, NB loss:7.2691\n",
      "Pretrain epoch [14/12], ZINB loss:0.4211, NB loss:7.2799\n",
      "Pretrain epoch [15/12], ZINB loss:0.4002, NB loss:7.3089\n",
      "Pretrain epoch [16/12], ZINB loss:0.3877, NB loss:7.2832\n",
      "Pretrain epoch [17/12], ZINB loss:0.4063, NB loss:7.1942\n",
      "Pretrain epoch [18/12], ZINB loss:0.4139, NB loss:7.1679\n",
      "Pretrain epoch [19/12], ZINB loss:0.4137, NB loss:7.2117\n",
      "Pretrain epoch [20/12], ZINB loss:0.3772, NB loss:7.2176\n",
      "Pretrain epoch [21/12], ZINB loss:0.4176, NB loss:7.1951\n",
      "Pretrain epoch [22/12], ZINB loss:0.4081, NB loss:7.1798\n",
      "Pretrain epoch [23/12], ZINB loss:0.3974, NB loss:7.2014\n",
      "Pretrain epoch [24/12], ZINB loss:0.3920, NB loss:7.1672\n",
      "Pretrain epoch [25/12], ZINB loss:0.4145, NB loss:7.1431\n",
      "Pretrain epoch [26/12], ZINB loss:0.3887, NB loss:7.1785\n",
      "Pretrain epoch [27/12], ZINB loss:0.4878, NB loss:7.0562\n",
      "Pretrain epoch [1/13], ZINB loss:0.3939, NB loss:7.1499\n",
      "Pretrain epoch [2/13], ZINB loss:0.3804, NB loss:7.1100\n",
      "Pretrain epoch [3/13], ZINB loss:0.3852, NB loss:7.1249\n",
      "Pretrain epoch [4/13], ZINB loss:0.4001, NB loss:7.1364\n",
      "Pretrain epoch [5/13], ZINB loss:0.4006, NB loss:7.0833\n",
      "Pretrain epoch [6/13], ZINB loss:0.3886, NB loss:7.0986\n",
      "Pretrain epoch [7/13], ZINB loss:0.3999, NB loss:7.1565\n",
      "Pretrain epoch [8/13], ZINB loss:0.4058, NB loss:7.1235\n",
      "Pretrain epoch [9/13], ZINB loss:0.3957, NB loss:7.1097\n",
      "Pretrain epoch [10/13], ZINB loss:0.4300, NB loss:7.1703\n",
      "Pretrain epoch [11/13], ZINB loss:0.4120, NB loss:7.0719\n",
      "Pretrain epoch [12/13], ZINB loss:0.4122, NB loss:7.0663\n",
      "Pretrain epoch [13/13], ZINB loss:0.4030, NB loss:7.0870\n",
      "Pretrain epoch [14/13], ZINB loss:0.4159, NB loss:7.0420\n",
      "Pretrain epoch [15/13], ZINB loss:0.4000, NB loss:7.0370\n",
      "Pretrain epoch [16/13], ZINB loss:0.4160, NB loss:7.0066\n",
      "Pretrain epoch [17/13], ZINB loss:0.3894, NB loss:6.9689\n",
      "Pretrain epoch [18/13], ZINB loss:0.4151, NB loss:7.0227\n",
      "Pretrain epoch [19/13], ZINB loss:0.4065, NB loss:7.0331\n",
      "Pretrain epoch [20/13], ZINB loss:0.4045, NB loss:7.0251\n",
      "Pretrain epoch [21/13], ZINB loss:0.4016, NB loss:7.0921\n",
      "Pretrain epoch [22/13], ZINB loss:0.4086, NB loss:6.9833\n",
      "Pretrain epoch [23/13], ZINB loss:0.3981, NB loss:7.0399\n",
      "Pretrain epoch [24/13], ZINB loss:0.4159, NB loss:7.0230\n",
      "Pretrain epoch [25/13], ZINB loss:0.4124, NB loss:6.9961\n",
      "Pretrain epoch [26/13], ZINB loss:0.3915, NB loss:7.0164\n",
      "Pretrain epoch [27/13], ZINB loss:0.3275, NB loss:6.7617\n",
      "Pretrain epoch [1/14], ZINB loss:0.4007, NB loss:7.0369\n",
      "Pretrain epoch [2/14], ZINB loss:0.4073, NB loss:6.9869\n",
      "Pretrain epoch [3/14], ZINB loss:0.4008, NB loss:6.9707\n",
      "Pretrain epoch [4/14], ZINB loss:0.3902, NB loss:6.9488\n",
      "Pretrain epoch [5/14], ZINB loss:0.4096, NB loss:7.0254\n",
      "Pretrain epoch [6/14], ZINB loss:0.4153, NB loss:6.9561\n",
      "Pretrain epoch [7/14], ZINB loss:0.3904, NB loss:6.8958\n",
      "Pretrain epoch [8/14], ZINB loss:0.4171, NB loss:6.9501\n",
      "Pretrain epoch [9/14], ZINB loss:0.4032, NB loss:6.9445\n",
      "Pretrain epoch [10/14], ZINB loss:0.3968, NB loss:6.8917\n",
      "Pretrain epoch [11/14], ZINB loss:0.4013, NB loss:6.9096\n",
      "Pretrain epoch [12/14], ZINB loss:0.3957, NB loss:6.8791\n",
      "Pretrain epoch [13/14], ZINB loss:0.4103, NB loss:6.9100\n",
      "Pretrain epoch [14/14], ZINB loss:0.3754, NB loss:6.8587\n",
      "Pretrain epoch [15/14], ZINB loss:0.3847, NB loss:6.9296\n",
      "Pretrain epoch [16/14], ZINB loss:0.4042, NB loss:6.9426\n",
      "Pretrain epoch [17/14], ZINB loss:0.4104, NB loss:6.8947\n",
      "Pretrain epoch [18/14], ZINB loss:0.4042, NB loss:6.9306\n",
      "Pretrain epoch [19/14], ZINB loss:0.3818, NB loss:6.8248\n",
      "Pretrain epoch [20/14], ZINB loss:0.3959, NB loss:6.8885\n",
      "Pretrain epoch [21/14], ZINB loss:0.4090, NB loss:6.8714\n",
      "Pretrain epoch [22/14], ZINB loss:0.4081, NB loss:6.9083\n",
      "Pretrain epoch [23/14], ZINB loss:0.3942, NB loss:6.8913\n",
      "Pretrain epoch [24/14], ZINB loss:0.4117, NB loss:6.8568\n",
      "Pretrain epoch [25/14], ZINB loss:0.4161, NB loss:6.8440\n",
      "Pretrain epoch [26/14], ZINB loss:0.4032, NB loss:6.8483\n",
      "Pretrain epoch [27/14], ZINB loss:0.2754, NB loss:6.6752\n",
      "Pretrain epoch [1/15], ZINB loss:0.4164, NB loss:6.8362\n",
      "Pretrain epoch [2/15], ZINB loss:0.3971, NB loss:6.8263\n",
      "Pretrain epoch [3/15], ZINB loss:0.4002, NB loss:6.8133\n",
      "Pretrain epoch [4/15], ZINB loss:0.3983, NB loss:6.8508\n",
      "Pretrain epoch [5/15], ZINB loss:0.3859, NB loss:6.8240\n",
      "Pretrain epoch [6/15], ZINB loss:0.4059, NB loss:6.8096\n",
      "Pretrain epoch [7/15], ZINB loss:0.4114, NB loss:6.8423\n",
      "Pretrain epoch [8/15], ZINB loss:0.4016, NB loss:6.8437\n",
      "Pretrain epoch [9/15], ZINB loss:0.3997, NB loss:6.7682\n",
      "Pretrain epoch [10/15], ZINB loss:0.3807, NB loss:6.7824\n",
      "Pretrain epoch [11/15], ZINB loss:0.3973, NB loss:6.7834\n",
      "Pretrain epoch [12/15], ZINB loss:0.3974, NB loss:6.8332\n",
      "Pretrain epoch [13/15], ZINB loss:0.3777, NB loss:6.8378\n",
      "Pretrain epoch [14/15], ZINB loss:0.3928, NB loss:6.8087\n",
      "Pretrain epoch [15/15], ZINB loss:0.3982, NB loss:6.7994\n",
      "Pretrain epoch [16/15], ZINB loss:0.3990, NB loss:6.7836\n",
      "Pretrain epoch [17/15], ZINB loss:0.4341, NB loss:6.7769\n",
      "Pretrain epoch [18/15], ZINB loss:0.4027, NB loss:6.8039\n",
      "Pretrain epoch [19/15], ZINB loss:0.3974, NB loss:6.7441\n",
      "Pretrain epoch [20/15], ZINB loss:0.4003, NB loss:6.7743\n",
      "Pretrain epoch [21/15], ZINB loss:0.4027, NB loss:6.7325\n",
      "Pretrain epoch [22/15], ZINB loss:0.4075, NB loss:6.7303\n",
      "Pretrain epoch [23/15], ZINB loss:0.3871, NB loss:6.7342\n",
      "Pretrain epoch [24/15], ZINB loss:0.3888, NB loss:6.7653\n",
      "Pretrain epoch [25/15], ZINB loss:0.4188, NB loss:6.7075\n",
      "Pretrain epoch [26/15], ZINB loss:0.4024, NB loss:6.7491\n",
      "Pretrain epoch [27/15], ZINB loss:0.3542, NB loss:6.8711\n",
      "Pretrain epoch [1/16], ZINB loss:0.3868, NB loss:6.7510\n",
      "Pretrain epoch [2/16], ZINB loss:0.3998, NB loss:6.7201\n",
      "Pretrain epoch [3/16], ZINB loss:0.3988, NB loss:6.7649\n",
      "Pretrain epoch [4/16], ZINB loss:0.3870, NB loss:6.7104\n",
      "Pretrain epoch [5/16], ZINB loss:0.4067, NB loss:6.7013\n",
      "Pretrain epoch [6/16], ZINB loss:0.4069, NB loss:6.7221\n",
      "Pretrain epoch [7/16], ZINB loss:0.4086, NB loss:6.6651\n",
      "Pretrain epoch [8/16], ZINB loss:0.4031, NB loss:6.7234\n",
      "Pretrain epoch [9/16], ZINB loss:0.4115, NB loss:6.6800\n",
      "Pretrain epoch [10/16], ZINB loss:0.4029, NB loss:6.6894\n",
      "Pretrain epoch [11/16], ZINB loss:0.3954, NB loss:6.6907\n",
      "Pretrain epoch [12/16], ZINB loss:0.4049, NB loss:6.7329\n",
      "Pretrain epoch [13/16], ZINB loss:0.3915, NB loss:6.6838\n",
      "Pretrain epoch [14/16], ZINB loss:0.4102, NB loss:6.6680\n",
      "Pretrain epoch [15/16], ZINB loss:0.3874, NB loss:6.6863\n",
      "Pretrain epoch [16/16], ZINB loss:0.4131, NB loss:6.7170\n",
      "Pretrain epoch [17/16], ZINB loss:0.3974, NB loss:6.6980\n",
      "Pretrain epoch [18/16], ZINB loss:0.4114, NB loss:6.6331\n",
      "Pretrain epoch [19/16], ZINB loss:0.3778, NB loss:6.6509\n",
      "Pretrain epoch [20/16], ZINB loss:0.3922, NB loss:6.6746\n",
      "Pretrain epoch [21/16], ZINB loss:0.3979, NB loss:6.6856\n",
      "Pretrain epoch [22/16], ZINB loss:0.4102, NB loss:6.6216\n",
      "Pretrain epoch [23/16], ZINB loss:0.4041, NB loss:6.6707\n",
      "Pretrain epoch [24/16], ZINB loss:0.3685, NB loss:6.6534\n",
      "Pretrain epoch [25/16], ZINB loss:0.4097, NB loss:6.6622\n",
      "Pretrain epoch [26/16], ZINB loss:0.4045, NB loss:6.6133\n",
      "Pretrain epoch [27/16], ZINB loss:0.3724, NB loss:6.8095\n",
      "Pretrain epoch [1/17], ZINB loss:0.3998, NB loss:6.6435\n",
      "Pretrain epoch [2/17], ZINB loss:0.3949, NB loss:6.6703\n",
      "Pretrain epoch [3/17], ZINB loss:0.3963, NB loss:6.6615\n",
      "Pretrain epoch [4/17], ZINB loss:0.4112, NB loss:6.5838\n",
      "Pretrain epoch [5/17], ZINB loss:0.4010, NB loss:6.6036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [6/17], ZINB loss:0.3877, NB loss:6.6217\n",
      "Pretrain epoch [7/17], ZINB loss:0.4047, NB loss:6.5931\n",
      "Pretrain epoch [8/17], ZINB loss:0.3960, NB loss:6.6003\n",
      "Pretrain epoch [9/17], ZINB loss:0.3904, NB loss:6.6170\n",
      "Pretrain epoch [10/17], ZINB loss:0.4088, NB loss:6.6186\n",
      "Pretrain epoch [11/17], ZINB loss:0.3899, NB loss:6.5849\n",
      "Pretrain epoch [12/17], ZINB loss:0.4095, NB loss:6.6228\n",
      "Pretrain epoch [13/17], ZINB loss:0.3783, NB loss:6.5799\n",
      "Pretrain epoch [14/17], ZINB loss:0.4109, NB loss:6.6175\n",
      "Pretrain epoch [15/17], ZINB loss:0.4005, NB loss:6.5944\n",
      "Pretrain epoch [16/17], ZINB loss:0.4013, NB loss:6.5919\n",
      "Pretrain epoch [17/17], ZINB loss:0.3848, NB loss:6.5743\n",
      "Pretrain epoch [18/17], ZINB loss:0.4195, NB loss:6.6341\n",
      "Pretrain epoch [19/17], ZINB loss:0.4056, NB loss:6.5652\n",
      "Pretrain epoch [20/17], ZINB loss:0.4017, NB loss:6.5480\n",
      "Pretrain epoch [21/17], ZINB loss:0.4113, NB loss:6.5292\n",
      "Pretrain epoch [22/17], ZINB loss:0.3907, NB loss:6.6087\n",
      "Pretrain epoch [23/17], ZINB loss:0.4215, NB loss:6.6009\n",
      "Pretrain epoch [24/17], ZINB loss:0.3699, NB loss:6.5416\n",
      "Pretrain epoch [25/17], ZINB loss:0.4015, NB loss:6.5916\n",
      "Pretrain epoch [26/17], ZINB loss:0.4078, NB loss:6.5872\n",
      "Pretrain epoch [27/17], ZINB loss:0.2464, NB loss:6.5788\n",
      "Pretrain epoch [1/18], ZINB loss:0.3989, NB loss:6.5672\n",
      "Pretrain epoch [2/18], ZINB loss:0.3967, NB loss:6.5776\n",
      "Pretrain epoch [3/18], ZINB loss:0.4083, NB loss:6.5803\n",
      "Pretrain epoch [4/18], ZINB loss:0.4118, NB loss:6.5854\n",
      "Pretrain epoch [5/18], ZINB loss:0.3868, NB loss:6.5352\n",
      "Pretrain epoch [6/18], ZINB loss:0.3896, NB loss:6.5326\n",
      "Pretrain epoch [7/18], ZINB loss:0.4051, NB loss:6.5835\n",
      "Pretrain epoch [8/18], ZINB loss:0.4140, NB loss:6.5376\n",
      "Pretrain epoch [9/18], ZINB loss:0.3914, NB loss:6.5035\n",
      "Pretrain epoch [10/18], ZINB loss:0.3975, NB loss:6.5393\n",
      "Pretrain epoch [11/18], ZINB loss:0.3895, NB loss:6.5137\n",
      "Pretrain epoch [12/18], ZINB loss:0.4071, NB loss:6.5436\n",
      "Pretrain epoch [13/18], ZINB loss:0.4068, NB loss:6.5298\n",
      "Pretrain epoch [14/18], ZINB loss:0.3949, NB loss:6.4926\n",
      "Pretrain epoch [15/18], ZINB loss:0.4086, NB loss:6.5493\n",
      "Pretrain epoch [16/18], ZINB loss:0.3867, NB loss:6.5209\n",
      "Pretrain epoch [17/18], ZINB loss:0.3982, NB loss:6.5451\n",
      "Pretrain epoch [18/18], ZINB loss:0.4027, NB loss:6.4914\n",
      "Pretrain epoch [19/18], ZINB loss:0.4041, NB loss:6.4834\n",
      "Pretrain epoch [20/18], ZINB loss:0.3965, NB loss:6.4744\n",
      "Pretrain epoch [21/18], ZINB loss:0.3827, NB loss:6.4745\n",
      "Pretrain epoch [22/18], ZINB loss:0.4018, NB loss:6.4939\n",
      "Pretrain epoch [23/18], ZINB loss:0.3813, NB loss:6.5181\n",
      "Pretrain epoch [24/18], ZINB loss:0.3742, NB loss:6.4534\n",
      "Pretrain epoch [25/18], ZINB loss:0.4193, NB loss:6.4766\n",
      "Pretrain epoch [26/18], ZINB loss:0.4107, NB loss:6.4972\n",
      "Pretrain epoch [27/18], ZINB loss:0.4575, NB loss:6.3700\n",
      "Pretrain epoch [1/19], ZINB loss:0.3984, NB loss:6.4454\n",
      "Pretrain epoch [2/19], ZINB loss:0.4025, NB loss:6.4520\n",
      "Pretrain epoch [3/19], ZINB loss:0.3987, NB loss:6.5003\n",
      "Pretrain epoch [4/19], ZINB loss:0.3972, NB loss:6.4482\n",
      "Pretrain epoch [5/19], ZINB loss:0.3997, NB loss:6.5203\n",
      "Pretrain epoch [6/19], ZINB loss:0.4003, NB loss:6.4553\n",
      "Pretrain epoch [7/19], ZINB loss:0.3968, NB loss:6.4755\n",
      "Pretrain epoch [8/19], ZINB loss:0.4030, NB loss:6.4887\n",
      "Pretrain epoch [9/19], ZINB loss:0.3948, NB loss:6.4587\n",
      "Pretrain epoch [10/19], ZINB loss:0.4027, NB loss:6.4455\n",
      "Pretrain epoch [11/19], ZINB loss:0.3671, NB loss:6.4182\n",
      "Pretrain epoch [12/19], ZINB loss:0.4119, NB loss:6.4479\n",
      "Pretrain epoch [13/19], ZINB loss:0.4132, NB loss:6.4578\n",
      "Pretrain epoch [14/19], ZINB loss:0.4037, NB loss:6.4326\n",
      "Pretrain epoch [15/19], ZINB loss:0.3783, NB loss:6.4533\n",
      "Pretrain epoch [16/19], ZINB loss:0.4025, NB loss:6.4630\n",
      "Pretrain epoch [17/19], ZINB loss:0.4133, NB loss:6.4534\n",
      "Pretrain epoch [18/19], ZINB loss:0.3976, NB loss:6.4285\n",
      "Pretrain epoch [19/19], ZINB loss:0.3998, NB loss:6.4446\n",
      "Pretrain epoch [20/19], ZINB loss:0.3986, NB loss:6.5325\n",
      "Pretrain epoch [21/19], ZINB loss:0.4042, NB loss:6.4280\n",
      "Pretrain epoch [22/19], ZINB loss:0.4031, NB loss:6.4160\n",
      "Pretrain epoch [23/19], ZINB loss:0.3986, NB loss:6.4411\n",
      "Pretrain epoch [24/19], ZINB loss:0.3905, NB loss:6.4198\n",
      "Pretrain epoch [25/19], ZINB loss:0.4033, NB loss:6.4947\n",
      "Pretrain epoch [26/19], ZINB loss:0.3985, NB loss:6.4316\n",
      "Pretrain epoch [27/19], ZINB loss:0.3363, NB loss:6.4142\n",
      "Pretrain epoch [1/20], ZINB loss:0.3924, NB loss:6.4103\n",
      "Pretrain epoch [2/20], ZINB loss:0.3803, NB loss:6.3926\n",
      "Pretrain epoch [3/20], ZINB loss:0.3948, NB loss:6.4113\n",
      "Pretrain epoch [4/20], ZINB loss:0.3919, NB loss:6.3443\n",
      "Pretrain epoch [5/20], ZINB loss:0.4018, NB loss:6.4610\n",
      "Pretrain epoch [6/20], ZINB loss:0.3899, NB loss:6.4271\n",
      "Pretrain epoch [7/20], ZINB loss:0.3764, NB loss:6.4549\n",
      "Pretrain epoch [8/20], ZINB loss:0.4083, NB loss:6.4125\n",
      "Pretrain epoch [9/20], ZINB loss:0.3984, NB loss:6.3937\n",
      "Pretrain epoch [10/20], ZINB loss:0.4037, NB loss:6.3471\n",
      "Pretrain epoch [11/20], ZINB loss:0.4142, NB loss:6.3987\n",
      "Pretrain epoch [12/20], ZINB loss:0.4181, NB loss:6.4457\n",
      "Pretrain epoch [13/20], ZINB loss:0.3928, NB loss:6.4333\n",
      "Pretrain epoch [14/20], ZINB loss:0.4026, NB loss:6.3795\n",
      "Pretrain epoch [15/20], ZINB loss:0.3981, NB loss:6.3635\n",
      "Pretrain epoch [16/20], ZINB loss:0.3927, NB loss:6.3598\n",
      "Pretrain epoch [17/20], ZINB loss:0.3952, NB loss:6.4300\n",
      "Pretrain epoch [18/20], ZINB loss:0.3982, NB loss:6.4298\n",
      "Pretrain epoch [19/20], ZINB loss:0.3958, NB loss:6.3743\n",
      "Pretrain epoch [20/20], ZINB loss:0.4004, NB loss:6.3545\n",
      "Pretrain epoch [21/20], ZINB loss:0.3773, NB loss:6.4089\n",
      "Pretrain epoch [22/20], ZINB loss:0.4045, NB loss:6.3537\n",
      "Pretrain epoch [23/20], ZINB loss:0.4090, NB loss:6.3795\n",
      "Pretrain epoch [24/20], ZINB loss:0.4068, NB loss:6.4190\n",
      "Pretrain epoch [25/20], ZINB loss:0.4314, NB loss:6.3548\n",
      "Pretrain epoch [26/20], ZINB loss:0.3921, NB loss:6.3616\n",
      "Pretrain epoch [27/20], ZINB loss:0.4478, NB loss:6.3022\n",
      "Pretrain epoch [1/21], ZINB loss:0.3989, NB loss:6.4081\n",
      "Pretrain epoch [2/21], ZINB loss:0.3914, NB loss:6.3064\n",
      "Pretrain epoch [3/21], ZINB loss:0.4298, NB loss:6.4152\n",
      "Pretrain epoch [4/21], ZINB loss:0.3976, NB loss:6.3357\n",
      "Pretrain epoch [5/21], ZINB loss:0.3976, NB loss:6.3576\n",
      "Pretrain epoch [6/21], ZINB loss:0.3959, NB loss:6.3447\n",
      "Pretrain epoch [7/21], ZINB loss:0.3929, NB loss:6.3611\n",
      "Pretrain epoch [8/21], ZINB loss:0.4089, NB loss:6.3809\n",
      "Pretrain epoch [9/21], ZINB loss:0.3952, NB loss:6.4082\n",
      "Pretrain epoch [10/21], ZINB loss:0.3971, NB loss:6.2940\n",
      "Pretrain epoch [11/21], ZINB loss:0.3879, NB loss:6.3545\n",
      "Pretrain epoch [12/21], ZINB loss:0.3825, NB loss:6.3792\n",
      "Pretrain epoch [13/21], ZINB loss:0.3868, NB loss:6.3265\n",
      "Pretrain epoch [14/21], ZINB loss:0.4030, NB loss:6.3482\n",
      "Pretrain epoch [15/21], ZINB loss:0.3803, NB loss:6.3653\n",
      "Pretrain epoch [16/21], ZINB loss:0.4014, NB loss:6.3327\n",
      "Pretrain epoch [17/21], ZINB loss:0.4114, NB loss:6.3405\n",
      "Pretrain epoch [18/21], ZINB loss:0.4015, NB loss:6.3193\n",
      "Pretrain epoch [19/21], ZINB loss:0.4072, NB loss:6.3336\n",
      "Pretrain epoch [20/21], ZINB loss:0.4082, NB loss:6.3140\n",
      "Pretrain epoch [21/21], ZINB loss:0.3983, NB loss:6.2919\n",
      "Pretrain epoch [22/21], ZINB loss:0.3957, NB loss:6.3692\n",
      "Pretrain epoch [23/21], ZINB loss:0.3884, NB loss:6.2997\n",
      "Pretrain epoch [24/21], ZINB loss:0.4057, NB loss:6.3375\n",
      "Pretrain epoch [25/21], ZINB loss:0.4043, NB loss:6.2968\n",
      "Pretrain epoch [26/21], ZINB loss:0.4068, NB loss:6.2889\n",
      "Pretrain epoch [27/21], ZINB loss:0.3328, NB loss:6.0539\n",
      "Pretrain epoch [1/22], ZINB loss:0.4170, NB loss:6.3107\n",
      "Pretrain epoch [2/22], ZINB loss:0.3888, NB loss:6.2843\n",
      "Pretrain epoch [3/22], ZINB loss:0.4012, NB loss:6.3006\n",
      "Pretrain epoch [4/22], ZINB loss:0.3980, NB loss:6.2798\n",
      "Pretrain epoch [5/22], ZINB loss:0.3929, NB loss:6.2796\n",
      "Pretrain epoch [6/22], ZINB loss:0.3867, NB loss:6.3390\n",
      "Pretrain epoch [7/22], ZINB loss:0.3886, NB loss:6.2873\n",
      "Pretrain epoch [8/22], ZINB loss:0.4075, NB loss:6.3159\n",
      "Pretrain epoch [9/22], ZINB loss:0.3878, NB loss:6.2950\n",
      "Pretrain epoch [10/22], ZINB loss:0.4018, NB loss:6.3259\n",
      "Pretrain epoch [11/22], ZINB loss:0.3942, NB loss:6.3224\n",
      "Pretrain epoch [12/22], ZINB loss:0.4069, NB loss:6.3653\n",
      "Pretrain epoch [13/22], ZINB loss:0.3951, NB loss:6.3233\n",
      "Pretrain epoch [14/22], ZINB loss:0.3879, NB loss:6.2573\n",
      "Pretrain epoch [15/22], ZINB loss:0.3958, NB loss:6.2640\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [16/22], ZINB loss:0.3976, NB loss:6.2902\n",
      "Pretrain epoch [17/22], ZINB loss:0.3969, NB loss:6.2999\n",
      "Pretrain epoch [18/22], ZINB loss:0.4102, NB loss:6.2948\n",
      "Pretrain epoch [19/22], ZINB loss:0.3839, NB loss:6.3357\n",
      "Pretrain epoch [20/22], ZINB loss:0.3993, NB loss:6.2622\n",
      "Pretrain epoch [21/22], ZINB loss:0.4110, NB loss:6.2831\n",
      "Pretrain epoch [22/22], ZINB loss:0.4075, NB loss:6.2900\n",
      "Pretrain epoch [23/22], ZINB loss:0.4030, NB loss:6.2727\n",
      "Pretrain epoch [24/22], ZINB loss:0.3958, NB loss:6.2472\n",
      "Pretrain epoch [25/22], ZINB loss:0.3978, NB loss:6.2772\n",
      "Pretrain epoch [26/22], ZINB loss:0.3860, NB loss:6.2362\n",
      "Pretrain epoch [27/22], ZINB loss:0.3093, NB loss:6.5036\n",
      "Pretrain epoch [1/23], ZINB loss:0.3908, NB loss:6.2844\n",
      "Pretrain epoch [2/23], ZINB loss:0.3862, NB loss:6.2527\n",
      "Pretrain epoch [3/23], ZINB loss:0.4026, NB loss:6.3013\n",
      "Pretrain epoch [4/23], ZINB loss:0.3999, NB loss:6.2755\n",
      "Pretrain epoch [5/23], ZINB loss:0.4022, NB loss:6.2317\n",
      "Pretrain epoch [6/23], ZINB loss:0.3889, NB loss:6.2451\n",
      "Pretrain epoch [7/23], ZINB loss:0.4055, NB loss:6.2401\n",
      "Pretrain epoch [8/23], ZINB loss:0.3923, NB loss:6.3685\n",
      "Pretrain epoch [9/23], ZINB loss:0.3997, NB loss:6.2543\n",
      "Pretrain epoch [10/23], ZINB loss:0.4003, NB loss:6.2098\n",
      "Pretrain epoch [11/23], ZINB loss:0.3932, NB loss:6.2331\n",
      "Pretrain epoch [12/23], ZINB loss:0.4075, NB loss:6.2406\n",
      "Pretrain epoch [13/23], ZINB loss:0.3932, NB loss:6.2476\n",
      "Pretrain epoch [14/23], ZINB loss:0.3867, NB loss:6.2398\n",
      "Pretrain epoch [15/23], ZINB loss:0.3974, NB loss:6.2568\n",
      "Pretrain epoch [16/23], ZINB loss:0.4010, NB loss:6.2385\n",
      "Pretrain epoch [17/23], ZINB loss:0.4050, NB loss:6.2454\n",
      "Pretrain epoch [18/23], ZINB loss:0.4220, NB loss:6.2219\n",
      "Pretrain epoch [19/23], ZINB loss:0.4068, NB loss:6.2518\n",
      "Pretrain epoch [20/23], ZINB loss:0.3852, NB loss:6.2542\n",
      "Pretrain epoch [21/23], ZINB loss:0.4009, NB loss:6.2076\n",
      "Pretrain epoch [22/23], ZINB loss:0.3781, NB loss:6.2192\n",
      "Pretrain epoch [23/23], ZINB loss:0.3909, NB loss:6.2502\n",
      "Pretrain epoch [24/23], ZINB loss:0.3921, NB loss:6.2371\n",
      "Pretrain epoch [25/23], ZINB loss:0.3999, NB loss:6.2550\n",
      "Pretrain epoch [26/23], ZINB loss:0.4050, NB loss:6.2389\n",
      "Pretrain epoch [27/23], ZINB loss:0.4399, NB loss:6.2323\n",
      "Pretrain epoch [1/24], ZINB loss:0.4022, NB loss:6.2197\n",
      "Pretrain epoch [2/24], ZINB loss:0.3984, NB loss:6.2339\n",
      "Pretrain epoch [3/24], ZINB loss:0.3975, NB loss:6.2156\n",
      "Pretrain epoch [4/24], ZINB loss:0.3901, NB loss:6.2322\n",
      "Pretrain epoch [5/24], ZINB loss:0.4150, NB loss:6.2516\n",
      "Pretrain epoch [6/24], ZINB loss:0.4174, NB loss:6.2121\n",
      "Pretrain epoch [7/24], ZINB loss:0.4181, NB loss:6.2125\n",
      "Pretrain epoch [8/24], ZINB loss:0.4142, NB loss:6.1762\n",
      "Pretrain epoch [9/24], ZINB loss:0.3887, NB loss:6.2094\n",
      "Pretrain epoch [10/24], ZINB loss:0.3973, NB loss:6.2728\n",
      "Pretrain epoch [11/24], ZINB loss:0.3961, NB loss:6.2214\n",
      "Pretrain epoch [12/24], ZINB loss:0.3972, NB loss:6.1738\n",
      "Pretrain epoch [13/24], ZINB loss:0.4016, NB loss:6.2577\n",
      "Pretrain epoch [14/24], ZINB loss:0.3905, NB loss:6.2275\n",
      "Pretrain epoch [15/24], ZINB loss:0.3998, NB loss:6.1975\n",
      "Pretrain epoch [16/24], ZINB loss:0.3934, NB loss:6.1918\n",
      "Pretrain epoch [17/24], ZINB loss:0.3937, NB loss:6.1877\n",
      "Pretrain epoch [18/24], ZINB loss:0.3969, NB loss:6.1918\n",
      "Pretrain epoch [19/24], ZINB loss:0.3986, NB loss:6.2163\n",
      "Pretrain epoch [20/24], ZINB loss:0.3931, NB loss:6.1893\n",
      "Pretrain epoch [21/24], ZINB loss:0.3987, NB loss:6.2042\n",
      "Pretrain epoch [22/24], ZINB loss:0.3915, NB loss:6.2379\n",
      "Pretrain epoch [23/24], ZINB loss:0.3902, NB loss:6.1651\n",
      "Pretrain epoch [24/24], ZINB loss:0.3997, NB loss:6.1880\n",
      "Pretrain epoch [25/24], ZINB loss:0.4043, NB loss:6.1915\n",
      "Pretrain epoch [26/24], ZINB loss:0.3911, NB loss:6.1738\n",
      "Pretrain epoch [27/24], ZINB loss:0.4282, NB loss:6.3487\n",
      "Pretrain epoch [1/25], ZINB loss:0.4037, NB loss:6.2245\n",
      "Pretrain epoch [2/25], ZINB loss:0.3851, NB loss:6.2294\n",
      "Pretrain epoch [3/25], ZINB loss:0.3979, NB loss:6.1849\n",
      "Pretrain epoch [4/25], ZINB loss:0.3895, NB loss:6.1757\n",
      "Pretrain epoch [5/25], ZINB loss:0.3920, NB loss:6.1962\n",
      "Pretrain epoch [6/25], ZINB loss:0.4003, NB loss:6.2354\n",
      "Pretrain epoch [7/25], ZINB loss:0.3887, NB loss:6.1537\n",
      "Pretrain epoch [8/25], ZINB loss:0.4064, NB loss:6.1907\n",
      "Pretrain epoch [9/25], ZINB loss:0.4028, NB loss:6.1957\n",
      "Pretrain epoch [10/25], ZINB loss:0.3996, NB loss:6.2287\n",
      "Pretrain epoch [11/25], ZINB loss:0.4138, NB loss:6.1652\n",
      "Pretrain epoch [12/25], ZINB loss:0.3857, NB loss:6.1874\n",
      "Pretrain epoch [13/25], ZINB loss:0.4082, NB loss:6.1640\n",
      "Pretrain epoch [14/25], ZINB loss:0.3933, NB loss:6.1543\n",
      "Pretrain epoch [15/25], ZINB loss:0.3884, NB loss:6.1651\n",
      "Pretrain epoch [16/25], ZINB loss:0.4026, NB loss:6.2021\n",
      "Pretrain epoch [17/25], ZINB loss:0.3794, NB loss:6.1319\n",
      "Pretrain epoch [18/25], ZINB loss:0.3791, NB loss:6.1351\n",
      "Pretrain epoch [19/25], ZINB loss:0.4201, NB loss:6.1195\n",
      "Pretrain epoch [20/25], ZINB loss:0.4076, NB loss:6.1508\n",
      "Pretrain epoch [21/25], ZINB loss:0.3905, NB loss:6.1616\n",
      "Pretrain epoch [22/25], ZINB loss:0.3967, NB loss:6.1981\n",
      "Pretrain epoch [23/25], ZINB loss:0.3962, NB loss:6.0875\n",
      "Pretrain epoch [24/25], ZINB loss:0.4236, NB loss:6.1820\n",
      "Pretrain epoch [25/25], ZINB loss:0.3896, NB loss:6.1442\n",
      "Pretrain epoch [26/25], ZINB loss:0.3950, NB loss:6.1235\n",
      "Pretrain epoch [27/25], ZINB loss:0.4411, NB loss:5.9682\n",
      "Pretrain epoch [1/26], ZINB loss:0.3952, NB loss:6.1250\n",
      "Pretrain epoch [2/26], ZINB loss:0.4010, NB loss:6.1727\n",
      "Pretrain epoch [3/26], ZINB loss:0.4088, NB loss:6.1725\n",
      "Pretrain epoch [4/26], ZINB loss:0.4084, NB loss:6.1813\n",
      "Pretrain epoch [5/26], ZINB loss:0.3894, NB loss:6.2020\n",
      "Pretrain epoch [6/26], ZINB loss:0.3949, NB loss:6.1369\n",
      "Pretrain epoch [7/26], ZINB loss:0.3869, NB loss:6.0938\n",
      "Pretrain epoch [8/26], ZINB loss:0.4082, NB loss:6.1059\n",
      "Pretrain epoch [9/26], ZINB loss:0.4044, NB loss:6.1256\n",
      "Pretrain epoch [10/26], ZINB loss:0.3881, NB loss:6.0931\n",
      "Pretrain epoch [11/26], ZINB loss:0.3939, NB loss:6.1622\n",
      "Pretrain epoch [12/26], ZINB loss:0.4004, NB loss:6.1344\n",
      "Pretrain epoch [13/26], ZINB loss:0.4025, NB loss:6.1481\n",
      "Pretrain epoch [14/26], ZINB loss:0.4022, NB loss:6.0972\n",
      "Pretrain epoch [15/26], ZINB loss:0.3890, NB loss:6.1569\n",
      "Pretrain epoch [16/26], ZINB loss:0.4025, NB loss:6.1375\n",
      "Pretrain epoch [17/26], ZINB loss:0.3875, NB loss:6.1727\n",
      "Pretrain epoch [18/26], ZINB loss:0.3876, NB loss:6.1624\n",
      "Pretrain epoch [19/26], ZINB loss:0.4140, NB loss:6.1458\n",
      "Pretrain epoch [20/26], ZINB loss:0.4077, NB loss:6.1535\n",
      "Pretrain epoch [21/26], ZINB loss:0.4136, NB loss:6.1182\n",
      "Pretrain epoch [22/26], ZINB loss:0.3749, NB loss:6.0897\n",
      "Pretrain epoch [23/26], ZINB loss:0.3970, NB loss:6.1342\n",
      "Pretrain epoch [24/26], ZINB loss:0.3878, NB loss:6.1654\n",
      "Pretrain epoch [25/26], ZINB loss:0.4059, NB loss:6.0531\n",
      "Pretrain epoch [26/26], ZINB loss:0.3867, NB loss:6.1401\n",
      "Pretrain epoch [27/26], ZINB loss:0.5325, NB loss:6.2986\n",
      "Pretrain epoch [1/27], ZINB loss:0.3925, NB loss:6.1226\n",
      "Pretrain epoch [2/27], ZINB loss:0.3847, NB loss:6.1251\n",
      "Pretrain epoch [3/27], ZINB loss:0.3910, NB loss:6.1796\n",
      "Pretrain epoch [4/27], ZINB loss:0.3973, NB loss:6.1147\n",
      "Pretrain epoch [5/27], ZINB loss:0.3960, NB loss:6.1413\n",
      "Pretrain epoch [6/27], ZINB loss:0.4108, NB loss:6.1088\n",
      "Pretrain epoch [7/27], ZINB loss:0.4073, NB loss:6.0918\n",
      "Pretrain epoch [8/27], ZINB loss:0.3913, NB loss:6.0952\n",
      "Pretrain epoch [9/27], ZINB loss:0.4106, NB loss:6.0713\n",
      "Pretrain epoch [10/27], ZINB loss:0.4114, NB loss:6.1223\n",
      "Pretrain epoch [11/27], ZINB loss:0.4221, NB loss:6.1515\n",
      "Pretrain epoch [12/27], ZINB loss:0.3974, NB loss:6.1081\n",
      "Pretrain epoch [13/27], ZINB loss:0.3934, NB loss:6.1122\n",
      "Pretrain epoch [14/27], ZINB loss:0.4175, NB loss:6.0936\n",
      "Pretrain epoch [15/27], ZINB loss:0.3936, NB loss:6.0685\n",
      "Pretrain epoch [16/27], ZINB loss:0.3867, NB loss:6.0943\n",
      "Pretrain epoch [17/27], ZINB loss:0.4162, NB loss:6.1102\n",
      "Pretrain epoch [18/27], ZINB loss:0.3881, NB loss:6.0841\n",
      "Pretrain epoch [19/27], ZINB loss:0.3945, NB loss:6.0612\n",
      "Pretrain epoch [20/27], ZINB loss:0.3941, NB loss:6.0707\n",
      "Pretrain epoch [21/27], ZINB loss:0.3899, NB loss:6.1203\n",
      "Pretrain epoch [22/27], ZINB loss:0.3719, NB loss:6.1058\n",
      "Pretrain epoch [23/27], ZINB loss:0.3912, NB loss:6.0703\n",
      "Pretrain epoch [24/27], ZINB loss:0.3994, NB loss:6.1155\n",
      "Pretrain epoch [25/27], ZINB loss:0.3992, NB loss:6.0655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [26/27], ZINB loss:0.3861, NB loss:6.1498\n",
      "Pretrain epoch [27/27], ZINB loss:0.3889, NB loss:5.8454\n",
      "Pretrain epoch [1/28], ZINB loss:0.3778, NB loss:6.0882\n",
      "Pretrain epoch [2/28], ZINB loss:0.3975, NB loss:6.1065\n",
      "Pretrain epoch [3/28], ZINB loss:0.3921, NB loss:6.0781\n",
      "Pretrain epoch [4/28], ZINB loss:0.3893, NB loss:6.0515\n",
      "Pretrain epoch [5/28], ZINB loss:0.3862, NB loss:6.0357\n",
      "Pretrain epoch [6/28], ZINB loss:0.3763, NB loss:6.0619\n",
      "Pretrain epoch [7/28], ZINB loss:0.4026, NB loss:6.0526\n",
      "Pretrain epoch [8/28], ZINB loss:0.4016, NB loss:6.0788\n",
      "Pretrain epoch [9/28], ZINB loss:0.3935, NB loss:6.0917\n",
      "Pretrain epoch [10/28], ZINB loss:0.4066, NB loss:6.1500\n",
      "Pretrain epoch [11/28], ZINB loss:0.4012, NB loss:6.1238\n",
      "Pretrain epoch [12/28], ZINB loss:0.3993, NB loss:6.0765\n",
      "Pretrain epoch [13/28], ZINB loss:0.4097, NB loss:6.0161\n",
      "Pretrain epoch [14/28], ZINB loss:0.4227, NB loss:6.1018\n",
      "Pretrain epoch [15/28], ZINB loss:0.3835, NB loss:6.0701\n",
      "Pretrain epoch [16/28], ZINB loss:0.4170, NB loss:6.0778\n",
      "Pretrain epoch [17/28], ZINB loss:0.3964, NB loss:6.0747\n",
      "Pretrain epoch [18/28], ZINB loss:0.4058, NB loss:6.0495\n",
      "Pretrain epoch [19/28], ZINB loss:0.4052, NB loss:6.0968\n",
      "Pretrain epoch [20/28], ZINB loss:0.3921, NB loss:6.0791\n",
      "Pretrain epoch [21/28], ZINB loss:0.3933, NB loss:6.0741\n",
      "Pretrain epoch [22/28], ZINB loss:0.3992, NB loss:6.0422\n",
      "Pretrain epoch [23/28], ZINB loss:0.3836, NB loss:6.0813\n",
      "Pretrain epoch [24/28], ZINB loss:0.4167, NB loss:6.0543\n",
      "Pretrain epoch [25/28], ZINB loss:0.3873, NB loss:6.0503\n",
      "Pretrain epoch [26/28], ZINB loss:0.3869, NB loss:6.0909\n",
      "Pretrain epoch [27/28], ZINB loss:0.3599, NB loss:6.0231\n",
      "Pretrain epoch [1/29], ZINB loss:0.3996, NB loss:6.0587\n",
      "Pretrain epoch [2/29], ZINB loss:0.3943, NB loss:6.0131\n",
      "Pretrain epoch [3/29], ZINB loss:0.3986, NB loss:6.0738\n",
      "Pretrain epoch [4/29], ZINB loss:0.3805, NB loss:6.0646\n",
      "Pretrain epoch [5/29], ZINB loss:0.4066, NB loss:6.0164\n",
      "Pretrain epoch [6/29], ZINB loss:0.4084, NB loss:6.0541\n",
      "Pretrain epoch [7/29], ZINB loss:0.3864, NB loss:6.0997\n",
      "Pretrain epoch [8/29], ZINB loss:0.3894, NB loss:6.0349\n",
      "Pretrain epoch [9/29], ZINB loss:0.3986, NB loss:6.1045\n",
      "Pretrain epoch [10/29], ZINB loss:0.4130, NB loss:6.0288\n",
      "Pretrain epoch [11/29], ZINB loss:0.3934, NB loss:6.0724\n",
      "Pretrain epoch [12/29], ZINB loss:0.3971, NB loss:6.0008\n",
      "Pretrain epoch [13/29], ZINB loss:0.3910, NB loss:6.0935\n",
      "Pretrain epoch [14/29], ZINB loss:0.3837, NB loss:6.0585\n",
      "Pretrain epoch [15/29], ZINB loss:0.4082, NB loss:6.0288\n",
      "Pretrain epoch [16/29], ZINB loss:0.4117, NB loss:6.0541\n",
      "Pretrain epoch [17/29], ZINB loss:0.4098, NB loss:6.0192\n",
      "Pretrain epoch [18/29], ZINB loss:0.3873, NB loss:5.9953\n",
      "Pretrain epoch [19/29], ZINB loss:0.4138, NB loss:6.0795\n",
      "Pretrain epoch [20/29], ZINB loss:0.4073, NB loss:6.0363\n",
      "Pretrain epoch [21/29], ZINB loss:0.3911, NB loss:6.0312\n",
      "Pretrain epoch [22/29], ZINB loss:0.3950, NB loss:6.0083\n",
      "Pretrain epoch [23/29], ZINB loss:0.3905, NB loss:6.0407\n",
      "Pretrain epoch [24/29], ZINB loss:0.4045, NB loss:6.0473\n",
      "Pretrain epoch [25/29], ZINB loss:0.3782, NB loss:6.0081\n",
      "Pretrain epoch [26/29], ZINB loss:0.3881, NB loss:6.0829\n",
      "Pretrain epoch [27/29], ZINB loss:0.3310, NB loss:6.4184\n",
      "Pretrain epoch [1/30], ZINB loss:0.4009, NB loss:5.9676\n",
      "Pretrain epoch [2/30], ZINB loss:0.4122, NB loss:6.0385\n",
      "Pretrain epoch [3/30], ZINB loss:0.4090, NB loss:6.0557\n",
      "Pretrain epoch [4/30], ZINB loss:0.3863, NB loss:5.9708\n",
      "Pretrain epoch [5/30], ZINB loss:0.4048, NB loss:5.9951\n",
      "Pretrain epoch [6/30], ZINB loss:0.3947, NB loss:6.0200\n",
      "Pretrain epoch [7/30], ZINB loss:0.4080, NB loss:6.0560\n",
      "Pretrain epoch [8/30], ZINB loss:0.3997, NB loss:5.9643\n",
      "Pretrain epoch [9/30], ZINB loss:0.4248, NB loss:5.9961\n",
      "Pretrain epoch [10/30], ZINB loss:0.3870, NB loss:6.0186\n",
      "Pretrain epoch [11/30], ZINB loss:0.3983, NB loss:6.0876\n",
      "Pretrain epoch [12/30], ZINB loss:0.3839, NB loss:6.0132\n",
      "Pretrain epoch [13/30], ZINB loss:0.3854, NB loss:6.0492\n",
      "Pretrain epoch [14/30], ZINB loss:0.3954, NB loss:6.0631\n",
      "Pretrain epoch [15/30], ZINB loss:0.4005, NB loss:5.9886\n",
      "Pretrain epoch [16/30], ZINB loss:0.3799, NB loss:6.0145\n",
      "Pretrain epoch [17/30], ZINB loss:0.3937, NB loss:6.0108\n",
      "Pretrain epoch [18/30], ZINB loss:0.3831, NB loss:5.9978\n",
      "Pretrain epoch [19/30], ZINB loss:0.3953, NB loss:6.0738\n",
      "Pretrain epoch [20/30], ZINB loss:0.3848, NB loss:6.0277\n",
      "Pretrain epoch [21/30], ZINB loss:0.3846, NB loss:6.0349\n",
      "Pretrain epoch [22/30], ZINB loss:0.3973, NB loss:6.0200\n",
      "Pretrain epoch [23/30], ZINB loss:0.3825, NB loss:6.0038\n",
      "Pretrain epoch [24/30], ZINB loss:0.3923, NB loss:6.0275\n",
      "Pretrain epoch [25/30], ZINB loss:0.4096, NB loss:6.0488\n",
      "Pretrain epoch [26/30], ZINB loss:0.4270, NB loss:5.9631\n",
      "Pretrain epoch [27/30], ZINB loss:0.3723, NB loss:6.0485\n",
      "Pretrain epoch [1/31], ZINB loss:0.3972, NB loss:6.0017\n",
      "Pretrain epoch [2/31], ZINB loss:0.4113, NB loss:6.0862\n",
      "Pretrain epoch [3/31], ZINB loss:0.4141, NB loss:6.0323\n",
      "Pretrain epoch [4/31], ZINB loss:0.3850, NB loss:6.0381\n",
      "Pretrain epoch [5/31], ZINB loss:0.3784, NB loss:5.9663\n",
      "Pretrain epoch [6/31], ZINB loss:0.3920, NB loss:5.9637\n",
      "Pretrain epoch [7/31], ZINB loss:0.4107, NB loss:6.0560\n",
      "Pretrain epoch [8/31], ZINB loss:0.3916, NB loss:6.0022\n",
      "Pretrain epoch [9/31], ZINB loss:0.3909, NB loss:5.9653\n",
      "Pretrain epoch [10/31], ZINB loss:0.3875, NB loss:5.9867\n",
      "Pretrain epoch [11/31], ZINB loss:0.3912, NB loss:5.9567\n",
      "Pretrain epoch [12/31], ZINB loss:0.4010, NB loss:5.9628\n",
      "Pretrain epoch [13/31], ZINB loss:0.3942, NB loss:5.9550\n",
      "Pretrain epoch [14/31], ZINB loss:0.4024, NB loss:5.9933\n",
      "Pretrain epoch [15/31], ZINB loss:0.3899, NB loss:5.9800\n",
      "Pretrain epoch [16/31], ZINB loss:0.4123, NB loss:6.0065\n",
      "Pretrain epoch [17/31], ZINB loss:0.3775, NB loss:6.0213\n",
      "Pretrain epoch [18/31], ZINB loss:0.3904, NB loss:5.9828\n",
      "Pretrain epoch [19/31], ZINB loss:0.4118, NB loss:6.0490\n",
      "Pretrain epoch [20/31], ZINB loss:0.4073, NB loss:5.9822\n",
      "Pretrain epoch [21/31], ZINB loss:0.3866, NB loss:6.0206\n",
      "Pretrain epoch [22/31], ZINB loss:0.4153, NB loss:5.9681\n",
      "Pretrain epoch [23/31], ZINB loss:0.4027, NB loss:5.9340\n",
      "Pretrain epoch [24/31], ZINB loss:0.3967, NB loss:6.0055\n",
      "Pretrain epoch [25/31], ZINB loss:0.3879, NB loss:5.9549\n",
      "Pretrain epoch [26/31], ZINB loss:0.3823, NB loss:5.9781\n",
      "Pretrain epoch [27/31], ZINB loss:0.2835, NB loss:5.8291\n",
      "Pretrain epoch [1/32], ZINB loss:0.3774, NB loss:5.9963\n",
      "Pretrain epoch [2/32], ZINB loss:0.3995, NB loss:5.9997\n",
      "Pretrain epoch [3/32], ZINB loss:0.4113, NB loss:5.9692\n",
      "Pretrain epoch [4/32], ZINB loss:0.3844, NB loss:5.9506\n",
      "Pretrain epoch [5/32], ZINB loss:0.4020, NB loss:5.9419\n",
      "Pretrain epoch [6/32], ZINB loss:0.4069, NB loss:5.9585\n",
      "Pretrain epoch [7/32], ZINB loss:0.3989, NB loss:5.9931\n",
      "Pretrain epoch [8/32], ZINB loss:0.3931, NB loss:5.9986\n",
      "Pretrain epoch [9/32], ZINB loss:0.3956, NB loss:5.9596\n",
      "Pretrain epoch [10/32], ZINB loss:0.3842, NB loss:5.9895\n",
      "Pretrain epoch [11/32], ZINB loss:0.3986, NB loss:5.9658\n",
      "Pretrain epoch [12/32], ZINB loss:0.4038, NB loss:5.9376\n",
      "Pretrain epoch [13/32], ZINB loss:0.4013, NB loss:5.9303\n",
      "Pretrain epoch [14/32], ZINB loss:0.3901, NB loss:5.9342\n",
      "Pretrain epoch [15/32], ZINB loss:0.3959, NB loss:5.9666\n",
      "Pretrain epoch [16/32], ZINB loss:0.3904, NB loss:5.9909\n",
      "Pretrain epoch [17/32], ZINB loss:0.3951, NB loss:5.9360\n",
      "Pretrain epoch [18/32], ZINB loss:0.3952, NB loss:5.9571\n",
      "Pretrain epoch [19/32], ZINB loss:0.3841, NB loss:6.0021\n",
      "Pretrain epoch [20/32], ZINB loss:0.3911, NB loss:5.9656\n",
      "Pretrain epoch [21/32], ZINB loss:0.3954, NB loss:5.9769\n",
      "Pretrain epoch [22/32], ZINB loss:0.4098, NB loss:6.0144\n",
      "Pretrain epoch [23/32], ZINB loss:0.4000, NB loss:5.9263\n",
      "Pretrain epoch [24/32], ZINB loss:0.4042, NB loss:5.9625\n",
      "Pretrain epoch [25/32], ZINB loss:0.4082, NB loss:5.9827\n",
      "Pretrain epoch [26/32], ZINB loss:0.3880, NB loss:5.9950\n",
      "Pretrain epoch [27/32], ZINB loss:0.2153, NB loss:5.8052\n",
      "Pretrain epoch [1/33], ZINB loss:0.4115, NB loss:5.9843\n",
      "Pretrain epoch [2/33], ZINB loss:0.3872, NB loss:5.9106\n",
      "Pretrain epoch [3/33], ZINB loss:0.4042, NB loss:5.9868\n",
      "Pretrain epoch [4/33], ZINB loss:0.3928, NB loss:5.9827\n",
      "Pretrain epoch [5/33], ZINB loss:0.3951, NB loss:5.8820\n",
      "Pretrain epoch [6/33], ZINB loss:0.4033, NB loss:5.9515\n",
      "Pretrain epoch [7/33], ZINB loss:0.3909, NB loss:6.0003\n",
      "Pretrain epoch [8/33], ZINB loss:0.4034, NB loss:5.9767\n",
      "Pretrain epoch [9/33], ZINB loss:0.3962, NB loss:5.9237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [10/33], ZINB loss:0.3957, NB loss:5.8804\n",
      "Pretrain epoch [11/33], ZINB loss:0.3956, NB loss:5.9975\n",
      "Pretrain epoch [12/33], ZINB loss:0.4038, NB loss:5.9118\n",
      "Pretrain epoch [13/33], ZINB loss:0.4173, NB loss:5.9194\n",
      "Pretrain epoch [14/33], ZINB loss:0.3800, NB loss:5.9508\n",
      "Pretrain epoch [15/33], ZINB loss:0.3827, NB loss:5.9636\n",
      "Pretrain epoch [16/33], ZINB loss:0.4197, NB loss:5.9989\n",
      "Pretrain epoch [17/33], ZINB loss:0.4068, NB loss:5.9166\n",
      "Pretrain epoch [18/33], ZINB loss:0.3901, NB loss:5.9564\n",
      "Pretrain epoch [19/33], ZINB loss:0.3918, NB loss:5.9825\n",
      "Pretrain epoch [20/33], ZINB loss:0.4088, NB loss:5.9468\n",
      "Pretrain epoch [21/33], ZINB loss:0.3885, NB loss:5.8947\n",
      "Pretrain epoch [22/33], ZINB loss:0.3901, NB loss:5.9635\n",
      "Pretrain epoch [23/33], ZINB loss:0.3650, NB loss:5.9346\n",
      "Pretrain epoch [24/33], ZINB loss:0.3926, NB loss:5.8999\n",
      "Pretrain epoch [25/33], ZINB loss:0.3881, NB loss:5.9405\n",
      "Pretrain epoch [26/33], ZINB loss:0.3888, NB loss:5.9192\n",
      "Pretrain epoch [27/33], ZINB loss:0.4794, NB loss:6.3789\n",
      "Pretrain epoch [1/34], ZINB loss:0.4031, NB loss:5.9652\n",
      "Pretrain epoch [2/34], ZINB loss:0.3760, NB loss:5.9162\n",
      "Pretrain epoch [3/34], ZINB loss:0.4200, NB loss:5.9900\n",
      "Pretrain epoch [4/34], ZINB loss:0.3995, NB loss:5.9553\n",
      "Pretrain epoch [5/34], ZINB loss:0.3726, NB loss:5.8769\n",
      "Pretrain epoch [6/34], ZINB loss:0.3948, NB loss:5.9231\n",
      "Pretrain epoch [7/34], ZINB loss:0.4186, NB loss:5.8852\n",
      "Pretrain epoch [8/34], ZINB loss:0.4054, NB loss:5.9017\n",
      "Pretrain epoch [9/34], ZINB loss:0.3985, NB loss:5.8597\n",
      "Pretrain epoch [10/34], ZINB loss:0.4049, NB loss:5.9557\n",
      "Pretrain epoch [11/34], ZINB loss:0.4117, NB loss:5.9337\n",
      "Pretrain epoch [12/34], ZINB loss:0.4029, NB loss:5.9297\n",
      "Pretrain epoch [13/34], ZINB loss:0.4045, NB loss:5.9293\n",
      "Pretrain epoch [14/34], ZINB loss:0.3872, NB loss:5.9359\n",
      "Pretrain epoch [15/34], ZINB loss:0.3946, NB loss:5.9165\n",
      "Pretrain epoch [16/34], ZINB loss:0.4063, NB loss:5.9249\n",
      "Pretrain epoch [17/34], ZINB loss:0.3957, NB loss:5.9100\n",
      "Pretrain epoch [18/34], ZINB loss:0.4027, NB loss:5.8937\n",
      "Pretrain epoch [19/34], ZINB loss:0.3892, NB loss:5.9468\n",
      "Pretrain epoch [20/34], ZINB loss:0.3872, NB loss:5.9363\n",
      "Pretrain epoch [21/34], ZINB loss:0.3995, NB loss:5.8909\n",
      "Pretrain epoch [22/34], ZINB loss:0.3934, NB loss:5.9268\n",
      "Pretrain epoch [23/34], ZINB loss:0.4004, NB loss:5.9005\n",
      "Pretrain epoch [24/34], ZINB loss:0.3848, NB loss:5.9690\n",
      "Pretrain epoch [25/34], ZINB loss:0.3971, NB loss:5.9614\n",
      "Pretrain epoch [26/34], ZINB loss:0.3875, NB loss:5.8792\n",
      "Pretrain epoch [27/34], ZINB loss:0.5177, NB loss:6.1321\n",
      "Pretrain epoch [1/35], ZINB loss:0.3925, NB loss:5.8704\n",
      "Pretrain epoch [2/35], ZINB loss:0.4007, NB loss:5.8449\n",
      "Pretrain epoch [3/35], ZINB loss:0.4264, NB loss:5.9050\n",
      "Pretrain epoch [4/35], ZINB loss:0.3952, NB loss:5.8811\n",
      "Pretrain epoch [5/35], ZINB loss:0.3938, NB loss:5.9147\n",
      "Pretrain epoch [6/35], ZINB loss:0.4022, NB loss:5.9323\n",
      "Pretrain epoch [7/35], ZINB loss:0.4015, NB loss:5.8390\n",
      "Pretrain epoch [8/35], ZINB loss:0.4193, NB loss:5.9465\n",
      "Pretrain epoch [9/35], ZINB loss:0.3916, NB loss:5.9315\n",
      "Pretrain epoch [10/35], ZINB loss:0.4025, NB loss:5.9046\n",
      "Pretrain epoch [11/35], ZINB loss:0.4137, NB loss:5.8824\n",
      "Pretrain epoch [12/35], ZINB loss:0.4035, NB loss:5.8798\n",
      "Pretrain epoch [13/35], ZINB loss:0.4049, NB loss:5.9279\n",
      "Pretrain epoch [14/35], ZINB loss:0.4207, NB loss:5.9154\n",
      "Pretrain epoch [15/35], ZINB loss:0.3933, NB loss:5.8675\n",
      "Pretrain epoch [16/35], ZINB loss:0.3834, NB loss:5.9056\n",
      "Pretrain epoch [17/35], ZINB loss:0.3771, NB loss:5.9016\n",
      "Pretrain epoch [18/35], ZINB loss:0.3930, NB loss:5.9347\n",
      "Pretrain epoch [19/35], ZINB loss:0.3802, NB loss:5.9163\n",
      "Pretrain epoch [20/35], ZINB loss:0.3808, NB loss:5.9723\n",
      "Pretrain epoch [21/35], ZINB loss:0.3939, NB loss:5.9301\n",
      "Pretrain epoch [22/35], ZINB loss:0.4060, NB loss:5.8840\n",
      "Pretrain epoch [23/35], ZINB loss:0.3889, NB loss:5.8901\n",
      "Pretrain epoch [24/35], ZINB loss:0.3893, NB loss:5.8991\n",
      "Pretrain epoch [25/35], ZINB loss:0.3940, NB loss:5.8623\n",
      "Pretrain epoch [26/35], ZINB loss:0.4000, NB loss:5.8913\n",
      "Pretrain epoch [27/35], ZINB loss:0.4154, NB loss:5.8655\n",
      "Pretrain epoch [1/36], ZINB loss:0.3759, NB loss:5.8751\n",
      "Pretrain epoch [2/36], ZINB loss:0.3902, NB loss:5.8944\n",
      "Pretrain epoch [3/36], ZINB loss:0.4034, NB loss:5.8636\n",
      "Pretrain epoch [4/36], ZINB loss:0.3860, NB loss:5.8822\n",
      "Pretrain epoch [5/36], ZINB loss:0.4160, NB loss:5.9306\n",
      "Pretrain epoch [6/36], ZINB loss:0.4075, NB loss:5.9307\n",
      "Pretrain epoch [7/36], ZINB loss:0.4067, NB loss:5.8542\n",
      "Pretrain epoch [8/36], ZINB loss:0.3982, NB loss:5.9613\n",
      "Pretrain epoch [9/36], ZINB loss:0.4014, NB loss:5.8684\n",
      "Pretrain epoch [10/36], ZINB loss:0.3852, NB loss:5.8565\n",
      "Pretrain epoch [11/36], ZINB loss:0.3955, NB loss:5.9018\n",
      "Pretrain epoch [12/36], ZINB loss:0.4032, NB loss:5.9287\n",
      "Pretrain epoch [13/36], ZINB loss:0.3897, NB loss:5.8955\n",
      "Pretrain epoch [14/36], ZINB loss:0.4113, NB loss:5.8773\n",
      "Pretrain epoch [15/36], ZINB loss:0.4174, NB loss:5.8885\n",
      "Pretrain epoch [16/36], ZINB loss:0.3803, NB loss:5.9304\n",
      "Pretrain epoch [17/36], ZINB loss:0.3857, NB loss:5.8141\n",
      "Pretrain epoch [18/36], ZINB loss:0.3931, NB loss:5.8752\n",
      "Pretrain epoch [19/36], ZINB loss:0.4113, NB loss:5.8743\n",
      "Pretrain epoch [20/36], ZINB loss:0.3995, NB loss:5.8787\n",
      "Pretrain epoch [21/36], ZINB loss:0.3841, NB loss:5.8847\n",
      "Pretrain epoch [22/36], ZINB loss:0.3921, NB loss:5.8753\n",
      "Pretrain epoch [23/36], ZINB loss:0.3775, NB loss:5.7981\n",
      "Pretrain epoch [24/36], ZINB loss:0.4151, NB loss:5.8432\n",
      "Pretrain epoch [25/36], ZINB loss:0.3834, NB loss:5.8424\n",
      "Pretrain epoch [26/36], ZINB loss:0.4033, NB loss:5.8408\n",
      "Pretrain epoch [27/36], ZINB loss:0.5075, NB loss:5.8657\n",
      "Pretrain epoch [1/37], ZINB loss:0.3833, NB loss:5.8624\n",
      "Pretrain epoch [2/37], ZINB loss:0.4187, NB loss:5.9167\n",
      "Pretrain epoch [3/37], ZINB loss:0.3942, NB loss:5.8204\n",
      "Pretrain epoch [4/37], ZINB loss:0.3937, NB loss:5.8992\n",
      "Pretrain epoch [5/37], ZINB loss:0.3772, NB loss:5.8372\n",
      "Pretrain epoch [6/37], ZINB loss:0.3947, NB loss:5.8687\n",
      "Pretrain epoch [7/37], ZINB loss:0.4083, NB loss:5.8427\n",
      "Pretrain epoch [8/37], ZINB loss:0.3933, NB loss:5.8590\n",
      "Pretrain epoch [9/37], ZINB loss:0.4087, NB loss:5.8888\n",
      "Pretrain epoch [10/37], ZINB loss:0.4076, NB loss:5.8191\n",
      "Pretrain epoch [11/37], ZINB loss:0.4015, NB loss:5.8595\n",
      "Pretrain epoch [12/37], ZINB loss:0.3859, NB loss:5.8378\n",
      "Pretrain epoch [13/37], ZINB loss:0.3965, NB loss:5.8321\n",
      "Pretrain epoch [14/37], ZINB loss:0.4000, NB loss:5.8534\n",
      "Pretrain epoch [15/37], ZINB loss:0.4075, NB loss:5.8569\n",
      "Pretrain epoch [16/37], ZINB loss:0.4079, NB loss:5.8540\n",
      "Pretrain epoch [17/37], ZINB loss:0.3837, NB loss:5.9111\n",
      "Pretrain epoch [18/37], ZINB loss:0.4099, NB loss:5.8952\n",
      "Pretrain epoch [19/37], ZINB loss:0.3988, NB loss:5.8582\n",
      "Pretrain epoch [20/37], ZINB loss:0.3934, NB loss:5.8425\n",
      "Pretrain epoch [21/37], ZINB loss:0.3741, NB loss:5.8720\n",
      "Pretrain epoch [22/37], ZINB loss:0.4137, NB loss:5.8169\n",
      "Pretrain epoch [23/37], ZINB loss:0.4099, NB loss:5.8617\n",
      "Pretrain epoch [24/37], ZINB loss:0.3923, NB loss:5.7917\n",
      "Pretrain epoch [25/37], ZINB loss:0.3876, NB loss:5.9082\n",
      "Pretrain epoch [26/37], ZINB loss:0.3820, NB loss:5.8562\n",
      "Pretrain epoch [27/37], ZINB loss:0.2603, NB loss:5.8456\n",
      "Pretrain epoch [1/38], ZINB loss:0.3975, NB loss:5.8267\n",
      "Pretrain epoch [2/38], ZINB loss:0.4078, NB loss:5.8378\n",
      "Pretrain epoch [3/38], ZINB loss:0.3995, NB loss:5.8168\n",
      "Pretrain epoch [4/38], ZINB loss:0.3795, NB loss:5.8203\n",
      "Pretrain epoch [5/38], ZINB loss:0.3987, NB loss:5.8484\n",
      "Pretrain epoch [6/38], ZINB loss:0.3974, NB loss:5.8448\n",
      "Pretrain epoch [7/38], ZINB loss:0.3873, NB loss:5.8423\n",
      "Pretrain epoch [8/38], ZINB loss:0.3980, NB loss:5.8614\n",
      "Pretrain epoch [9/38], ZINB loss:0.3928, NB loss:5.8196\n",
      "Pretrain epoch [10/38], ZINB loss:0.3967, NB loss:5.8524\n",
      "Pretrain epoch [11/38], ZINB loss:0.3800, NB loss:5.8208\n",
      "Pretrain epoch [12/38], ZINB loss:0.3930, NB loss:5.8871\n",
      "Pretrain epoch [13/38], ZINB loss:0.3850, NB loss:5.8244\n",
      "Pretrain epoch [14/38], ZINB loss:0.3962, NB loss:5.8711\n",
      "Pretrain epoch [15/38], ZINB loss:0.3934, NB loss:5.8416\n",
      "Pretrain epoch [16/38], ZINB loss:0.4077, NB loss:5.8179\n",
      "Pretrain epoch [17/38], ZINB loss:0.3945, NB loss:5.8376\n",
      "Pretrain epoch [18/38], ZINB loss:0.3946, NB loss:5.8467\n",
      "Pretrain epoch [19/38], ZINB loss:0.3829, NB loss:5.8420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [20/38], ZINB loss:0.3982, NB loss:5.8652\n",
      "Pretrain epoch [21/38], ZINB loss:0.4058, NB loss:5.8419\n",
      "Pretrain epoch [22/38], ZINB loss:0.4368, NB loss:5.8391\n",
      "Pretrain epoch [23/38], ZINB loss:0.3894, NB loss:5.7976\n",
      "Pretrain epoch [24/38], ZINB loss:0.3989, NB loss:5.8014\n",
      "Pretrain epoch [25/38], ZINB loss:0.3863, NB loss:5.8306\n",
      "Pretrain epoch [26/38], ZINB loss:0.3888, NB loss:5.8581\n",
      "Pretrain epoch [27/38], ZINB loss:0.4127, NB loss:5.9136\n",
      "Pretrain epoch [1/39], ZINB loss:0.3915, NB loss:5.8318\n",
      "Pretrain epoch [2/39], ZINB loss:0.4050, NB loss:5.8852\n",
      "Pretrain epoch [3/39], ZINB loss:0.3801, NB loss:5.8392\n",
      "Pretrain epoch [4/39], ZINB loss:0.4189, NB loss:5.8572\n",
      "Pretrain epoch [5/39], ZINB loss:0.3931, NB loss:5.8538\n",
      "Pretrain epoch [6/39], ZINB loss:0.4038, NB loss:5.8338\n",
      "Pretrain epoch [7/39], ZINB loss:0.3947, NB loss:5.8050\n",
      "Pretrain epoch [8/39], ZINB loss:0.4075, NB loss:5.8673\n",
      "Pretrain epoch [9/39], ZINB loss:0.4025, NB loss:5.7861\n",
      "Pretrain epoch [10/39], ZINB loss:0.3911, NB loss:5.8469\n",
      "Pretrain epoch [11/39], ZINB loss:0.4169, NB loss:5.8142\n",
      "Pretrain epoch [12/39], ZINB loss:0.3867, NB loss:5.7516\n",
      "Pretrain epoch [13/39], ZINB loss:0.3838, NB loss:5.8260\n",
      "Pretrain epoch [14/39], ZINB loss:0.3971, NB loss:5.8754\n",
      "Pretrain epoch [15/39], ZINB loss:0.3819, NB loss:5.8183\n",
      "Pretrain epoch [16/39], ZINB loss:0.3898, NB loss:5.7720\n",
      "Pretrain epoch [17/39], ZINB loss:0.3947, NB loss:5.7859\n",
      "Pretrain epoch [18/39], ZINB loss:0.4079, NB loss:5.8120\n",
      "Pretrain epoch [19/39], ZINB loss:0.3932, NB loss:5.7815\n",
      "Pretrain epoch [20/39], ZINB loss:0.3888, NB loss:5.8001\n",
      "Pretrain epoch [21/39], ZINB loss:0.4105, NB loss:5.7945\n",
      "Pretrain epoch [22/39], ZINB loss:0.3960, NB loss:5.8071\n",
      "Pretrain epoch [23/39], ZINB loss:0.3939, NB loss:5.7760\n",
      "Pretrain epoch [24/39], ZINB loss:0.3912, NB loss:5.8347\n",
      "Pretrain epoch [25/39], ZINB loss:0.3831, NB loss:5.8157\n",
      "Pretrain epoch [26/39], ZINB loss:0.3896, NB loss:5.8088\n",
      "Pretrain epoch [27/39], ZINB loss:0.3791, NB loss:5.6184\n",
      "Pretrain epoch [1/40], ZINB loss:0.3943, NB loss:5.8241\n",
      "Pretrain epoch [2/40], ZINB loss:0.4012, NB loss:5.7968\n",
      "Pretrain epoch [3/40], ZINB loss:0.4127, NB loss:5.8207\n",
      "Pretrain epoch [4/40], ZINB loss:0.3948, NB loss:5.8069\n",
      "Pretrain epoch [5/40], ZINB loss:0.4144, NB loss:5.7790\n",
      "Pretrain epoch [6/40], ZINB loss:0.4085, NB loss:5.7482\n",
      "Pretrain epoch [7/40], ZINB loss:0.3913, NB loss:5.7784\n",
      "Pretrain epoch [8/40], ZINB loss:0.3843, NB loss:5.7967\n",
      "Pretrain epoch [9/40], ZINB loss:0.4035, NB loss:5.8409\n",
      "Pretrain epoch [10/40], ZINB loss:0.3966, NB loss:5.7553\n",
      "Pretrain epoch [11/40], ZINB loss:0.3968, NB loss:5.7750\n",
      "Pretrain epoch [12/40], ZINB loss:0.3885, NB loss:5.7788\n",
      "Pretrain epoch [13/40], ZINB loss:0.3827, NB loss:5.8160\n",
      "Pretrain epoch [14/40], ZINB loss:0.3820, NB loss:5.8080\n",
      "Pretrain epoch [15/40], ZINB loss:0.3736, NB loss:5.8082\n",
      "Pretrain epoch [16/40], ZINB loss:0.3920, NB loss:5.7847\n",
      "Pretrain epoch [17/40], ZINB loss:0.3974, NB loss:5.7731\n",
      "Pretrain epoch [18/40], ZINB loss:0.4100, NB loss:5.7839\n",
      "Pretrain epoch [19/40], ZINB loss:0.3908, NB loss:5.8170\n",
      "Pretrain epoch [20/40], ZINB loss:0.3829, NB loss:5.8180\n",
      "Pretrain epoch [21/40], ZINB loss:0.3968, NB loss:5.8455\n",
      "Pretrain epoch [22/40], ZINB loss:0.3892, NB loss:5.8262\n",
      "Pretrain epoch [23/40], ZINB loss:0.3913, NB loss:5.7833\n",
      "Pretrain epoch [24/40], ZINB loss:0.4093, NB loss:5.8069\n",
      "Pretrain epoch [25/40], ZINB loss:0.3887, NB loss:5.8030\n",
      "Pretrain epoch [26/40], ZINB loss:0.4131, NB loss:5.7980\n",
      "Pretrain epoch [27/40], ZINB loss:0.3121, NB loss:5.9018\n",
      "Pretrain epoch [1/41], ZINB loss:0.4088, NB loss:5.7950\n",
      "Pretrain epoch [2/41], ZINB loss:0.3912, NB loss:5.8039\n",
      "Pretrain epoch [3/41], ZINB loss:0.3829, NB loss:5.7982\n",
      "Pretrain epoch [4/41], ZINB loss:0.3943, NB loss:5.7795\n",
      "Pretrain epoch [5/41], ZINB loss:0.3956, NB loss:5.8047\n",
      "Pretrain epoch [6/41], ZINB loss:0.3995, NB loss:5.7546\n",
      "Pretrain epoch [7/41], ZINB loss:0.4058, NB loss:5.7757\n",
      "Pretrain epoch [8/41], ZINB loss:0.3827, NB loss:5.7919\n",
      "Pretrain epoch [9/41], ZINB loss:0.4117, NB loss:5.7392\n",
      "Pretrain epoch [10/41], ZINB loss:0.4135, NB loss:5.7182\n",
      "Pretrain epoch [11/41], ZINB loss:0.3967, NB loss:5.8534\n",
      "Pretrain epoch [12/41], ZINB loss:0.3847, NB loss:5.8099\n",
      "Pretrain epoch [13/41], ZINB loss:0.3860, NB loss:5.7895\n",
      "Pretrain epoch [14/41], ZINB loss:0.3886, NB loss:5.7699\n",
      "Pretrain epoch [15/41], ZINB loss:0.3929, NB loss:5.8209\n",
      "Pretrain epoch [16/41], ZINB loss:0.4043, NB loss:5.7923\n",
      "Pretrain epoch [17/41], ZINB loss:0.4011, NB loss:5.7444\n",
      "Pretrain epoch [18/41], ZINB loss:0.3787, NB loss:5.7964\n",
      "Pretrain epoch [19/41], ZINB loss:0.3997, NB loss:5.8009\n",
      "Pretrain epoch [20/41], ZINB loss:0.3940, NB loss:5.7560\n",
      "Pretrain epoch [21/41], ZINB loss:0.3895, NB loss:5.7785\n",
      "Pretrain epoch [22/41], ZINB loss:0.3870, NB loss:5.7292\n",
      "Pretrain epoch [23/41], ZINB loss:0.4128, NB loss:5.7950\n",
      "Pretrain epoch [24/41], ZINB loss:0.4000, NB loss:5.8128\n",
      "Pretrain epoch [25/41], ZINB loss:0.3700, NB loss:5.7387\n",
      "Pretrain epoch [26/41], ZINB loss:0.4017, NB loss:5.7276\n",
      "Pretrain epoch [27/41], ZINB loss:0.3027, NB loss:6.0922\n",
      "Pretrain epoch [1/42], ZINB loss:0.3800, NB loss:5.7883\n",
      "Pretrain epoch [2/42], ZINB loss:0.3949, NB loss:5.7732\n",
      "Pretrain epoch [3/42], ZINB loss:0.4129, NB loss:5.7626\n",
      "Pretrain epoch [4/42], ZINB loss:0.3979, NB loss:5.8044\n",
      "Pretrain epoch [5/42], ZINB loss:0.3821, NB loss:5.7663\n",
      "Pretrain epoch [6/42], ZINB loss:0.3926, NB loss:5.7821\n",
      "Pretrain epoch [7/42], ZINB loss:0.3945, NB loss:5.7766\n",
      "Pretrain epoch [8/42], ZINB loss:0.3972, NB loss:5.8228\n",
      "Pretrain epoch [9/42], ZINB loss:0.3920, NB loss:5.7400\n",
      "Pretrain epoch [10/42], ZINB loss:0.4049, NB loss:5.7725\n",
      "Pretrain epoch [11/42], ZINB loss:0.3895, NB loss:5.7377\n",
      "Pretrain epoch [12/42], ZINB loss:0.4007, NB loss:5.7835\n",
      "Pretrain epoch [13/42], ZINB loss:0.3825, NB loss:5.7675\n",
      "Pretrain epoch [14/42], ZINB loss:0.3838, NB loss:5.7231\n",
      "Pretrain epoch [15/42], ZINB loss:0.3749, NB loss:5.6952\n",
      "Pretrain epoch [16/42], ZINB loss:0.4021, NB loss:5.7582\n",
      "Pretrain epoch [17/42], ZINB loss:0.4187, NB loss:5.7422\n",
      "Pretrain epoch [18/42], ZINB loss:0.3977, NB loss:5.7332\n",
      "Pretrain epoch [19/42], ZINB loss:0.4147, NB loss:5.7850\n",
      "Pretrain epoch [20/42], ZINB loss:0.3833, NB loss:5.7734\n",
      "Pretrain epoch [21/42], ZINB loss:0.3963, NB loss:5.7827\n",
      "Pretrain epoch [22/42], ZINB loss:0.3927, NB loss:5.7467\n",
      "Pretrain epoch [23/42], ZINB loss:0.3974, NB loss:5.7493\n",
      "Pretrain epoch [24/42], ZINB loss:0.3882, NB loss:5.7562\n",
      "Pretrain epoch [25/42], ZINB loss:0.3983, NB loss:5.7316\n",
      "Pretrain epoch [26/42], ZINB loss:0.3936, NB loss:5.7437\n",
      "Pretrain epoch [27/42], ZINB loss:0.4012, NB loss:5.9007\n",
      "Pretrain epoch [1/43], ZINB loss:0.3759, NB loss:5.7149\n",
      "Pretrain epoch [2/43], ZINB loss:0.3981, NB loss:5.7831\n",
      "Pretrain epoch [3/43], ZINB loss:0.4082, NB loss:5.7666\n",
      "Pretrain epoch [4/43], ZINB loss:0.4018, NB loss:5.7182\n",
      "Pretrain epoch [5/43], ZINB loss:0.4010, NB loss:5.7364\n",
      "Pretrain epoch [6/43], ZINB loss:0.4008, NB loss:5.7983\n",
      "Pretrain epoch [7/43], ZINB loss:0.4023, NB loss:5.7534\n",
      "Pretrain epoch [8/43], ZINB loss:0.4032, NB loss:5.7584\n",
      "Pretrain epoch [9/43], ZINB loss:0.3980, NB loss:5.7144\n",
      "Pretrain epoch [10/43], ZINB loss:0.4170, NB loss:5.7413\n",
      "Pretrain epoch [11/43], ZINB loss:0.3825, NB loss:5.7170\n",
      "Pretrain epoch [12/43], ZINB loss:0.4111, NB loss:5.7253\n",
      "Pretrain epoch [13/43], ZINB loss:0.3947, NB loss:5.8178\n",
      "Pretrain epoch [14/43], ZINB loss:0.3922, NB loss:5.7515\n",
      "Pretrain epoch [15/43], ZINB loss:0.3950, NB loss:5.7655\n",
      "Pretrain epoch [16/43], ZINB loss:0.3774, NB loss:5.7169\n",
      "Pretrain epoch [17/43], ZINB loss:0.3820, NB loss:5.7519\n",
      "Pretrain epoch [18/43], ZINB loss:0.4077, NB loss:5.7377\n",
      "Pretrain epoch [19/43], ZINB loss:0.3955, NB loss:5.8167\n",
      "Pretrain epoch [20/43], ZINB loss:0.4051, NB loss:5.7107\n",
      "Pretrain epoch [21/43], ZINB loss:0.3810, NB loss:5.7142\n",
      "Pretrain epoch [22/43], ZINB loss:0.3833, NB loss:5.7538\n",
      "Pretrain epoch [23/43], ZINB loss:0.3968, NB loss:5.7053\n",
      "Pretrain epoch [24/43], ZINB loss:0.4148, NB loss:5.6860\n",
      "Pretrain epoch [25/43], ZINB loss:0.3930, NB loss:5.7245\n",
      "Pretrain epoch [26/43], ZINB loss:0.3731, NB loss:5.7567\n",
      "Pretrain epoch [27/43], ZINB loss:0.3194, NB loss:5.4397\n",
      "Pretrain epoch [1/44], ZINB loss:0.4037, NB loss:5.7563\n",
      "Pretrain epoch [2/44], ZINB loss:0.4026, NB loss:5.7617\n",
      "Pretrain epoch [3/44], ZINB loss:0.4086, NB loss:5.7080\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [4/44], ZINB loss:0.3740, NB loss:5.7722\n",
      "Pretrain epoch [5/44], ZINB loss:0.3833, NB loss:5.7010\n",
      "Pretrain epoch [6/44], ZINB loss:0.4018, NB loss:5.6823\n",
      "Pretrain epoch [7/44], ZINB loss:0.3848, NB loss:5.7692\n",
      "Pretrain epoch [8/44], ZINB loss:0.4057, NB loss:5.7520\n",
      "Pretrain epoch [9/44], ZINB loss:0.4055, NB loss:5.6882\n",
      "Pretrain epoch [10/44], ZINB loss:0.4025, NB loss:5.7391\n",
      "Pretrain epoch [11/44], ZINB loss:0.4106, NB loss:5.7279\n",
      "Pretrain epoch [12/44], ZINB loss:0.4007, NB loss:5.7173\n",
      "Pretrain epoch [13/44], ZINB loss:0.4103, NB loss:5.6808\n",
      "Pretrain epoch [14/44], ZINB loss:0.3952, NB loss:5.6582\n",
      "Pretrain epoch [15/44], ZINB loss:0.3865, NB loss:5.7156\n",
      "Pretrain epoch [16/44], ZINB loss:0.3939, NB loss:5.7344\n",
      "Pretrain epoch [17/44], ZINB loss:0.4033, NB loss:5.7526\n",
      "Pretrain epoch [18/44], ZINB loss:0.4077, NB loss:5.7729\n",
      "Pretrain epoch [19/44], ZINB loss:0.4061, NB loss:5.7960\n",
      "Pretrain epoch [20/44], ZINB loss:0.3903, NB loss:5.7422\n",
      "Pretrain epoch [21/44], ZINB loss:0.3977, NB loss:5.7044\n",
      "Pretrain epoch [22/44], ZINB loss:0.3738, NB loss:5.7116\n",
      "Pretrain epoch [23/44], ZINB loss:0.3838, NB loss:5.7089\n",
      "Pretrain epoch [24/44], ZINB loss:0.3763, NB loss:5.6996\n",
      "Pretrain epoch [25/44], ZINB loss:0.3755, NB loss:5.6607\n",
      "Pretrain epoch [26/44], ZINB loss:0.3818, NB loss:5.7459\n",
      "Pretrain epoch [27/44], ZINB loss:0.4933, NB loss:6.0399\n",
      "Pretrain epoch [1/45], ZINB loss:0.3857, NB loss:5.7266\n",
      "Pretrain epoch [2/45], ZINB loss:0.3954, NB loss:5.7287\n",
      "Pretrain epoch [3/45], ZINB loss:0.4114, NB loss:5.6970\n",
      "Pretrain epoch [4/45], ZINB loss:0.4004, NB loss:5.7556\n",
      "Pretrain epoch [5/45], ZINB loss:0.4008, NB loss:5.7213\n",
      "Pretrain epoch [6/45], ZINB loss:0.3954, NB loss:5.7084\n",
      "Pretrain epoch [7/45], ZINB loss:0.4050, NB loss:5.7189\n",
      "Pretrain epoch [8/45], ZINB loss:0.3920, NB loss:5.7020\n",
      "Pretrain epoch [9/45], ZINB loss:0.3917, NB loss:5.6814\n",
      "Pretrain epoch [10/45], ZINB loss:0.4007, NB loss:5.7322\n",
      "Pretrain epoch [11/45], ZINB loss:0.3895, NB loss:5.7653\n",
      "Pretrain epoch [12/45], ZINB loss:0.4015, NB loss:5.6913\n",
      "Pretrain epoch [13/45], ZINB loss:0.4066, NB loss:5.6916\n",
      "Pretrain epoch [14/45], ZINB loss:0.3780, NB loss:5.7222\n",
      "Pretrain epoch [15/45], ZINB loss:0.3845, NB loss:5.6506\n",
      "Pretrain epoch [16/45], ZINB loss:0.3983, NB loss:5.7075\n",
      "Pretrain epoch [17/45], ZINB loss:0.4073, NB loss:5.7478\n",
      "Pretrain epoch [18/45], ZINB loss:0.3815, NB loss:5.7179\n",
      "Pretrain epoch [19/45], ZINB loss:0.4102, NB loss:5.6680\n",
      "Pretrain epoch [20/45], ZINB loss:0.4017, NB loss:5.6792\n",
      "Pretrain epoch [21/45], ZINB loss:0.3823, NB loss:5.6661\n",
      "Pretrain epoch [22/45], ZINB loss:0.3680, NB loss:5.6444\n",
      "Pretrain epoch [23/45], ZINB loss:0.3826, NB loss:5.6972\n",
      "Pretrain epoch [24/45], ZINB loss:0.4129, NB loss:5.7193\n",
      "Pretrain epoch [25/45], ZINB loss:0.3919, NB loss:5.7312\n",
      "Pretrain epoch [26/45], ZINB loss:0.4092, NB loss:5.7294\n",
      "Pretrain epoch [27/45], ZINB loss:0.3352, NB loss:5.9573\n",
      "Pretrain epoch [1/46], ZINB loss:0.4076, NB loss:5.6738\n",
      "Pretrain epoch [2/46], ZINB loss:0.3864, NB loss:5.7065\n",
      "Pretrain epoch [3/46], ZINB loss:0.4070, NB loss:5.7132\n",
      "Pretrain epoch [4/46], ZINB loss:0.3977, NB loss:5.6738\n",
      "Pretrain epoch [5/46], ZINB loss:0.3761, NB loss:5.7042\n",
      "Pretrain epoch [6/46], ZINB loss:0.3951, NB loss:5.6668\n",
      "Pretrain epoch [7/46], ZINB loss:0.4028, NB loss:5.6962\n",
      "Pretrain epoch [8/46], ZINB loss:0.4053, NB loss:5.6260\n",
      "Pretrain epoch [9/46], ZINB loss:0.3724, NB loss:5.7385\n",
      "Pretrain epoch [10/46], ZINB loss:0.3884, NB loss:5.6871\n",
      "Pretrain epoch [11/46], ZINB loss:0.3835, NB loss:5.6779\n",
      "Pretrain epoch [12/46], ZINB loss:0.3708, NB loss:5.6839\n",
      "Pretrain epoch [13/46], ZINB loss:0.4000, NB loss:5.7053\n",
      "Pretrain epoch [14/46], ZINB loss:0.3866, NB loss:5.7522\n",
      "Pretrain epoch [15/46], ZINB loss:0.4154, NB loss:5.6982\n",
      "Pretrain epoch [16/46], ZINB loss:0.3676, NB loss:5.7368\n",
      "Pretrain epoch [17/46], ZINB loss:0.4104, NB loss:5.6738\n",
      "Pretrain epoch [18/46], ZINB loss:0.3863, NB loss:5.6959\n",
      "Pretrain epoch [19/46], ZINB loss:0.3832, NB loss:5.6673\n",
      "Pretrain epoch [20/46], ZINB loss:0.3964, NB loss:5.6790\n",
      "Pretrain epoch [21/46], ZINB loss:0.4106, NB loss:5.6685\n",
      "Pretrain epoch [22/46], ZINB loss:0.3827, NB loss:5.7523\n",
      "Pretrain epoch [23/46], ZINB loss:0.4004, NB loss:5.6657\n",
      "Pretrain epoch [24/46], ZINB loss:0.3996, NB loss:5.6524\n",
      "Pretrain epoch [25/46], ZINB loss:0.4059, NB loss:5.6694\n",
      "Pretrain epoch [26/46], ZINB loss:0.4171, NB loss:5.6975\n",
      "Pretrain epoch [27/46], ZINB loss:0.3331, NB loss:5.5296\n",
      "Pretrain epoch [1/47], ZINB loss:0.4064, NB loss:5.6736\n",
      "Pretrain epoch [2/47], ZINB loss:0.3874, NB loss:5.6846\n",
      "Pretrain epoch [3/47], ZINB loss:0.3981, NB loss:5.6501\n",
      "Pretrain epoch [4/47], ZINB loss:0.4090, NB loss:5.6708\n",
      "Pretrain epoch [5/47], ZINB loss:0.3740, NB loss:5.6642\n",
      "Pretrain epoch [6/47], ZINB loss:0.3929, NB loss:5.6767\n",
      "Pretrain epoch [7/47], ZINB loss:0.4051, NB loss:5.6622\n",
      "Pretrain epoch [8/47], ZINB loss:0.3776, NB loss:5.6068\n",
      "Pretrain epoch [9/47], ZINB loss:0.4027, NB loss:5.6688\n",
      "Pretrain epoch [10/47], ZINB loss:0.4058, NB loss:5.6666\n",
      "Pretrain epoch [11/47], ZINB loss:0.3992, NB loss:5.7112\n",
      "Pretrain epoch [12/47], ZINB loss:0.3987, NB loss:5.7155\n",
      "Pretrain epoch [13/47], ZINB loss:0.3929, NB loss:5.6311\n",
      "Pretrain epoch [14/47], ZINB loss:0.3914, NB loss:5.7354\n",
      "Pretrain epoch [15/47], ZINB loss:0.3951, NB loss:5.6990\n",
      "Pretrain epoch [16/47], ZINB loss:0.3986, NB loss:5.6886\n",
      "Pretrain epoch [17/47], ZINB loss:0.4027, NB loss:5.6752\n",
      "Pretrain epoch [18/47], ZINB loss:0.3707, NB loss:5.6780\n",
      "Pretrain epoch [19/47], ZINB loss:0.4292, NB loss:5.7231\n",
      "Pretrain epoch [20/47], ZINB loss:0.3878, NB loss:5.7279\n",
      "Pretrain epoch [21/47], ZINB loss:0.3919, NB loss:5.6808\n",
      "Pretrain epoch [22/47], ZINB loss:0.3882, NB loss:5.6044\n",
      "Pretrain epoch [23/47], ZINB loss:0.3914, NB loss:5.6537\n",
      "Pretrain epoch [24/47], ZINB loss:0.3946, NB loss:5.6195\n",
      "Pretrain epoch [25/47], ZINB loss:0.3787, NB loss:5.7142\n",
      "Pretrain epoch [26/47], ZINB loss:0.3843, NB loss:5.6344\n",
      "Pretrain epoch [27/47], ZINB loss:0.3211, NB loss:5.5986\n",
      "Pretrain epoch [1/48], ZINB loss:0.3848, NB loss:5.6886\n",
      "Pretrain epoch [2/48], ZINB loss:0.4013, NB loss:5.6918\n",
      "Pretrain epoch [3/48], ZINB loss:0.4034, NB loss:5.6580\n",
      "Pretrain epoch [4/48], ZINB loss:0.3915, NB loss:5.6742\n",
      "Pretrain epoch [5/48], ZINB loss:0.4016, NB loss:5.6648\n",
      "Pretrain epoch [6/48], ZINB loss:0.4062, NB loss:5.6374\n",
      "Pretrain epoch [7/48], ZINB loss:0.4059, NB loss:5.7002\n",
      "Pretrain epoch [8/48], ZINB loss:0.3874, NB loss:5.6774\n",
      "Pretrain epoch [9/48], ZINB loss:0.3902, NB loss:5.6685\n",
      "Pretrain epoch [10/48], ZINB loss:0.4009, NB loss:5.6251\n",
      "Pretrain epoch [11/48], ZINB loss:0.3797, NB loss:5.6521\n",
      "Pretrain epoch [12/48], ZINB loss:0.3853, NB loss:5.6339\n",
      "Pretrain epoch [13/48], ZINB loss:0.3892, NB loss:5.6370\n",
      "Pretrain epoch [14/48], ZINB loss:0.4014, NB loss:5.6043\n",
      "Pretrain epoch [15/48], ZINB loss:0.3951, NB loss:5.6471\n",
      "Pretrain epoch [16/48], ZINB loss:0.3930, NB loss:5.6417\n",
      "Pretrain epoch [17/48], ZINB loss:0.3746, NB loss:5.6912\n",
      "Pretrain epoch [18/48], ZINB loss:0.3890, NB loss:5.6456\n",
      "Pretrain epoch [19/48], ZINB loss:0.3976, NB loss:5.6923\n",
      "Pretrain epoch [20/48], ZINB loss:0.3958, NB loss:5.6541\n",
      "Pretrain epoch [21/48], ZINB loss:0.3974, NB loss:5.6513\n",
      "Pretrain epoch [22/48], ZINB loss:0.4007, NB loss:5.5796\n",
      "Pretrain epoch [23/48], ZINB loss:0.3837, NB loss:5.6929\n",
      "Pretrain epoch [24/48], ZINB loss:0.4037, NB loss:5.6469\n",
      "Pretrain epoch [25/48], ZINB loss:0.4043, NB loss:5.6559\n",
      "Pretrain epoch [26/48], ZINB loss:0.4015, NB loss:5.6632\n",
      "Pretrain epoch [27/48], ZINB loss:0.5822, NB loss:5.7334\n",
      "Pretrain epoch [1/49], ZINB loss:0.3788, NB loss:5.6536\n",
      "Pretrain epoch [2/49], ZINB loss:0.4071, NB loss:5.6779\n",
      "Pretrain epoch [3/49], ZINB loss:0.3661, NB loss:5.6614\n",
      "Pretrain epoch [4/49], ZINB loss:0.3865, NB loss:5.6120\n",
      "Pretrain epoch [5/49], ZINB loss:0.3907, NB loss:5.6924\n",
      "Pretrain epoch [6/49], ZINB loss:0.3876, NB loss:5.6457\n",
      "Pretrain epoch [7/49], ZINB loss:0.4002, NB loss:5.6509\n",
      "Pretrain epoch [8/49], ZINB loss:0.3815, NB loss:5.6163\n",
      "Pretrain epoch [9/49], ZINB loss:0.4101, NB loss:5.7104\n",
      "Pretrain epoch [10/49], ZINB loss:0.3952, NB loss:5.6092\n",
      "Pretrain epoch [11/49], ZINB loss:0.3974, NB loss:5.6124\n",
      "Pretrain epoch [12/49], ZINB loss:0.4092, NB loss:5.6558\n",
      "Pretrain epoch [13/49], ZINB loss:0.3991, NB loss:5.6321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [14/49], ZINB loss:0.3937, NB loss:5.6594\n",
      "Pretrain epoch [15/49], ZINB loss:0.3885, NB loss:5.6429\n",
      "Pretrain epoch [16/49], ZINB loss:0.3932, NB loss:5.6881\n",
      "Pretrain epoch [17/49], ZINB loss:0.3927, NB loss:5.5456\n",
      "Pretrain epoch [18/49], ZINB loss:0.3873, NB loss:5.5844\n",
      "Pretrain epoch [19/49], ZINB loss:0.3787, NB loss:5.6073\n",
      "Pretrain epoch [20/49], ZINB loss:0.4044, NB loss:5.5898\n",
      "Pretrain epoch [21/49], ZINB loss:0.4011, NB loss:5.6365\n",
      "Pretrain epoch [22/49], ZINB loss:0.4248, NB loss:5.6567\n",
      "Pretrain epoch [23/49], ZINB loss:0.4157, NB loss:5.6470\n",
      "Pretrain epoch [24/49], ZINB loss:0.3781, NB loss:5.6479\n",
      "Pretrain epoch [25/49], ZINB loss:0.3925, NB loss:5.6664\n",
      "Pretrain epoch [26/49], ZINB loss:0.4210, NB loss:5.6472\n",
      "Pretrain epoch [27/49], ZINB loss:0.2723, NB loss:5.7229\n",
      "Pretrain epoch [1/50], ZINB loss:0.3950, NB loss:5.6257\n",
      "Pretrain epoch [2/50], ZINB loss:0.3912, NB loss:5.6535\n",
      "Pretrain epoch [3/50], ZINB loss:0.4005, NB loss:5.6730\n",
      "Pretrain epoch [4/50], ZINB loss:0.3979, NB loss:5.6256\n",
      "Pretrain epoch [5/50], ZINB loss:0.3941, NB loss:5.6240\n",
      "Pretrain epoch [6/50], ZINB loss:0.3943, NB loss:5.6081\n",
      "Pretrain epoch [7/50], ZINB loss:0.3887, NB loss:5.6707\n",
      "Pretrain epoch [8/50], ZINB loss:0.4002, NB loss:5.6269\n",
      "Pretrain epoch [9/50], ZINB loss:0.3830, NB loss:5.6007\n",
      "Pretrain epoch [10/50], ZINB loss:0.3894, NB loss:5.5582\n",
      "Pretrain epoch [11/50], ZINB loss:0.3976, NB loss:5.6615\n",
      "Pretrain epoch [12/50], ZINB loss:0.3948, NB loss:5.6297\n",
      "Pretrain epoch [13/50], ZINB loss:0.3930, NB loss:5.6013\n",
      "Pretrain epoch [14/50], ZINB loss:0.4014, NB loss:5.5696\n",
      "Pretrain epoch [15/50], ZINB loss:0.3982, NB loss:5.6209\n",
      "Pretrain epoch [16/50], ZINB loss:0.3904, NB loss:5.6144\n",
      "Pretrain epoch [17/50], ZINB loss:0.4110, NB loss:5.6497\n",
      "Pretrain epoch [18/50], ZINB loss:0.3926, NB loss:5.5977\n",
      "Pretrain epoch [19/50], ZINB loss:0.3925, NB loss:5.6276\n",
      "Pretrain epoch [20/50], ZINB loss:0.3800, NB loss:5.5796\n",
      "Pretrain epoch [21/50], ZINB loss:0.3957, NB loss:5.6160\n",
      "Pretrain epoch [22/50], ZINB loss:0.4021, NB loss:5.6850\n",
      "Pretrain epoch [23/50], ZINB loss:0.3891, NB loss:5.6724\n",
      "Pretrain epoch [24/50], ZINB loss:0.3775, NB loss:5.6296\n",
      "Pretrain epoch [25/50], ZINB loss:0.4056, NB loss:5.5966\n",
      "Pretrain epoch [26/50], ZINB loss:0.3960, NB loss:5.6076\n",
      "Pretrain epoch [27/50], ZINB loss:0.4428, NB loss:5.6611\n",
      "Pretrain epoch [1/51], ZINB loss:0.4005, NB loss:5.6168\n",
      "Pretrain epoch [2/51], ZINB loss:0.4060, NB loss:5.5748\n",
      "Pretrain epoch [3/51], ZINB loss:0.4030, NB loss:5.6004\n",
      "Pretrain epoch [4/51], ZINB loss:0.4011, NB loss:5.5888\n",
      "Pretrain epoch [5/51], ZINB loss:0.4121, NB loss:5.5939\n",
      "Pretrain epoch [6/51], ZINB loss:0.3884, NB loss:5.5890\n",
      "Pretrain epoch [7/51], ZINB loss:0.4004, NB loss:5.5736\n",
      "Pretrain epoch [8/51], ZINB loss:0.3942, NB loss:5.6091\n",
      "Pretrain epoch [9/51], ZINB loss:0.4040, NB loss:5.5576\n",
      "Pretrain epoch [10/51], ZINB loss:0.3992, NB loss:5.5744\n",
      "Pretrain epoch [11/51], ZINB loss:0.3825, NB loss:5.6138\n",
      "Pretrain epoch [12/51], ZINB loss:0.4248, NB loss:5.5963\n",
      "Pretrain epoch [13/51], ZINB loss:0.3788, NB loss:5.6383\n",
      "Pretrain epoch [14/51], ZINB loss:0.3884, NB loss:5.6755\n",
      "Pretrain epoch [15/51], ZINB loss:0.3791, NB loss:5.6046\n",
      "Pretrain epoch [16/51], ZINB loss:0.3857, NB loss:5.6714\n",
      "Pretrain epoch [17/51], ZINB loss:0.3876, NB loss:5.6058\n",
      "Pretrain epoch [18/51], ZINB loss:0.3767, NB loss:5.5995\n",
      "Pretrain epoch [19/51], ZINB loss:0.4039, NB loss:5.6024\n",
      "Pretrain epoch [20/51], ZINB loss:0.3928, NB loss:5.6234\n",
      "Pretrain epoch [21/51], ZINB loss:0.3983, NB loss:5.6678\n",
      "Pretrain epoch [22/51], ZINB loss:0.3852, NB loss:5.5611\n",
      "Pretrain epoch [23/51], ZINB loss:0.3991, NB loss:5.6007\n",
      "Pretrain epoch [24/51], ZINB loss:0.3951, NB loss:5.6535\n",
      "Pretrain epoch [25/51], ZINB loss:0.3915, NB loss:5.5843\n",
      "Pretrain epoch [26/51], ZINB loss:0.3974, NB loss:5.6189\n",
      "Pretrain epoch [27/51], ZINB loss:0.4090, NB loss:6.3338\n",
      "Pretrain epoch [1/52], ZINB loss:0.4026, NB loss:5.6564\n",
      "Pretrain epoch [2/52], ZINB loss:0.4027, NB loss:5.5828\n",
      "Pretrain epoch [3/52], ZINB loss:0.3910, NB loss:5.6300\n",
      "Pretrain epoch [4/52], ZINB loss:0.4025, NB loss:5.5631\n",
      "Pretrain epoch [5/52], ZINB loss:0.4030, NB loss:5.5491\n",
      "Pretrain epoch [6/52], ZINB loss:0.3942, NB loss:5.5738\n",
      "Pretrain epoch [7/52], ZINB loss:0.4099, NB loss:5.6339\n",
      "Pretrain epoch [8/52], ZINB loss:0.3916, NB loss:5.5578\n",
      "Pretrain epoch [9/52], ZINB loss:0.4096, NB loss:5.5158\n",
      "Pretrain epoch [10/52], ZINB loss:0.3925, NB loss:5.6703\n",
      "Pretrain epoch [11/52], ZINB loss:0.3909, NB loss:5.5791\n",
      "Pretrain epoch [12/52], ZINB loss:0.3812, NB loss:5.5588\n",
      "Pretrain epoch [13/52], ZINB loss:0.4003, NB loss:5.5725\n",
      "Pretrain epoch [14/52], ZINB loss:0.3932, NB loss:5.5984\n",
      "Pretrain epoch [15/52], ZINB loss:0.3709, NB loss:5.5726\n",
      "Pretrain epoch [16/52], ZINB loss:0.3888, NB loss:5.6388\n",
      "Pretrain epoch [17/52], ZINB loss:0.3972, NB loss:5.5807\n",
      "Pretrain epoch [18/52], ZINB loss:0.3819, NB loss:5.6246\n",
      "Pretrain epoch [19/52], ZINB loss:0.3996, NB loss:5.5918\n",
      "Pretrain epoch [20/52], ZINB loss:0.4004, NB loss:5.6232\n",
      "Pretrain epoch [21/52], ZINB loss:0.3827, NB loss:5.5937\n",
      "Pretrain epoch [22/52], ZINB loss:0.3770, NB loss:5.6078\n",
      "Pretrain epoch [23/52], ZINB loss:0.4023, NB loss:5.5913\n",
      "Pretrain epoch [24/52], ZINB loss:0.4158, NB loss:5.5763\n",
      "Pretrain epoch [25/52], ZINB loss:0.3929, NB loss:5.5511\n",
      "Pretrain epoch [26/52], ZINB loss:0.3825, NB loss:5.6111\n",
      "Pretrain epoch [27/52], ZINB loss:0.4015, NB loss:5.3898\n",
      "Pretrain epoch [1/53], ZINB loss:0.3920, NB loss:5.6142\n",
      "Pretrain epoch [2/53], ZINB loss:0.3977, NB loss:5.6102\n",
      "Pretrain epoch [3/53], ZINB loss:0.3686, NB loss:5.5663\n",
      "Pretrain epoch [4/53], ZINB loss:0.4061, NB loss:5.5830\n",
      "Pretrain epoch [5/53], ZINB loss:0.3726, NB loss:5.6222\n",
      "Pretrain epoch [6/53], ZINB loss:0.4015, NB loss:5.5873\n",
      "Pretrain epoch [7/53], ZINB loss:0.3906, NB loss:5.5988\n",
      "Pretrain epoch [8/53], ZINB loss:0.3809, NB loss:5.5915\n",
      "Pretrain epoch [9/53], ZINB loss:0.3972, NB loss:5.5380\n",
      "Pretrain epoch [10/53], ZINB loss:0.4195, NB loss:5.5815\n",
      "Pretrain epoch [11/53], ZINB loss:0.4105, NB loss:5.6111\n",
      "Pretrain epoch [12/53], ZINB loss:0.3909, NB loss:5.5590\n",
      "Pretrain epoch [13/53], ZINB loss:0.4073, NB loss:5.5762\n",
      "Pretrain epoch [14/53], ZINB loss:0.3848, NB loss:5.5481\n",
      "Pretrain epoch [15/53], ZINB loss:0.3987, NB loss:5.5929\n",
      "Pretrain epoch [16/53], ZINB loss:0.3921, NB loss:5.5851\n",
      "Pretrain epoch [17/53], ZINB loss:0.3918, NB loss:5.5485\n",
      "Pretrain epoch [18/53], ZINB loss:0.3885, NB loss:5.5492\n",
      "Pretrain epoch [19/53], ZINB loss:0.3935, NB loss:5.5738\n",
      "Pretrain epoch [20/53], ZINB loss:0.3921, NB loss:5.6006\n",
      "Pretrain epoch [21/53], ZINB loss:0.3934, NB loss:5.5451\n",
      "Pretrain epoch [22/53], ZINB loss:0.3920, NB loss:5.6594\n",
      "Pretrain epoch [23/53], ZINB loss:0.3927, NB loss:5.5703\n",
      "Pretrain epoch [24/53], ZINB loss:0.3985, NB loss:5.5574\n",
      "Pretrain epoch [25/53], ZINB loss:0.3883, NB loss:5.5243\n",
      "Pretrain epoch [26/53], ZINB loss:0.4087, NB loss:5.5002\n",
      "Pretrain epoch [27/53], ZINB loss:0.4230, NB loss:5.5007\n",
      "Pretrain epoch [1/54], ZINB loss:0.3916, NB loss:5.5362\n",
      "Pretrain epoch [2/54], ZINB loss:0.3814, NB loss:5.5938\n",
      "Pretrain epoch [3/54], ZINB loss:0.4080, NB loss:5.5320\n",
      "Pretrain epoch [4/54], ZINB loss:0.3928, NB loss:5.5511\n",
      "Pretrain epoch [5/54], ZINB loss:0.3872, NB loss:5.5481\n",
      "Pretrain epoch [6/54], ZINB loss:0.4061, NB loss:5.5710\n",
      "Pretrain epoch [7/54], ZINB loss:0.3643, NB loss:5.5878\n",
      "Pretrain epoch [8/54], ZINB loss:0.3945, NB loss:5.5770\n",
      "Pretrain epoch [9/54], ZINB loss:0.3943, NB loss:5.5615\n",
      "Pretrain epoch [10/54], ZINB loss:0.4004, NB loss:5.5347\n",
      "Pretrain epoch [11/54], ZINB loss:0.3898, NB loss:5.5433\n",
      "Pretrain epoch [12/54], ZINB loss:0.4042, NB loss:5.5892\n",
      "Pretrain epoch [13/54], ZINB loss:0.3971, NB loss:5.6155\n",
      "Pretrain epoch [14/54], ZINB loss:0.4062, NB loss:5.5557\n",
      "Pretrain epoch [15/54], ZINB loss:0.3776, NB loss:5.5879\n",
      "Pretrain epoch [16/54], ZINB loss:0.3696, NB loss:5.6113\n",
      "Pretrain epoch [17/54], ZINB loss:0.4046, NB loss:5.5737\n",
      "Pretrain epoch [18/54], ZINB loss:0.3942, NB loss:5.5748\n",
      "Pretrain epoch [19/54], ZINB loss:0.4013, NB loss:5.5419\n",
      "Pretrain epoch [20/54], ZINB loss:0.3897, NB loss:5.5074\n",
      "Pretrain epoch [21/54], ZINB loss:0.4171, NB loss:5.5543\n",
      "Pretrain epoch [22/54], ZINB loss:0.4000, NB loss:5.5436\n",
      "Pretrain epoch [23/54], ZINB loss:0.4041, NB loss:5.5419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [24/54], ZINB loss:0.3903, NB loss:5.5377\n",
      "Pretrain epoch [25/54], ZINB loss:0.4043, NB loss:5.5767\n",
      "Pretrain epoch [26/54], ZINB loss:0.3814, NB loss:5.5401\n",
      "Pretrain epoch [27/54], ZINB loss:0.3767, NB loss:5.7101\n",
      "Pretrain epoch [1/55], ZINB loss:0.3721, NB loss:5.5802\n",
      "Pretrain epoch [2/55], ZINB loss:0.3945, NB loss:5.5061\n",
      "Pretrain epoch [3/55], ZINB loss:0.3983, NB loss:5.5560\n",
      "Pretrain epoch [4/55], ZINB loss:0.3716, NB loss:5.6272\n",
      "Pretrain epoch [5/55], ZINB loss:0.3801, NB loss:5.5349\n",
      "Pretrain epoch [6/55], ZINB loss:0.3973, NB loss:5.5617\n",
      "Pretrain epoch [7/55], ZINB loss:0.4162, NB loss:5.5622\n",
      "Pretrain epoch [8/55], ZINB loss:0.4102, NB loss:5.5163\n",
      "Pretrain epoch [9/55], ZINB loss:0.3983, NB loss:5.5348\n",
      "Pretrain epoch [10/55], ZINB loss:0.3995, NB loss:5.6115\n",
      "Pretrain epoch [11/55], ZINB loss:0.4008, NB loss:5.5276\n",
      "Pretrain epoch [12/55], ZINB loss:0.3829, NB loss:5.6281\n",
      "Pretrain epoch [13/55], ZINB loss:0.3853, NB loss:5.5334\n",
      "Pretrain epoch [14/55], ZINB loss:0.4087, NB loss:5.5565\n",
      "Pretrain epoch [15/55], ZINB loss:0.3906, NB loss:5.4838\n",
      "Pretrain epoch [16/55], ZINB loss:0.3752, NB loss:5.5539\n",
      "Pretrain epoch [17/55], ZINB loss:0.3810, NB loss:5.5222\n",
      "Pretrain epoch [18/55], ZINB loss:0.3959, NB loss:5.5864\n",
      "Pretrain epoch [19/55], ZINB loss:0.3909, NB loss:5.5525\n",
      "Pretrain epoch [20/55], ZINB loss:0.3955, NB loss:5.5831\n",
      "Pretrain epoch [21/55], ZINB loss:0.3864, NB loss:5.5025\n",
      "Pretrain epoch [22/55], ZINB loss:0.4012, NB loss:5.5300\n",
      "Pretrain epoch [23/55], ZINB loss:0.4017, NB loss:5.5125\n",
      "Pretrain epoch [24/55], ZINB loss:0.4193, NB loss:5.5136\n",
      "Pretrain epoch [25/55], ZINB loss:0.3961, NB loss:5.5250\n",
      "Pretrain epoch [26/55], ZINB loss:0.4026, NB loss:5.4944\n",
      "Pretrain epoch [27/55], ZINB loss:0.2969, NB loss:5.5497\n",
      "Pretrain epoch [1/56], ZINB loss:0.3942, NB loss:5.5282\n",
      "Pretrain epoch [2/56], ZINB loss:0.4065, NB loss:5.5255\n",
      "Pretrain epoch [3/56], ZINB loss:0.3867, NB loss:5.5127\n",
      "Pretrain epoch [4/56], ZINB loss:0.3981, NB loss:5.5889\n",
      "Pretrain epoch [5/56], ZINB loss:0.3977, NB loss:5.5087\n",
      "Pretrain epoch [6/56], ZINB loss:0.3902, NB loss:5.5365\n",
      "Pretrain epoch [7/56], ZINB loss:0.3908, NB loss:5.5549\n",
      "Pretrain epoch [8/56], ZINB loss:0.3986, NB loss:5.5643\n",
      "Pretrain epoch [9/56], ZINB loss:0.4167, NB loss:5.5190\n",
      "Pretrain epoch [10/56], ZINB loss:0.3820, NB loss:5.5750\n",
      "Pretrain epoch [11/56], ZINB loss:0.3984, NB loss:5.5211\n",
      "Pretrain epoch [12/56], ZINB loss:0.3915, NB loss:5.5752\n",
      "Pretrain epoch [13/56], ZINB loss:0.3741, NB loss:5.4733\n",
      "Pretrain epoch [14/56], ZINB loss:0.4000, NB loss:5.4929\n",
      "Pretrain epoch [15/56], ZINB loss:0.3958, NB loss:5.5906\n",
      "Pretrain epoch [16/56], ZINB loss:0.3846, NB loss:5.5320\n",
      "Pretrain epoch [17/56], ZINB loss:0.3754, NB loss:5.5036\n",
      "Pretrain epoch [18/56], ZINB loss:0.3898, NB loss:5.5476\n",
      "Pretrain epoch [19/56], ZINB loss:0.4022, NB loss:5.4839\n",
      "Pretrain epoch [20/56], ZINB loss:0.4051, NB loss:5.5203\n",
      "Pretrain epoch [21/56], ZINB loss:0.3982, NB loss:5.5451\n",
      "Pretrain epoch [22/56], ZINB loss:0.3984, NB loss:5.5279\n",
      "Pretrain epoch [23/56], ZINB loss:0.4124, NB loss:5.5502\n",
      "Pretrain epoch [24/56], ZINB loss:0.3883, NB loss:5.5312\n",
      "Pretrain epoch [25/56], ZINB loss:0.3844, NB loss:5.5010\n",
      "Pretrain epoch [26/56], ZINB loss:0.3871, NB loss:5.4994\n",
      "Pretrain epoch [27/56], ZINB loss:0.3775, NB loss:5.3712\n",
      "Pretrain epoch [1/57], ZINB loss:0.3863, NB loss:5.5324\n",
      "Pretrain epoch [2/57], ZINB loss:0.4137, NB loss:5.5149\n",
      "Pretrain epoch [3/57], ZINB loss:0.3735, NB loss:5.5890\n",
      "Pretrain epoch [4/57], ZINB loss:0.3886, NB loss:5.5076\n",
      "Pretrain epoch [5/57], ZINB loss:0.3939, NB loss:5.4982\n",
      "Pretrain epoch [6/57], ZINB loss:0.3959, NB loss:5.5228\n",
      "Pretrain epoch [7/57], ZINB loss:0.3938, NB loss:5.4502\n",
      "Pretrain epoch [8/57], ZINB loss:0.4074, NB loss:5.4889\n",
      "Pretrain epoch [9/57], ZINB loss:0.3976, NB loss:5.4997\n",
      "Pretrain epoch [10/57], ZINB loss:0.3943, NB loss:5.5317\n",
      "Pretrain epoch [11/57], ZINB loss:0.4075, NB loss:5.5629\n",
      "Pretrain epoch [12/57], ZINB loss:0.3970, NB loss:5.5229\n",
      "Pretrain epoch [13/57], ZINB loss:0.3842, NB loss:5.5019\n",
      "Pretrain epoch [14/57], ZINB loss:0.3899, NB loss:5.5644\n",
      "Pretrain epoch [15/57], ZINB loss:0.4032, NB loss:5.5053\n",
      "Pretrain epoch [16/57], ZINB loss:0.4079, NB loss:5.5080\n",
      "Pretrain epoch [17/57], ZINB loss:0.3844, NB loss:5.5420\n",
      "Pretrain epoch [18/57], ZINB loss:0.3978, NB loss:5.4885\n",
      "Pretrain epoch [19/57], ZINB loss:0.4094, NB loss:5.4729\n",
      "Pretrain epoch [20/57], ZINB loss:0.3957, NB loss:5.4801\n",
      "Pretrain epoch [21/57], ZINB loss:0.3993, NB loss:5.5735\n",
      "Pretrain epoch [22/57], ZINB loss:0.3782, NB loss:5.5310\n",
      "Pretrain epoch [23/57], ZINB loss:0.3761, NB loss:5.5227\n",
      "Pretrain epoch [24/57], ZINB loss:0.3848, NB loss:5.4921\n",
      "Pretrain epoch [25/57], ZINB loss:0.3810, NB loss:5.4863\n",
      "Pretrain epoch [26/57], ZINB loss:0.4001, NB loss:5.5249\n",
      "Pretrain epoch [27/57], ZINB loss:0.3924, NB loss:5.8042\n",
      "Pretrain epoch [1/58], ZINB loss:0.3873, NB loss:5.4543\n",
      "Pretrain epoch [2/58], ZINB loss:0.3862, NB loss:5.4730\n",
      "Pretrain epoch [3/58], ZINB loss:0.3782, NB loss:5.5066\n",
      "Pretrain epoch [4/58], ZINB loss:0.3924, NB loss:5.4738\n",
      "Pretrain epoch [5/58], ZINB loss:0.4167, NB loss:5.5489\n",
      "Pretrain epoch [6/58], ZINB loss:0.4114, NB loss:5.4313\n",
      "Pretrain epoch [7/58], ZINB loss:0.4145, NB loss:5.5044\n",
      "Pretrain epoch [8/58], ZINB loss:0.3976, NB loss:5.5328\n",
      "Pretrain epoch [9/58], ZINB loss:0.4023, NB loss:5.4867\n",
      "Pretrain epoch [10/58], ZINB loss:0.3951, NB loss:5.5716\n",
      "Pretrain epoch [11/58], ZINB loss:0.3857, NB loss:5.4948\n",
      "Pretrain epoch [12/58], ZINB loss:0.3791, NB loss:5.5052\n",
      "Pretrain epoch [13/58], ZINB loss:0.4124, NB loss:5.5154\n",
      "Pretrain epoch [14/58], ZINB loss:0.4076, NB loss:5.5472\n",
      "Pretrain epoch [15/58], ZINB loss:0.4053, NB loss:5.5628\n",
      "Pretrain epoch [16/58], ZINB loss:0.3807, NB loss:5.5166\n",
      "Pretrain epoch [17/58], ZINB loss:0.3902, NB loss:5.4608\n",
      "Pretrain epoch [18/58], ZINB loss:0.3944, NB loss:5.5215\n",
      "Pretrain epoch [19/58], ZINB loss:0.3973, NB loss:5.4910\n",
      "Pretrain epoch [20/58], ZINB loss:0.4009, NB loss:5.4802\n",
      "Pretrain epoch [21/58], ZINB loss:0.3934, NB loss:5.4560\n",
      "Pretrain epoch [22/58], ZINB loss:0.3910, NB loss:5.4858\n",
      "Pretrain epoch [23/58], ZINB loss:0.3825, NB loss:5.4555\n",
      "Pretrain epoch [24/58], ZINB loss:0.3641, NB loss:5.4856\n",
      "Pretrain epoch [25/58], ZINB loss:0.3801, NB loss:5.5646\n",
      "Pretrain epoch [26/58], ZINB loss:0.3977, NB loss:5.5157\n",
      "Pretrain epoch [27/58], ZINB loss:0.3589, NB loss:5.4521\n",
      "Pretrain epoch [1/59], ZINB loss:0.3867, NB loss:5.5169\n",
      "Pretrain epoch [2/59], ZINB loss:0.3950, NB loss:5.5014\n",
      "Pretrain epoch [3/59], ZINB loss:0.3834, NB loss:5.5017\n",
      "Pretrain epoch [4/59], ZINB loss:0.3917, NB loss:5.4870\n",
      "Pretrain epoch [5/59], ZINB loss:0.3791, NB loss:5.5000\n",
      "Pretrain epoch [6/59], ZINB loss:0.3805, NB loss:5.5069\n",
      "Pretrain epoch [7/59], ZINB loss:0.3863, NB loss:5.4916\n",
      "Pretrain epoch [8/59], ZINB loss:0.3953, NB loss:5.5128\n",
      "Pretrain epoch [9/59], ZINB loss:0.3774, NB loss:5.4618\n",
      "Pretrain epoch [10/59], ZINB loss:0.3956, NB loss:5.5321\n",
      "Pretrain epoch [11/59], ZINB loss:0.3803, NB loss:5.4386\n",
      "Pretrain epoch [12/59], ZINB loss:0.4089, NB loss:5.4812\n",
      "Pretrain epoch [13/59], ZINB loss:0.3895, NB loss:5.4360\n",
      "Pretrain epoch [14/59], ZINB loss:0.3935, NB loss:5.4690\n",
      "Pretrain epoch [15/59], ZINB loss:0.3986, NB loss:5.4819\n",
      "Pretrain epoch [16/59], ZINB loss:0.3927, NB loss:5.4686\n",
      "Pretrain epoch [17/59], ZINB loss:0.4057, NB loss:5.4791\n",
      "Pretrain epoch [18/59], ZINB loss:0.3863, NB loss:5.4382\n",
      "Pretrain epoch [19/59], ZINB loss:0.4029, NB loss:5.4657\n",
      "Pretrain epoch [20/59], ZINB loss:0.4099, NB loss:5.5016\n",
      "Pretrain epoch [21/59], ZINB loss:0.3938, NB loss:5.4811\n",
      "Pretrain epoch [22/59], ZINB loss:0.4033, NB loss:5.5165\n",
      "Pretrain epoch [23/59], ZINB loss:0.3934, NB loss:5.5284\n",
      "Pretrain epoch [24/59], ZINB loss:0.4141, NB loss:5.5117\n",
      "Pretrain epoch [25/59], ZINB loss:0.4022, NB loss:5.4651\n",
      "Pretrain epoch [26/59], ZINB loss:0.3914, NB loss:5.4819\n",
      "Pretrain epoch [27/59], ZINB loss:0.4019, NB loss:5.9931\n",
      "Pretrain epoch [1/60], ZINB loss:0.3917, NB loss:5.5155\n",
      "Pretrain epoch [2/60], ZINB loss:0.4051, NB loss:5.5012\n",
      "Pretrain epoch [3/60], ZINB loss:0.3907, NB loss:5.5198\n",
      "Pretrain epoch [4/60], ZINB loss:0.3754, NB loss:5.4705\n",
      "Pretrain epoch [5/60], ZINB loss:0.3846, NB loss:5.4785\n",
      "Pretrain epoch [6/60], ZINB loss:0.3975, NB loss:5.5437\n",
      "Pretrain epoch [7/60], ZINB loss:0.3951, NB loss:5.4855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [8/60], ZINB loss:0.3791, NB loss:5.4608\n",
      "Pretrain epoch [9/60], ZINB loss:0.3943, NB loss:5.4615\n",
      "Pretrain epoch [10/60], ZINB loss:0.4035, NB loss:5.4419\n",
      "Pretrain epoch [11/60], ZINB loss:0.3945, NB loss:5.4481\n",
      "Pretrain epoch [12/60], ZINB loss:0.3792, NB loss:5.4383\n",
      "Pretrain epoch [13/60], ZINB loss:0.3909, NB loss:5.4944\n",
      "Pretrain epoch [14/60], ZINB loss:0.3953, NB loss:5.4771\n",
      "Pretrain epoch [15/60], ZINB loss:0.3933, NB loss:5.5145\n",
      "Pretrain epoch [16/60], ZINB loss:0.3926, NB loss:5.4102\n",
      "Pretrain epoch [17/60], ZINB loss:0.3930, NB loss:5.4516\n",
      "Pretrain epoch [18/60], ZINB loss:0.3993, NB loss:5.4560\n",
      "Pretrain epoch [19/60], ZINB loss:0.3885, NB loss:5.4977\n",
      "Pretrain epoch [20/60], ZINB loss:0.3921, NB loss:5.4565\n",
      "Pretrain epoch [21/60], ZINB loss:0.3998, NB loss:5.4702\n",
      "Pretrain epoch [22/60], ZINB loss:0.4103, NB loss:5.4495\n",
      "Pretrain epoch [23/60], ZINB loss:0.3752, NB loss:5.4434\n",
      "Pretrain epoch [24/60], ZINB loss:0.4032, NB loss:5.5365\n",
      "Pretrain epoch [25/60], ZINB loss:0.4078, NB loss:5.4256\n",
      "Pretrain epoch [26/60], ZINB loss:0.3956, NB loss:5.4425\n",
      "Pretrain epoch [27/60], ZINB loss:0.4501, NB loss:5.9951\n",
      "Pretrain epoch [1/61], ZINB loss:0.3951, NB loss:5.4288\n",
      "Pretrain epoch [2/61], ZINB loss:0.4078, NB loss:5.4090\n",
      "Pretrain epoch [3/61], ZINB loss:0.3868, NB loss:5.4499\n",
      "Pretrain epoch [4/61], ZINB loss:0.4011, NB loss:5.5274\n",
      "Pretrain epoch [5/61], ZINB loss:0.3810, NB loss:5.4374\n",
      "Pretrain epoch [6/61], ZINB loss:0.3847, NB loss:5.5294\n",
      "Pretrain epoch [7/61], ZINB loss:0.3862, NB loss:5.4657\n",
      "Pretrain epoch [8/61], ZINB loss:0.4168, NB loss:5.4485\n",
      "Pretrain epoch [9/61], ZINB loss:0.3800, NB loss:5.4926\n",
      "Pretrain epoch [10/61], ZINB loss:0.3738, NB loss:5.4925\n",
      "Pretrain epoch [11/61], ZINB loss:0.3953, NB loss:5.4719\n",
      "Pretrain epoch [12/61], ZINB loss:0.4065, NB loss:5.4720\n",
      "Pretrain epoch [13/61], ZINB loss:0.3795, NB loss:5.4384\n",
      "Pretrain epoch [14/61], ZINB loss:0.4066, NB loss:5.4480\n",
      "Pretrain epoch [15/61], ZINB loss:0.3742, NB loss:5.5238\n",
      "Pretrain epoch [16/61], ZINB loss:0.4196, NB loss:5.4611\n",
      "Pretrain epoch [17/61], ZINB loss:0.3778, NB loss:5.4556\n",
      "Pretrain epoch [18/61], ZINB loss:0.3836, NB loss:5.3883\n",
      "Pretrain epoch [19/61], ZINB loss:0.3902, NB loss:5.4877\n",
      "Pretrain epoch [20/61], ZINB loss:0.3862, NB loss:5.4390\n",
      "Pretrain epoch [21/61], ZINB loss:0.3871, NB loss:5.4466\n",
      "Pretrain epoch [22/61], ZINB loss:0.3964, NB loss:5.4285\n",
      "Pretrain epoch [23/61], ZINB loss:0.3925, NB loss:5.4768\n",
      "Pretrain epoch [24/61], ZINB loss:0.4260, NB loss:5.4604\n",
      "Pretrain epoch [25/61], ZINB loss:0.3971, NB loss:5.4630\n",
      "Pretrain epoch [26/61], ZINB loss:0.3953, NB loss:5.4064\n",
      "Pretrain epoch [27/61], ZINB loss:0.3173, NB loss:5.1549\n",
      "Pretrain epoch [1/62], ZINB loss:0.3750, NB loss:5.4441\n",
      "Pretrain epoch [2/62], ZINB loss:0.3830, NB loss:5.3955\n",
      "Pretrain epoch [3/62], ZINB loss:0.3958, NB loss:5.4189\n",
      "Pretrain epoch [4/62], ZINB loss:0.3877, NB loss:5.4954\n",
      "Pretrain epoch [5/62], ZINB loss:0.3889, NB loss:5.4304\n",
      "Pretrain epoch [6/62], ZINB loss:0.3889, NB loss:5.4561\n",
      "Pretrain epoch [7/62], ZINB loss:0.4078, NB loss:5.4423\n",
      "Pretrain epoch [8/62], ZINB loss:0.4000, NB loss:5.4364\n",
      "Pretrain epoch [9/62], ZINB loss:0.3833, NB loss:5.4560\n",
      "Pretrain epoch [10/62], ZINB loss:0.4186, NB loss:5.5030\n",
      "Pretrain epoch [11/62], ZINB loss:0.3842, NB loss:5.4613\n",
      "Pretrain epoch [12/62], ZINB loss:0.3887, NB loss:5.4054\n",
      "Pretrain epoch [13/62], ZINB loss:0.3943, NB loss:5.4110\n",
      "Pretrain epoch [14/62], ZINB loss:0.3932, NB loss:5.4641\n",
      "Pretrain epoch [15/62], ZINB loss:0.3887, NB loss:5.4903\n",
      "Pretrain epoch [16/62], ZINB loss:0.3756, NB loss:5.4697\n",
      "Pretrain epoch [17/62], ZINB loss:0.3840, NB loss:5.4094\n",
      "Pretrain epoch [18/62], ZINB loss:0.3911, NB loss:5.4741\n",
      "Pretrain epoch [19/62], ZINB loss:0.4004, NB loss:5.4454\n",
      "Pretrain epoch [20/62], ZINB loss:0.3853, NB loss:5.4200\n",
      "Pretrain epoch [21/62], ZINB loss:0.3933, NB loss:5.4018\n",
      "Pretrain epoch [22/62], ZINB loss:0.4148, NB loss:5.4665\n",
      "Pretrain epoch [23/62], ZINB loss:0.4090, NB loss:5.4536\n",
      "Pretrain epoch [24/62], ZINB loss:0.3927, NB loss:5.4158\n",
      "Pretrain epoch [25/62], ZINB loss:0.3933, NB loss:5.4800\n",
      "Pretrain epoch [26/62], ZINB loss:0.3992, NB loss:5.4345\n",
      "Pretrain epoch [27/62], ZINB loss:0.3680, NB loss:5.4045\n",
      "Pretrain epoch [1/63], ZINB loss:0.3991, NB loss:5.4039\n",
      "Pretrain epoch [2/63], ZINB loss:0.3756, NB loss:5.4568\n",
      "Pretrain epoch [3/63], ZINB loss:0.4001, NB loss:5.4132\n",
      "Pretrain epoch [4/63], ZINB loss:0.3945, NB loss:5.4451\n",
      "Pretrain epoch [5/63], ZINB loss:0.4010, NB loss:5.4567\n",
      "Pretrain epoch [6/63], ZINB loss:0.3826, NB loss:5.4239\n",
      "Pretrain epoch [7/63], ZINB loss:0.3880, NB loss:5.4438\n",
      "Pretrain epoch [8/63], ZINB loss:0.3934, NB loss:5.4220\n",
      "Pretrain epoch [9/63], ZINB loss:0.3919, NB loss:5.4854\n",
      "Pretrain epoch [10/63], ZINB loss:0.3767, NB loss:5.4061\n",
      "Pretrain epoch [11/63], ZINB loss:0.4016, NB loss:5.4754\n",
      "Pretrain epoch [12/63], ZINB loss:0.4052, NB loss:5.3742\n",
      "Pretrain epoch [13/63], ZINB loss:0.4230, NB loss:5.4343\n",
      "Pretrain epoch [14/63], ZINB loss:0.3974, NB loss:5.4499\n",
      "Pretrain epoch [15/63], ZINB loss:0.3779, NB loss:5.4535\n",
      "Pretrain epoch [16/63], ZINB loss:0.3969, NB loss:5.4341\n",
      "Pretrain epoch [17/63], ZINB loss:0.3887, NB loss:5.3802\n",
      "Pretrain epoch [18/63], ZINB loss:0.3820, NB loss:5.4149\n",
      "Pretrain epoch [19/63], ZINB loss:0.3882, NB loss:5.5058\n",
      "Pretrain epoch [20/63], ZINB loss:0.3995, NB loss:5.4257\n",
      "Pretrain epoch [21/63], ZINB loss:0.4100, NB loss:5.3817\n",
      "Pretrain epoch [22/63], ZINB loss:0.3935, NB loss:5.4489\n",
      "Pretrain epoch [23/63], ZINB loss:0.3859, NB loss:5.3773\n",
      "Pretrain epoch [24/63], ZINB loss:0.4062, NB loss:5.4644\n",
      "Pretrain epoch [25/63], ZINB loss:0.3855, NB loss:5.4109\n",
      "Pretrain epoch [26/63], ZINB loss:0.3943, NB loss:5.4423\n",
      "Pretrain epoch [27/63], ZINB loss:0.2766, NB loss:5.5598\n",
      "Pretrain epoch [1/64], ZINB loss:0.3844, NB loss:5.4097\n",
      "Pretrain epoch [2/64], ZINB loss:0.3767, NB loss:5.3830\n",
      "Pretrain epoch [3/64], ZINB loss:0.3900, NB loss:5.3813\n",
      "Pretrain epoch [4/64], ZINB loss:0.3881, NB loss:5.4311\n",
      "Pretrain epoch [5/64], ZINB loss:0.4110, NB loss:5.4536\n",
      "Pretrain epoch [6/64], ZINB loss:0.3912, NB loss:5.4946\n",
      "Pretrain epoch [7/64], ZINB loss:0.3681, NB loss:5.3968\n",
      "Pretrain epoch [8/64], ZINB loss:0.3947, NB loss:5.4136\n",
      "Pretrain epoch [9/64], ZINB loss:0.3865, NB loss:5.3981\n",
      "Pretrain epoch [10/64], ZINB loss:0.3922, NB loss:5.4371\n",
      "Pretrain epoch [11/64], ZINB loss:0.4170, NB loss:5.4350\n",
      "Pretrain epoch [12/64], ZINB loss:0.3838, NB loss:5.4889\n",
      "Pretrain epoch [13/64], ZINB loss:0.3875, NB loss:5.3782\n",
      "Pretrain epoch [14/64], ZINB loss:0.3995, NB loss:5.4152\n",
      "Pretrain epoch [15/64], ZINB loss:0.3939, NB loss:5.3943\n",
      "Pretrain epoch [16/64], ZINB loss:0.3806, NB loss:5.3664\n",
      "Pretrain epoch [17/64], ZINB loss:0.3890, NB loss:5.3808\n",
      "Pretrain epoch [18/64], ZINB loss:0.3984, NB loss:5.4497\n",
      "Pretrain epoch [19/64], ZINB loss:0.3972, NB loss:5.4048\n",
      "Pretrain epoch [20/64], ZINB loss:0.4012, NB loss:5.4183\n",
      "Pretrain epoch [21/64], ZINB loss:0.3880, NB loss:5.3985\n",
      "Pretrain epoch [22/64], ZINB loss:0.4046, NB loss:5.4539\n",
      "Pretrain epoch [23/64], ZINB loss:0.3998, NB loss:5.4412\n",
      "Pretrain epoch [24/64], ZINB loss:0.3913, NB loss:5.3615\n",
      "Pretrain epoch [25/64], ZINB loss:0.4006, NB loss:5.4652\n",
      "Pretrain epoch [26/64], ZINB loss:0.4070, NB loss:5.4366\n",
      "Pretrain epoch [27/64], ZINB loss:0.3973, NB loss:5.4741\n",
      "Pretrain epoch [1/65], ZINB loss:0.3850, NB loss:5.4024\n",
      "Pretrain epoch [2/65], ZINB loss:0.3905, NB loss:5.3776\n",
      "Pretrain epoch [3/65], ZINB loss:0.3968, NB loss:5.4193\n",
      "Pretrain epoch [4/65], ZINB loss:0.3821, NB loss:5.4077\n",
      "Pretrain epoch [5/65], ZINB loss:0.3912, NB loss:5.3785\n",
      "Pretrain epoch [6/65], ZINB loss:0.4145, NB loss:5.4261\n",
      "Pretrain epoch [7/65], ZINB loss:0.3826, NB loss:5.4383\n",
      "Pretrain epoch [8/65], ZINB loss:0.3909, NB loss:5.3582\n",
      "Pretrain epoch [9/65], ZINB loss:0.3889, NB loss:5.4527\n",
      "Pretrain epoch [10/65], ZINB loss:0.4034, NB loss:5.4378\n",
      "Pretrain epoch [11/65], ZINB loss:0.3936, NB loss:5.3768\n",
      "Pretrain epoch [12/65], ZINB loss:0.3949, NB loss:5.4116\n",
      "Pretrain epoch [13/65], ZINB loss:0.3884, NB loss:5.4527\n",
      "Pretrain epoch [14/65], ZINB loss:0.3986, NB loss:5.3650\n",
      "Pretrain epoch [15/65], ZINB loss:0.4019, NB loss:5.3813\n",
      "Pretrain epoch [16/65], ZINB loss:0.3947, NB loss:5.3744\n",
      "Pretrain epoch [17/65], ZINB loss:0.3882, NB loss:5.4138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [18/65], ZINB loss:0.3986, NB loss:5.4288\n",
      "Pretrain epoch [19/65], ZINB loss:0.4021, NB loss:5.4098\n",
      "Pretrain epoch [20/65], ZINB loss:0.4089, NB loss:5.3413\n",
      "Pretrain epoch [21/65], ZINB loss:0.3804, NB loss:5.3940\n",
      "Pretrain epoch [22/65], ZINB loss:0.3985, NB loss:5.3769\n",
      "Pretrain epoch [23/65], ZINB loss:0.3876, NB loss:5.3992\n",
      "Pretrain epoch [24/65], ZINB loss:0.3908, NB loss:5.4314\n",
      "Pretrain epoch [25/65], ZINB loss:0.3977, NB loss:5.3883\n",
      "Pretrain epoch [26/65], ZINB loss:0.3850, NB loss:5.4916\n",
      "Pretrain epoch [27/65], ZINB loss:0.2245, NB loss:5.7986\n",
      "Pretrain epoch [1/66], ZINB loss:0.3807, NB loss:5.3713\n",
      "Pretrain epoch [2/66], ZINB loss:0.3886, NB loss:5.3750\n",
      "Pretrain epoch [3/66], ZINB loss:0.3871, NB loss:5.3284\n",
      "Pretrain epoch [4/66], ZINB loss:0.4005, NB loss:5.4033\n",
      "Pretrain epoch [5/66], ZINB loss:0.3956, NB loss:5.3969\n",
      "Pretrain epoch [6/66], ZINB loss:0.4056, NB loss:5.3991\n",
      "Pretrain epoch [7/66], ZINB loss:0.3874, NB loss:5.4225\n",
      "Pretrain epoch [8/66], ZINB loss:0.4021, NB loss:5.3714\n",
      "Pretrain epoch [9/66], ZINB loss:0.3915, NB loss:5.4319\n",
      "Pretrain epoch [10/66], ZINB loss:0.4073, NB loss:5.4273\n",
      "Pretrain epoch [11/66], ZINB loss:0.3769, NB loss:5.3778\n",
      "Pretrain epoch [12/66], ZINB loss:0.4000, NB loss:5.3631\n",
      "Pretrain epoch [13/66], ZINB loss:0.3898, NB loss:5.4203\n",
      "Pretrain epoch [14/66], ZINB loss:0.4010, NB loss:5.4231\n",
      "Pretrain epoch [15/66], ZINB loss:0.4059, NB loss:5.4225\n",
      "Pretrain epoch [16/66], ZINB loss:0.3863, NB loss:5.4148\n",
      "Pretrain epoch [17/66], ZINB loss:0.3831, NB loss:5.3612\n",
      "Pretrain epoch [18/66], ZINB loss:0.3969, NB loss:5.3748\n",
      "Pretrain epoch [19/66], ZINB loss:0.3800, NB loss:5.3940\n",
      "Pretrain epoch [20/66], ZINB loss:0.4058, NB loss:5.4006\n",
      "Pretrain epoch [21/66], ZINB loss:0.4026, NB loss:5.4287\n",
      "Pretrain epoch [22/66], ZINB loss:0.3891, NB loss:5.3911\n",
      "Pretrain epoch [23/66], ZINB loss:0.3800, NB loss:5.4510\n",
      "Pretrain epoch [24/66], ZINB loss:0.3909, NB loss:5.4109\n",
      "Pretrain epoch [25/66], ZINB loss:0.3817, NB loss:5.3320\n",
      "Pretrain epoch [26/66], ZINB loss:0.3999, NB loss:5.3241\n",
      "Pretrain epoch [27/66], ZINB loss:0.3739, NB loss:4.9047\n",
      "Pretrain epoch [1/67], ZINB loss:0.4032, NB loss:5.3816\n",
      "Pretrain epoch [2/67], ZINB loss:0.3941, NB loss:5.4524\n",
      "Pretrain epoch [3/67], ZINB loss:0.3914, NB loss:5.3772\n",
      "Pretrain epoch [4/67], ZINB loss:0.3911, NB loss:5.4140\n",
      "Pretrain epoch [5/67], ZINB loss:0.3768, NB loss:5.3665\n",
      "Pretrain epoch [6/67], ZINB loss:0.4009, NB loss:5.3916\n",
      "Pretrain epoch [7/67], ZINB loss:0.3909, NB loss:5.3703\n",
      "Pretrain epoch [8/67], ZINB loss:0.4048, NB loss:5.3763\n",
      "Pretrain epoch [9/67], ZINB loss:0.3795, NB loss:5.4018\n",
      "Pretrain epoch [10/67], ZINB loss:0.4084, NB loss:5.3922\n",
      "Pretrain epoch [11/67], ZINB loss:0.3746, NB loss:5.3699\n",
      "Pretrain epoch [12/67], ZINB loss:0.3969, NB loss:5.4307\n",
      "Pretrain epoch [13/67], ZINB loss:0.4148, NB loss:5.3569\n",
      "Pretrain epoch [14/67], ZINB loss:0.3962, NB loss:5.4102\n",
      "Pretrain epoch [15/67], ZINB loss:0.3746, NB loss:5.3908\n",
      "Pretrain epoch [16/67], ZINB loss:0.3977, NB loss:5.3772\n",
      "Pretrain epoch [17/67], ZINB loss:0.3716, NB loss:5.3628\n",
      "Pretrain epoch [18/67], ZINB loss:0.3705, NB loss:5.3625\n",
      "Pretrain epoch [19/67], ZINB loss:0.4042, NB loss:5.3743\n",
      "Pretrain epoch [20/67], ZINB loss:0.3982, NB loss:5.3726\n",
      "Pretrain epoch [21/67], ZINB loss:0.4022, NB loss:5.3786\n",
      "Pretrain epoch [22/67], ZINB loss:0.3747, NB loss:5.3650\n",
      "Pretrain epoch [23/67], ZINB loss:0.4014, NB loss:5.4090\n",
      "Pretrain epoch [24/67], ZINB loss:0.3963, NB loss:5.3299\n",
      "Pretrain epoch [25/67], ZINB loss:0.3943, NB loss:5.3416\n",
      "Pretrain epoch [26/67], ZINB loss:0.4073, NB loss:5.3188\n",
      "Pretrain epoch [27/67], ZINB loss:0.3685, NB loss:5.5333\n",
      "Pretrain epoch [1/68], ZINB loss:0.3966, NB loss:5.4075\n",
      "Pretrain epoch [2/68], ZINB loss:0.4045, NB loss:5.3498\n",
      "Pretrain epoch [3/68], ZINB loss:0.4147, NB loss:5.3451\n",
      "Pretrain epoch [4/68], ZINB loss:0.3939, NB loss:5.3818\n",
      "Pretrain epoch [5/68], ZINB loss:0.3765, NB loss:5.3584\n",
      "Pretrain epoch [6/68], ZINB loss:0.4007, NB loss:5.3919\n",
      "Pretrain epoch [7/68], ZINB loss:0.3996, NB loss:5.3546\n",
      "Pretrain epoch [8/68], ZINB loss:0.4029, NB loss:5.3598\n",
      "Pretrain epoch [9/68], ZINB loss:0.3795, NB loss:5.3291\n",
      "Pretrain epoch [10/68], ZINB loss:0.3914, NB loss:5.3565\n",
      "Pretrain epoch [11/68], ZINB loss:0.3843, NB loss:5.3217\n",
      "Pretrain epoch [12/68], ZINB loss:0.3992, NB loss:5.3972\n",
      "Pretrain epoch [13/68], ZINB loss:0.3891, NB loss:5.3977\n",
      "Pretrain epoch [14/68], ZINB loss:0.3862, NB loss:5.4217\n",
      "Pretrain epoch [15/68], ZINB loss:0.3748, NB loss:5.3106\n",
      "Pretrain epoch [16/68], ZINB loss:0.3916, NB loss:5.3725\n",
      "Pretrain epoch [17/68], ZINB loss:0.3833, NB loss:5.4033\n",
      "Pretrain epoch [18/68], ZINB loss:0.3954, NB loss:5.3233\n",
      "Pretrain epoch [19/68], ZINB loss:0.3880, NB loss:5.3783\n",
      "Pretrain epoch [20/68], ZINB loss:0.4004, NB loss:5.3283\n",
      "Pretrain epoch [21/68], ZINB loss:0.4105, NB loss:5.3951\n",
      "Pretrain epoch [22/68], ZINB loss:0.3728, NB loss:5.2990\n",
      "Pretrain epoch [23/68], ZINB loss:0.3984, NB loss:5.4011\n",
      "Pretrain epoch [24/68], ZINB loss:0.3870, NB loss:5.3803\n",
      "Pretrain epoch [25/68], ZINB loss:0.4039, NB loss:5.3995\n",
      "Pretrain epoch [26/68], ZINB loss:0.3889, NB loss:5.3881\n",
      "Pretrain epoch [27/68], ZINB loss:0.3791, NB loss:5.3297\n",
      "Pretrain epoch [1/69], ZINB loss:0.4015, NB loss:5.3225\n",
      "Pretrain epoch [2/69], ZINB loss:0.4132, NB loss:5.3455\n",
      "Pretrain epoch [3/69], ZINB loss:0.3952, NB loss:5.3560\n",
      "Pretrain epoch [4/69], ZINB loss:0.3813, NB loss:5.3641\n",
      "Pretrain epoch [5/69], ZINB loss:0.4076, NB loss:5.3349\n",
      "Pretrain epoch [6/69], ZINB loss:0.3936, NB loss:5.3605\n",
      "Pretrain epoch [7/69], ZINB loss:0.3921, NB loss:5.3305\n",
      "Pretrain epoch [8/69], ZINB loss:0.3901, NB loss:5.4011\n",
      "Pretrain epoch [9/69], ZINB loss:0.3841, NB loss:5.3813\n",
      "Pretrain epoch [10/69], ZINB loss:0.3972, NB loss:5.3620\n",
      "Pretrain epoch [11/69], ZINB loss:0.4193, NB loss:5.3430\n",
      "Pretrain epoch [12/69], ZINB loss:0.3934, NB loss:5.3349\n",
      "Pretrain epoch [13/69], ZINB loss:0.3935, NB loss:5.3406\n",
      "Pretrain epoch [14/69], ZINB loss:0.3752, NB loss:5.3615\n",
      "Pretrain epoch [15/69], ZINB loss:0.3817, NB loss:5.3438\n",
      "Pretrain epoch [16/69], ZINB loss:0.3842, NB loss:5.3706\n",
      "Pretrain epoch [17/69], ZINB loss:0.4042, NB loss:5.3903\n",
      "Pretrain epoch [18/69], ZINB loss:0.3907, NB loss:5.3119\n",
      "Pretrain epoch [19/69], ZINB loss:0.3788, NB loss:5.4210\n",
      "Pretrain epoch [20/69], ZINB loss:0.3851, NB loss:5.3030\n",
      "Pretrain epoch [21/69], ZINB loss:0.3933, NB loss:5.3677\n",
      "Pretrain epoch [22/69], ZINB loss:0.3990, NB loss:5.3851\n",
      "Pretrain epoch [23/69], ZINB loss:0.3873, NB loss:5.3789\n",
      "Pretrain epoch [24/69], ZINB loss:0.3974, NB loss:5.3472\n",
      "Pretrain epoch [25/69], ZINB loss:0.4032, NB loss:5.3281\n",
      "Pretrain epoch [26/69], ZINB loss:0.3890, NB loss:5.3491\n",
      "Pretrain epoch [27/69], ZINB loss:0.2953, NB loss:5.3692\n",
      "Pretrain epoch [1/70], ZINB loss:0.4080, NB loss:5.3674\n",
      "Pretrain epoch [2/70], ZINB loss:0.3823, NB loss:5.3495\n",
      "Pretrain epoch [3/70], ZINB loss:0.4033, NB loss:5.3312\n",
      "Pretrain epoch [4/70], ZINB loss:0.3948, NB loss:5.4031\n",
      "Pretrain epoch [5/70], ZINB loss:0.3970, NB loss:5.3834\n",
      "Pretrain epoch [6/70], ZINB loss:0.3841, NB loss:5.3468\n",
      "Pretrain epoch [7/70], ZINB loss:0.3914, NB loss:5.3527\n",
      "Pretrain epoch [8/70], ZINB loss:0.4140, NB loss:5.3091\n",
      "Pretrain epoch [9/70], ZINB loss:0.3839, NB loss:5.3169\n",
      "Pretrain epoch [10/70], ZINB loss:0.3970, NB loss:5.3026\n",
      "Pretrain epoch [11/70], ZINB loss:0.3956, NB loss:5.3622\n",
      "Pretrain epoch [12/70], ZINB loss:0.3967, NB loss:5.3732\n",
      "Pretrain epoch [13/70], ZINB loss:0.3921, NB loss:5.3020\n",
      "Pretrain epoch [14/70], ZINB loss:0.3889, NB loss:5.4203\n",
      "Pretrain epoch [15/70], ZINB loss:0.3962, NB loss:5.3089\n",
      "Pretrain epoch [16/70], ZINB loss:0.3873, NB loss:5.3089\n",
      "Pretrain epoch [17/70], ZINB loss:0.4007, NB loss:5.2989\n",
      "Pretrain epoch [18/70], ZINB loss:0.3947, NB loss:5.3621\n",
      "Pretrain epoch [19/70], ZINB loss:0.3953, NB loss:5.4103\n",
      "Pretrain epoch [20/70], ZINB loss:0.3993, NB loss:5.3165\n",
      "Pretrain epoch [21/70], ZINB loss:0.3871, NB loss:5.3382\n",
      "Pretrain epoch [22/70], ZINB loss:0.3990, NB loss:5.3254\n",
      "Pretrain epoch [23/70], ZINB loss:0.3779, NB loss:5.2701\n",
      "Pretrain epoch [24/70], ZINB loss:0.3803, NB loss:5.3320\n",
      "Pretrain epoch [25/70], ZINB loss:0.3872, NB loss:5.3573\n",
      "Pretrain epoch [26/70], ZINB loss:0.3829, NB loss:5.3791\n",
      "Pretrain epoch [27/70], ZINB loss:0.4073, NB loss:5.2459\n",
      "Pretrain epoch [1/71], ZINB loss:0.3981, NB loss:5.3396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [2/71], ZINB loss:0.3933, NB loss:5.3484\n",
      "Pretrain epoch [3/71], ZINB loss:0.3759, NB loss:5.3626\n",
      "Pretrain epoch [4/71], ZINB loss:0.3775, NB loss:5.3408\n",
      "Pretrain epoch [5/71], ZINB loss:0.3692, NB loss:5.3452\n",
      "Pretrain epoch [6/71], ZINB loss:0.3800, NB loss:5.3767\n",
      "Pretrain epoch [7/71], ZINB loss:0.4024, NB loss:5.3632\n",
      "Pretrain epoch [8/71], ZINB loss:0.3738, NB loss:5.2945\n",
      "Pretrain epoch [9/71], ZINB loss:0.4039, NB loss:5.2967\n",
      "Pretrain epoch [10/71], ZINB loss:0.3888, NB loss:5.3966\n",
      "Pretrain epoch [11/71], ZINB loss:0.4177, NB loss:5.3427\n",
      "Pretrain epoch [12/71], ZINB loss:0.3902, NB loss:5.3806\n",
      "Pretrain epoch [13/71], ZINB loss:0.4108, NB loss:5.2885\n",
      "Pretrain epoch [14/71], ZINB loss:0.4077, NB loss:5.3336\n",
      "Pretrain epoch [15/71], ZINB loss:0.3865, NB loss:5.4067\n",
      "Pretrain epoch [16/71], ZINB loss:0.3913, NB loss:5.2926\n",
      "Pretrain epoch [17/71], ZINB loss:0.4002, NB loss:5.2671\n",
      "Pretrain epoch [18/71], ZINB loss:0.4031, NB loss:5.3338\n",
      "Pretrain epoch [19/71], ZINB loss:0.3834, NB loss:5.2686\n",
      "Pretrain epoch [20/71], ZINB loss:0.3950, NB loss:5.3688\n",
      "Pretrain epoch [21/71], ZINB loss:0.4180, NB loss:5.3292\n",
      "Pretrain epoch [22/71], ZINB loss:0.3763, NB loss:5.3113\n",
      "Pretrain epoch [23/71], ZINB loss:0.3860, NB loss:5.2915\n",
      "Pretrain epoch [24/71], ZINB loss:0.3971, NB loss:5.3175\n",
      "Pretrain epoch [25/71], ZINB loss:0.3958, NB loss:5.3286\n",
      "Pretrain epoch [26/71], ZINB loss:0.3967, NB loss:5.3087\n",
      "Pretrain epoch [27/71], ZINB loss:0.4813, NB loss:5.0901\n",
      "Pretrain epoch [1/72], ZINB loss:0.3927, NB loss:5.3167\n",
      "Pretrain epoch [2/72], ZINB loss:0.3886, NB loss:5.3358\n",
      "Pretrain epoch [3/72], ZINB loss:0.3969, NB loss:5.3695\n",
      "Pretrain epoch [4/72], ZINB loss:0.3887, NB loss:5.3098\n",
      "Pretrain epoch [5/72], ZINB loss:0.3894, NB loss:5.3555\n",
      "Pretrain epoch [6/72], ZINB loss:0.3814, NB loss:5.4035\n",
      "Pretrain epoch [7/72], ZINB loss:0.4047, NB loss:5.3229\n",
      "Pretrain epoch [8/72], ZINB loss:0.3972, NB loss:5.2772\n",
      "Pretrain epoch [9/72], ZINB loss:0.3736, NB loss:5.3231\n",
      "Pretrain epoch [10/72], ZINB loss:0.3910, NB loss:5.3312\n",
      "Pretrain epoch [11/72], ZINB loss:0.3945, NB loss:5.3359\n",
      "Pretrain epoch [12/72], ZINB loss:0.3951, NB loss:5.2473\n",
      "Pretrain epoch [13/72], ZINB loss:0.3925, NB loss:5.3520\n",
      "Pretrain epoch [14/72], ZINB loss:0.4176, NB loss:5.2788\n",
      "Pretrain epoch [15/72], ZINB loss:0.4051, NB loss:5.2790\n",
      "Pretrain epoch [16/72], ZINB loss:0.3874, NB loss:5.3623\n",
      "Pretrain epoch [17/72], ZINB loss:0.3787, NB loss:5.3197\n",
      "Pretrain epoch [18/72], ZINB loss:0.3993, NB loss:5.2697\n",
      "Pretrain epoch [19/72], ZINB loss:0.3831, NB loss:5.2969\n",
      "Pretrain epoch [20/72], ZINB loss:0.4019, NB loss:5.3158\n",
      "Pretrain epoch [21/72], ZINB loss:0.3841, NB loss:5.3119\n",
      "Pretrain epoch [22/72], ZINB loss:0.4007, NB loss:5.3277\n",
      "Pretrain epoch [23/72], ZINB loss:0.3999, NB loss:5.3611\n",
      "Pretrain epoch [24/72], ZINB loss:0.3932, NB loss:5.3044\n",
      "Pretrain epoch [25/72], ZINB loss:0.3938, NB loss:5.3909\n",
      "Pretrain epoch [26/72], ZINB loss:0.3914, NB loss:5.2368\n",
      "Pretrain epoch [27/72], ZINB loss:0.3492, NB loss:4.9686\n",
      "Pretrain epoch [1/73], ZINB loss:0.3946, NB loss:5.3591\n",
      "Pretrain epoch [2/73], ZINB loss:0.3742, NB loss:5.3025\n",
      "Pretrain epoch [3/73], ZINB loss:0.3977, NB loss:5.3154\n",
      "Pretrain epoch [4/73], ZINB loss:0.3876, NB loss:5.3198\n",
      "Pretrain epoch [5/73], ZINB loss:0.3995, NB loss:5.3156\n",
      "Pretrain epoch [6/73], ZINB loss:0.3958, NB loss:5.3239\n",
      "Pretrain epoch [7/73], ZINB loss:0.3990, NB loss:5.3141\n",
      "Pretrain epoch [8/73], ZINB loss:0.3873, NB loss:5.3490\n",
      "Pretrain epoch [9/73], ZINB loss:0.3987, NB loss:5.3261\n",
      "Pretrain epoch [10/73], ZINB loss:0.3922, NB loss:5.2438\n",
      "Pretrain epoch [11/73], ZINB loss:0.3932, NB loss:5.2858\n",
      "Pretrain epoch [12/73], ZINB loss:0.3842, NB loss:5.2841\n",
      "Pretrain epoch [13/73], ZINB loss:0.4032, NB loss:5.3007\n",
      "Pretrain epoch [14/73], ZINB loss:0.3987, NB loss:5.3390\n",
      "Pretrain epoch [15/73], ZINB loss:0.3955, NB loss:5.3170\n",
      "Pretrain epoch [16/73], ZINB loss:0.3992, NB loss:5.3207\n",
      "Pretrain epoch [17/73], ZINB loss:0.3839, NB loss:5.3608\n",
      "Pretrain epoch [18/73], ZINB loss:0.4005, NB loss:5.3029\n",
      "Pretrain epoch [19/73], ZINB loss:0.4021, NB loss:5.3119\n",
      "Pretrain epoch [20/73], ZINB loss:0.3751, NB loss:5.2601\n",
      "Pretrain epoch [21/73], ZINB loss:0.4076, NB loss:5.3506\n",
      "Pretrain epoch [22/73], ZINB loss:0.3749, NB loss:5.2440\n",
      "Pretrain epoch [23/73], ZINB loss:0.4139, NB loss:5.2994\n",
      "Pretrain epoch [24/73], ZINB loss:0.3851, NB loss:5.3062\n",
      "Pretrain epoch [25/73], ZINB loss:0.3884, NB loss:5.2648\n",
      "Pretrain epoch [26/73], ZINB loss:0.3949, NB loss:5.3195\n",
      "Pretrain epoch [27/73], ZINB loss:0.2956, NB loss:5.2844\n",
      "Pretrain epoch [1/74], ZINB loss:0.3871, NB loss:5.2353\n",
      "Pretrain epoch [2/74], ZINB loss:0.3913, NB loss:5.2937\n",
      "Pretrain epoch [3/74], ZINB loss:0.4015, NB loss:5.2834\n",
      "Pretrain epoch [4/74], ZINB loss:0.4013, NB loss:5.2865\n",
      "Pretrain epoch [5/74], ZINB loss:0.4016, NB loss:5.2871\n",
      "Pretrain epoch [6/74], ZINB loss:0.3759, NB loss:5.3263\n",
      "Pretrain epoch [7/74], ZINB loss:0.3767, NB loss:5.3027\n",
      "Pretrain epoch [8/74], ZINB loss:0.4128, NB loss:5.2921\n",
      "Pretrain epoch [9/74], ZINB loss:0.3826, NB loss:5.3613\n",
      "Pretrain epoch [10/74], ZINB loss:0.3830, NB loss:5.3153\n",
      "Pretrain epoch [11/74], ZINB loss:0.3889, NB loss:5.2980\n",
      "Pretrain epoch [12/74], ZINB loss:0.4068, NB loss:5.3107\n",
      "Pretrain epoch [13/74], ZINB loss:0.4102, NB loss:5.3192\n",
      "Pretrain epoch [14/74], ZINB loss:0.3968, NB loss:5.2904\n",
      "Pretrain epoch [15/74], ZINB loss:0.3919, NB loss:5.3177\n",
      "Pretrain epoch [16/74], ZINB loss:0.4034, NB loss:5.3514\n",
      "Pretrain epoch [17/74], ZINB loss:0.3969, NB loss:5.2890\n",
      "Pretrain epoch [18/74], ZINB loss:0.3968, NB loss:5.3145\n",
      "Pretrain epoch [19/74], ZINB loss:0.4011, NB loss:5.3017\n",
      "Pretrain epoch [20/74], ZINB loss:0.3807, NB loss:5.2798\n",
      "Pretrain epoch [21/74], ZINB loss:0.3896, NB loss:5.3132\n",
      "Pretrain epoch [22/74], ZINB loss:0.3945, NB loss:5.2868\n",
      "Pretrain epoch [23/74], ZINB loss:0.3928, NB loss:5.2444\n",
      "Pretrain epoch [24/74], ZINB loss:0.3782, NB loss:5.2788\n",
      "Pretrain epoch [25/74], ZINB loss:0.3842, NB loss:5.3138\n",
      "Pretrain epoch [26/74], ZINB loss:0.3826, NB loss:5.2645\n",
      "Pretrain epoch [27/74], ZINB loss:0.5179, NB loss:5.1541\n",
      "Pretrain epoch [1/75], ZINB loss:0.3815, NB loss:5.2142\n",
      "Pretrain epoch [2/75], ZINB loss:0.3986, NB loss:5.2835\n",
      "Pretrain epoch [3/75], ZINB loss:0.3974, NB loss:5.3035\n",
      "Pretrain epoch [4/75], ZINB loss:0.4029, NB loss:5.3477\n",
      "Pretrain epoch [5/75], ZINB loss:0.3981, NB loss:5.3753\n",
      "Pretrain epoch [6/75], ZINB loss:0.4074, NB loss:5.3214\n",
      "Pretrain epoch [7/75], ZINB loss:0.4016, NB loss:5.2809\n",
      "Pretrain epoch [8/75], ZINB loss:0.3945, NB loss:5.2972\n",
      "Pretrain epoch [9/75], ZINB loss:0.3945, NB loss:5.2448\n",
      "Pretrain epoch [10/75], ZINB loss:0.3941, NB loss:5.2856\n",
      "Pretrain epoch [11/75], ZINB loss:0.3950, NB loss:5.2739\n",
      "Pretrain epoch [12/75], ZINB loss:0.3877, NB loss:5.2955\n",
      "Pretrain epoch [13/75], ZINB loss:0.3917, NB loss:5.2819\n",
      "Pretrain epoch [14/75], ZINB loss:0.3722, NB loss:5.2737\n",
      "Pretrain epoch [15/75], ZINB loss:0.3982, NB loss:5.2600\n",
      "Pretrain epoch [16/75], ZINB loss:0.3942, NB loss:5.2374\n",
      "Pretrain epoch [17/75], ZINB loss:0.3998, NB loss:5.3240\n",
      "Pretrain epoch [18/75], ZINB loss:0.4132, NB loss:5.2528\n",
      "Pretrain epoch [19/75], ZINB loss:0.3905, NB loss:5.3411\n",
      "Pretrain epoch [20/75], ZINB loss:0.3911, NB loss:5.2600\n",
      "Pretrain epoch [21/75], ZINB loss:0.3994, NB loss:5.2994\n",
      "Pretrain epoch [22/75], ZINB loss:0.3776, NB loss:5.2866\n",
      "Pretrain epoch [23/75], ZINB loss:0.4111, NB loss:5.2253\n",
      "Pretrain epoch [24/75], ZINB loss:0.3899, NB loss:5.3716\n",
      "Pretrain epoch [25/75], ZINB loss:0.3690, NB loss:5.2627\n",
      "Pretrain epoch [26/75], ZINB loss:0.3784, NB loss:5.2880\n",
      "Pretrain epoch [27/75], ZINB loss:0.3061, NB loss:5.1055\n",
      "Pretrain epoch [1/76], ZINB loss:0.3869, NB loss:5.3203\n",
      "Pretrain epoch [2/76], ZINB loss:0.4019, NB loss:5.2759\n",
      "Pretrain epoch [3/76], ZINB loss:0.3911, NB loss:5.3620\n",
      "Pretrain epoch [4/76], ZINB loss:0.3995, NB loss:5.2943\n",
      "Pretrain epoch [5/76], ZINB loss:0.3769, NB loss:5.2250\n",
      "Pretrain epoch [6/76], ZINB loss:0.3951, NB loss:5.3123\n",
      "Pretrain epoch [7/76], ZINB loss:0.3906, NB loss:5.2242\n",
      "Pretrain epoch [8/76], ZINB loss:0.4001, NB loss:5.2891\n",
      "Pretrain epoch [9/76], ZINB loss:0.4128, NB loss:5.2626\n",
      "Pretrain epoch [10/76], ZINB loss:0.3806, NB loss:5.2843\n",
      "Pretrain epoch [11/76], ZINB loss:0.4036, NB loss:5.2726\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [12/76], ZINB loss:0.3800, NB loss:5.2891\n",
      "Pretrain epoch [13/76], ZINB loss:0.3803, NB loss:5.2706\n",
      "Pretrain epoch [14/76], ZINB loss:0.3927, NB loss:5.2706\n",
      "Pretrain epoch [15/76], ZINB loss:0.3798, NB loss:5.3472\n",
      "Pretrain epoch [16/76], ZINB loss:0.3889, NB loss:5.2621\n",
      "Pretrain epoch [17/76], ZINB loss:0.4132, NB loss:5.2359\n",
      "Pretrain epoch [18/76], ZINB loss:0.4054, NB loss:5.2509\n",
      "Pretrain epoch [19/76], ZINB loss:0.3734, NB loss:5.2806\n",
      "Pretrain epoch [20/76], ZINB loss:0.4019, NB loss:5.2365\n",
      "Pretrain epoch [21/76], ZINB loss:0.3895, NB loss:5.2463\n",
      "Pretrain epoch [22/76], ZINB loss:0.3760, NB loss:5.2640\n",
      "Pretrain epoch [23/76], ZINB loss:0.3889, NB loss:5.3104\n",
      "Pretrain epoch [24/76], ZINB loss:0.4107, NB loss:5.3039\n",
      "Pretrain epoch [25/76], ZINB loss:0.4032, NB loss:5.2703\n",
      "Pretrain epoch [26/76], ZINB loss:0.3868, NB loss:5.2545\n",
      "Pretrain epoch [27/76], ZINB loss:0.5631, NB loss:4.9933\n",
      "Pretrain epoch [1/77], ZINB loss:0.3792, NB loss:5.2607\n",
      "Pretrain epoch [2/77], ZINB loss:0.3770, NB loss:5.2165\n",
      "Pretrain epoch [3/77], ZINB loss:0.3921, NB loss:5.2568\n",
      "Pretrain epoch [4/77], ZINB loss:0.3818, NB loss:5.2477\n",
      "Pretrain epoch [5/77], ZINB loss:0.4010, NB loss:5.2560\n",
      "Pretrain epoch [6/77], ZINB loss:0.4060, NB loss:5.1931\n",
      "Pretrain epoch [7/77], ZINB loss:0.3777, NB loss:5.2475\n",
      "Pretrain epoch [8/77], ZINB loss:0.3971, NB loss:5.3511\n",
      "Pretrain epoch [9/77], ZINB loss:0.3960, NB loss:5.2614\n",
      "Pretrain epoch [10/77], ZINB loss:0.3819, NB loss:5.3008\n",
      "Pretrain epoch [11/77], ZINB loss:0.3998, NB loss:5.2600\n",
      "Pretrain epoch [12/77], ZINB loss:0.4096, NB loss:5.2889\n",
      "Pretrain epoch [13/77], ZINB loss:0.4076, NB loss:5.2608\n",
      "Pretrain epoch [14/77], ZINB loss:0.3968, NB loss:5.3182\n",
      "Pretrain epoch [15/77], ZINB loss:0.3936, NB loss:5.2026\n",
      "Pretrain epoch [16/77], ZINB loss:0.4059, NB loss:5.2508\n",
      "Pretrain epoch [17/77], ZINB loss:0.4049, NB loss:5.2464\n",
      "Pretrain epoch [18/77], ZINB loss:0.3869, NB loss:5.2560\n",
      "Pretrain epoch [19/77], ZINB loss:0.3966, NB loss:5.3007\n",
      "Pretrain epoch [20/77], ZINB loss:0.3883, NB loss:5.2729\n",
      "Pretrain epoch [21/77], ZINB loss:0.3838, NB loss:5.2142\n",
      "Pretrain epoch [22/77], ZINB loss:0.3848, NB loss:5.3088\n",
      "Pretrain epoch [23/77], ZINB loss:0.3765, NB loss:5.2930\n",
      "Pretrain epoch [24/77], ZINB loss:0.4159, NB loss:5.2613\n",
      "Pretrain epoch [25/77], ZINB loss:0.3858, NB loss:5.3001\n",
      "Pretrain epoch [26/77], ZINB loss:0.3992, NB loss:5.3114\n",
      "Pretrain epoch [27/77], ZINB loss:0.2967, NB loss:5.5803\n",
      "Pretrain epoch [1/78], ZINB loss:0.4006, NB loss:5.2972\n",
      "Pretrain epoch [2/78], ZINB loss:0.3793, NB loss:5.2117\n",
      "Pretrain epoch [3/78], ZINB loss:0.4140, NB loss:5.2767\n",
      "Pretrain epoch [4/78], ZINB loss:0.4089, NB loss:5.3226\n",
      "Pretrain epoch [5/78], ZINB loss:0.3972, NB loss:5.2507\n",
      "Pretrain epoch [6/78], ZINB loss:0.4046, NB loss:5.2576\n",
      "Pretrain epoch [7/78], ZINB loss:0.3878, NB loss:5.2987\n",
      "Pretrain epoch [8/78], ZINB loss:0.3863, NB loss:5.2487\n",
      "Pretrain epoch [9/78], ZINB loss:0.3878, NB loss:5.2700\n",
      "Pretrain epoch [10/78], ZINB loss:0.3806, NB loss:5.2642\n",
      "Pretrain epoch [11/78], ZINB loss:0.3896, NB loss:5.2191\n",
      "Pretrain epoch [12/78], ZINB loss:0.3956, NB loss:5.2660\n",
      "Pretrain epoch [13/78], ZINB loss:0.3891, NB loss:5.2508\n",
      "Pretrain epoch [14/78], ZINB loss:0.3882, NB loss:5.2422\n",
      "Pretrain epoch [15/78], ZINB loss:0.3986, NB loss:5.3003\n",
      "Pretrain epoch [16/78], ZINB loss:0.3838, NB loss:5.2512\n",
      "Pretrain epoch [17/78], ZINB loss:0.3914, NB loss:5.2182\n",
      "Pretrain epoch [18/78], ZINB loss:0.3788, NB loss:5.2408\n",
      "Pretrain epoch [19/78], ZINB loss:0.3965, NB loss:5.2812\n",
      "Pretrain epoch [20/78], ZINB loss:0.3960, NB loss:5.2069\n",
      "Pretrain epoch [21/78], ZINB loss:0.3772, NB loss:5.2442\n",
      "Pretrain epoch [22/78], ZINB loss:0.3959, NB loss:5.2768\n",
      "Pretrain epoch [23/78], ZINB loss:0.4114, NB loss:5.2340\n",
      "Pretrain epoch [24/78], ZINB loss:0.4012, NB loss:5.2533\n",
      "Pretrain epoch [25/78], ZINB loss:0.3896, NB loss:5.2682\n",
      "Pretrain epoch [26/78], ZINB loss:0.3722, NB loss:5.2358\n",
      "Pretrain epoch [27/78], ZINB loss:0.3161, NB loss:5.4739\n",
      "Pretrain epoch [1/79], ZINB loss:0.3755, NB loss:5.2350\n",
      "Pretrain epoch [2/79], ZINB loss:0.3797, NB loss:5.2558\n",
      "Pretrain epoch [3/79], ZINB loss:0.3843, NB loss:5.2606\n",
      "Pretrain epoch [4/79], ZINB loss:0.3899, NB loss:5.2519\n",
      "Pretrain epoch [5/79], ZINB loss:0.3984, NB loss:5.2778\n",
      "Pretrain epoch [6/79], ZINB loss:0.4106, NB loss:5.2524\n",
      "Pretrain epoch [7/79], ZINB loss:0.3800, NB loss:5.2206\n",
      "Pretrain epoch [8/79], ZINB loss:0.3882, NB loss:5.2312\n",
      "Pretrain epoch [9/79], ZINB loss:0.4052, NB loss:5.2786\n",
      "Pretrain epoch [10/79], ZINB loss:0.3794, NB loss:5.2520\n",
      "Pretrain epoch [11/79], ZINB loss:0.3778, NB loss:5.2138\n",
      "Pretrain epoch [12/79], ZINB loss:0.4003, NB loss:5.2560\n",
      "Pretrain epoch [13/79], ZINB loss:0.3876, NB loss:5.2727\n",
      "Pretrain epoch [14/79], ZINB loss:0.3875, NB loss:5.2319\n",
      "Pretrain epoch [15/79], ZINB loss:0.4051, NB loss:5.1847\n",
      "Pretrain epoch [16/79], ZINB loss:0.3964, NB loss:5.2369\n",
      "Pretrain epoch [17/79], ZINB loss:0.4007, NB loss:5.2903\n",
      "Pretrain epoch [18/79], ZINB loss:0.4051, NB loss:5.2533\n",
      "Pretrain epoch [19/79], ZINB loss:0.4041, NB loss:5.2816\n",
      "Pretrain epoch [20/79], ZINB loss:0.4035, NB loss:5.3225\n",
      "Pretrain epoch [21/79], ZINB loss:0.3855, NB loss:5.2846\n",
      "Pretrain epoch [22/79], ZINB loss:0.4006, NB loss:5.2296\n",
      "Pretrain epoch [23/79], ZINB loss:0.3766, NB loss:5.2524\n",
      "Pretrain epoch [24/79], ZINB loss:0.4014, NB loss:5.2448\n",
      "Pretrain epoch [25/79], ZINB loss:0.3867, NB loss:5.1431\n",
      "Pretrain epoch [26/79], ZINB loss:0.3949, NB loss:5.2187\n",
      "Pretrain epoch [27/79], ZINB loss:0.3073, NB loss:5.2993\n",
      "Pretrain epoch [1/80], ZINB loss:0.3709, NB loss:5.2831\n",
      "Pretrain epoch [2/80], ZINB loss:0.4006, NB loss:5.2452\n",
      "Pretrain epoch [3/80], ZINB loss:0.3910, NB loss:5.2766\n",
      "Pretrain epoch [4/80], ZINB loss:0.3919, NB loss:5.2464\n",
      "Pretrain epoch [5/80], ZINB loss:0.4059, NB loss:5.2440\n",
      "Pretrain epoch [6/80], ZINB loss:0.3901, NB loss:5.2592\n",
      "Pretrain epoch [7/80], ZINB loss:0.3867, NB loss:5.2708\n",
      "Pretrain epoch [8/80], ZINB loss:0.4034, NB loss:5.2541\n",
      "Pretrain epoch [9/80], ZINB loss:0.3764, NB loss:5.2493\n",
      "Pretrain epoch [10/80], ZINB loss:0.3934, NB loss:5.2324\n",
      "Pretrain epoch [11/80], ZINB loss:0.3870, NB loss:5.2274\n",
      "Pretrain epoch [12/80], ZINB loss:0.3944, NB loss:5.2473\n",
      "Pretrain epoch [13/80], ZINB loss:0.4150, NB loss:5.2267\n",
      "Pretrain epoch [14/80], ZINB loss:0.3951, NB loss:5.2140\n",
      "Pretrain epoch [15/80], ZINB loss:0.3867, NB loss:5.1882\n",
      "Pretrain epoch [16/80], ZINB loss:0.3952, NB loss:5.2341\n",
      "Pretrain epoch [17/80], ZINB loss:0.3892, NB loss:5.2230\n",
      "Pretrain epoch [18/80], ZINB loss:0.3920, NB loss:5.1968\n",
      "Pretrain epoch [19/80], ZINB loss:0.3869, NB loss:5.2253\n",
      "Pretrain epoch [20/80], ZINB loss:0.4006, NB loss:5.1771\n",
      "Pretrain epoch [21/80], ZINB loss:0.3875, NB loss:5.2061\n",
      "Pretrain epoch [22/80], ZINB loss:0.3896, NB loss:5.2967\n",
      "Pretrain epoch [23/80], ZINB loss:0.3943, NB loss:5.2020\n",
      "Pretrain epoch [24/80], ZINB loss:0.3814, NB loss:5.2460\n",
      "Pretrain epoch [25/80], ZINB loss:0.3994, NB loss:5.2471\n",
      "Pretrain epoch [26/80], ZINB loss:0.3999, NB loss:5.2711\n",
      "Pretrain epoch [27/80], ZINB loss:0.4315, NB loss:4.9959\n",
      "Pretrain epoch [1/81], ZINB loss:0.3851, NB loss:5.1902\n",
      "Pretrain epoch [2/81], ZINB loss:0.3967, NB loss:5.1990\n",
      "Pretrain epoch [3/81], ZINB loss:0.3935, NB loss:5.1920\n",
      "Pretrain epoch [4/81], ZINB loss:0.4034, NB loss:5.2197\n",
      "Pretrain epoch [5/81], ZINB loss:0.4032, NB loss:5.2251\n",
      "Pretrain epoch [6/81], ZINB loss:0.3855, NB loss:5.1927\n",
      "Pretrain epoch [7/81], ZINB loss:0.3779, NB loss:5.2341\n",
      "Pretrain epoch [8/81], ZINB loss:0.3890, NB loss:5.1858\n",
      "Pretrain epoch [9/81], ZINB loss:0.3892, NB loss:5.2635\n",
      "Pretrain epoch [10/81], ZINB loss:0.3892, NB loss:5.2523\n",
      "Pretrain epoch [11/81], ZINB loss:0.3985, NB loss:5.2424\n",
      "Pretrain epoch [12/81], ZINB loss:0.3955, NB loss:5.2253\n",
      "Pretrain epoch [13/81], ZINB loss:0.3905, NB loss:5.2048\n",
      "Pretrain epoch [14/81], ZINB loss:0.3781, NB loss:5.2279\n",
      "Pretrain epoch [15/81], ZINB loss:0.4007, NB loss:5.2424\n",
      "Pretrain epoch [16/81], ZINB loss:0.3873, NB loss:5.2497\n",
      "Pretrain epoch [17/81], ZINB loss:0.4032, NB loss:5.2064\n",
      "Pretrain epoch [18/81], ZINB loss:0.3964, NB loss:5.2003\n",
      "Pretrain epoch [19/81], ZINB loss:0.3908, NB loss:5.2898\n",
      "Pretrain epoch [20/81], ZINB loss:0.3998, NB loss:5.2091\n",
      "Pretrain epoch [21/81], ZINB loss:0.4036, NB loss:5.2262\n",
      "Pretrain epoch [22/81], ZINB loss:0.3799, NB loss:5.2879\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [23/81], ZINB loss:0.3887, NB loss:5.1854\n",
      "Pretrain epoch [24/81], ZINB loss:0.3910, NB loss:5.2413\n",
      "Pretrain epoch [25/81], ZINB loss:0.3882, NB loss:5.3023\n",
      "Pretrain epoch [26/81], ZINB loss:0.4232, NB loss:5.2388\n",
      "Pretrain epoch [27/81], ZINB loss:0.3247, NB loss:5.5494\n",
      "Pretrain epoch [1/82], ZINB loss:0.3978, NB loss:5.1836\n",
      "Pretrain epoch [2/82], ZINB loss:0.3807, NB loss:5.2359\n",
      "Pretrain epoch [3/82], ZINB loss:0.3797, NB loss:5.2046\n",
      "Pretrain epoch [4/82], ZINB loss:0.3875, NB loss:5.2161\n",
      "Pretrain epoch [5/82], ZINB loss:0.3950, NB loss:5.1710\n",
      "Pretrain epoch [6/82], ZINB loss:0.3990, NB loss:5.2311\n",
      "Pretrain epoch [7/82], ZINB loss:0.3973, NB loss:5.2504\n",
      "Pretrain epoch [8/82], ZINB loss:0.3919, NB loss:5.2564\n",
      "Pretrain epoch [9/82], ZINB loss:0.3786, NB loss:5.3111\n",
      "Pretrain epoch [10/82], ZINB loss:0.3938, NB loss:5.1760\n",
      "Pretrain epoch [11/82], ZINB loss:0.3912, NB loss:5.2136\n",
      "Pretrain epoch [12/82], ZINB loss:0.3800, NB loss:5.2409\n",
      "Pretrain epoch [13/82], ZINB loss:0.3917, NB loss:5.1849\n",
      "Pretrain epoch [14/82], ZINB loss:0.3883, NB loss:5.2353\n",
      "Pretrain epoch [15/82], ZINB loss:0.3974, NB loss:5.2423\n",
      "Pretrain epoch [16/82], ZINB loss:0.4210, NB loss:5.1695\n",
      "Pretrain epoch [17/82], ZINB loss:0.4014, NB loss:5.2510\n",
      "Pretrain epoch [18/82], ZINB loss:0.4030, NB loss:5.2675\n",
      "Pretrain epoch [19/82], ZINB loss:0.3801, NB loss:5.2342\n",
      "Pretrain epoch [20/82], ZINB loss:0.3781, NB loss:5.2273\n",
      "Pretrain epoch [21/82], ZINB loss:0.3996, NB loss:5.2459\n",
      "Pretrain epoch [22/82], ZINB loss:0.3847, NB loss:5.2011\n",
      "Pretrain epoch [23/82], ZINB loss:0.3807, NB loss:5.1789\n",
      "Pretrain epoch [24/82], ZINB loss:0.4247, NB loss:5.2116\n",
      "Pretrain epoch [25/82], ZINB loss:0.3882, NB loss:5.1706\n",
      "Pretrain epoch [26/82], ZINB loss:0.3890, NB loss:5.1967\n",
      "Pretrain epoch [27/82], ZINB loss:0.4142, NB loss:5.2961\n",
      "Pretrain epoch [1/83], ZINB loss:0.4055, NB loss:5.2204\n",
      "Pretrain epoch [2/83], ZINB loss:0.3741, NB loss:5.2148\n",
      "Pretrain epoch [3/83], ZINB loss:0.4110, NB loss:5.2228\n",
      "Pretrain epoch [4/83], ZINB loss:0.3965, NB loss:5.1854\n",
      "Pretrain epoch [5/83], ZINB loss:0.3901, NB loss:5.2244\n",
      "Pretrain epoch [6/83], ZINB loss:0.3920, NB loss:5.2178\n",
      "Pretrain epoch [7/83], ZINB loss:0.3816, NB loss:5.3122\n",
      "Pretrain epoch [8/83], ZINB loss:0.3943, NB loss:5.2002\n",
      "Pretrain epoch [9/83], ZINB loss:0.3786, NB loss:5.2665\n",
      "Pretrain epoch [10/83], ZINB loss:0.3683, NB loss:5.2436\n",
      "Pretrain epoch [11/83], ZINB loss:0.4132, NB loss:5.1477\n",
      "Pretrain epoch [12/83], ZINB loss:0.4028, NB loss:5.1901\n",
      "Pretrain epoch [13/83], ZINB loss:0.3959, NB loss:5.2051\n",
      "Pretrain epoch [14/83], ZINB loss:0.3937, NB loss:5.1785\n",
      "Pretrain epoch [15/83], ZINB loss:0.3826, NB loss:5.2014\n",
      "Pretrain epoch [16/83], ZINB loss:0.4052, NB loss:5.2263\n",
      "Pretrain epoch [17/83], ZINB loss:0.3991, NB loss:5.2371\n",
      "Pretrain epoch [18/83], ZINB loss:0.3895, NB loss:5.1971\n",
      "Pretrain epoch [19/83], ZINB loss:0.3890, NB loss:5.1740\n",
      "Pretrain epoch [20/83], ZINB loss:0.4046, NB loss:5.2418\n",
      "Pretrain epoch [21/83], ZINB loss:0.3956, NB loss:5.1310\n",
      "Pretrain epoch [22/83], ZINB loss:0.3905, NB loss:5.2213\n",
      "Pretrain epoch [23/83], ZINB loss:0.4129, NB loss:5.2220\n",
      "Pretrain epoch [24/83], ZINB loss:0.3937, NB loss:5.1893\n",
      "Pretrain epoch [25/83], ZINB loss:0.3764, NB loss:5.2436\n",
      "Pretrain epoch [26/83], ZINB loss:0.3983, NB loss:5.1554\n",
      "Pretrain epoch [27/83], ZINB loss:0.3488, NB loss:5.1066\n",
      "Pretrain epoch [1/84], ZINB loss:0.3990, NB loss:5.1832\n",
      "Pretrain epoch [2/84], ZINB loss:0.4036, NB loss:5.2076\n",
      "Pretrain epoch [3/84], ZINB loss:0.3946, NB loss:5.1931\n",
      "Pretrain epoch [4/84], ZINB loss:0.4167, NB loss:5.1531\n",
      "Pretrain epoch [5/84], ZINB loss:0.3902, NB loss:5.2002\n",
      "Pretrain epoch [6/84], ZINB loss:0.3948, NB loss:5.2131\n",
      "Pretrain epoch [7/84], ZINB loss:0.3753, NB loss:5.2196\n",
      "Pretrain epoch [8/84], ZINB loss:0.3798, NB loss:5.1943\n",
      "Pretrain epoch [9/84], ZINB loss:0.3885, NB loss:5.2358\n",
      "Pretrain epoch [10/84], ZINB loss:0.3819, NB loss:5.1876\n",
      "Pretrain epoch [11/84], ZINB loss:0.4188, NB loss:5.2212\n",
      "Pretrain epoch [12/84], ZINB loss:0.4151, NB loss:5.2538\n",
      "Pretrain epoch [13/84], ZINB loss:0.4116, NB loss:5.1661\n",
      "Pretrain epoch [14/84], ZINB loss:0.3795, NB loss:5.2187\n",
      "Pretrain epoch [15/84], ZINB loss:0.3727, NB loss:5.2284\n",
      "Pretrain epoch [16/84], ZINB loss:0.3954, NB loss:5.1478\n",
      "Pretrain epoch [17/84], ZINB loss:0.3986, NB loss:5.1884\n",
      "Pretrain epoch [18/84], ZINB loss:0.3920, NB loss:5.1814\n",
      "Pretrain epoch [19/84], ZINB loss:0.3959, NB loss:5.1550\n",
      "Pretrain epoch [20/84], ZINB loss:0.4159, NB loss:5.2388\n",
      "Pretrain epoch [21/84], ZINB loss:0.3911, NB loss:5.1829\n",
      "Pretrain epoch [22/84], ZINB loss:0.3822, NB loss:5.1599\n",
      "Pretrain epoch [23/84], ZINB loss:0.3798, NB loss:5.1963\n",
      "Pretrain epoch [24/84], ZINB loss:0.3759, NB loss:5.1921\n",
      "Pretrain epoch [25/84], ZINB loss:0.3753, NB loss:5.2756\n",
      "Pretrain epoch [26/84], ZINB loss:0.3930, NB loss:5.2507\n",
      "Pretrain epoch [27/84], ZINB loss:0.3714, NB loss:4.9072\n",
      "Pretrain epoch [1/85], ZINB loss:0.3839, NB loss:5.2182\n",
      "Pretrain epoch [2/85], ZINB loss:0.4095, NB loss:5.1484\n",
      "Pretrain epoch [3/85], ZINB loss:0.4058, NB loss:5.2138\n",
      "Pretrain epoch [4/85], ZINB loss:0.4007, NB loss:5.2208\n",
      "Pretrain epoch [5/85], ZINB loss:0.4125, NB loss:5.1525\n",
      "Pretrain epoch [6/85], ZINB loss:0.4012, NB loss:5.1841\n",
      "Pretrain epoch [7/85], ZINB loss:0.3979, NB loss:5.1652\n",
      "Pretrain epoch [8/85], ZINB loss:0.3948, NB loss:5.2125\n",
      "Pretrain epoch [9/85], ZINB loss:0.3924, NB loss:5.2466\n",
      "Pretrain epoch [10/85], ZINB loss:0.4233, NB loss:5.2630\n",
      "Pretrain epoch [11/85], ZINB loss:0.3756, NB loss:5.1520\n",
      "Pretrain epoch [12/85], ZINB loss:0.3647, NB loss:5.2199\n",
      "Pretrain epoch [13/85], ZINB loss:0.3852, NB loss:5.2524\n",
      "Pretrain epoch [14/85], ZINB loss:0.3882, NB loss:5.2286\n",
      "Pretrain epoch [15/85], ZINB loss:0.3949, NB loss:5.1609\n",
      "Pretrain epoch [16/85], ZINB loss:0.3770, NB loss:5.1410\n",
      "Pretrain epoch [17/85], ZINB loss:0.3911, NB loss:5.2289\n",
      "Pretrain epoch [18/85], ZINB loss:0.3984, NB loss:5.2501\n",
      "Pretrain epoch [19/85], ZINB loss:0.3775, NB loss:5.1432\n",
      "Pretrain epoch [20/85], ZINB loss:0.3833, NB loss:5.1425\n",
      "Pretrain epoch [21/85], ZINB loss:0.3733, NB loss:5.1976\n",
      "Pretrain epoch [22/85], ZINB loss:0.3973, NB loss:5.1437\n",
      "Pretrain epoch [23/85], ZINB loss:0.3831, NB loss:5.1201\n",
      "Pretrain epoch [24/85], ZINB loss:0.3911, NB loss:5.1448\n",
      "Pretrain epoch [25/85], ZINB loss:0.4006, NB loss:5.2173\n",
      "Pretrain epoch [26/85], ZINB loss:0.3960, NB loss:5.2490\n",
      "Pretrain epoch [27/85], ZINB loss:0.3669, NB loss:4.8828\n",
      "Pretrain epoch [1/86], ZINB loss:0.3878, NB loss:5.1716\n",
      "Pretrain epoch [2/86], ZINB loss:0.4032, NB loss:5.1917\n",
      "Pretrain epoch [3/86], ZINB loss:0.3727, NB loss:5.2247\n",
      "Pretrain epoch [4/86], ZINB loss:0.3943, NB loss:5.1426\n",
      "Pretrain epoch [5/86], ZINB loss:0.3716, NB loss:5.1842\n",
      "Pretrain epoch [6/86], ZINB loss:0.3979, NB loss:5.1736\n",
      "Pretrain epoch [7/86], ZINB loss:0.4055, NB loss:5.1979\n",
      "Pretrain epoch [8/86], ZINB loss:0.3906, NB loss:5.2164\n",
      "Pretrain epoch [9/86], ZINB loss:0.3995, NB loss:5.2652\n",
      "Pretrain epoch [10/86], ZINB loss:0.3920, NB loss:5.1308\n",
      "Pretrain epoch [11/86], ZINB loss:0.4031, NB loss:5.1776\n",
      "Pretrain epoch [12/86], ZINB loss:0.3900, NB loss:5.1710\n",
      "Pretrain epoch [13/86], ZINB loss:0.3757, NB loss:5.1870\n",
      "Pretrain epoch [14/86], ZINB loss:0.3978, NB loss:5.1914\n",
      "Pretrain epoch [15/86], ZINB loss:0.4014, NB loss:5.1591\n",
      "Pretrain epoch [16/86], ZINB loss:0.3880, NB loss:5.1061\n",
      "Pretrain epoch [17/86], ZINB loss:0.3904, NB loss:5.1781\n",
      "Pretrain epoch [18/86], ZINB loss:0.3888, NB loss:5.2250\n",
      "Pretrain epoch [19/86], ZINB loss:0.3875, NB loss:5.1796\n",
      "Pretrain epoch [20/86], ZINB loss:0.3769, NB loss:5.2329\n",
      "Pretrain epoch [21/86], ZINB loss:0.3797, NB loss:5.2007\n",
      "Pretrain epoch [22/86], ZINB loss:0.3970, NB loss:5.1846\n",
      "Pretrain epoch [23/86], ZINB loss:0.4118, NB loss:5.1797\n",
      "Pretrain epoch [24/86], ZINB loss:0.4094, NB loss:5.1420\n",
      "Pretrain epoch [25/86], ZINB loss:0.3879, NB loss:5.2288\n",
      "Pretrain epoch [26/86], ZINB loss:0.4016, NB loss:5.1400\n",
      "Pretrain epoch [27/86], ZINB loss:0.3898, NB loss:5.3483\n",
      "Pretrain epoch [1/87], ZINB loss:0.3933, NB loss:5.2331\n",
      "Pretrain epoch [2/87], ZINB loss:0.3962, NB loss:5.1943\n",
      "Pretrain epoch [3/87], ZINB loss:0.3904, NB loss:5.1731\n",
      "Pretrain epoch [4/87], ZINB loss:0.3898, NB loss:5.2218\n",
      "Pretrain epoch [5/87], ZINB loss:0.3990, NB loss:5.2325\n",
      "Pretrain epoch [6/87], ZINB loss:0.3939, NB loss:5.1150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [7/87], ZINB loss:0.3828, NB loss:5.1757\n",
      "Pretrain epoch [8/87], ZINB loss:0.3966, NB loss:5.1686\n",
      "Pretrain epoch [9/87], ZINB loss:0.3788, NB loss:5.2098\n",
      "Pretrain epoch [10/87], ZINB loss:0.3971, NB loss:5.1365\n",
      "Pretrain epoch [11/87], ZINB loss:0.3944, NB loss:5.1909\n",
      "Pretrain epoch [12/87], ZINB loss:0.3925, NB loss:5.1747\n",
      "Pretrain epoch [13/87], ZINB loss:0.3885, NB loss:5.2253\n",
      "Pretrain epoch [14/87], ZINB loss:0.3733, NB loss:5.0977\n",
      "Pretrain epoch [15/87], ZINB loss:0.3976, NB loss:5.1172\n",
      "Pretrain epoch [16/87], ZINB loss:0.3990, NB loss:5.1057\n",
      "Pretrain epoch [17/87], ZINB loss:0.4149, NB loss:5.1967\n",
      "Pretrain epoch [18/87], ZINB loss:0.3877, NB loss:5.1478\n",
      "Pretrain epoch [19/87], ZINB loss:0.4029, NB loss:5.1442\n",
      "Pretrain epoch [20/87], ZINB loss:0.3827, NB loss:5.1573\n",
      "Pretrain epoch [21/87], ZINB loss:0.3853, NB loss:5.1625\n",
      "Pretrain epoch [22/87], ZINB loss:0.3854, NB loss:5.2178\n",
      "Pretrain epoch [23/87], ZINB loss:0.3887, NB loss:5.1735\n",
      "Pretrain epoch [24/87], ZINB loss:0.4000, NB loss:5.1944\n",
      "Pretrain epoch [25/87], ZINB loss:0.3951, NB loss:5.1926\n",
      "Pretrain epoch [26/87], ZINB loss:0.3960, NB loss:5.2126\n",
      "Pretrain epoch [27/87], ZINB loss:0.3552, NB loss:5.0077\n",
      "Pretrain epoch [1/88], ZINB loss:0.3937, NB loss:5.1720\n",
      "Pretrain epoch [2/88], ZINB loss:0.3866, NB loss:5.2027\n",
      "Pretrain epoch [3/88], ZINB loss:0.4070, NB loss:5.2237\n",
      "Pretrain epoch [4/88], ZINB loss:0.3909, NB loss:5.1697\n",
      "Pretrain epoch [5/88], ZINB loss:0.3770, NB loss:5.1798\n",
      "Pretrain epoch [6/88], ZINB loss:0.3821, NB loss:5.1256\n",
      "Pretrain epoch [7/88], ZINB loss:0.3917, NB loss:5.1148\n",
      "Pretrain epoch [8/88], ZINB loss:0.4137, NB loss:5.0760\n",
      "Pretrain epoch [9/88], ZINB loss:0.3886, NB loss:5.1086\n",
      "Pretrain epoch [10/88], ZINB loss:0.3912, NB loss:5.1567\n",
      "Pretrain epoch [11/88], ZINB loss:0.3873, NB loss:5.1782\n",
      "Pretrain epoch [12/88], ZINB loss:0.3931, NB loss:5.1646\n",
      "Pretrain epoch [13/88], ZINB loss:0.3869, NB loss:5.1942\n",
      "Pretrain epoch [14/88], ZINB loss:0.3895, NB loss:5.1537\n",
      "Pretrain epoch [15/88], ZINB loss:0.4025, NB loss:5.1316\n",
      "Pretrain epoch [16/88], ZINB loss:0.4090, NB loss:5.2083\n",
      "Pretrain epoch [17/88], ZINB loss:0.4015, NB loss:5.2063\n",
      "Pretrain epoch [18/88], ZINB loss:0.3941, NB loss:5.1361\n",
      "Pretrain epoch [19/88], ZINB loss:0.3969, NB loss:5.1945\n",
      "Pretrain epoch [20/88], ZINB loss:0.4012, NB loss:5.2226\n",
      "Pretrain epoch [21/88], ZINB loss:0.3898, NB loss:5.1549\n",
      "Pretrain epoch [22/88], ZINB loss:0.3723, NB loss:5.1420\n",
      "Pretrain epoch [23/88], ZINB loss:0.4019, NB loss:5.1117\n",
      "Pretrain epoch [24/88], ZINB loss:0.4059, NB loss:5.2045\n",
      "Pretrain epoch [25/88], ZINB loss:0.3682, NB loss:5.2218\n",
      "Pretrain epoch [26/88], ZINB loss:0.3838, NB loss:5.2064\n",
      "Pretrain epoch [27/88], ZINB loss:0.4088, NB loss:4.8487\n",
      "Pretrain epoch [1/89], ZINB loss:0.3857, NB loss:5.1216\n",
      "Pretrain epoch [2/89], ZINB loss:0.3898, NB loss:5.0853\n",
      "Pretrain epoch [3/89], ZINB loss:0.3820, NB loss:5.1746\n",
      "Pretrain epoch [4/89], ZINB loss:0.3929, NB loss:5.2151\n",
      "Pretrain epoch [5/89], ZINB loss:0.3957, NB loss:5.1501\n",
      "Pretrain epoch [6/89], ZINB loss:0.3907, NB loss:5.2093\n",
      "Pretrain epoch [7/89], ZINB loss:0.3846, NB loss:5.1385\n",
      "Pretrain epoch [8/89], ZINB loss:0.3851, NB loss:5.1922\n",
      "Pretrain epoch [9/89], ZINB loss:0.3740, NB loss:5.1554\n",
      "Pretrain epoch [10/89], ZINB loss:0.4074, NB loss:5.1518\n",
      "Pretrain epoch [11/89], ZINB loss:0.3965, NB loss:5.1105\n",
      "Pretrain epoch [12/89], ZINB loss:0.3975, NB loss:5.1694\n",
      "Pretrain epoch [13/89], ZINB loss:0.3880, NB loss:5.1469\n",
      "Pretrain epoch [14/89], ZINB loss:0.4055, NB loss:5.1057\n",
      "Pretrain epoch [15/89], ZINB loss:0.4047, NB loss:5.2002\n",
      "Pretrain epoch [16/89], ZINB loss:0.4023, NB loss:5.1119\n",
      "Pretrain epoch [17/89], ZINB loss:0.3885, NB loss:5.1010\n",
      "Pretrain epoch [18/89], ZINB loss:0.3924, NB loss:5.1546\n",
      "Pretrain epoch [19/89], ZINB loss:0.3934, NB loss:5.2671\n",
      "Pretrain epoch [20/89], ZINB loss:0.3865, NB loss:5.1284\n",
      "Pretrain epoch [21/89], ZINB loss:0.3895, NB loss:5.1767\n",
      "Pretrain epoch [22/89], ZINB loss:0.3993, NB loss:5.1900\n",
      "Pretrain epoch [23/89], ZINB loss:0.3996, NB loss:5.1866\n",
      "Pretrain epoch [24/89], ZINB loss:0.3795, NB loss:5.1608\n",
      "Pretrain epoch [25/89], ZINB loss:0.4184, NB loss:5.1448\n",
      "Pretrain epoch [26/89], ZINB loss:0.3819, NB loss:5.1905\n",
      "Pretrain epoch [27/89], ZINB loss:0.3732, NB loss:5.2250\n",
      "Pretrain epoch [1/90], ZINB loss:0.4028, NB loss:5.1441\n",
      "Pretrain epoch [2/90], ZINB loss:0.3927, NB loss:5.1061\n",
      "Pretrain epoch [3/90], ZINB loss:0.3903, NB loss:5.1603\n",
      "Pretrain epoch [4/90], ZINB loss:0.3954, NB loss:5.1532\n",
      "Pretrain epoch [5/90], ZINB loss:0.4161, NB loss:5.1859\n",
      "Pretrain epoch [6/90], ZINB loss:0.3812, NB loss:5.1789\n",
      "Pretrain epoch [7/90], ZINB loss:0.3935, NB loss:5.1506\n",
      "Pretrain epoch [8/90], ZINB loss:0.3863, NB loss:5.1883\n",
      "Pretrain epoch [9/90], ZINB loss:0.4013, NB loss:5.1482\n",
      "Pretrain epoch [10/90], ZINB loss:0.3808, NB loss:5.1835\n",
      "Pretrain epoch [11/90], ZINB loss:0.3890, NB loss:5.1916\n",
      "Pretrain epoch [12/90], ZINB loss:0.4024, NB loss:5.1564\n",
      "Pretrain epoch [13/90], ZINB loss:0.3958, NB loss:5.1613\n",
      "Pretrain epoch [14/90], ZINB loss:0.3829, NB loss:5.1759\n",
      "Pretrain epoch [15/90], ZINB loss:0.3710, NB loss:5.1167\n",
      "Pretrain epoch [16/90], ZINB loss:0.4019, NB loss:5.1198\n",
      "Pretrain epoch [17/90], ZINB loss:0.4010, NB loss:5.1585\n",
      "Pretrain epoch [18/90], ZINB loss:0.4054, NB loss:5.0763\n",
      "Pretrain epoch [19/90], ZINB loss:0.3975, NB loss:5.1125\n",
      "Pretrain epoch [20/90], ZINB loss:0.3712, NB loss:5.1269\n",
      "Pretrain epoch [21/90], ZINB loss:0.3967, NB loss:5.1762\n",
      "Pretrain epoch [22/90], ZINB loss:0.3836, NB loss:5.1666\n",
      "Pretrain epoch [23/90], ZINB loss:0.3992, NB loss:5.1480\n",
      "Pretrain epoch [24/90], ZINB loss:0.3848, NB loss:5.1475\n",
      "Pretrain epoch [25/90], ZINB loss:0.3948, NB loss:5.1715\n",
      "Pretrain epoch [26/90], ZINB loss:0.3843, NB loss:5.1272\n",
      "Pretrain epoch [27/90], ZINB loss:0.3236, NB loss:5.1131\n",
      "Pretrain epoch [1/91], ZINB loss:0.3849, NB loss:5.1426\n",
      "Pretrain epoch [2/91], ZINB loss:0.3807, NB loss:5.1905\n",
      "Pretrain epoch [3/91], ZINB loss:0.3706, NB loss:5.1682\n",
      "Pretrain epoch [4/91], ZINB loss:0.3858, NB loss:5.1704\n",
      "Pretrain epoch [5/91], ZINB loss:0.3881, NB loss:5.1036\n",
      "Pretrain epoch [6/91], ZINB loss:0.3821, NB loss:5.1614\n",
      "Pretrain epoch [7/91], ZINB loss:0.3773, NB loss:5.1028\n",
      "Pretrain epoch [8/91], ZINB loss:0.4024, NB loss:5.1221\n",
      "Pretrain epoch [9/91], ZINB loss:0.3804, NB loss:5.1239\n",
      "Pretrain epoch [10/91], ZINB loss:0.4006, NB loss:5.1292\n",
      "Pretrain epoch [11/91], ZINB loss:0.4251, NB loss:5.1067\n",
      "Pretrain epoch [12/91], ZINB loss:0.3740, NB loss:5.1607\n",
      "Pretrain epoch [13/91], ZINB loss:0.4007, NB loss:5.1028\n",
      "Pretrain epoch [14/91], ZINB loss:0.3964, NB loss:5.1302\n",
      "Pretrain epoch [15/91], ZINB loss:0.4096, NB loss:5.1042\n",
      "Pretrain epoch [16/91], ZINB loss:0.4131, NB loss:5.1883\n",
      "Pretrain epoch [17/91], ZINB loss:0.3930, NB loss:5.0988\n",
      "Pretrain epoch [18/91], ZINB loss:0.3819, NB loss:5.1404\n",
      "Pretrain epoch [19/91], ZINB loss:0.3835, NB loss:5.1878\n",
      "Pretrain epoch [20/91], ZINB loss:0.3876, NB loss:5.1319\n",
      "Pretrain epoch [21/91], ZINB loss:0.4062, NB loss:5.1709\n",
      "Pretrain epoch [22/91], ZINB loss:0.3982, NB loss:5.1529\n",
      "Pretrain epoch [23/91], ZINB loss:0.3856, NB loss:5.1097\n",
      "Pretrain epoch [24/91], ZINB loss:0.3786, NB loss:5.1951\n",
      "Pretrain epoch [25/91], ZINB loss:0.4004, NB loss:5.1695\n",
      "Pretrain epoch [26/91], ZINB loss:0.4054, NB loss:5.1528\n",
      "Pretrain epoch [27/91], ZINB loss:0.4370, NB loss:5.3615\n",
      "Pretrain epoch [1/92], ZINB loss:0.4039, NB loss:5.1107\n",
      "Pretrain epoch [2/92], ZINB loss:0.4013, NB loss:5.1431\n",
      "Pretrain epoch [3/92], ZINB loss:0.3959, NB loss:5.0919\n",
      "Pretrain epoch [4/92], ZINB loss:0.3942, NB loss:5.1365\n",
      "Pretrain epoch [5/92], ZINB loss:0.3804, NB loss:5.1683\n",
      "Pretrain epoch [6/92], ZINB loss:0.3799, NB loss:5.1417\n",
      "Pretrain epoch [7/92], ZINB loss:0.4062, NB loss:5.1358\n",
      "Pretrain epoch [8/92], ZINB loss:0.4018, NB loss:5.1569\n",
      "Pretrain epoch [9/92], ZINB loss:0.4085, NB loss:5.1433\n",
      "Pretrain epoch [10/92], ZINB loss:0.4045, NB loss:5.2153\n",
      "Pretrain epoch [11/92], ZINB loss:0.3959, NB loss:5.1545\n",
      "Pretrain epoch [12/92], ZINB loss:0.3712, NB loss:5.1679\n",
      "Pretrain epoch [13/92], ZINB loss:0.3912, NB loss:5.1196\n",
      "Pretrain epoch [14/92], ZINB loss:0.3834, NB loss:5.1563\n",
      "Pretrain epoch [15/92], ZINB loss:0.3702, NB loss:5.1183\n",
      "Pretrain epoch [16/92], ZINB loss:0.3770, NB loss:5.1254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [17/92], ZINB loss:0.3991, NB loss:5.1077\n",
      "Pretrain epoch [18/92], ZINB loss:0.3996, NB loss:5.1354\n",
      "Pretrain epoch [19/92], ZINB loss:0.3988, NB loss:5.1170\n",
      "Pretrain epoch [20/92], ZINB loss:0.3880, NB loss:5.1335\n",
      "Pretrain epoch [21/92], ZINB loss:0.3979, NB loss:5.1504\n",
      "Pretrain epoch [22/92], ZINB loss:0.3963, NB loss:5.1198\n",
      "Pretrain epoch [23/92], ZINB loss:0.3985, NB loss:5.1502\n",
      "Pretrain epoch [24/92], ZINB loss:0.4178, NB loss:5.1167\n",
      "Pretrain epoch [25/92], ZINB loss:0.3978, NB loss:5.0661\n",
      "Pretrain epoch [26/92], ZINB loss:0.4045, NB loss:5.1459\n",
      "Pretrain epoch [27/92], ZINB loss:0.3271, NB loss:4.9136\n",
      "Pretrain epoch [1/93], ZINB loss:0.4074, NB loss:5.1110\n",
      "Pretrain epoch [2/93], ZINB loss:0.3890, NB loss:5.1306\n",
      "Pretrain epoch [3/93], ZINB loss:0.4000, NB loss:5.1768\n",
      "Pretrain epoch [4/93], ZINB loss:0.3873, NB loss:5.1309\n",
      "Pretrain epoch [5/93], ZINB loss:0.3821, NB loss:5.1722\n",
      "Pretrain epoch [6/93], ZINB loss:0.3982, NB loss:5.1826\n",
      "Pretrain epoch [7/93], ZINB loss:0.3930, NB loss:5.1319\n",
      "Pretrain epoch [8/93], ZINB loss:0.3993, NB loss:5.2091\n",
      "Pretrain epoch [9/93], ZINB loss:0.3994, NB loss:5.1803\n",
      "Pretrain epoch [10/93], ZINB loss:0.4023, NB loss:5.1001\n",
      "Pretrain epoch [11/93], ZINB loss:0.3900, NB loss:5.1419\n",
      "Pretrain epoch [12/93], ZINB loss:0.4051, NB loss:5.0811\n",
      "Pretrain epoch [13/93], ZINB loss:0.3992, NB loss:5.1039\n",
      "Pretrain epoch [14/93], ZINB loss:0.3699, NB loss:5.1057\n",
      "Pretrain epoch [15/93], ZINB loss:0.4008, NB loss:5.1828\n",
      "Pretrain epoch [16/93], ZINB loss:0.3970, NB loss:5.1799\n",
      "Pretrain epoch [17/93], ZINB loss:0.3742, NB loss:5.1116\n",
      "Pretrain epoch [18/93], ZINB loss:0.3932, NB loss:5.1394\n",
      "Pretrain epoch [19/93], ZINB loss:0.4072, NB loss:5.0953\n",
      "Pretrain epoch [20/93], ZINB loss:0.3854, NB loss:5.0671\n",
      "Pretrain epoch [21/93], ZINB loss:0.3778, NB loss:5.1513\n",
      "Pretrain epoch [22/93], ZINB loss:0.4127, NB loss:5.1206\n",
      "Pretrain epoch [23/93], ZINB loss:0.3849, NB loss:5.1284\n",
      "Pretrain epoch [24/93], ZINB loss:0.3812, NB loss:5.1109\n",
      "Pretrain epoch [25/93], ZINB loss:0.3869, NB loss:5.0545\n",
      "Pretrain epoch [26/93], ZINB loss:0.3968, NB loss:5.0182\n",
      "Pretrain epoch [27/93], ZINB loss:0.2642, NB loss:5.2677\n",
      "Pretrain epoch [1/94], ZINB loss:0.3938, NB loss:5.1076\n",
      "Pretrain epoch [2/94], ZINB loss:0.3784, NB loss:5.1158\n",
      "Pretrain epoch [3/94], ZINB loss:0.3912, NB loss:5.1418\n",
      "Pretrain epoch [4/94], ZINB loss:0.3877, NB loss:5.1008\n",
      "Pretrain epoch [5/94], ZINB loss:0.3964, NB loss:5.1814\n",
      "Pretrain epoch [6/94], ZINB loss:0.3888, NB loss:5.0419\n",
      "Pretrain epoch [7/94], ZINB loss:0.3938, NB loss:5.1132\n",
      "Pretrain epoch [8/94], ZINB loss:0.3968, NB loss:5.1594\n",
      "Pretrain epoch [9/94], ZINB loss:0.3892, NB loss:5.0683\n",
      "Pretrain epoch [10/94], ZINB loss:0.3832, NB loss:5.1303\n",
      "Pretrain epoch [11/94], ZINB loss:0.4117, NB loss:5.0922\n",
      "Pretrain epoch [12/94], ZINB loss:0.4039, NB loss:5.1714\n",
      "Pretrain epoch [13/94], ZINB loss:0.3893, NB loss:5.0621\n",
      "Pretrain epoch [14/94], ZINB loss:0.4057, NB loss:5.1838\n",
      "Pretrain epoch [15/94], ZINB loss:0.3896, NB loss:5.1168\n",
      "Pretrain epoch [16/94], ZINB loss:0.3872, NB loss:5.0605\n",
      "Pretrain epoch [17/94], ZINB loss:0.4105, NB loss:5.1288\n",
      "Pretrain epoch [18/94], ZINB loss:0.3894, NB loss:5.1691\n",
      "Pretrain epoch [19/94], ZINB loss:0.4106, NB loss:5.1363\n",
      "Pretrain epoch [20/94], ZINB loss:0.3789, NB loss:5.1434\n",
      "Pretrain epoch [21/94], ZINB loss:0.3887, NB loss:5.1103\n",
      "Pretrain epoch [22/94], ZINB loss:0.4019, NB loss:5.1321\n",
      "Pretrain epoch [23/94], ZINB loss:0.3936, NB loss:5.0917\n",
      "Pretrain epoch [24/94], ZINB loss:0.3718, NB loss:5.1354\n",
      "Pretrain epoch [25/94], ZINB loss:0.3733, NB loss:5.0798\n",
      "Pretrain epoch [26/94], ZINB loss:0.3845, NB loss:5.1520\n",
      "Pretrain epoch [27/94], ZINB loss:0.3498, NB loss:5.1966\n",
      "Pretrain epoch [1/95], ZINB loss:0.4013, NB loss:5.1671\n",
      "Pretrain epoch [2/95], ZINB loss:0.4116, NB loss:5.1101\n",
      "Pretrain epoch [3/95], ZINB loss:0.3958, NB loss:5.0836\n",
      "Pretrain epoch [4/95], ZINB loss:0.3914, NB loss:5.0852\n",
      "Pretrain epoch [5/95], ZINB loss:0.3746, NB loss:5.0758\n",
      "Pretrain epoch [6/95], ZINB loss:0.4000, NB loss:5.1416\n",
      "Pretrain epoch [7/95], ZINB loss:0.3883, NB loss:5.1101\n",
      "Pretrain epoch [8/95], ZINB loss:0.3942, NB loss:5.1356\n",
      "Pretrain epoch [9/95], ZINB loss:0.3927, NB loss:5.1020\n",
      "Pretrain epoch [10/95], ZINB loss:0.4042, NB loss:5.1283\n",
      "Pretrain epoch [11/95], ZINB loss:0.4012, NB loss:5.1135\n",
      "Pretrain epoch [12/95], ZINB loss:0.3931, NB loss:5.1670\n",
      "Pretrain epoch [13/95], ZINB loss:0.3835, NB loss:5.1052\n",
      "Pretrain epoch [14/95], ZINB loss:0.4000, NB loss:5.1168\n",
      "Pretrain epoch [15/95], ZINB loss:0.3854, NB loss:5.1097\n",
      "Pretrain epoch [16/95], ZINB loss:0.3848, NB loss:5.1315\n",
      "Pretrain epoch [17/95], ZINB loss:0.3951, NB loss:5.1073\n",
      "Pretrain epoch [18/95], ZINB loss:0.3925, NB loss:5.1419\n",
      "Pretrain epoch [19/95], ZINB loss:0.3886, NB loss:5.1498\n",
      "Pretrain epoch [20/95], ZINB loss:0.3917, NB loss:5.1791\n",
      "Pretrain epoch [21/95], ZINB loss:0.4000, NB loss:5.0679\n",
      "Pretrain epoch [22/95], ZINB loss:0.3793, NB loss:5.0948\n",
      "Pretrain epoch [23/95], ZINB loss:0.3751, NB loss:5.0970\n",
      "Pretrain epoch [24/95], ZINB loss:0.3890, NB loss:5.0865\n",
      "Pretrain epoch [25/95], ZINB loss:0.3877, NB loss:5.0582\n",
      "Pretrain epoch [26/95], ZINB loss:0.3976, NB loss:5.0618\n",
      "Pretrain epoch [27/95], ZINB loss:0.3204, NB loss:5.3635\n",
      "Pretrain epoch [1/96], ZINB loss:0.4078, NB loss:5.1105\n",
      "Pretrain epoch [2/96], ZINB loss:0.3870, NB loss:5.1415\n",
      "Pretrain epoch [3/96], ZINB loss:0.4055, NB loss:5.1105\n",
      "Pretrain epoch [4/96], ZINB loss:0.4003, NB loss:5.0848\n",
      "Pretrain epoch [5/96], ZINB loss:0.3858, NB loss:5.1303\n",
      "Pretrain epoch [6/96], ZINB loss:0.4004, NB loss:5.1553\n",
      "Pretrain epoch [7/96], ZINB loss:0.3885, NB loss:5.1361\n",
      "Pretrain epoch [8/96], ZINB loss:0.4033, NB loss:5.1232\n",
      "Pretrain epoch [9/96], ZINB loss:0.3882, NB loss:5.0587\n",
      "Pretrain epoch [10/96], ZINB loss:0.3843, NB loss:5.1435\n",
      "Pretrain epoch [11/96], ZINB loss:0.3908, NB loss:5.0809\n",
      "Pretrain epoch [12/96], ZINB loss:0.3765, NB loss:5.1059\n",
      "Pretrain epoch [13/96], ZINB loss:0.3920, NB loss:5.1590\n",
      "Pretrain epoch [14/96], ZINB loss:0.4050, NB loss:5.1365\n",
      "Pretrain epoch [15/96], ZINB loss:0.3859, NB loss:5.1286\n",
      "Pretrain epoch [16/96], ZINB loss:0.3851, NB loss:5.0919\n",
      "Pretrain epoch [17/96], ZINB loss:0.3991, NB loss:5.1075\n",
      "Pretrain epoch [18/96], ZINB loss:0.4049, NB loss:5.1456\n",
      "Pretrain epoch [19/96], ZINB loss:0.3823, NB loss:5.0835\n",
      "Pretrain epoch [20/96], ZINB loss:0.3968, NB loss:5.1113\n",
      "Pretrain epoch [21/96], ZINB loss:0.3945, NB loss:5.0839\n",
      "Pretrain epoch [22/96], ZINB loss:0.3917, NB loss:5.0834\n",
      "Pretrain epoch [23/96], ZINB loss:0.3981, NB loss:5.0117\n",
      "Pretrain epoch [24/96], ZINB loss:0.3928, NB loss:5.0835\n",
      "Pretrain epoch [25/96], ZINB loss:0.3814, NB loss:5.0686\n",
      "Pretrain epoch [26/96], ZINB loss:0.3817, NB loss:5.0704\n",
      "Pretrain epoch [27/96], ZINB loss:0.4769, NB loss:4.8778\n",
      "Pretrain epoch [1/97], ZINB loss:0.3662, NB loss:5.1152\n",
      "Pretrain epoch [2/97], ZINB loss:0.3925, NB loss:5.0887\n",
      "Pretrain epoch [3/97], ZINB loss:0.3854, NB loss:5.0995\n",
      "Pretrain epoch [4/97], ZINB loss:0.4009, NB loss:5.1140\n",
      "Pretrain epoch [5/97], ZINB loss:0.4095, NB loss:5.0619\n",
      "Pretrain epoch [6/97], ZINB loss:0.3890, NB loss:5.1082\n",
      "Pretrain epoch [7/97], ZINB loss:0.3838, NB loss:5.1126\n",
      "Pretrain epoch [8/97], ZINB loss:0.3841, NB loss:5.0606\n",
      "Pretrain epoch [9/97], ZINB loss:0.4016, NB loss:5.1976\n",
      "Pretrain epoch [10/97], ZINB loss:0.4069, NB loss:5.1105\n",
      "Pretrain epoch [11/97], ZINB loss:0.4127, NB loss:5.1201\n",
      "Pretrain epoch [12/97], ZINB loss:0.3950, NB loss:5.1080\n",
      "Pretrain epoch [13/97], ZINB loss:0.3980, NB loss:5.1335\n",
      "Pretrain epoch [14/97], ZINB loss:0.3928, NB loss:5.0971\n",
      "Pretrain epoch [15/97], ZINB loss:0.4057, NB loss:5.0779\n",
      "Pretrain epoch [16/97], ZINB loss:0.3780, NB loss:5.0956\n",
      "Pretrain epoch [17/97], ZINB loss:0.4155, NB loss:5.1161\n",
      "Pretrain epoch [18/97], ZINB loss:0.3918, NB loss:5.1171\n",
      "Pretrain epoch [19/97], ZINB loss:0.3959, NB loss:5.0367\n",
      "Pretrain epoch [20/97], ZINB loss:0.3824, NB loss:5.0759\n",
      "Pretrain epoch [21/97], ZINB loss:0.4011, NB loss:5.1956\n",
      "Pretrain epoch [22/97], ZINB loss:0.3840, NB loss:5.0325\n",
      "Pretrain epoch [23/97], ZINB loss:0.3943, NB loss:5.0523\n",
      "Pretrain epoch [24/97], ZINB loss:0.4074, NB loss:5.0383\n",
      "Pretrain epoch [25/97], ZINB loss:0.3890, NB loss:5.0983\n",
      "Pretrain epoch [26/97], ZINB loss:0.3859, NB loss:5.0738\n",
      "Pretrain epoch [27/97], ZINB loss:0.3017, NB loss:5.7337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [1/98], ZINB loss:0.3967, NB loss:5.0773\n",
      "Pretrain epoch [2/98], ZINB loss:0.3982, NB loss:5.1351\n",
      "Pretrain epoch [3/98], ZINB loss:0.4027, NB loss:5.0714\n",
      "Pretrain epoch [4/98], ZINB loss:0.3971, NB loss:5.1388\n",
      "Pretrain epoch [5/98], ZINB loss:0.3943, NB loss:5.0707\n",
      "Pretrain epoch [6/98], ZINB loss:0.3858, NB loss:5.1644\n",
      "Pretrain epoch [7/98], ZINB loss:0.4003, NB loss:5.0910\n",
      "Pretrain epoch [8/98], ZINB loss:0.3780, NB loss:5.0199\n",
      "Pretrain epoch [9/98], ZINB loss:0.3853, NB loss:5.0052\n",
      "Pretrain epoch [10/98], ZINB loss:0.4013, NB loss:5.0391\n",
      "Pretrain epoch [11/98], ZINB loss:0.4051, NB loss:5.1425\n",
      "Pretrain epoch [12/98], ZINB loss:0.3839, NB loss:5.1188\n",
      "Pretrain epoch [13/98], ZINB loss:0.3871, NB loss:5.0365\n",
      "Pretrain epoch [14/98], ZINB loss:0.3714, NB loss:5.1207\n",
      "Pretrain epoch [15/98], ZINB loss:0.4092, NB loss:5.1004\n",
      "Pretrain epoch [16/98], ZINB loss:0.3860, NB loss:5.1693\n",
      "Pretrain epoch [17/98], ZINB loss:0.4017, NB loss:5.1117\n",
      "Pretrain epoch [18/98], ZINB loss:0.3787, NB loss:5.1127\n",
      "Pretrain epoch [19/98], ZINB loss:0.3870, NB loss:5.0385\n",
      "Pretrain epoch [20/98], ZINB loss:0.4066, NB loss:5.0588\n",
      "Pretrain epoch [21/98], ZINB loss:0.3959, NB loss:5.0802\n",
      "Pretrain epoch [22/98], ZINB loss:0.3826, NB loss:5.0938\n",
      "Pretrain epoch [23/98], ZINB loss:0.4046, NB loss:5.0625\n",
      "Pretrain epoch [24/98], ZINB loss:0.3906, NB loss:5.1379\n",
      "Pretrain epoch [25/98], ZINB loss:0.4012, NB loss:5.1391\n",
      "Pretrain epoch [26/98], ZINB loss:0.3791, NB loss:5.0394\n",
      "Pretrain epoch [27/98], ZINB loss:0.3026, NB loss:4.7643\n",
      "Pretrain epoch [1/99], ZINB loss:0.4080, NB loss:5.0887\n",
      "Pretrain epoch [2/99], ZINB loss:0.3695, NB loss:5.0651\n",
      "Pretrain epoch [3/99], ZINB loss:0.3897, NB loss:5.1331\n",
      "Pretrain epoch [4/99], ZINB loss:0.3986, NB loss:5.1560\n",
      "Pretrain epoch [5/99], ZINB loss:0.3968, NB loss:5.1429\n",
      "Pretrain epoch [6/99], ZINB loss:0.3866, NB loss:5.1688\n",
      "Pretrain epoch [7/99], ZINB loss:0.3991, NB loss:5.0709\n",
      "Pretrain epoch [8/99], ZINB loss:0.3979, NB loss:5.0792\n",
      "Pretrain epoch [9/99], ZINB loss:0.3853, NB loss:5.0091\n",
      "Pretrain epoch [10/99], ZINB loss:0.3989, NB loss:5.1062\n",
      "Pretrain epoch [11/99], ZINB loss:0.3896, NB loss:5.0474\n",
      "Pretrain epoch [12/99], ZINB loss:0.3846, NB loss:5.1071\n",
      "Pretrain epoch [13/99], ZINB loss:0.3808, NB loss:5.1052\n",
      "Pretrain epoch [14/99], ZINB loss:0.3839, NB loss:5.0901\n",
      "Pretrain epoch [15/99], ZINB loss:0.3884, NB loss:5.0434\n",
      "Pretrain epoch [16/99], ZINB loss:0.3944, NB loss:5.0724\n",
      "Pretrain epoch [17/99], ZINB loss:0.3982, NB loss:5.1724\n",
      "Pretrain epoch [18/99], ZINB loss:0.3922, NB loss:5.0576\n",
      "Pretrain epoch [19/99], ZINB loss:0.3917, NB loss:5.0025\n",
      "Pretrain epoch [20/99], ZINB loss:0.3997, NB loss:5.0902\n",
      "Pretrain epoch [21/99], ZINB loss:0.3967, NB loss:5.0200\n",
      "Pretrain epoch [22/99], ZINB loss:0.3956, NB loss:5.1159\n",
      "Pretrain epoch [23/99], ZINB loss:0.4016, NB loss:5.0742\n",
      "Pretrain epoch [24/99], ZINB loss:0.3965, NB loss:5.0561\n",
      "Pretrain epoch [25/99], ZINB loss:0.3830, NB loss:5.0260\n",
      "Pretrain epoch [26/99], ZINB loss:0.3920, NB loss:5.0664\n",
      "Pretrain epoch [27/99], ZINB loss:0.2819, NB loss:5.4529\n",
      "Pretrain epoch [1/100], ZINB loss:0.4005, NB loss:5.0824\n",
      "Pretrain epoch [2/100], ZINB loss:0.3860, NB loss:5.0890\n",
      "Pretrain epoch [3/100], ZINB loss:0.3721, NB loss:5.0610\n",
      "Pretrain epoch [4/100], ZINB loss:0.4057, NB loss:5.0993\n",
      "Pretrain epoch [5/100], ZINB loss:0.4091, NB loss:5.0868\n",
      "Pretrain epoch [6/100], ZINB loss:0.3888, NB loss:5.0355\n",
      "Pretrain epoch [7/100], ZINB loss:0.3860, NB loss:5.0404\n",
      "Pretrain epoch [8/100], ZINB loss:0.3889, NB loss:5.0716\n",
      "Pretrain epoch [9/100], ZINB loss:0.3997, NB loss:5.0963\n",
      "Pretrain epoch [10/100], ZINB loss:0.3807, NB loss:5.0621\n",
      "Pretrain epoch [11/100], ZINB loss:0.4167, NB loss:5.0362\n",
      "Pretrain epoch [12/100], ZINB loss:0.3804, NB loss:5.1173\n",
      "Pretrain epoch [13/100], ZINB loss:0.3885, NB loss:5.0289\n",
      "Pretrain epoch [14/100], ZINB loss:0.3867, NB loss:5.1018\n",
      "Pretrain epoch [15/100], ZINB loss:0.4039, NB loss:5.1077\n",
      "Pretrain epoch [16/100], ZINB loss:0.3859, NB loss:5.0542\n",
      "Pretrain epoch [17/100], ZINB loss:0.3847, NB loss:5.1273\n",
      "Pretrain epoch [18/100], ZINB loss:0.3724, NB loss:5.0994\n",
      "Pretrain epoch [19/100], ZINB loss:0.4038, NB loss:5.0729\n",
      "Pretrain epoch [20/100], ZINB loss:0.3959, NB loss:5.1253\n",
      "Pretrain epoch [21/100], ZINB loss:0.3878, NB loss:5.1070\n",
      "Pretrain epoch [22/100], ZINB loss:0.4081, NB loss:5.0290\n",
      "Pretrain epoch [23/100], ZINB loss:0.3865, NB loss:5.1069\n",
      "Pretrain epoch [24/100], ZINB loss:0.4055, NB loss:5.0535\n",
      "Pretrain epoch [25/100], ZINB loss:0.3985, NB loss:5.0639\n",
      "Pretrain epoch [26/100], ZINB loss:0.3807, NB loss:5.0337\n",
      "Pretrain epoch [27/100], ZINB loss:0.3888, NB loss:5.5003\n",
      "Pretrain epoch [1/101], ZINB loss:0.3888, NB loss:5.0605\n",
      "Pretrain epoch [2/101], ZINB loss:0.3837, NB loss:5.1347\n",
      "Pretrain epoch [3/101], ZINB loss:0.3878, NB loss:5.0812\n",
      "Pretrain epoch [4/101], ZINB loss:0.3856, NB loss:5.0376\n",
      "Pretrain epoch [5/101], ZINB loss:0.3995, NB loss:5.0583\n",
      "Pretrain epoch [6/101], ZINB loss:0.3827, NB loss:5.1059\n",
      "Pretrain epoch [7/101], ZINB loss:0.3700, NB loss:5.0877\n",
      "Pretrain epoch [8/101], ZINB loss:0.3991, NB loss:5.0862\n",
      "Pretrain epoch [9/101], ZINB loss:0.3860, NB loss:5.1255\n",
      "Pretrain epoch [10/101], ZINB loss:0.3971, NB loss:5.0450\n",
      "Pretrain epoch [11/101], ZINB loss:0.3913, NB loss:5.1119\n",
      "Pretrain epoch [12/101], ZINB loss:0.4042, NB loss:5.1171\n",
      "Pretrain epoch [13/101], ZINB loss:0.3889, NB loss:5.0311\n",
      "Pretrain epoch [14/101], ZINB loss:0.4003, NB loss:5.1265\n",
      "Pretrain epoch [15/101], ZINB loss:0.3988, NB loss:4.9859\n",
      "Pretrain epoch [16/101], ZINB loss:0.3935, NB loss:5.0770\n",
      "Pretrain epoch [17/101], ZINB loss:0.4012, NB loss:5.0651\n",
      "Pretrain epoch [18/101], ZINB loss:0.3806, NB loss:5.0725\n",
      "Pretrain epoch [19/101], ZINB loss:0.3689, NB loss:5.0373\n",
      "Pretrain epoch [20/101], ZINB loss:0.4063, NB loss:5.0577\n",
      "Pretrain epoch [21/101], ZINB loss:0.3802, NB loss:5.0062\n",
      "Pretrain epoch [22/101], ZINB loss:0.3992, NB loss:4.9771\n",
      "Pretrain epoch [23/101], ZINB loss:0.4027, NB loss:5.0701\n",
      "Pretrain epoch [24/101], ZINB loss:0.4101, NB loss:5.0578\n",
      "Pretrain epoch [25/101], ZINB loss:0.4096, NB loss:5.0943\n",
      "Pretrain epoch [26/101], ZINB loss:0.3956, NB loss:5.1080\n",
      "Pretrain epoch [27/101], ZINB loss:0.5616, NB loss:5.1878\n",
      "Pretrain epoch [1/102], ZINB loss:0.4028, NB loss:5.1117\n",
      "Pretrain epoch [2/102], ZINB loss:0.3940, NB loss:5.1076\n",
      "Pretrain epoch [3/102], ZINB loss:0.3874, NB loss:5.0676\n",
      "Pretrain epoch [4/102], ZINB loss:0.4131, NB loss:5.0430\n",
      "Pretrain epoch [5/102], ZINB loss:0.3963, NB loss:5.0473\n",
      "Pretrain epoch [6/102], ZINB loss:0.4017, NB loss:5.0771\n",
      "Pretrain epoch [7/102], ZINB loss:0.3947, NB loss:5.0251\n",
      "Pretrain epoch [8/102], ZINB loss:0.3703, NB loss:5.1091\n",
      "Pretrain epoch [9/102], ZINB loss:0.3906, NB loss:5.1442\n",
      "Pretrain epoch [10/102], ZINB loss:0.3940, NB loss:5.0230\n",
      "Pretrain epoch [11/102], ZINB loss:0.3899, NB loss:5.0603\n",
      "Pretrain epoch [12/102], ZINB loss:0.3917, NB loss:5.0401\n",
      "Pretrain epoch [13/102], ZINB loss:0.3969, NB loss:5.0128\n",
      "Pretrain epoch [14/102], ZINB loss:0.3992, NB loss:5.0324\n",
      "Pretrain epoch [15/102], ZINB loss:0.4115, NB loss:5.1119\n",
      "Pretrain epoch [16/102], ZINB loss:0.3817, NB loss:5.0796\n",
      "Pretrain epoch [17/102], ZINB loss:0.3975, NB loss:5.0185\n",
      "Pretrain epoch [18/102], ZINB loss:0.3963, NB loss:5.0355\n",
      "Pretrain epoch [19/102], ZINB loss:0.3945, NB loss:5.0547\n",
      "Pretrain epoch [20/102], ZINB loss:0.4039, NB loss:5.0628\n",
      "Pretrain epoch [21/102], ZINB loss:0.3973, NB loss:5.0149\n",
      "Pretrain epoch [22/102], ZINB loss:0.4022, NB loss:5.0652\n",
      "Pretrain epoch [23/102], ZINB loss:0.4021, NB loss:5.1169\n",
      "Pretrain epoch [24/102], ZINB loss:0.4017, NB loss:5.0369\n",
      "Pretrain epoch [25/102], ZINB loss:0.4120, NB loss:5.0769\n",
      "Pretrain epoch [26/102], ZINB loss:0.4205, NB loss:5.0524\n",
      "Pretrain epoch [27/102], ZINB loss:0.3909, NB loss:5.4740\n",
      "Pretrain epoch [1/103], ZINB loss:0.3881, NB loss:5.0308\n",
      "Pretrain epoch [2/103], ZINB loss:0.3743, NB loss:5.0715\n",
      "Pretrain epoch [3/103], ZINB loss:0.3972, NB loss:5.1090\n",
      "Pretrain epoch [4/103], ZINB loss:0.3801, NB loss:4.9846\n",
      "Pretrain epoch [5/103], ZINB loss:0.3922, NB loss:5.0054\n",
      "Pretrain epoch [6/103], ZINB loss:0.3889, NB loss:5.0803\n",
      "Pretrain epoch [7/103], ZINB loss:0.3915, NB loss:5.0156\n",
      "Pretrain epoch [8/103], ZINB loss:0.4019, NB loss:5.0987\n",
      "Pretrain epoch [9/103], ZINB loss:0.3965, NB loss:5.0257\n",
      "Pretrain epoch [10/103], ZINB loss:0.3828, NB loss:5.0937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [11/103], ZINB loss:0.4160, NB loss:5.0599\n",
      "Pretrain epoch [12/103], ZINB loss:0.3942, NB loss:5.0768\n",
      "Pretrain epoch [13/103], ZINB loss:0.4072, NB loss:5.0821\n",
      "Pretrain epoch [14/103], ZINB loss:0.4057, NB loss:4.9645\n",
      "Pretrain epoch [15/103], ZINB loss:0.3975, NB loss:5.0963\n",
      "Pretrain epoch [16/103], ZINB loss:0.3820, NB loss:5.0593\n",
      "Pretrain epoch [17/103], ZINB loss:0.3906, NB loss:5.0879\n",
      "Pretrain epoch [18/103], ZINB loss:0.4113, NB loss:5.0575\n",
      "Pretrain epoch [19/103], ZINB loss:0.3928, NB loss:5.0383\n",
      "Pretrain epoch [20/103], ZINB loss:0.3850, NB loss:5.1542\n",
      "Pretrain epoch [21/103], ZINB loss:0.3932, NB loss:5.0548\n",
      "Pretrain epoch [22/103], ZINB loss:0.4163, NB loss:5.0226\n",
      "Pretrain epoch [23/103], ZINB loss:0.3999, NB loss:5.0081\n",
      "Pretrain epoch [24/103], ZINB loss:0.3774, NB loss:5.0254\n",
      "Pretrain epoch [25/103], ZINB loss:0.3996, NB loss:5.1361\n",
      "Pretrain epoch [26/103], ZINB loss:0.3931, NB loss:5.0263\n",
      "Pretrain epoch [27/103], ZINB loss:0.3714, NB loss:5.0474\n",
      "Pretrain epoch [1/104], ZINB loss:0.4061, NB loss:5.0206\n",
      "Pretrain epoch [2/104], ZINB loss:0.3876, NB loss:5.0281\n",
      "Pretrain epoch [3/104], ZINB loss:0.3818, NB loss:4.9936\n",
      "Pretrain epoch [4/104], ZINB loss:0.3926, NB loss:5.0725\n",
      "Pretrain epoch [5/104], ZINB loss:0.3877, NB loss:5.1151\n",
      "Pretrain epoch [6/104], ZINB loss:0.3934, NB loss:5.0240\n",
      "Pretrain epoch [7/104], ZINB loss:0.4092, NB loss:5.0160\n",
      "Pretrain epoch [8/104], ZINB loss:0.3890, NB loss:5.0910\n",
      "Pretrain epoch [9/104], ZINB loss:0.4062, NB loss:5.0413\n",
      "Pretrain epoch [10/104], ZINB loss:0.3886, NB loss:5.0331\n",
      "Pretrain epoch [11/104], ZINB loss:0.3940, NB loss:5.0713\n",
      "Pretrain epoch [12/104], ZINB loss:0.3745, NB loss:5.0387\n",
      "Pretrain epoch [13/104], ZINB loss:0.3997, NB loss:5.0352\n",
      "Pretrain epoch [14/104], ZINB loss:0.4029, NB loss:5.0718\n",
      "Pretrain epoch [15/104], ZINB loss:0.4056, NB loss:5.0749\n",
      "Pretrain epoch [16/104], ZINB loss:0.3811, NB loss:5.0710\n",
      "Pretrain epoch [17/104], ZINB loss:0.4078, NB loss:5.0731\n",
      "Pretrain epoch [18/104], ZINB loss:0.3905, NB loss:5.0256\n",
      "Pretrain epoch [19/104], ZINB loss:0.4066, NB loss:5.0353\n",
      "Pretrain epoch [20/104], ZINB loss:0.3964, NB loss:5.0233\n",
      "Pretrain epoch [21/104], ZINB loss:0.4175, NB loss:5.0805\n",
      "Pretrain epoch [22/104], ZINB loss:0.3778, NB loss:5.0493\n",
      "Pretrain epoch [23/104], ZINB loss:0.4076, NB loss:5.0414\n",
      "Pretrain epoch [24/104], ZINB loss:0.3916, NB loss:5.0483\n",
      "Pretrain epoch [25/104], ZINB loss:0.3582, NB loss:5.0649\n",
      "Pretrain epoch [26/104], ZINB loss:0.3860, NB loss:5.0528\n",
      "Pretrain epoch [27/104], ZINB loss:0.4874, NB loss:4.8469\n",
      "Pretrain epoch [1/105], ZINB loss:0.4070, NB loss:5.0766\n",
      "Pretrain epoch [2/105], ZINB loss:0.3962, NB loss:5.0867\n",
      "Pretrain epoch [3/105], ZINB loss:0.4063, NB loss:5.0363\n",
      "Pretrain epoch [4/105], ZINB loss:0.4047, NB loss:5.0849\n",
      "Pretrain epoch [5/105], ZINB loss:0.4068, NB loss:5.0444\n",
      "Pretrain epoch [6/105], ZINB loss:0.3947, NB loss:5.0537\n",
      "Pretrain epoch [7/105], ZINB loss:0.3940, NB loss:5.0006\n",
      "Pretrain epoch [8/105], ZINB loss:0.4193, NB loss:5.0496\n",
      "Pretrain epoch [9/105], ZINB loss:0.3912, NB loss:5.0760\n",
      "Pretrain epoch [10/105], ZINB loss:0.3886, NB loss:5.0753\n",
      "Pretrain epoch [11/105], ZINB loss:0.4001, NB loss:5.0007\n",
      "Pretrain epoch [12/105], ZINB loss:0.4188, NB loss:5.0580\n",
      "Pretrain epoch [13/105], ZINB loss:0.3868, NB loss:5.0284\n",
      "Pretrain epoch [14/105], ZINB loss:0.4043, NB loss:5.0114\n",
      "Pretrain epoch [15/105], ZINB loss:0.4020, NB loss:5.0979\n",
      "Pretrain epoch [16/105], ZINB loss:0.3832, NB loss:5.0063\n",
      "Pretrain epoch [17/105], ZINB loss:0.3740, NB loss:4.9808\n",
      "Pretrain epoch [18/105], ZINB loss:0.3942, NB loss:5.0778\n",
      "Pretrain epoch [19/105], ZINB loss:0.3735, NB loss:4.9836\n",
      "Pretrain epoch [20/105], ZINB loss:0.3909, NB loss:4.9742\n",
      "Pretrain epoch [21/105], ZINB loss:0.4025, NB loss:5.0183\n",
      "Pretrain epoch [22/105], ZINB loss:0.4055, NB loss:5.0778\n",
      "Pretrain epoch [23/105], ZINB loss:0.3893, NB loss:5.0002\n",
      "Pretrain epoch [24/105], ZINB loss:0.3876, NB loss:5.0844\n",
      "Pretrain epoch [25/105], ZINB loss:0.3859, NB loss:5.0459\n",
      "Pretrain epoch [26/105], ZINB loss:0.3996, NB loss:5.0876\n",
      "Pretrain epoch [27/105], ZINB loss:0.3776, NB loss:4.7353\n",
      "Pretrain epoch [1/106], ZINB loss:0.3894, NB loss:5.0016\n",
      "Pretrain epoch [2/106], ZINB loss:0.3868, NB loss:4.9934\n",
      "Pretrain epoch [3/106], ZINB loss:0.3911, NB loss:5.0615\n",
      "Pretrain epoch [4/106], ZINB loss:0.3975, NB loss:5.0488\n",
      "Pretrain epoch [5/106], ZINB loss:0.4025, NB loss:5.0287\n",
      "Pretrain epoch [6/106], ZINB loss:0.3816, NB loss:5.1244\n",
      "Pretrain epoch [7/106], ZINB loss:0.4209, NB loss:4.9638\n",
      "Pretrain epoch [8/106], ZINB loss:0.3910, NB loss:5.0742\n",
      "Pretrain epoch [9/106], ZINB loss:0.3837, NB loss:5.0828\n",
      "Pretrain epoch [10/106], ZINB loss:0.4018, NB loss:5.0784\n",
      "Pretrain epoch [11/106], ZINB loss:0.3953, NB loss:5.0869\n",
      "Pretrain epoch [12/106], ZINB loss:0.3964, NB loss:5.0694\n",
      "Pretrain epoch [13/106], ZINB loss:0.3805, NB loss:5.0053\n",
      "Pretrain epoch [14/106], ZINB loss:0.4098, NB loss:4.9841\n",
      "Pretrain epoch [15/106], ZINB loss:0.4041, NB loss:5.0416\n",
      "Pretrain epoch [16/106], ZINB loss:0.3866, NB loss:5.0331\n",
      "Pretrain epoch [17/106], ZINB loss:0.4007, NB loss:5.0312\n",
      "Pretrain epoch [18/106], ZINB loss:0.3776, NB loss:5.0338\n",
      "Pretrain epoch [19/106], ZINB loss:0.3712, NB loss:5.0127\n",
      "Pretrain epoch [20/106], ZINB loss:0.4196, NB loss:4.9977\n",
      "Pretrain epoch [21/106], ZINB loss:0.3905, NB loss:5.0051\n",
      "Pretrain epoch [22/106], ZINB loss:0.3907, NB loss:5.0249\n",
      "Pretrain epoch [23/106], ZINB loss:0.4004, NB loss:4.9848\n",
      "Pretrain epoch [24/106], ZINB loss:0.3918, NB loss:5.0685\n",
      "Pretrain epoch [25/106], ZINB loss:0.4035, NB loss:5.0725\n",
      "Pretrain epoch [26/106], ZINB loss:0.3998, NB loss:5.0335\n",
      "Pretrain epoch [27/106], ZINB loss:0.3293, NB loss:4.9692\n",
      "Pretrain epoch [1/107], ZINB loss:0.3975, NB loss:4.9960\n",
      "Pretrain epoch [2/107], ZINB loss:0.3910, NB loss:5.0528\n",
      "Pretrain epoch [3/107], ZINB loss:0.4035, NB loss:4.9665\n",
      "Pretrain epoch [4/107], ZINB loss:0.3924, NB loss:5.0640\n",
      "Pretrain epoch [5/107], ZINB loss:0.3844, NB loss:5.0905\n",
      "Pretrain epoch [6/107], ZINB loss:0.4006, NB loss:5.0096\n",
      "Pretrain epoch [7/107], ZINB loss:0.3852, NB loss:4.9479\n",
      "Pretrain epoch [8/107], ZINB loss:0.3922, NB loss:5.0016\n",
      "Pretrain epoch [9/107], ZINB loss:0.3992, NB loss:5.0706\n",
      "Pretrain epoch [10/107], ZINB loss:0.3941, NB loss:5.0302\n",
      "Pretrain epoch [11/107], ZINB loss:0.3865, NB loss:5.0555\n",
      "Pretrain epoch [12/107], ZINB loss:0.3812, NB loss:5.0111\n",
      "Pretrain epoch [13/107], ZINB loss:0.3926, NB loss:4.9477\n",
      "Pretrain epoch [14/107], ZINB loss:0.3874, NB loss:5.0300\n",
      "Pretrain epoch [15/107], ZINB loss:0.4130, NB loss:5.1141\n",
      "Pretrain epoch [16/107], ZINB loss:0.4048, NB loss:5.0681\n",
      "Pretrain epoch [17/107], ZINB loss:0.3998, NB loss:5.0817\n",
      "Pretrain epoch [18/107], ZINB loss:0.3851, NB loss:4.9666\n",
      "Pretrain epoch [19/107], ZINB loss:0.3868, NB loss:5.0268\n",
      "Pretrain epoch [20/107], ZINB loss:0.3959, NB loss:5.0335\n",
      "Pretrain epoch [21/107], ZINB loss:0.4046, NB loss:5.0718\n",
      "Pretrain epoch [22/107], ZINB loss:0.4053, NB loss:5.0630\n",
      "Pretrain epoch [23/107], ZINB loss:0.3922, NB loss:5.0151\n",
      "Pretrain epoch [24/107], ZINB loss:0.3808, NB loss:5.0088\n",
      "Pretrain epoch [25/107], ZINB loss:0.3978, NB loss:5.0363\n",
      "Pretrain epoch [26/107], ZINB loss:0.4047, NB loss:5.0028\n",
      "Pretrain epoch [27/107], ZINB loss:0.3655, NB loss:5.4211\n",
      "Pretrain epoch [1/108], ZINB loss:0.3904, NB loss:5.0025\n",
      "Pretrain epoch [2/108], ZINB loss:0.3864, NB loss:4.9949\n",
      "Pretrain epoch [3/108], ZINB loss:0.3959, NB loss:5.1065\n",
      "Pretrain epoch [4/108], ZINB loss:0.3992, NB loss:5.1157\n",
      "Pretrain epoch [5/108], ZINB loss:0.4023, NB loss:5.0201\n",
      "Pretrain epoch [6/108], ZINB loss:0.4002, NB loss:4.9860\n",
      "Pretrain epoch [7/108], ZINB loss:0.3942, NB loss:4.9293\n",
      "Pretrain epoch [8/108], ZINB loss:0.3925, NB loss:5.0786\n",
      "Pretrain epoch [9/108], ZINB loss:0.4111, NB loss:5.0525\n",
      "Pretrain epoch [10/108], ZINB loss:0.3912, NB loss:5.0160\n",
      "Pretrain epoch [11/108], ZINB loss:0.4116, NB loss:4.9975\n",
      "Pretrain epoch [12/108], ZINB loss:0.3761, NB loss:4.9087\n",
      "Pretrain epoch [13/108], ZINB loss:0.3801, NB loss:5.0738\n",
      "Pretrain epoch [14/108], ZINB loss:0.3782, NB loss:5.0145\n",
      "Pretrain epoch [15/108], ZINB loss:0.3925, NB loss:4.9789\n",
      "Pretrain epoch [16/108], ZINB loss:0.3883, NB loss:5.0274\n",
      "Pretrain epoch [17/108], ZINB loss:0.3918, NB loss:5.0835\n",
      "Pretrain epoch [18/108], ZINB loss:0.4103, NB loss:5.0089\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [19/108], ZINB loss:0.3961, NB loss:5.0712\n",
      "Pretrain epoch [20/108], ZINB loss:0.3938, NB loss:5.0197\n",
      "Pretrain epoch [21/108], ZINB loss:0.3937, NB loss:4.9674\n",
      "Pretrain epoch [22/108], ZINB loss:0.3964, NB loss:4.9447\n",
      "Pretrain epoch [23/108], ZINB loss:0.3981, NB loss:5.0445\n",
      "Pretrain epoch [24/108], ZINB loss:0.3918, NB loss:5.0056\n",
      "Pretrain epoch [25/108], ZINB loss:0.3824, NB loss:5.0962\n",
      "Pretrain epoch [26/108], ZINB loss:0.3838, NB loss:5.0626\n",
      "Pretrain epoch [27/108], ZINB loss:0.3158, NB loss:4.8922\n",
      "Pretrain epoch [1/109], ZINB loss:0.3838, NB loss:5.0223\n",
      "Pretrain epoch [2/109], ZINB loss:0.3857, NB loss:5.0175\n",
      "Pretrain epoch [3/109], ZINB loss:0.3924, NB loss:5.0359\n",
      "Pretrain epoch [4/109], ZINB loss:0.3901, NB loss:4.9952\n",
      "Pretrain epoch [5/109], ZINB loss:0.3719, NB loss:5.1097\n",
      "Pretrain epoch [6/109], ZINB loss:0.3968, NB loss:4.9945\n",
      "Pretrain epoch [7/109], ZINB loss:0.3961, NB loss:5.0254\n",
      "Pretrain epoch [8/109], ZINB loss:0.3951, NB loss:4.9798\n",
      "Pretrain epoch [9/109], ZINB loss:0.3969, NB loss:5.0443\n",
      "Pretrain epoch [10/109], ZINB loss:0.3878, NB loss:4.9855\n",
      "Pretrain epoch [11/109], ZINB loss:0.3931, NB loss:4.9765\n",
      "Pretrain epoch [12/109], ZINB loss:0.3844, NB loss:4.9896\n",
      "Pretrain epoch [13/109], ZINB loss:0.3985, NB loss:4.9988\n",
      "Pretrain epoch [14/109], ZINB loss:0.3870, NB loss:5.0454\n",
      "Pretrain epoch [15/109], ZINB loss:0.4075, NB loss:4.9748\n",
      "Pretrain epoch [16/109], ZINB loss:0.3804, NB loss:5.0220\n",
      "Pretrain epoch [17/109], ZINB loss:0.3985, NB loss:5.0246\n",
      "Pretrain epoch [18/109], ZINB loss:0.4085, NB loss:4.9769\n",
      "Pretrain epoch [19/109], ZINB loss:0.3930, NB loss:5.0462\n",
      "Pretrain epoch [20/109], ZINB loss:0.3915, NB loss:5.0549\n",
      "Pretrain epoch [21/109], ZINB loss:0.4037, NB loss:5.0239\n",
      "Pretrain epoch [22/109], ZINB loss:0.3801, NB loss:5.0692\n",
      "Pretrain epoch [23/109], ZINB loss:0.3966, NB loss:4.9996\n",
      "Pretrain epoch [24/109], ZINB loss:0.4119, NB loss:5.0004\n",
      "Pretrain epoch [25/109], ZINB loss:0.3964, NB loss:5.0313\n",
      "Pretrain epoch [26/109], ZINB loss:0.3938, NB loss:4.9887\n",
      "Pretrain epoch [27/109], ZINB loss:0.3198, NB loss:5.3825\n",
      "Pretrain epoch [1/110], ZINB loss:0.3912, NB loss:5.0173\n",
      "Pretrain epoch [2/110], ZINB loss:0.3991, NB loss:5.1045\n",
      "Pretrain epoch [3/110], ZINB loss:0.3981, NB loss:5.0790\n",
      "Pretrain epoch [4/110], ZINB loss:0.3924, NB loss:5.0490\n",
      "Pretrain epoch [5/110], ZINB loss:0.3924, NB loss:4.9788\n",
      "Pretrain epoch [6/110], ZINB loss:0.3939, NB loss:5.0040\n",
      "Pretrain epoch [7/110], ZINB loss:0.4014, NB loss:5.0082\n",
      "Pretrain epoch [8/110], ZINB loss:0.4015, NB loss:5.0749\n",
      "Pretrain epoch [9/110], ZINB loss:0.4077, NB loss:5.0380\n",
      "Pretrain epoch [10/110], ZINB loss:0.3925, NB loss:4.9680\n",
      "Pretrain epoch [11/110], ZINB loss:0.3951, NB loss:4.9674\n",
      "Pretrain epoch [12/110], ZINB loss:0.4016, NB loss:5.0691\n",
      "Pretrain epoch [13/110], ZINB loss:0.3875, NB loss:5.0057\n",
      "Pretrain epoch [14/110], ZINB loss:0.3896, NB loss:5.0123\n",
      "Pretrain epoch [15/110], ZINB loss:0.4010, NB loss:5.0532\n",
      "Pretrain epoch [16/110], ZINB loss:0.4037, NB loss:4.9935\n",
      "Pretrain epoch [17/110], ZINB loss:0.3851, NB loss:4.9342\n",
      "Pretrain epoch [18/110], ZINB loss:0.3941, NB loss:4.9506\n",
      "Pretrain epoch [19/110], ZINB loss:0.4098, NB loss:4.9705\n",
      "Pretrain epoch [20/110], ZINB loss:0.3936, NB loss:5.0448\n",
      "Pretrain epoch [21/110], ZINB loss:0.3795, NB loss:4.9629\n",
      "Pretrain epoch [22/110], ZINB loss:0.3975, NB loss:5.0244\n",
      "Pretrain epoch [23/110], ZINB loss:0.3838, NB loss:4.9548\n",
      "Pretrain epoch [24/110], ZINB loss:0.3712, NB loss:4.9548\n",
      "Pretrain epoch [25/110], ZINB loss:0.3801, NB loss:5.0483\n",
      "Pretrain epoch [26/110], ZINB loss:0.3763, NB loss:5.0167\n",
      "Pretrain epoch [27/110], ZINB loss:0.4808, NB loss:4.4470\n",
      "Pretrain epoch [1/111], ZINB loss:0.3725, NB loss:5.0650\n",
      "Pretrain epoch [2/111], ZINB loss:0.4238, NB loss:5.0295\n",
      "Pretrain epoch [3/111], ZINB loss:0.3771, NB loss:5.0314\n",
      "Pretrain epoch [4/111], ZINB loss:0.3953, NB loss:4.9702\n",
      "Pretrain epoch [5/111], ZINB loss:0.3895, NB loss:5.0008\n",
      "Pretrain epoch [6/111], ZINB loss:0.3867, NB loss:5.0029\n",
      "Pretrain epoch [7/111], ZINB loss:0.3904, NB loss:4.9410\n",
      "Pretrain epoch [8/111], ZINB loss:0.4020, NB loss:4.9978\n",
      "Pretrain epoch [9/111], ZINB loss:0.4114, NB loss:4.9642\n",
      "Pretrain epoch [10/111], ZINB loss:0.3929, NB loss:5.0058\n",
      "Pretrain epoch [11/111], ZINB loss:0.4030, NB loss:4.9777\n",
      "Pretrain epoch [12/111], ZINB loss:0.3743, NB loss:5.0423\n",
      "Pretrain epoch [13/111], ZINB loss:0.3811, NB loss:5.0018\n",
      "Pretrain epoch [14/111], ZINB loss:0.4003, NB loss:5.0260\n",
      "Pretrain epoch [15/111], ZINB loss:0.3853, NB loss:4.9600\n",
      "Pretrain epoch [16/111], ZINB loss:0.4126, NB loss:5.0421\n",
      "Pretrain epoch [17/111], ZINB loss:0.3909, NB loss:4.9967\n",
      "Pretrain epoch [18/111], ZINB loss:0.3695, NB loss:5.0208\n",
      "Pretrain epoch [19/111], ZINB loss:0.4056, NB loss:5.0416\n",
      "Pretrain epoch [20/111], ZINB loss:0.3969, NB loss:5.0748\n",
      "Pretrain epoch [21/111], ZINB loss:0.3952, NB loss:4.9833\n",
      "Pretrain epoch [22/111], ZINB loss:0.4007, NB loss:4.9505\n",
      "Pretrain epoch [23/111], ZINB loss:0.3936, NB loss:4.9875\n",
      "Pretrain epoch [24/111], ZINB loss:0.4007, NB loss:4.9348\n",
      "Pretrain epoch [25/111], ZINB loss:0.3881, NB loss:5.0210\n",
      "Pretrain epoch [26/111], ZINB loss:0.3858, NB loss:5.0420\n",
      "Pretrain epoch [27/111], ZINB loss:0.3441, NB loss:4.9677\n",
      "Pretrain epoch [1/112], ZINB loss:0.3901, NB loss:5.0234\n",
      "Pretrain epoch [2/112], ZINB loss:0.3727, NB loss:4.9527\n",
      "Pretrain epoch [3/112], ZINB loss:0.3976, NB loss:4.9708\n",
      "Pretrain epoch [4/112], ZINB loss:0.3911, NB loss:4.9282\n",
      "Pretrain epoch [5/112], ZINB loss:0.3840, NB loss:5.0037\n",
      "Pretrain epoch [6/112], ZINB loss:0.3999, NB loss:5.0854\n",
      "Pretrain epoch [7/112], ZINB loss:0.3924, NB loss:5.0290\n",
      "Pretrain epoch [8/112], ZINB loss:0.3876, NB loss:5.0237\n",
      "Pretrain epoch [9/112], ZINB loss:0.3878, NB loss:4.9565\n",
      "Pretrain epoch [10/112], ZINB loss:0.3777, NB loss:4.9772\n",
      "Pretrain epoch [11/112], ZINB loss:0.4080, NB loss:4.9660\n",
      "Pretrain epoch [12/112], ZINB loss:0.4120, NB loss:5.0176\n",
      "Pretrain epoch [13/112], ZINB loss:0.3889, NB loss:5.0111\n",
      "Pretrain epoch [14/112], ZINB loss:0.3979, NB loss:5.0765\n",
      "Pretrain epoch [15/112], ZINB loss:0.3995, NB loss:5.0630\n",
      "Pretrain epoch [16/112], ZINB loss:0.3797, NB loss:4.9980\n",
      "Pretrain epoch [17/112], ZINB loss:0.4063, NB loss:5.0060\n",
      "Pretrain epoch [18/112], ZINB loss:0.4034, NB loss:5.0254\n",
      "Pretrain epoch [19/112], ZINB loss:0.3905, NB loss:4.9571\n",
      "Pretrain epoch [20/112], ZINB loss:0.4033, NB loss:4.9674\n",
      "Pretrain epoch [21/112], ZINB loss:0.4021, NB loss:4.9975\n",
      "Pretrain epoch [22/112], ZINB loss:0.4011, NB loss:4.9951\n",
      "Pretrain epoch [23/112], ZINB loss:0.3966, NB loss:4.9824\n",
      "Pretrain epoch [24/112], ZINB loss:0.3791, NB loss:4.9666\n",
      "Pretrain epoch [25/112], ZINB loss:0.3807, NB loss:4.9838\n",
      "Pretrain epoch [26/112], ZINB loss:0.3906, NB loss:4.9944\n",
      "Pretrain epoch [27/112], ZINB loss:0.3620, NB loss:4.7172\n",
      "Pretrain epoch [1/113], ZINB loss:0.3883, NB loss:4.9696\n",
      "Pretrain epoch [2/113], ZINB loss:0.3895, NB loss:4.9564\n",
      "Pretrain epoch [3/113], ZINB loss:0.4011, NB loss:5.0599\n",
      "Pretrain epoch [4/113], ZINB loss:0.3810, NB loss:4.9840\n",
      "Pretrain epoch [5/113], ZINB loss:0.3965, NB loss:5.0371\n",
      "Pretrain epoch [6/113], ZINB loss:0.3914, NB loss:5.0008\n",
      "Pretrain epoch [7/113], ZINB loss:0.3914, NB loss:4.9552\n",
      "Pretrain epoch [8/113], ZINB loss:0.3773, NB loss:5.0595\n",
      "Pretrain epoch [9/113], ZINB loss:0.3834, NB loss:4.9908\n",
      "Pretrain epoch [10/113], ZINB loss:0.3792, NB loss:4.9878\n",
      "Pretrain epoch [11/113], ZINB loss:0.3916, NB loss:4.9647\n",
      "Pretrain epoch [12/113], ZINB loss:0.4039, NB loss:4.9517\n",
      "Pretrain epoch [13/113], ZINB loss:0.3947, NB loss:4.9381\n",
      "Pretrain epoch [14/113], ZINB loss:0.3921, NB loss:5.0220\n",
      "Pretrain epoch [15/113], ZINB loss:0.4029, NB loss:5.0286\n",
      "Pretrain epoch [16/113], ZINB loss:0.3799, NB loss:4.9210\n",
      "Pretrain epoch [17/113], ZINB loss:0.3903, NB loss:4.9948\n",
      "Pretrain epoch [18/113], ZINB loss:0.3964, NB loss:5.0053\n",
      "Pretrain epoch [19/113], ZINB loss:0.4068, NB loss:5.0141\n",
      "Pretrain epoch [20/113], ZINB loss:0.3896, NB loss:4.9370\n",
      "Pretrain epoch [21/113], ZINB loss:0.4006, NB loss:5.0160\n",
      "Pretrain epoch [22/113], ZINB loss:0.3799, NB loss:5.0097\n",
      "Pretrain epoch [23/113], ZINB loss:0.4044, NB loss:4.9997\n",
      "Pretrain epoch [24/113], ZINB loss:0.3936, NB loss:4.9615\n",
      "Pretrain epoch [25/113], ZINB loss:0.3962, NB loss:4.9720\n",
      "Pretrain epoch [26/113], ZINB loss:0.4032, NB loss:5.0434\n",
      "Pretrain epoch [27/113], ZINB loss:0.4467, NB loss:5.4124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [1/114], ZINB loss:0.3944, NB loss:4.8774\n",
      "Pretrain epoch [2/114], ZINB loss:0.3797, NB loss:4.9838\n",
      "Pretrain epoch [3/114], ZINB loss:0.3911, NB loss:4.9534\n",
      "Pretrain epoch [4/114], ZINB loss:0.3970, NB loss:4.9305\n",
      "Pretrain epoch [5/114], ZINB loss:0.4060, NB loss:4.9883\n",
      "Pretrain epoch [6/114], ZINB loss:0.3857, NB loss:5.0028\n",
      "Pretrain epoch [7/114], ZINB loss:0.3966, NB loss:4.9460\n",
      "Pretrain epoch [8/114], ZINB loss:0.3949, NB loss:5.0101\n",
      "Pretrain epoch [9/114], ZINB loss:0.3810, NB loss:4.9683\n",
      "Pretrain epoch [10/114], ZINB loss:0.3968, NB loss:5.0357\n",
      "Pretrain epoch [11/114], ZINB loss:0.3801, NB loss:4.9614\n",
      "Pretrain epoch [12/114], ZINB loss:0.3911, NB loss:4.9856\n",
      "Pretrain epoch [13/114], ZINB loss:0.4072, NB loss:4.9724\n",
      "Pretrain epoch [14/114], ZINB loss:0.3740, NB loss:4.9792\n",
      "Pretrain epoch [15/114], ZINB loss:0.4065, NB loss:5.0035\n",
      "Pretrain epoch [16/114], ZINB loss:0.3950, NB loss:4.9938\n",
      "Pretrain epoch [17/114], ZINB loss:0.3827, NB loss:4.9603\n",
      "Pretrain epoch [18/114], ZINB loss:0.4146, NB loss:5.0111\n",
      "Pretrain epoch [19/114], ZINB loss:0.3960, NB loss:4.9983\n",
      "Pretrain epoch [20/114], ZINB loss:0.3839, NB loss:5.0563\n",
      "Pretrain epoch [21/114], ZINB loss:0.3942, NB loss:4.9793\n",
      "Pretrain epoch [22/114], ZINB loss:0.3889, NB loss:4.9829\n",
      "Pretrain epoch [23/114], ZINB loss:0.3792, NB loss:5.0065\n",
      "Pretrain epoch [24/114], ZINB loss:0.4116, NB loss:4.9962\n",
      "Pretrain epoch [25/114], ZINB loss:0.3968, NB loss:5.0498\n",
      "Pretrain epoch [26/114], ZINB loss:0.3907, NB loss:5.0038\n",
      "Pretrain epoch [27/114], ZINB loss:0.3324, NB loss:5.1917\n",
      "Pretrain epoch [1/115], ZINB loss:0.3859, NB loss:4.9734\n",
      "Pretrain epoch [2/115], ZINB loss:0.3769, NB loss:4.9716\n",
      "Pretrain epoch [3/115], ZINB loss:0.3887, NB loss:5.0101\n",
      "Pretrain epoch [4/115], ZINB loss:0.3894, NB loss:4.9360\n",
      "Pretrain epoch [5/115], ZINB loss:0.3951, NB loss:4.9865\n",
      "Pretrain epoch [6/115], ZINB loss:0.3877, NB loss:4.9306\n",
      "Pretrain epoch [7/115], ZINB loss:0.4194, NB loss:4.9938\n",
      "Pretrain epoch [8/115], ZINB loss:0.3931, NB loss:4.9882\n",
      "Pretrain epoch [9/115], ZINB loss:0.3843, NB loss:4.9423\n",
      "Pretrain epoch [10/115], ZINB loss:0.3850, NB loss:5.0023\n",
      "Pretrain epoch [11/115], ZINB loss:0.4099, NB loss:4.9210\n",
      "Pretrain epoch [12/115], ZINB loss:0.4136, NB loss:4.9393\n",
      "Pretrain epoch [13/115], ZINB loss:0.3966, NB loss:5.0023\n",
      "Pretrain epoch [14/115], ZINB loss:0.4010, NB loss:5.0407\n",
      "Pretrain epoch [15/115], ZINB loss:0.3918, NB loss:5.0406\n",
      "Pretrain epoch [16/115], ZINB loss:0.3960, NB loss:4.9532\n",
      "Pretrain epoch [17/115], ZINB loss:0.3828, NB loss:5.0382\n",
      "Pretrain epoch [18/115], ZINB loss:0.3780, NB loss:4.9864\n",
      "Pretrain epoch [19/115], ZINB loss:0.3959, NB loss:5.0310\n",
      "Pretrain epoch [20/115], ZINB loss:0.3956, NB loss:4.9616\n",
      "Pretrain epoch [21/115], ZINB loss:0.3937, NB loss:4.9690\n",
      "Pretrain epoch [22/115], ZINB loss:0.3791, NB loss:4.9921\n",
      "Pretrain epoch [23/115], ZINB loss:0.3827, NB loss:4.9656\n",
      "Pretrain epoch [24/115], ZINB loss:0.3933, NB loss:5.0315\n",
      "Pretrain epoch [25/115], ZINB loss:0.3884, NB loss:4.9498\n",
      "Pretrain epoch [26/115], ZINB loss:0.3990, NB loss:4.9537\n",
      "Pretrain epoch [27/115], ZINB loss:0.3018, NB loss:4.8977\n",
      "Pretrain epoch [1/116], ZINB loss:0.3991, NB loss:4.9879\n",
      "Pretrain epoch [2/116], ZINB loss:0.3673, NB loss:4.9930\n",
      "Pretrain epoch [3/116], ZINB loss:0.3871, NB loss:4.9672\n",
      "Pretrain epoch [4/116], ZINB loss:0.3931, NB loss:4.9986\n",
      "Pretrain epoch [5/116], ZINB loss:0.3894, NB loss:5.0340\n",
      "Pretrain epoch [6/116], ZINB loss:0.4082, NB loss:5.0057\n",
      "Pretrain epoch [7/116], ZINB loss:0.4055, NB loss:4.9254\n",
      "Pretrain epoch [8/116], ZINB loss:0.3939, NB loss:4.9792\n",
      "Pretrain epoch [9/116], ZINB loss:0.3819, NB loss:4.9594\n",
      "Pretrain epoch [10/116], ZINB loss:0.3818, NB loss:4.9179\n",
      "Pretrain epoch [11/116], ZINB loss:0.3940, NB loss:4.9371\n",
      "Pretrain epoch [12/116], ZINB loss:0.3845, NB loss:4.9764\n",
      "Pretrain epoch [13/116], ZINB loss:0.3956, NB loss:4.9739\n",
      "Pretrain epoch [14/116], ZINB loss:0.3971, NB loss:4.9813\n",
      "Pretrain epoch [15/116], ZINB loss:0.3904, NB loss:4.9703\n",
      "Pretrain epoch [16/116], ZINB loss:0.3953, NB loss:5.0098\n",
      "Pretrain epoch [17/116], ZINB loss:0.3938, NB loss:4.9653\n",
      "Pretrain epoch [18/116], ZINB loss:0.4017, NB loss:4.9194\n",
      "Pretrain epoch [19/116], ZINB loss:0.4020, NB loss:5.0083\n",
      "Pretrain epoch [20/116], ZINB loss:0.3826, NB loss:5.0146\n",
      "Pretrain epoch [21/116], ZINB loss:0.3721, NB loss:4.9519\n",
      "Pretrain epoch [22/116], ZINB loss:0.3959, NB loss:5.0367\n",
      "Pretrain epoch [23/116], ZINB loss:0.3970, NB loss:4.9725\n",
      "Pretrain epoch [24/116], ZINB loss:0.3912, NB loss:4.9396\n",
      "Pretrain epoch [25/116], ZINB loss:0.4025, NB loss:4.9299\n",
      "Pretrain epoch [26/116], ZINB loss:0.3892, NB loss:4.9759\n",
      "Pretrain epoch [27/116], ZINB loss:0.6274, NB loss:4.8013\n",
      "Pretrain epoch [1/117], ZINB loss:0.3949, NB loss:4.9956\n",
      "Pretrain epoch [2/117], ZINB loss:0.4050, NB loss:4.9394\n",
      "Pretrain epoch [3/117], ZINB loss:0.3842, NB loss:5.0119\n",
      "Pretrain epoch [4/117], ZINB loss:0.3880, NB loss:4.9440\n",
      "Pretrain epoch [5/117], ZINB loss:0.4001, NB loss:4.9368\n",
      "Pretrain epoch [6/117], ZINB loss:0.4079, NB loss:4.9188\n",
      "Pretrain epoch [7/117], ZINB loss:0.4069, NB loss:5.0155\n",
      "Pretrain epoch [8/117], ZINB loss:0.3878, NB loss:4.9717\n",
      "Pretrain epoch [9/117], ZINB loss:0.3917, NB loss:4.9549\n",
      "Pretrain epoch [10/117], ZINB loss:0.4033, NB loss:4.9389\n",
      "Pretrain epoch [11/117], ZINB loss:0.4015, NB loss:4.9825\n",
      "Pretrain epoch [12/117], ZINB loss:0.4076, NB loss:4.9421\n",
      "Pretrain epoch [13/117], ZINB loss:0.4109, NB loss:4.9462\n",
      "Pretrain epoch [14/117], ZINB loss:0.4097, NB loss:4.9328\n",
      "Pretrain epoch [15/117], ZINB loss:0.3957, NB loss:4.9851\n",
      "Pretrain epoch [16/117], ZINB loss:0.3801, NB loss:4.9947\n",
      "Pretrain epoch [17/117], ZINB loss:0.3884, NB loss:4.9417\n",
      "Pretrain epoch [18/117], ZINB loss:0.4171, NB loss:4.9749\n",
      "Pretrain epoch [19/117], ZINB loss:0.4028, NB loss:5.0122\n",
      "Pretrain epoch [20/117], ZINB loss:0.3911, NB loss:4.9720\n",
      "Pretrain epoch [21/117], ZINB loss:0.3743, NB loss:4.9730\n",
      "Pretrain epoch [22/117], ZINB loss:0.4066, NB loss:4.9607\n",
      "Pretrain epoch [23/117], ZINB loss:0.3745, NB loss:4.9571\n",
      "Pretrain epoch [24/117], ZINB loss:0.3876, NB loss:5.0165\n",
      "Pretrain epoch [25/117], ZINB loss:0.4031, NB loss:4.9584\n",
      "Pretrain epoch [26/117], ZINB loss:0.3915, NB loss:4.9999\n",
      "Pretrain epoch [27/117], ZINB loss:0.3896, NB loss:4.9601\n",
      "Pretrain epoch [1/118], ZINB loss:0.3805, NB loss:4.9836\n",
      "Pretrain epoch [2/118], ZINB loss:0.3668, NB loss:4.9201\n",
      "Pretrain epoch [3/118], ZINB loss:0.4182, NB loss:5.0075\n",
      "Pretrain epoch [4/118], ZINB loss:0.3898, NB loss:4.9690\n",
      "Pretrain epoch [5/118], ZINB loss:0.3964, NB loss:4.9469\n",
      "Pretrain epoch [6/118], ZINB loss:0.3829, NB loss:5.0362\n",
      "Pretrain epoch [7/118], ZINB loss:0.3967, NB loss:4.9486\n",
      "Pretrain epoch [8/118], ZINB loss:0.4025, NB loss:4.9545\n",
      "Pretrain epoch [9/118], ZINB loss:0.4207, NB loss:4.9849\n",
      "Pretrain epoch [10/118], ZINB loss:0.4106, NB loss:4.9762\n",
      "Pretrain epoch [11/118], ZINB loss:0.3894, NB loss:4.9646\n",
      "Pretrain epoch [12/118], ZINB loss:0.3795, NB loss:4.9514\n",
      "Pretrain epoch [13/118], ZINB loss:0.3924, NB loss:4.9724\n",
      "Pretrain epoch [14/118], ZINB loss:0.4008, NB loss:4.9439\n",
      "Pretrain epoch [15/118], ZINB loss:0.3957, NB loss:4.9649\n",
      "Pretrain epoch [16/118], ZINB loss:0.4016, NB loss:4.9593\n",
      "Pretrain epoch [17/118], ZINB loss:0.3872, NB loss:4.9181\n",
      "Pretrain epoch [18/118], ZINB loss:0.3730, NB loss:5.0155\n",
      "Pretrain epoch [19/118], ZINB loss:0.4041, NB loss:4.9379\n",
      "Pretrain epoch [20/118], ZINB loss:0.4141, NB loss:4.9255\n",
      "Pretrain epoch [21/118], ZINB loss:0.4070, NB loss:4.9686\n",
      "Pretrain epoch [22/118], ZINB loss:0.4028, NB loss:4.9560\n",
      "Pretrain epoch [23/118], ZINB loss:0.3828, NB loss:4.9391\n",
      "Pretrain epoch [24/118], ZINB loss:0.3832, NB loss:4.9808\n",
      "Pretrain epoch [25/118], ZINB loss:0.4053, NB loss:4.9388\n",
      "Pretrain epoch [26/118], ZINB loss:0.4006, NB loss:4.9646\n",
      "Pretrain epoch [27/118], ZINB loss:0.4422, NB loss:4.8277\n",
      "Pretrain epoch [1/119], ZINB loss:0.3870, NB loss:5.0031\n",
      "Pretrain epoch [2/119], ZINB loss:0.4044, NB loss:4.9911\n",
      "Pretrain epoch [3/119], ZINB loss:0.4127, NB loss:4.9984\n",
      "Pretrain epoch [4/119], ZINB loss:0.3901, NB loss:5.0163\n",
      "Pretrain epoch [5/119], ZINB loss:0.4014, NB loss:4.9926\n",
      "Pretrain epoch [6/119], ZINB loss:0.3982, NB loss:4.9074\n",
      "Pretrain epoch [7/119], ZINB loss:0.4115, NB loss:5.0005\n",
      "Pretrain epoch [8/119], ZINB loss:0.4088, NB loss:4.9457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [9/119], ZINB loss:0.3908, NB loss:4.9019\n",
      "Pretrain epoch [10/119], ZINB loss:0.3956, NB loss:4.9959\n",
      "Pretrain epoch [11/119], ZINB loss:0.3934, NB loss:4.9555\n",
      "Pretrain epoch [12/119], ZINB loss:0.4033, NB loss:4.9930\n",
      "Pretrain epoch [13/119], ZINB loss:0.3886, NB loss:4.8851\n",
      "Pretrain epoch [14/119], ZINB loss:0.3914, NB loss:4.9200\n",
      "Pretrain epoch [15/119], ZINB loss:0.3970, NB loss:4.9633\n",
      "Pretrain epoch [16/119], ZINB loss:0.3923, NB loss:5.0129\n",
      "Pretrain epoch [17/119], ZINB loss:0.3949, NB loss:4.8991\n",
      "Pretrain epoch [18/119], ZINB loss:0.4076, NB loss:4.9600\n",
      "Pretrain epoch [19/119], ZINB loss:0.4034, NB loss:4.9170\n",
      "Pretrain epoch [20/119], ZINB loss:0.3853, NB loss:4.9327\n",
      "Pretrain epoch [21/119], ZINB loss:0.3897, NB loss:4.9630\n",
      "Pretrain epoch [22/119], ZINB loss:0.4081, NB loss:4.9315\n",
      "Pretrain epoch [23/119], ZINB loss:0.4007, NB loss:4.9542\n",
      "Pretrain epoch [24/119], ZINB loss:0.3976, NB loss:4.9648\n",
      "Pretrain epoch [25/119], ZINB loss:0.3818, NB loss:4.9419\n",
      "Pretrain epoch [26/119], ZINB loss:0.3873, NB loss:4.9314\n",
      "Pretrain epoch [27/119], ZINB loss:0.3236, NB loss:4.8873\n",
      "Pretrain epoch [1/120], ZINB loss:0.3881, NB loss:5.0399\n",
      "Pretrain epoch [2/120], ZINB loss:0.3991, NB loss:4.9544\n",
      "Pretrain epoch [3/120], ZINB loss:0.3973, NB loss:4.9698\n",
      "Pretrain epoch [4/120], ZINB loss:0.4098, NB loss:4.9407\n",
      "Pretrain epoch [5/120], ZINB loss:0.3684, NB loss:4.9994\n",
      "Pretrain epoch [6/120], ZINB loss:0.4067, NB loss:4.9874\n",
      "Pretrain epoch [7/120], ZINB loss:0.3920, NB loss:4.8886\n",
      "Pretrain epoch [8/120], ZINB loss:0.3929, NB loss:4.9736\n",
      "Pretrain epoch [9/120], ZINB loss:0.4040, NB loss:4.9464\n",
      "Pretrain epoch [10/120], ZINB loss:0.3850, NB loss:4.9596\n",
      "Pretrain epoch [11/120], ZINB loss:0.3804, NB loss:4.9394\n",
      "Pretrain epoch [12/120], ZINB loss:0.3897, NB loss:4.9693\n",
      "Pretrain epoch [13/120], ZINB loss:0.4142, NB loss:4.9327\n",
      "Pretrain epoch [14/120], ZINB loss:0.3908, NB loss:4.9666\n",
      "Pretrain epoch [15/120], ZINB loss:0.3965, NB loss:4.9311\n",
      "Pretrain epoch [16/120], ZINB loss:0.3954, NB loss:4.9903\n",
      "Pretrain epoch [17/120], ZINB loss:0.3843, NB loss:4.9241\n",
      "Pretrain epoch [18/120], ZINB loss:0.4075, NB loss:4.9500\n",
      "Pretrain epoch [19/120], ZINB loss:0.3980, NB loss:4.9531\n",
      "Pretrain epoch [20/120], ZINB loss:0.4004, NB loss:4.9814\n",
      "Pretrain epoch [21/120], ZINB loss:0.3932, NB loss:4.9166\n",
      "Pretrain epoch [22/120], ZINB loss:0.3801, NB loss:4.9727\n",
      "Pretrain epoch [23/120], ZINB loss:0.4010, NB loss:4.8704\n",
      "Pretrain epoch [24/120], ZINB loss:0.3978, NB loss:4.9050\n",
      "Pretrain epoch [25/120], ZINB loss:0.3865, NB loss:4.9380\n",
      "Pretrain epoch [26/120], ZINB loss:0.3845, NB loss:4.9338\n",
      "Pretrain epoch [27/120], ZINB loss:0.4236, NB loss:4.8585\n",
      "Pretrain epoch [1/121], ZINB loss:0.3685, NB loss:4.9901\n",
      "Pretrain epoch [2/121], ZINB loss:0.3980, NB loss:4.9759\n",
      "Pretrain epoch [3/121], ZINB loss:0.4179, NB loss:4.9501\n",
      "Pretrain epoch [4/121], ZINB loss:0.3928, NB loss:4.9576\n",
      "Pretrain epoch [5/121], ZINB loss:0.4035, NB loss:4.9463\n",
      "Pretrain epoch [6/121], ZINB loss:0.4080, NB loss:4.9358\n",
      "Pretrain epoch [7/121], ZINB loss:0.3986, NB loss:4.9183\n",
      "Pretrain epoch [8/121], ZINB loss:0.3876, NB loss:4.9661\n",
      "Pretrain epoch [9/121], ZINB loss:0.3993, NB loss:5.0028\n",
      "Pretrain epoch [10/121], ZINB loss:0.4028, NB loss:4.9017\n",
      "Pretrain epoch [11/121], ZINB loss:0.4044, NB loss:4.9998\n",
      "Pretrain epoch [12/121], ZINB loss:0.3874, NB loss:4.9382\n",
      "Pretrain epoch [13/121], ZINB loss:0.3921, NB loss:4.9299\n",
      "Pretrain epoch [14/121], ZINB loss:0.3897, NB loss:4.8861\n",
      "Pretrain epoch [15/121], ZINB loss:0.3916, NB loss:4.9520\n",
      "Pretrain epoch [16/121], ZINB loss:0.4108, NB loss:4.9074\n",
      "Pretrain epoch [17/121], ZINB loss:0.3934, NB loss:4.8777\n",
      "Pretrain epoch [18/121], ZINB loss:0.3966, NB loss:4.9753\n",
      "Pretrain epoch [19/121], ZINB loss:0.3925, NB loss:4.9288\n",
      "Pretrain epoch [20/121], ZINB loss:0.3851, NB loss:4.9525\n",
      "Pretrain epoch [21/121], ZINB loss:0.4053, NB loss:4.9791\n",
      "Pretrain epoch [22/121], ZINB loss:0.3776, NB loss:4.9179\n",
      "Pretrain epoch [23/121], ZINB loss:0.3919, NB loss:4.9608\n",
      "Pretrain epoch [24/121], ZINB loss:0.3795, NB loss:4.9535\n",
      "Pretrain epoch [25/121], ZINB loss:0.3777, NB loss:4.9852\n",
      "Pretrain epoch [26/121], ZINB loss:0.3935, NB loss:4.8936\n",
      "Pretrain epoch [27/121], ZINB loss:0.3459, NB loss:5.2500\n",
      "Pretrain epoch [1/122], ZINB loss:0.3967, NB loss:4.9827\n",
      "Pretrain epoch [2/122], ZINB loss:0.3991, NB loss:4.8670\n",
      "Pretrain epoch [3/122], ZINB loss:0.3992, NB loss:4.9572\n",
      "Pretrain epoch [4/122], ZINB loss:0.3857, NB loss:5.0119\n",
      "Pretrain epoch [5/122], ZINB loss:0.4011, NB loss:4.9197\n",
      "Pretrain epoch [6/122], ZINB loss:0.3758, NB loss:4.9837\n",
      "Pretrain epoch [7/122], ZINB loss:0.3744, NB loss:4.9066\n",
      "Pretrain epoch [8/122], ZINB loss:0.4119, NB loss:4.9709\n",
      "Pretrain epoch [9/122], ZINB loss:0.3962, NB loss:4.9086\n",
      "Pretrain epoch [10/122], ZINB loss:0.3916, NB loss:4.9595\n",
      "Pretrain epoch [11/122], ZINB loss:0.3762, NB loss:4.9595\n",
      "Pretrain epoch [12/122], ZINB loss:0.3789, NB loss:4.9342\n",
      "Pretrain epoch [13/122], ZINB loss:0.4002, NB loss:4.9855\n",
      "Pretrain epoch [14/122], ZINB loss:0.3933, NB loss:4.9544\n",
      "Pretrain epoch [15/122], ZINB loss:0.3835, NB loss:4.9408\n",
      "Pretrain epoch [16/122], ZINB loss:0.3858, NB loss:4.8986\n",
      "Pretrain epoch [17/122], ZINB loss:0.3910, NB loss:4.8957\n",
      "Pretrain epoch [18/122], ZINB loss:0.4045, NB loss:4.8668\n",
      "Pretrain epoch [19/122], ZINB loss:0.3864, NB loss:4.9726\n",
      "Pretrain epoch [20/122], ZINB loss:0.4043, NB loss:4.9746\n",
      "Pretrain epoch [21/122], ZINB loss:0.4091, NB loss:4.9221\n",
      "Pretrain epoch [22/122], ZINB loss:0.4071, NB loss:4.9478\n",
      "Pretrain epoch [23/122], ZINB loss:0.4008, NB loss:4.9484\n",
      "Pretrain epoch [24/122], ZINB loss:0.4005, NB loss:5.0066\n",
      "Pretrain epoch [25/122], ZINB loss:0.3852, NB loss:4.9075\n",
      "Pretrain epoch [26/122], ZINB loss:0.3925, NB loss:4.8646\n",
      "Pretrain epoch [27/122], ZINB loss:0.4150, NB loss:4.8973\n",
      "Pretrain epoch [1/123], ZINB loss:0.4043, NB loss:4.9399\n",
      "Pretrain epoch [2/123], ZINB loss:0.3892, NB loss:4.9637\n",
      "Pretrain epoch [3/123], ZINB loss:0.4077, NB loss:4.8918\n",
      "Pretrain epoch [4/123], ZINB loss:0.4027, NB loss:4.9263\n",
      "Pretrain epoch [5/123], ZINB loss:0.4111, NB loss:4.8782\n",
      "Pretrain epoch [6/123], ZINB loss:0.3796, NB loss:4.9384\n",
      "Pretrain epoch [7/123], ZINB loss:0.3927, NB loss:5.0129\n",
      "Pretrain epoch [8/123], ZINB loss:0.3993, NB loss:4.9298\n",
      "Pretrain epoch [9/123], ZINB loss:0.3958, NB loss:4.9506\n",
      "Pretrain epoch [10/123], ZINB loss:0.3896, NB loss:4.9485\n",
      "Pretrain epoch [11/123], ZINB loss:0.3961, NB loss:4.9620\n",
      "Pretrain epoch [12/123], ZINB loss:0.3959, NB loss:4.9337\n",
      "Pretrain epoch [13/123], ZINB loss:0.3860, NB loss:4.9849\n",
      "Pretrain epoch [14/123], ZINB loss:0.3849, NB loss:4.8462\n",
      "Pretrain epoch [15/123], ZINB loss:0.3994, NB loss:4.9333\n",
      "Pretrain epoch [16/123], ZINB loss:0.4101, NB loss:4.9257\n",
      "Pretrain epoch [17/123], ZINB loss:0.3973, NB loss:4.9352\n",
      "Pretrain epoch [18/123], ZINB loss:0.3797, NB loss:4.9111\n",
      "Pretrain epoch [19/123], ZINB loss:0.3861, NB loss:4.9019\n",
      "Pretrain epoch [20/123], ZINB loss:0.3805, NB loss:5.0379\n",
      "Pretrain epoch [21/123], ZINB loss:0.3926, NB loss:4.9490\n",
      "Pretrain epoch [22/123], ZINB loss:0.3915, NB loss:4.8980\n",
      "Pretrain epoch [23/123], ZINB loss:0.3854, NB loss:4.9256\n",
      "Pretrain epoch [24/123], ZINB loss:0.3846, NB loss:4.9347\n",
      "Pretrain epoch [25/123], ZINB loss:0.3946, NB loss:4.9324\n",
      "Pretrain epoch [26/123], ZINB loss:0.3839, NB loss:4.9160\n",
      "Pretrain epoch [27/123], ZINB loss:0.4181, NB loss:5.0051\n",
      "Pretrain epoch [1/124], ZINB loss:0.3952, NB loss:4.8810\n",
      "Pretrain epoch [2/124], ZINB loss:0.3854, NB loss:4.9416\n",
      "Pretrain epoch [3/124], ZINB loss:0.3895, NB loss:4.9625\n",
      "Pretrain epoch [4/124], ZINB loss:0.4140, NB loss:4.9567\n",
      "Pretrain epoch [5/124], ZINB loss:0.3823, NB loss:4.9462\n",
      "Pretrain epoch [6/124], ZINB loss:0.3790, NB loss:4.8661\n",
      "Pretrain epoch [7/124], ZINB loss:0.3909, NB loss:4.9535\n",
      "Pretrain epoch [8/124], ZINB loss:0.3872, NB loss:4.8813\n",
      "Pretrain epoch [9/124], ZINB loss:0.4010, NB loss:4.9931\n",
      "Pretrain epoch [10/124], ZINB loss:0.3927, NB loss:4.9334\n",
      "Pretrain epoch [11/124], ZINB loss:0.3912, NB loss:4.9459\n",
      "Pretrain epoch [12/124], ZINB loss:0.3987, NB loss:4.9054\n",
      "Pretrain epoch [13/124], ZINB loss:0.3963, NB loss:4.9497\n",
      "Pretrain epoch [14/124], ZINB loss:0.3940, NB loss:4.8918\n",
      "Pretrain epoch [15/124], ZINB loss:0.3819, NB loss:4.9804\n",
      "Pretrain epoch [16/124], ZINB loss:0.3884, NB loss:4.9196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [17/124], ZINB loss:0.3996, NB loss:4.9258\n",
      "Pretrain epoch [18/124], ZINB loss:0.3940, NB loss:4.9247\n",
      "Pretrain epoch [19/124], ZINB loss:0.3975, NB loss:4.9321\n",
      "Pretrain epoch [20/124], ZINB loss:0.4070, NB loss:4.9629\n",
      "Pretrain epoch [21/124], ZINB loss:0.3823, NB loss:4.9181\n",
      "Pretrain epoch [22/124], ZINB loss:0.3880, NB loss:4.9520\n",
      "Pretrain epoch [23/124], ZINB loss:0.3721, NB loss:4.9456\n",
      "Pretrain epoch [24/124], ZINB loss:0.3975, NB loss:4.9297\n",
      "Pretrain epoch [25/124], ZINB loss:0.3999, NB loss:4.8875\n",
      "Pretrain epoch [26/124], ZINB loss:0.4010, NB loss:4.8741\n",
      "Pretrain epoch [27/124], ZINB loss:0.3579, NB loss:5.0462\n",
      "Pretrain epoch [1/125], ZINB loss:0.3833, NB loss:4.8814\n",
      "Pretrain epoch [2/125], ZINB loss:0.3949, NB loss:4.8358\n",
      "Pretrain epoch [3/125], ZINB loss:0.4051, NB loss:4.9483\n",
      "Pretrain epoch [4/125], ZINB loss:0.3949, NB loss:4.9128\n",
      "Pretrain epoch [5/125], ZINB loss:0.3790, NB loss:4.9814\n",
      "Pretrain epoch [6/125], ZINB loss:0.4006, NB loss:4.9400\n",
      "Pretrain epoch [7/125], ZINB loss:0.4017, NB loss:4.9127\n",
      "Pretrain epoch [8/125], ZINB loss:0.4072, NB loss:4.9600\n",
      "Pretrain epoch [9/125], ZINB loss:0.3835, NB loss:4.9834\n",
      "Pretrain epoch [10/125], ZINB loss:0.3929, NB loss:4.9110\n",
      "Pretrain epoch [11/125], ZINB loss:0.3834, NB loss:4.9383\n",
      "Pretrain epoch [12/125], ZINB loss:0.3985, NB loss:4.9211\n",
      "Pretrain epoch [13/125], ZINB loss:0.3988, NB loss:4.9372\n",
      "Pretrain epoch [14/125], ZINB loss:0.3809, NB loss:4.9116\n",
      "Pretrain epoch [15/125], ZINB loss:0.3874, NB loss:4.9600\n",
      "Pretrain epoch [16/125], ZINB loss:0.4143, NB loss:4.9279\n",
      "Pretrain epoch [17/125], ZINB loss:0.3869, NB loss:4.9000\n",
      "Pretrain epoch [18/125], ZINB loss:0.3780, NB loss:4.9271\n",
      "Pretrain epoch [19/125], ZINB loss:0.3995, NB loss:4.8972\n",
      "Pretrain epoch [20/125], ZINB loss:0.3831, NB loss:4.9275\n",
      "Pretrain epoch [21/125], ZINB loss:0.3927, NB loss:4.9778\n",
      "Pretrain epoch [22/125], ZINB loss:0.3863, NB loss:4.9436\n",
      "Pretrain epoch [23/125], ZINB loss:0.4103, NB loss:4.9155\n",
      "Pretrain epoch [24/125], ZINB loss:0.3860, NB loss:4.8400\n",
      "Pretrain epoch [25/125], ZINB loss:0.3780, NB loss:4.9052\n",
      "Pretrain epoch [26/125], ZINB loss:0.4028, NB loss:4.9234\n",
      "Pretrain epoch [27/125], ZINB loss:0.5089, NB loss:5.3035\n",
      "Pretrain epoch [1/126], ZINB loss:0.3871, NB loss:4.9615\n",
      "Pretrain epoch [2/126], ZINB loss:0.4172, NB loss:4.8998\n",
      "Pretrain epoch [3/126], ZINB loss:0.3955, NB loss:4.9235\n",
      "Pretrain epoch [4/126], ZINB loss:0.3777, NB loss:4.9359\n",
      "Pretrain epoch [5/126], ZINB loss:0.4253, NB loss:4.9649\n",
      "Pretrain epoch [6/126], ZINB loss:0.3860, NB loss:4.8925\n",
      "Pretrain epoch [7/126], ZINB loss:0.4085, NB loss:4.8929\n",
      "Pretrain epoch [8/126], ZINB loss:0.3972, NB loss:4.8774\n",
      "Pretrain epoch [9/126], ZINB loss:0.3956, NB loss:4.8300\n",
      "Pretrain epoch [10/126], ZINB loss:0.3764, NB loss:4.9789\n",
      "Pretrain epoch [11/126], ZINB loss:0.4044, NB loss:4.9333\n",
      "Pretrain epoch [12/126], ZINB loss:0.4003, NB loss:4.9018\n",
      "Pretrain epoch [13/126], ZINB loss:0.4030, NB loss:4.9017\n",
      "Pretrain epoch [14/126], ZINB loss:0.3854, NB loss:4.8677\n",
      "Pretrain epoch [15/126], ZINB loss:0.3901, NB loss:4.9461\n",
      "Pretrain epoch [16/126], ZINB loss:0.3944, NB loss:4.9429\n",
      "Pretrain epoch [17/126], ZINB loss:0.3845, NB loss:4.9005\n",
      "Pretrain epoch [18/126], ZINB loss:0.3696, NB loss:4.8409\n",
      "Pretrain epoch [19/126], ZINB loss:0.3952, NB loss:4.9297\n",
      "Pretrain epoch [20/126], ZINB loss:0.3993, NB loss:4.9716\n",
      "Pretrain epoch [21/126], ZINB loss:0.3778, NB loss:4.8983\n",
      "Pretrain epoch [22/126], ZINB loss:0.3916, NB loss:4.9006\n",
      "Pretrain epoch [23/126], ZINB loss:0.3907, NB loss:4.9729\n",
      "Pretrain epoch [24/126], ZINB loss:0.3827, NB loss:4.9524\n",
      "Pretrain epoch [25/126], ZINB loss:0.3879, NB loss:4.9422\n",
      "Pretrain epoch [26/126], ZINB loss:0.3933, NB loss:4.9355\n",
      "Pretrain epoch [27/126], ZINB loss:0.3275, NB loss:4.8634\n",
      "Pretrain epoch [1/127], ZINB loss:0.4084, NB loss:4.9961\n",
      "Pretrain epoch [2/127], ZINB loss:0.3814, NB loss:4.8967\n",
      "Pretrain epoch [3/127], ZINB loss:0.3915, NB loss:4.8990\n",
      "Pretrain epoch [4/127], ZINB loss:0.3993, NB loss:4.8624\n",
      "Pretrain epoch [5/127], ZINB loss:0.4248, NB loss:4.9619\n",
      "Pretrain epoch [6/127], ZINB loss:0.3935, NB loss:4.8751\n",
      "Pretrain epoch [7/127], ZINB loss:0.3866, NB loss:4.9001\n",
      "Pretrain epoch [8/127], ZINB loss:0.4080, NB loss:4.9142\n",
      "Pretrain epoch [9/127], ZINB loss:0.3978, NB loss:4.8441\n",
      "Pretrain epoch [10/127], ZINB loss:0.3791, NB loss:4.8947\n",
      "Pretrain epoch [11/127], ZINB loss:0.3841, NB loss:4.9020\n",
      "Pretrain epoch [12/127], ZINB loss:0.3672, NB loss:4.9113\n",
      "Pretrain epoch [13/127], ZINB loss:0.3796, NB loss:4.8767\n",
      "Pretrain epoch [14/127], ZINB loss:0.3862, NB loss:4.9655\n",
      "Pretrain epoch [15/127], ZINB loss:0.3927, NB loss:4.9076\n",
      "Pretrain epoch [16/127], ZINB loss:0.3844, NB loss:4.9450\n",
      "Pretrain epoch [17/127], ZINB loss:0.3919, NB loss:4.9270\n",
      "Pretrain epoch [18/127], ZINB loss:0.3974, NB loss:4.8921\n",
      "Pretrain epoch [19/127], ZINB loss:0.4049, NB loss:4.9263\n",
      "Pretrain epoch [20/127], ZINB loss:0.3935, NB loss:4.9315\n",
      "Pretrain epoch [21/127], ZINB loss:0.3928, NB loss:4.8791\n",
      "Pretrain epoch [22/127], ZINB loss:0.3995, NB loss:4.8813\n",
      "Pretrain epoch [23/127], ZINB loss:0.3816, NB loss:4.9245\n",
      "Pretrain epoch [24/127], ZINB loss:0.3817, NB loss:5.0242\n",
      "Pretrain epoch [25/127], ZINB loss:0.4017, NB loss:4.9152\n",
      "Pretrain epoch [26/127], ZINB loss:0.4068, NB loss:4.9092\n",
      "Pretrain epoch [27/127], ZINB loss:0.3382, NB loss:4.7638\n",
      "Pretrain epoch [1/128], ZINB loss:0.3926, NB loss:4.8983\n",
      "Pretrain epoch [2/128], ZINB loss:0.3692, NB loss:4.9988\n",
      "Pretrain epoch [3/128], ZINB loss:0.3985, NB loss:4.9129\n",
      "Pretrain epoch [4/128], ZINB loss:0.3813, NB loss:4.9086\n",
      "Pretrain epoch [5/128], ZINB loss:0.4109, NB loss:4.8896\n",
      "Pretrain epoch [6/128], ZINB loss:0.3836, NB loss:4.9073\n",
      "Pretrain epoch [7/128], ZINB loss:0.3934, NB loss:4.8309\n",
      "Pretrain epoch [8/128], ZINB loss:0.3968, NB loss:4.8782\n",
      "Pretrain epoch [9/128], ZINB loss:0.3755, NB loss:4.9278\n",
      "Pretrain epoch [10/128], ZINB loss:0.3999, NB loss:4.8785\n",
      "Pretrain epoch [11/128], ZINB loss:0.3927, NB loss:4.9065\n",
      "Pretrain epoch [12/128], ZINB loss:0.4132, NB loss:4.9266\n",
      "Pretrain epoch [13/128], ZINB loss:0.3946, NB loss:4.9119\n",
      "Pretrain epoch [14/128], ZINB loss:0.4031, NB loss:4.9038\n",
      "Pretrain epoch [15/128], ZINB loss:0.3876, NB loss:4.8896\n",
      "Pretrain epoch [16/128], ZINB loss:0.3713, NB loss:4.9181\n",
      "Pretrain epoch [17/128], ZINB loss:0.3880, NB loss:4.9092\n",
      "Pretrain epoch [18/128], ZINB loss:0.3945, NB loss:4.8961\n",
      "Pretrain epoch [19/128], ZINB loss:0.3864, NB loss:4.9580\n",
      "Pretrain epoch [20/128], ZINB loss:0.4084, NB loss:4.9006\n",
      "Pretrain epoch [21/128], ZINB loss:0.4009, NB loss:4.9210\n",
      "Pretrain epoch [22/128], ZINB loss:0.4022, NB loss:4.8970\n",
      "Pretrain epoch [23/128], ZINB loss:0.3934, NB loss:4.9202\n",
      "Pretrain epoch [24/128], ZINB loss:0.3719, NB loss:4.9324\n",
      "Pretrain epoch [25/128], ZINB loss:0.4009, NB loss:4.8957\n",
      "Pretrain epoch [26/128], ZINB loss:0.3962, NB loss:4.9049\n",
      "Pretrain epoch [27/128], ZINB loss:0.4405, NB loss:5.0625\n",
      "Pretrain epoch [1/129], ZINB loss:0.3924, NB loss:4.9309\n",
      "Pretrain epoch [2/129], ZINB loss:0.3946, NB loss:4.9541\n",
      "Pretrain epoch [3/129], ZINB loss:0.3916, NB loss:4.9163\n",
      "Pretrain epoch [4/129], ZINB loss:0.3930, NB loss:4.8926\n",
      "Pretrain epoch [5/129], ZINB loss:0.3995, NB loss:4.8602\n",
      "Pretrain epoch [6/129], ZINB loss:0.3865, NB loss:4.9365\n",
      "Pretrain epoch [7/129], ZINB loss:0.3886, NB loss:4.8992\n",
      "Pretrain epoch [8/129], ZINB loss:0.4106, NB loss:4.8780\n",
      "Pretrain epoch [9/129], ZINB loss:0.3828, NB loss:4.9033\n",
      "Pretrain epoch [10/129], ZINB loss:0.4123, NB loss:4.9293\n",
      "Pretrain epoch [11/129], ZINB loss:0.3812, NB loss:4.9286\n",
      "Pretrain epoch [12/129], ZINB loss:0.3827, NB loss:4.9062\n",
      "Pretrain epoch [13/129], ZINB loss:0.3812, NB loss:4.8657\n",
      "Pretrain epoch [14/129], ZINB loss:0.3851, NB loss:4.8522\n",
      "Pretrain epoch [15/129], ZINB loss:0.3995, NB loss:4.8899\n",
      "Pretrain epoch [16/129], ZINB loss:0.4090, NB loss:4.8745\n",
      "Pretrain epoch [17/129], ZINB loss:0.3864, NB loss:4.9332\n",
      "Pretrain epoch [18/129], ZINB loss:0.3999, NB loss:4.8645\n",
      "Pretrain epoch [19/129], ZINB loss:0.3889, NB loss:4.9212\n",
      "Pretrain epoch [20/129], ZINB loss:0.3969, NB loss:4.9852\n",
      "Pretrain epoch [21/129], ZINB loss:0.4006, NB loss:4.8763\n",
      "Pretrain epoch [22/129], ZINB loss:0.4035, NB loss:4.8924\n",
      "Pretrain epoch [23/129], ZINB loss:0.4037, NB loss:4.9367\n",
      "Pretrain epoch [24/129], ZINB loss:0.3835, NB loss:4.8635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [25/129], ZINB loss:0.3706, NB loss:4.8901\n",
      "Pretrain epoch [26/129], ZINB loss:0.3851, NB loss:4.9169\n",
      "Pretrain epoch [27/129], ZINB loss:0.4502, NB loss:4.6752\n",
      "Pretrain epoch [1/130], ZINB loss:0.3782, NB loss:4.8442\n",
      "Pretrain epoch [2/130], ZINB loss:0.3707, NB loss:4.9000\n",
      "Pretrain epoch [3/130], ZINB loss:0.3865, NB loss:4.8815\n",
      "Pretrain epoch [4/130], ZINB loss:0.3696, NB loss:4.9221\n",
      "Pretrain epoch [5/130], ZINB loss:0.3747, NB loss:4.8663\n",
      "Pretrain epoch [6/130], ZINB loss:0.3955, NB loss:4.9296\n",
      "Pretrain epoch [7/130], ZINB loss:0.3743, NB loss:4.9103\n",
      "Pretrain epoch [8/130], ZINB loss:0.4138, NB loss:4.8956\n",
      "Pretrain epoch [9/130], ZINB loss:0.4026, NB loss:4.9095\n",
      "Pretrain epoch [10/130], ZINB loss:0.4047, NB loss:4.8642\n",
      "Pretrain epoch [11/130], ZINB loss:0.3988, NB loss:4.9372\n",
      "Pretrain epoch [12/130], ZINB loss:0.3933, NB loss:4.9331\n",
      "Pretrain epoch [13/130], ZINB loss:0.3867, NB loss:4.8505\n",
      "Pretrain epoch [14/130], ZINB loss:0.4096, NB loss:4.9270\n",
      "Pretrain epoch [15/130], ZINB loss:0.3870, NB loss:4.9566\n",
      "Pretrain epoch [16/130], ZINB loss:0.3902, NB loss:4.8868\n",
      "Pretrain epoch [17/130], ZINB loss:0.3890, NB loss:4.8522\n",
      "Pretrain epoch [18/130], ZINB loss:0.3873, NB loss:4.8675\n",
      "Pretrain epoch [19/130], ZINB loss:0.4033, NB loss:4.9220\n",
      "Pretrain epoch [20/130], ZINB loss:0.4036, NB loss:4.8370\n",
      "Pretrain epoch [21/130], ZINB loss:0.3894, NB loss:4.9443\n",
      "Pretrain epoch [22/130], ZINB loss:0.4100, NB loss:4.8662\n",
      "Pretrain epoch [23/130], ZINB loss:0.4011, NB loss:4.9131\n",
      "Pretrain epoch [24/130], ZINB loss:0.3928, NB loss:4.8470\n",
      "Pretrain epoch [25/130], ZINB loss:0.4008, NB loss:4.9339\n",
      "Pretrain epoch [26/130], ZINB loss:0.3921, NB loss:4.9581\n",
      "Pretrain epoch [27/130], ZINB loss:0.3485, NB loss:5.1253\n",
      "Pretrain epoch [1/131], ZINB loss:0.3926, NB loss:4.8548\n",
      "Pretrain epoch [2/131], ZINB loss:0.3852, NB loss:4.9516\n",
      "Pretrain epoch [3/131], ZINB loss:0.3867, NB loss:4.9424\n",
      "Pretrain epoch [4/131], ZINB loss:0.3876, NB loss:4.9080\n",
      "Pretrain epoch [5/131], ZINB loss:0.3995, NB loss:5.0218\n",
      "Pretrain epoch [6/131], ZINB loss:0.4009, NB loss:4.8787\n",
      "Pretrain epoch [7/131], ZINB loss:0.3952, NB loss:4.8551\n",
      "Pretrain epoch [8/131], ZINB loss:0.3980, NB loss:4.9302\n",
      "Pretrain epoch [9/131], ZINB loss:0.4199, NB loss:4.9159\n",
      "Pretrain epoch [10/131], ZINB loss:0.3944, NB loss:4.9081\n",
      "Pretrain epoch [11/131], ZINB loss:0.3867, NB loss:4.8700\n",
      "Pretrain epoch [12/131], ZINB loss:0.3885, NB loss:4.8856\n",
      "Pretrain epoch [13/131], ZINB loss:0.3901, NB loss:4.9745\n",
      "Pretrain epoch [14/131], ZINB loss:0.3975, NB loss:4.8950\n",
      "Pretrain epoch [15/131], ZINB loss:0.3866, NB loss:4.8332\n",
      "Pretrain epoch [16/131], ZINB loss:0.3814, NB loss:4.8534\n",
      "Pretrain epoch [17/131], ZINB loss:0.3993, NB loss:4.9254\n",
      "Pretrain epoch [18/131], ZINB loss:0.3930, NB loss:4.9436\n",
      "Pretrain epoch [19/131], ZINB loss:0.3834, NB loss:4.9066\n",
      "Pretrain epoch [20/131], ZINB loss:0.3890, NB loss:4.8436\n",
      "Pretrain epoch [21/131], ZINB loss:0.3767, NB loss:4.8554\n",
      "Pretrain epoch [22/131], ZINB loss:0.3898, NB loss:4.8706\n",
      "Pretrain epoch [23/131], ZINB loss:0.3989, NB loss:4.8253\n",
      "Pretrain epoch [24/131], ZINB loss:0.3941, NB loss:4.8896\n",
      "Pretrain epoch [25/131], ZINB loss:0.4014, NB loss:4.8209\n",
      "Pretrain epoch [26/131], ZINB loss:0.3794, NB loss:4.8833\n",
      "Pretrain epoch [27/131], ZINB loss:0.3540, NB loss:4.6477\n",
      "Pretrain epoch [1/132], ZINB loss:0.3915, NB loss:4.9472\n",
      "Pretrain epoch [2/132], ZINB loss:0.4030, NB loss:4.9214\n",
      "Pretrain epoch [3/132], ZINB loss:0.3966, NB loss:4.9211\n",
      "Pretrain epoch [4/132], ZINB loss:0.3914, NB loss:4.8313\n",
      "Pretrain epoch [5/132], ZINB loss:0.3873, NB loss:4.9637\n",
      "Pretrain epoch [6/132], ZINB loss:0.3823, NB loss:4.8524\n",
      "Pretrain epoch [7/132], ZINB loss:0.4028, NB loss:4.8889\n",
      "Pretrain epoch [8/132], ZINB loss:0.3900, NB loss:4.9807\n",
      "Pretrain epoch [9/132], ZINB loss:0.3791, NB loss:4.8389\n",
      "Pretrain epoch [10/132], ZINB loss:0.3859, NB loss:4.9069\n",
      "Pretrain epoch [11/132], ZINB loss:0.3913, NB loss:4.8099\n",
      "Pretrain epoch [12/132], ZINB loss:0.3816, NB loss:4.8269\n",
      "Pretrain epoch [13/132], ZINB loss:0.3777, NB loss:4.8596\n",
      "Pretrain epoch [14/132], ZINB loss:0.3758, NB loss:4.9500\n",
      "Pretrain epoch [15/132], ZINB loss:0.3802, NB loss:4.9033\n",
      "Pretrain epoch [16/132], ZINB loss:0.4032, NB loss:4.8848\n",
      "Pretrain epoch [17/132], ZINB loss:0.3838, NB loss:4.9378\n",
      "Pretrain epoch [18/132], ZINB loss:0.3979, NB loss:4.8718\n",
      "Pretrain epoch [19/132], ZINB loss:0.3862, NB loss:4.8428\n",
      "Pretrain epoch [20/132], ZINB loss:0.3900, NB loss:4.8458\n",
      "Pretrain epoch [21/132], ZINB loss:0.3964, NB loss:4.8747\n",
      "Pretrain epoch [22/132], ZINB loss:0.4039, NB loss:4.8365\n",
      "Pretrain epoch [23/132], ZINB loss:0.4145, NB loss:4.8459\n",
      "Pretrain epoch [24/132], ZINB loss:0.4107, NB loss:4.9444\n",
      "Pretrain epoch [25/132], ZINB loss:0.4027, NB loss:4.9373\n",
      "Pretrain epoch [26/132], ZINB loss:0.3875, NB loss:4.8798\n",
      "Pretrain epoch [27/132], ZINB loss:0.4366, NB loss:5.0841\n",
      "Pretrain epoch [1/133], ZINB loss:0.3844, NB loss:4.8641\n",
      "Pretrain epoch [2/133], ZINB loss:0.4167, NB loss:4.8511\n",
      "Pretrain epoch [3/133], ZINB loss:0.3898, NB loss:4.8649\n",
      "Pretrain epoch [4/133], ZINB loss:0.4079, NB loss:4.9402\n",
      "Pretrain epoch [5/133], ZINB loss:0.4259, NB loss:4.9247\n",
      "Pretrain epoch [6/133], ZINB loss:0.4074, NB loss:4.9462\n",
      "Pretrain epoch [7/133], ZINB loss:0.4137, NB loss:4.8252\n",
      "Pretrain epoch [8/133], ZINB loss:0.3898, NB loss:4.9112\n",
      "Pretrain epoch [9/133], ZINB loss:0.3901, NB loss:4.9178\n",
      "Pretrain epoch [10/133], ZINB loss:0.3920, NB loss:4.8661\n",
      "Pretrain epoch [11/133], ZINB loss:0.3941, NB loss:4.9208\n",
      "Pretrain epoch [12/133], ZINB loss:0.4123, NB loss:4.9141\n",
      "Pretrain epoch [13/133], ZINB loss:0.4121, NB loss:4.9264\n",
      "Pretrain epoch [14/133], ZINB loss:0.3843, NB loss:4.7564\n",
      "Pretrain epoch [15/133], ZINB loss:0.3919, NB loss:4.8993\n",
      "Pretrain epoch [16/133], ZINB loss:0.4061, NB loss:4.8169\n",
      "Pretrain epoch [17/133], ZINB loss:0.3922, NB loss:4.8859\n",
      "Pretrain epoch [18/133], ZINB loss:0.4115, NB loss:4.8351\n",
      "Pretrain epoch [19/133], ZINB loss:0.4005, NB loss:4.8933\n",
      "Pretrain epoch [20/133], ZINB loss:0.4210, NB loss:4.8439\n",
      "Pretrain epoch [21/133], ZINB loss:0.3853, NB loss:4.8955\n",
      "Pretrain epoch [22/133], ZINB loss:0.3871, NB loss:4.8472\n",
      "Pretrain epoch [23/133], ZINB loss:0.3825, NB loss:4.9150\n",
      "Pretrain epoch [24/133], ZINB loss:0.3850, NB loss:4.9464\n",
      "Pretrain epoch [25/133], ZINB loss:0.4121, NB loss:4.8923\n",
      "Pretrain epoch [26/133], ZINB loss:0.3940, NB loss:4.9069\n",
      "Pretrain epoch [27/133], ZINB loss:0.4146, NB loss:5.1731\n",
      "Pretrain epoch [1/134], ZINB loss:0.3759, NB loss:4.8624\n",
      "Pretrain epoch [2/134], ZINB loss:0.4016, NB loss:4.9094\n",
      "Pretrain epoch [3/134], ZINB loss:0.3986, NB loss:4.8881\n",
      "Pretrain epoch [4/134], ZINB loss:0.4073, NB loss:4.8545\n",
      "Pretrain epoch [5/134], ZINB loss:0.4067, NB loss:4.9432\n",
      "Pretrain epoch [6/134], ZINB loss:0.4241, NB loss:4.8233\n",
      "Pretrain epoch [7/134], ZINB loss:0.3945, NB loss:4.8399\n",
      "Pretrain epoch [8/134], ZINB loss:0.4043, NB loss:4.8455\n",
      "Pretrain epoch [9/134], ZINB loss:0.3815, NB loss:4.9078\n",
      "Pretrain epoch [10/134], ZINB loss:0.3880, NB loss:4.9292\n",
      "Pretrain epoch [11/134], ZINB loss:0.4158, NB loss:4.9136\n",
      "Pretrain epoch [12/134], ZINB loss:0.4033, NB loss:4.8348\n",
      "Pretrain epoch [13/134], ZINB loss:0.3936, NB loss:4.7859\n",
      "Pretrain epoch [14/134], ZINB loss:0.3926, NB loss:4.8934\n",
      "Pretrain epoch [15/134], ZINB loss:0.3853, NB loss:4.8515\n",
      "Pretrain epoch [16/134], ZINB loss:0.4177, NB loss:4.8759\n",
      "Pretrain epoch [17/134], ZINB loss:0.3786, NB loss:4.8998\n",
      "Pretrain epoch [18/134], ZINB loss:0.3786, NB loss:4.8440\n",
      "Pretrain epoch [19/134], ZINB loss:0.3920, NB loss:4.9071\n",
      "Pretrain epoch [20/134], ZINB loss:0.3852, NB loss:4.9502\n",
      "Pretrain epoch [21/134], ZINB loss:0.3977, NB loss:4.9364\n",
      "Pretrain epoch [22/134], ZINB loss:0.3903, NB loss:4.8726\n",
      "Pretrain epoch [23/134], ZINB loss:0.3934, NB loss:4.9272\n",
      "Pretrain epoch [24/134], ZINB loss:0.3848, NB loss:4.8322\n",
      "Pretrain epoch [25/134], ZINB loss:0.3972, NB loss:4.8950\n",
      "Pretrain epoch [26/134], ZINB loss:0.3957, NB loss:4.8556\n",
      "Pretrain epoch [27/134], ZINB loss:0.3712, NB loss:5.1976\n",
      "Pretrain epoch [1/135], ZINB loss:0.3838, NB loss:4.8699\n",
      "Pretrain epoch [2/135], ZINB loss:0.3861, NB loss:4.8963\n",
      "Pretrain epoch [3/135], ZINB loss:0.3790, NB loss:4.8373\n",
      "Pretrain epoch [4/135], ZINB loss:0.3914, NB loss:4.8781\n",
      "Pretrain epoch [5/135], ZINB loss:0.3956, NB loss:4.8306\n",
      "Pretrain epoch [6/135], ZINB loss:0.4128, NB loss:4.8900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [7/135], ZINB loss:0.3858, NB loss:4.9245\n",
      "Pretrain epoch [8/135], ZINB loss:0.3859, NB loss:4.9774\n",
      "Pretrain epoch [9/135], ZINB loss:0.3995, NB loss:4.8959\n",
      "Pretrain epoch [10/135], ZINB loss:0.4113, NB loss:4.8691\n",
      "Pretrain epoch [11/135], ZINB loss:0.4273, NB loss:4.8855\n",
      "Pretrain epoch [12/135], ZINB loss:0.3876, NB loss:4.9261\n",
      "Pretrain epoch [13/135], ZINB loss:0.3762, NB loss:4.8265\n",
      "Pretrain epoch [14/135], ZINB loss:0.3782, NB loss:4.8959\n",
      "Pretrain epoch [15/135], ZINB loss:0.3980, NB loss:4.7836\n",
      "Pretrain epoch [16/135], ZINB loss:0.3915, NB loss:4.8745\n",
      "Pretrain epoch [17/135], ZINB loss:0.3790, NB loss:4.8751\n",
      "Pretrain epoch [18/135], ZINB loss:0.4018, NB loss:4.8491\n",
      "Pretrain epoch [19/135], ZINB loss:0.4161, NB loss:4.8469\n",
      "Pretrain epoch [20/135], ZINB loss:0.4071, NB loss:4.9162\n",
      "Pretrain epoch [21/135], ZINB loss:0.4031, NB loss:4.8578\n",
      "Pretrain epoch [22/135], ZINB loss:0.3961, NB loss:4.8575\n",
      "Pretrain epoch [23/135], ZINB loss:0.3775, NB loss:4.9010\n",
      "Pretrain epoch [24/135], ZINB loss:0.4033, NB loss:4.8602\n",
      "Pretrain epoch [25/135], ZINB loss:0.3816, NB loss:4.8828\n",
      "Pretrain epoch [26/135], ZINB loss:0.3866, NB loss:4.8521\n",
      "Pretrain epoch [27/135], ZINB loss:0.4454, NB loss:4.8197\n",
      "Pretrain epoch [1/136], ZINB loss:0.3842, NB loss:4.8488\n",
      "Pretrain epoch [2/136], ZINB loss:0.3864, NB loss:4.8668\n",
      "Pretrain epoch [3/136], ZINB loss:0.3828, NB loss:4.9390\n",
      "Pretrain epoch [4/136], ZINB loss:0.4034, NB loss:4.8892\n",
      "Pretrain epoch [5/136], ZINB loss:0.3991, NB loss:4.8996\n",
      "Pretrain epoch [6/136], ZINB loss:0.3995, NB loss:4.8378\n",
      "Pretrain epoch [7/136], ZINB loss:0.4045, NB loss:4.9356\n",
      "Pretrain epoch [8/136], ZINB loss:0.3990, NB loss:4.8629\n",
      "Pretrain epoch [9/136], ZINB loss:0.3952, NB loss:4.9197\n",
      "Pretrain epoch [10/136], ZINB loss:0.3963, NB loss:4.8623\n",
      "Pretrain epoch [11/136], ZINB loss:0.3871, NB loss:4.9013\n",
      "Pretrain epoch [12/136], ZINB loss:0.3977, NB loss:4.9256\n",
      "Pretrain epoch [13/136], ZINB loss:0.3895, NB loss:4.8183\n",
      "Pretrain epoch [14/136], ZINB loss:0.4076, NB loss:4.8415\n",
      "Pretrain epoch [15/136], ZINB loss:0.3966, NB loss:4.8018\n",
      "Pretrain epoch [16/136], ZINB loss:0.3949, NB loss:4.8270\n",
      "Pretrain epoch [17/136], ZINB loss:0.3963, NB loss:4.9363\n",
      "Pretrain epoch [18/136], ZINB loss:0.3690, NB loss:4.7875\n",
      "Pretrain epoch [19/136], ZINB loss:0.3908, NB loss:4.8780\n",
      "Pretrain epoch [20/136], ZINB loss:0.4108, NB loss:4.9333\n",
      "Pretrain epoch [21/136], ZINB loss:0.3884, NB loss:4.8542\n",
      "Pretrain epoch [22/136], ZINB loss:0.3770, NB loss:4.8130\n",
      "Pretrain epoch [23/136], ZINB loss:0.3877, NB loss:4.8717\n",
      "Pretrain epoch [24/136], ZINB loss:0.3959, NB loss:4.8445\n",
      "Pretrain epoch [25/136], ZINB loss:0.3903, NB loss:4.8529\n",
      "Pretrain epoch [26/136], ZINB loss:0.3971, NB loss:4.8737\n",
      "Pretrain epoch [27/136], ZINB loss:0.3291, NB loss:4.7025\n",
      "Pretrain epoch [1/137], ZINB loss:0.3802, NB loss:4.8228\n",
      "Pretrain epoch [2/137], ZINB loss:0.3891, NB loss:4.8793\n",
      "Pretrain epoch [3/137], ZINB loss:0.3977, NB loss:4.9289\n",
      "Pretrain epoch [4/137], ZINB loss:0.3882, NB loss:4.8703\n",
      "Pretrain epoch [5/137], ZINB loss:0.3972, NB loss:4.8264\n",
      "Pretrain epoch [6/137], ZINB loss:0.3827, NB loss:4.8689\n",
      "Pretrain epoch [7/137], ZINB loss:0.3938, NB loss:4.8142\n",
      "Pretrain epoch [8/137], ZINB loss:0.4116, NB loss:4.8290\n",
      "Pretrain epoch [9/137], ZINB loss:0.3937, NB loss:4.8569\n",
      "Pretrain epoch [10/137], ZINB loss:0.4027, NB loss:4.9425\n",
      "Pretrain epoch [11/137], ZINB loss:0.3953, NB loss:4.8660\n",
      "Pretrain epoch [12/137], ZINB loss:0.3904, NB loss:4.9112\n",
      "Pretrain epoch [13/137], ZINB loss:0.3980, NB loss:4.8691\n",
      "Pretrain epoch [14/137], ZINB loss:0.3955, NB loss:4.8716\n",
      "Pretrain epoch [15/137], ZINB loss:0.3746, NB loss:4.8470\n",
      "Pretrain epoch [16/137], ZINB loss:0.4039, NB loss:4.9207\n",
      "Pretrain epoch [17/137], ZINB loss:0.3931, NB loss:4.8201\n",
      "Pretrain epoch [18/137], ZINB loss:0.3980, NB loss:4.8505\n",
      "Pretrain epoch [19/137], ZINB loss:0.3986, NB loss:4.8840\n",
      "Pretrain epoch [20/137], ZINB loss:0.3882, NB loss:4.8520\n",
      "Pretrain epoch [21/137], ZINB loss:0.3929, NB loss:4.8630\n",
      "Pretrain epoch [22/137], ZINB loss:0.3923, NB loss:4.8932\n",
      "Pretrain epoch [23/137], ZINB loss:0.3946, NB loss:4.8160\n",
      "Pretrain epoch [24/137], ZINB loss:0.3760, NB loss:4.8238\n",
      "Pretrain epoch [25/137], ZINB loss:0.4060, NB loss:4.8867\n",
      "Pretrain epoch [26/137], ZINB loss:0.3939, NB loss:4.8935\n",
      "Pretrain epoch [27/137], ZINB loss:0.2791, NB loss:4.7938\n",
      "Pretrain epoch [1/138], ZINB loss:0.3774, NB loss:4.8574\n",
      "Pretrain epoch [2/138], ZINB loss:0.3921, NB loss:4.9007\n",
      "Pretrain epoch [3/138], ZINB loss:0.4129, NB loss:4.8865\n",
      "Pretrain epoch [4/138], ZINB loss:0.3792, NB loss:4.9126\n",
      "Pretrain epoch [5/138], ZINB loss:0.4039, NB loss:4.8442\n",
      "Pretrain epoch [6/138], ZINB loss:0.3924, NB loss:4.8335\n",
      "Pretrain epoch [7/138], ZINB loss:0.3844, NB loss:4.8028\n",
      "Pretrain epoch [8/138], ZINB loss:0.3887, NB loss:4.8807\n",
      "Pretrain epoch [9/138], ZINB loss:0.4002, NB loss:4.8115\n",
      "Pretrain epoch [10/138], ZINB loss:0.4081, NB loss:4.9156\n",
      "Pretrain epoch [11/138], ZINB loss:0.4094, NB loss:4.8392\n",
      "Pretrain epoch [12/138], ZINB loss:0.3852, NB loss:4.8994\n",
      "Pretrain epoch [13/138], ZINB loss:0.3810, NB loss:4.8338\n",
      "Pretrain epoch [14/138], ZINB loss:0.3829, NB loss:4.8613\n",
      "Pretrain epoch [15/138], ZINB loss:0.4003, NB loss:4.8172\n",
      "Pretrain epoch [16/138], ZINB loss:0.3997, NB loss:4.8789\n",
      "Pretrain epoch [17/138], ZINB loss:0.3898, NB loss:4.8528\n",
      "Pretrain epoch [18/138], ZINB loss:0.3764, NB loss:4.9529\n",
      "Pretrain epoch [19/138], ZINB loss:0.3709, NB loss:4.8650\n",
      "Pretrain epoch [20/138], ZINB loss:0.3792, NB loss:4.9205\n",
      "Pretrain epoch [21/138], ZINB loss:0.3947, NB loss:4.7729\n",
      "Pretrain epoch [22/138], ZINB loss:0.4060, NB loss:4.8779\n",
      "Pretrain epoch [23/138], ZINB loss:0.3997, NB loss:4.8242\n",
      "Pretrain epoch [24/138], ZINB loss:0.4061, NB loss:4.9314\n",
      "Pretrain epoch [25/138], ZINB loss:0.3969, NB loss:4.8339\n",
      "Pretrain epoch [26/138], ZINB loss:0.3906, NB loss:4.7933\n",
      "Pretrain epoch [27/138], ZINB loss:0.3323, NB loss:4.8253\n",
      "Pretrain epoch [1/139], ZINB loss:0.3942, NB loss:4.8496\n",
      "Pretrain epoch [2/139], ZINB loss:0.3917, NB loss:4.8220\n",
      "Pretrain epoch [3/139], ZINB loss:0.3802, NB loss:4.8340\n",
      "Pretrain epoch [4/139], ZINB loss:0.3742, NB loss:4.8142\n",
      "Pretrain epoch [5/139], ZINB loss:0.4105, NB loss:4.9129\n",
      "Pretrain epoch [6/139], ZINB loss:0.3908, NB loss:4.8391\n",
      "Pretrain epoch [7/139], ZINB loss:0.3909, NB loss:4.8480\n",
      "Pretrain epoch [8/139], ZINB loss:0.3982, NB loss:4.8454\n",
      "Pretrain epoch [9/139], ZINB loss:0.3772, NB loss:4.8857\n",
      "Pretrain epoch [10/139], ZINB loss:0.3880, NB loss:4.8564\n",
      "Pretrain epoch [11/139], ZINB loss:0.3870, NB loss:4.8857\n",
      "Pretrain epoch [12/139], ZINB loss:0.3907, NB loss:4.8821\n",
      "Pretrain epoch [13/139], ZINB loss:0.4046, NB loss:4.8123\n",
      "Pretrain epoch [14/139], ZINB loss:0.4068, NB loss:4.8926\n",
      "Pretrain epoch [15/139], ZINB loss:0.4137, NB loss:4.8642\n",
      "Pretrain epoch [16/139], ZINB loss:0.3894, NB loss:4.8661\n",
      "Pretrain epoch [17/139], ZINB loss:0.3893, NB loss:4.8521\n",
      "Pretrain epoch [18/139], ZINB loss:0.3885, NB loss:4.8441\n",
      "Pretrain epoch [19/139], ZINB loss:0.3832, NB loss:4.8127\n",
      "Pretrain epoch [20/139], ZINB loss:0.3940, NB loss:4.9056\n",
      "Pretrain epoch [21/139], ZINB loss:0.4026, NB loss:4.8828\n",
      "Pretrain epoch [22/139], ZINB loss:0.4175, NB loss:4.8457\n",
      "Pretrain epoch [23/139], ZINB loss:0.3690, NB loss:4.8478\n",
      "Pretrain epoch [24/139], ZINB loss:0.3804, NB loss:4.8450\n",
      "Pretrain epoch [25/139], ZINB loss:0.3913, NB loss:4.8706\n",
      "Pretrain epoch [26/139], ZINB loss:0.4006, NB loss:4.8616\n",
      "Pretrain epoch [27/139], ZINB loss:0.3090, NB loss:4.9612\n",
      "Pretrain epoch [1/140], ZINB loss:0.3840, NB loss:4.8661\n",
      "Pretrain epoch [2/140], ZINB loss:0.3840, NB loss:4.8434\n",
      "Pretrain epoch [3/140], ZINB loss:0.3753, NB loss:4.8285\n",
      "Pretrain epoch [4/140], ZINB loss:0.3878, NB loss:4.8727\n",
      "Pretrain epoch [5/140], ZINB loss:0.4068, NB loss:4.8468\n",
      "Pretrain epoch [6/140], ZINB loss:0.4025, NB loss:4.8079\n",
      "Pretrain epoch [7/140], ZINB loss:0.3978, NB loss:4.8950\n",
      "Pretrain epoch [8/140], ZINB loss:0.3910, NB loss:4.8483\n",
      "Pretrain epoch [9/140], ZINB loss:0.3999, NB loss:4.7900\n",
      "Pretrain epoch [10/140], ZINB loss:0.3990, NB loss:4.9208\n",
      "Pretrain epoch [11/140], ZINB loss:0.3982, NB loss:4.8775\n",
      "Pretrain epoch [12/140], ZINB loss:0.3876, NB loss:4.8187\n",
      "Pretrain epoch [13/140], ZINB loss:0.4044, NB loss:4.8640\n",
      "Pretrain epoch [14/140], ZINB loss:0.4047, NB loss:4.7984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [15/140], ZINB loss:0.3948, NB loss:4.8930\n",
      "Pretrain epoch [16/140], ZINB loss:0.3817, NB loss:4.8738\n",
      "Pretrain epoch [17/140], ZINB loss:0.3934, NB loss:4.8228\n",
      "Pretrain epoch [18/140], ZINB loss:0.4021, NB loss:4.8686\n",
      "Pretrain epoch [19/140], ZINB loss:0.3840, NB loss:4.8563\n",
      "Pretrain epoch [20/140], ZINB loss:0.3814, NB loss:4.8150\n",
      "Pretrain epoch [21/140], ZINB loss:0.4144, NB loss:4.8638\n",
      "Pretrain epoch [22/140], ZINB loss:0.3785, NB loss:4.8722\n",
      "Pretrain epoch [23/140], ZINB loss:0.3986, NB loss:4.8232\n",
      "Pretrain epoch [24/140], ZINB loss:0.3934, NB loss:4.8699\n",
      "Pretrain epoch [25/140], ZINB loss:0.3788, NB loss:4.8556\n",
      "Pretrain epoch [26/140], ZINB loss:0.3800, NB loss:4.8697\n",
      "Pretrain epoch [27/140], ZINB loss:0.3437, NB loss:4.8026\n",
      "Pretrain epoch [1/141], ZINB loss:0.4179, NB loss:4.8461\n",
      "Pretrain epoch [2/141], ZINB loss:0.3976, NB loss:4.8261\n",
      "Pretrain epoch [3/141], ZINB loss:0.3920, NB loss:4.8556\n",
      "Pretrain epoch [4/141], ZINB loss:0.3991, NB loss:4.8251\n",
      "Pretrain epoch [5/141], ZINB loss:0.3710, NB loss:4.8221\n",
      "Pretrain epoch [6/141], ZINB loss:0.3888, NB loss:4.8277\n",
      "Pretrain epoch [7/141], ZINB loss:0.4017, NB loss:4.9294\n",
      "Pretrain epoch [8/141], ZINB loss:0.3819, NB loss:4.8222\n",
      "Pretrain epoch [9/141], ZINB loss:0.3935, NB loss:4.8764\n",
      "Pretrain epoch [10/141], ZINB loss:0.4059, NB loss:4.8780\n",
      "Pretrain epoch [11/141], ZINB loss:0.3884, NB loss:4.8335\n",
      "Pretrain epoch [12/141], ZINB loss:0.4144, NB loss:4.8434\n",
      "Pretrain epoch [13/141], ZINB loss:0.3891, NB loss:4.8255\n",
      "Pretrain epoch [14/141], ZINB loss:0.3953, NB loss:4.8505\n",
      "Pretrain epoch [15/141], ZINB loss:0.3814, NB loss:4.8357\n",
      "Pretrain epoch [16/141], ZINB loss:0.3814, NB loss:4.9200\n",
      "Pretrain epoch [17/141], ZINB loss:0.3788, NB loss:4.7591\n",
      "Pretrain epoch [18/141], ZINB loss:0.3792, NB loss:4.8911\n",
      "Pretrain epoch [19/141], ZINB loss:0.3867, NB loss:4.8953\n",
      "Pretrain epoch [20/141], ZINB loss:0.3839, NB loss:4.8773\n",
      "Pretrain epoch [21/141], ZINB loss:0.3932, NB loss:4.8083\n",
      "Pretrain epoch [22/141], ZINB loss:0.3992, NB loss:4.7904\n",
      "Pretrain epoch [23/141], ZINB loss:0.3949, NB loss:4.7938\n",
      "Pretrain epoch [24/141], ZINB loss:0.3841, NB loss:4.8933\n",
      "Pretrain epoch [25/141], ZINB loss:0.4039, NB loss:4.8205\n",
      "Pretrain epoch [26/141], ZINB loss:0.4001, NB loss:4.8926\n",
      "Pretrain epoch [27/141], ZINB loss:0.5826, NB loss:5.3484\n",
      "Pretrain epoch [1/142], ZINB loss:0.3987, NB loss:4.7519\n",
      "Pretrain epoch [2/142], ZINB loss:0.3981, NB loss:4.8334\n",
      "Pretrain epoch [3/142], ZINB loss:0.4024, NB loss:4.7824\n",
      "Pretrain epoch [4/142], ZINB loss:0.3806, NB loss:4.7684\n",
      "Pretrain epoch [5/142], ZINB loss:0.4012, NB loss:4.8281\n",
      "Pretrain epoch [6/142], ZINB loss:0.3868, NB loss:4.8352\n",
      "Pretrain epoch [7/142], ZINB loss:0.4034, NB loss:4.9153\n",
      "Pretrain epoch [8/142], ZINB loss:0.3944, NB loss:4.8613\n",
      "Pretrain epoch [9/142], ZINB loss:0.3836, NB loss:4.8338\n",
      "Pretrain epoch [10/142], ZINB loss:0.3943, NB loss:4.9458\n",
      "Pretrain epoch [11/142], ZINB loss:0.3987, NB loss:4.8328\n",
      "Pretrain epoch [12/142], ZINB loss:0.4048, NB loss:4.8967\n",
      "Pretrain epoch [13/142], ZINB loss:0.3819, NB loss:4.9266\n",
      "Pretrain epoch [14/142], ZINB loss:0.3832, NB loss:4.8907\n",
      "Pretrain epoch [15/142], ZINB loss:0.4315, NB loss:4.8298\n",
      "Pretrain epoch [16/142], ZINB loss:0.3819, NB loss:4.8471\n",
      "Pretrain epoch [17/142], ZINB loss:0.3892, NB loss:4.9022\n",
      "Pretrain epoch [18/142], ZINB loss:0.4160, NB loss:4.8552\n",
      "Pretrain epoch [19/142], ZINB loss:0.3926, NB loss:4.8259\n",
      "Pretrain epoch [20/142], ZINB loss:0.3980, NB loss:4.8518\n",
      "Pretrain epoch [21/142], ZINB loss:0.3845, NB loss:4.7842\n",
      "Pretrain epoch [22/142], ZINB loss:0.3911, NB loss:4.8153\n",
      "Pretrain epoch [23/142], ZINB loss:0.3887, NB loss:4.7959\n",
      "Pretrain epoch [24/142], ZINB loss:0.3729, NB loss:4.8681\n",
      "Pretrain epoch [25/142], ZINB loss:0.3864, NB loss:4.8574\n",
      "Pretrain epoch [26/142], ZINB loss:0.3961, NB loss:4.8130\n",
      "Pretrain epoch [27/142], ZINB loss:0.3610, NB loss:4.7613\n",
      "Pretrain epoch [1/143], ZINB loss:0.3806, NB loss:4.8132\n",
      "Pretrain epoch [2/143], ZINB loss:0.4109, NB loss:4.8551\n",
      "Pretrain epoch [3/143], ZINB loss:0.3866, NB loss:4.8941\n",
      "Pretrain epoch [4/143], ZINB loss:0.3877, NB loss:4.8484\n",
      "Pretrain epoch [5/143], ZINB loss:0.4033, NB loss:4.8089\n",
      "Pretrain epoch [6/143], ZINB loss:0.3972, NB loss:4.9094\n",
      "Pretrain epoch [7/143], ZINB loss:0.3799, NB loss:4.8786\n",
      "Pretrain epoch [8/143], ZINB loss:0.4043, NB loss:4.8761\n",
      "Pretrain epoch [9/143], ZINB loss:0.3927, NB loss:4.7881\n",
      "Pretrain epoch [10/143], ZINB loss:0.3851, NB loss:4.8161\n",
      "Pretrain epoch [11/143], ZINB loss:0.3829, NB loss:4.8843\n",
      "Pretrain epoch [12/143], ZINB loss:0.3929, NB loss:4.7846\n",
      "Pretrain epoch [13/143], ZINB loss:0.3976, NB loss:4.7815\n",
      "Pretrain epoch [14/143], ZINB loss:0.3835, NB loss:4.8621\n",
      "Pretrain epoch [15/143], ZINB loss:0.4053, NB loss:4.8851\n",
      "Pretrain epoch [16/143], ZINB loss:0.3897, NB loss:4.8251\n",
      "Pretrain epoch [17/143], ZINB loss:0.4199, NB loss:4.8375\n",
      "Pretrain epoch [18/143], ZINB loss:0.4142, NB loss:4.8225\n",
      "Pretrain epoch [19/143], ZINB loss:0.3879, NB loss:4.8471\n",
      "Pretrain epoch [20/143], ZINB loss:0.3757, NB loss:4.8137\n",
      "Pretrain epoch [21/143], ZINB loss:0.3760, NB loss:4.8675\n",
      "Pretrain epoch [22/143], ZINB loss:0.3900, NB loss:4.8819\n",
      "Pretrain epoch [23/143], ZINB loss:0.3833, NB loss:4.7779\n",
      "Pretrain epoch [24/143], ZINB loss:0.3981, NB loss:4.8203\n",
      "Pretrain epoch [25/143], ZINB loss:0.3983, NB loss:4.8027\n",
      "Pretrain epoch [26/143], ZINB loss:0.3861, NB loss:4.8410\n",
      "Pretrain epoch [27/143], ZINB loss:0.3061, NB loss:5.2863\n",
      "Pretrain epoch [1/144], ZINB loss:0.4035, NB loss:4.9015\n",
      "Pretrain epoch [2/144], ZINB loss:0.3909, NB loss:4.8446\n",
      "Pretrain epoch [3/144], ZINB loss:0.3960, NB loss:4.8127\n",
      "Pretrain epoch [4/144], ZINB loss:0.3786, NB loss:4.8393\n",
      "Pretrain epoch [5/144], ZINB loss:0.4040, NB loss:4.8043\n",
      "Pretrain epoch [6/144], ZINB loss:0.3825, NB loss:4.8532\n",
      "Pretrain epoch [7/144], ZINB loss:0.3936, NB loss:4.8612\n",
      "Pretrain epoch [8/144], ZINB loss:0.3863, NB loss:4.8391\n",
      "Pretrain epoch [9/144], ZINB loss:0.3834, NB loss:4.8478\n",
      "Pretrain epoch [10/144], ZINB loss:0.3891, NB loss:4.8625\n",
      "Pretrain epoch [11/144], ZINB loss:0.4038, NB loss:4.8356\n",
      "Pretrain epoch [12/144], ZINB loss:0.3817, NB loss:4.8328\n",
      "Pretrain epoch [13/144], ZINB loss:0.4012, NB loss:4.8954\n",
      "Pretrain epoch [14/144], ZINB loss:0.4180, NB loss:4.7593\n",
      "Pretrain epoch [15/144], ZINB loss:0.3803, NB loss:4.8388\n",
      "Pretrain epoch [16/144], ZINB loss:0.3869, NB loss:4.8181\n",
      "Pretrain epoch [17/144], ZINB loss:0.3835, NB loss:4.8587\n",
      "Pretrain epoch [18/144], ZINB loss:0.3925, NB loss:4.7648\n",
      "Pretrain epoch [19/144], ZINB loss:0.3996, NB loss:4.8432\n",
      "Pretrain epoch [20/144], ZINB loss:0.3833, NB loss:4.8070\n",
      "Pretrain epoch [21/144], ZINB loss:0.3888, NB loss:4.8276\n",
      "Pretrain epoch [22/144], ZINB loss:0.4015, NB loss:4.7770\n",
      "Pretrain epoch [23/144], ZINB loss:0.3984, NB loss:4.8165\n",
      "Pretrain epoch [24/144], ZINB loss:0.4152, NB loss:4.8358\n",
      "Pretrain epoch [25/144], ZINB loss:0.3921, NB loss:4.8572\n",
      "Pretrain epoch [26/144], ZINB loss:0.3736, NB loss:4.8992\n",
      "Pretrain epoch [27/144], ZINB loss:0.3539, NB loss:5.5043\n",
      "Pretrain epoch [1/145], ZINB loss:0.3835, NB loss:4.7768\n",
      "Pretrain epoch [2/145], ZINB loss:0.4273, NB loss:4.8889\n",
      "Pretrain epoch [3/145], ZINB loss:0.3782, NB loss:4.8576\n",
      "Pretrain epoch [4/145], ZINB loss:0.4150, NB loss:4.8691\n",
      "Pretrain epoch [5/145], ZINB loss:0.3775, NB loss:4.8215\n",
      "Pretrain epoch [6/145], ZINB loss:0.3853, NB loss:4.7994\n",
      "Pretrain epoch [7/145], ZINB loss:0.3767, NB loss:4.8390\n",
      "Pretrain epoch [8/145], ZINB loss:0.3966, NB loss:4.8254\n",
      "Pretrain epoch [9/145], ZINB loss:0.4001, NB loss:4.7930\n",
      "Pretrain epoch [10/145], ZINB loss:0.3967, NB loss:4.7978\n",
      "Pretrain epoch [11/145], ZINB loss:0.3954, NB loss:4.8228\n",
      "Pretrain epoch [12/145], ZINB loss:0.3888, NB loss:4.8065\n",
      "Pretrain epoch [13/145], ZINB loss:0.3896, NB loss:4.8262\n",
      "Pretrain epoch [14/145], ZINB loss:0.3942, NB loss:4.8499\n",
      "Pretrain epoch [15/145], ZINB loss:0.3828, NB loss:4.7780\n",
      "Pretrain epoch [16/145], ZINB loss:0.3753, NB loss:4.8892\n",
      "Pretrain epoch [17/145], ZINB loss:0.3923, NB loss:4.8528\n",
      "Pretrain epoch [18/145], ZINB loss:0.3918, NB loss:4.8654\n",
      "Pretrain epoch [19/145], ZINB loss:0.3823, NB loss:4.9019\n",
      "Pretrain epoch [20/145], ZINB loss:0.3828, NB loss:4.8422\n",
      "Pretrain epoch [21/145], ZINB loss:0.3911, NB loss:4.8005\n",
      "Pretrain epoch [22/145], ZINB loss:0.3862, NB loss:4.8596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [23/145], ZINB loss:0.4152, NB loss:4.8036\n",
      "Pretrain epoch [24/145], ZINB loss:0.3831, NB loss:4.8776\n",
      "Pretrain epoch [25/145], ZINB loss:0.4041, NB loss:4.7574\n",
      "Pretrain epoch [26/145], ZINB loss:0.3980, NB loss:4.8735\n",
      "Pretrain epoch [27/145], ZINB loss:0.4222, NB loss:4.5268\n",
      "Pretrain epoch [1/146], ZINB loss:0.3906, NB loss:4.8187\n",
      "Pretrain epoch [2/146], ZINB loss:0.4086, NB loss:4.8671\n",
      "Pretrain epoch [3/146], ZINB loss:0.3762, NB loss:4.8435\n",
      "Pretrain epoch [4/146], ZINB loss:0.3886, NB loss:4.8312\n",
      "Pretrain epoch [5/146], ZINB loss:0.4075, NB loss:4.8177\n",
      "Pretrain epoch [6/146], ZINB loss:0.3907, NB loss:4.8518\n",
      "Pretrain epoch [7/146], ZINB loss:0.3836, NB loss:4.7685\n",
      "Pretrain epoch [8/146], ZINB loss:0.3854, NB loss:4.8223\n",
      "Pretrain epoch [9/146], ZINB loss:0.3788, NB loss:4.8128\n",
      "Pretrain epoch [10/146], ZINB loss:0.4016, NB loss:4.8445\n",
      "Pretrain epoch [11/146], ZINB loss:0.4021, NB loss:4.8244\n",
      "Pretrain epoch [12/146], ZINB loss:0.4053, NB loss:4.8439\n",
      "Pretrain epoch [13/146], ZINB loss:0.3992, NB loss:4.7960\n",
      "Pretrain epoch [14/146], ZINB loss:0.3891, NB loss:4.8126\n",
      "Pretrain epoch [15/146], ZINB loss:0.3974, NB loss:4.7885\n",
      "Pretrain epoch [16/146], ZINB loss:0.3968, NB loss:4.7898\n",
      "Pretrain epoch [17/146], ZINB loss:0.4027, NB loss:4.8686\n",
      "Pretrain epoch [18/146], ZINB loss:0.3696, NB loss:4.8746\n",
      "Pretrain epoch [19/146], ZINB loss:0.3979, NB loss:4.8527\n",
      "Pretrain epoch [20/146], ZINB loss:0.3936, NB loss:4.7916\n",
      "Pretrain epoch [21/146], ZINB loss:0.4072, NB loss:4.8081\n",
      "Pretrain epoch [22/146], ZINB loss:0.3811, NB loss:4.8593\n",
      "Pretrain epoch [23/146], ZINB loss:0.3753, NB loss:4.8466\n",
      "Pretrain epoch [24/146], ZINB loss:0.3897, NB loss:4.8026\n",
      "Pretrain epoch [25/146], ZINB loss:0.3893, NB loss:4.8555\n",
      "Pretrain epoch [26/146], ZINB loss:0.3967, NB loss:4.8320\n",
      "Pretrain epoch [27/146], ZINB loss:0.6433, NB loss:4.8843\n",
      "Pretrain epoch [1/147], ZINB loss:0.3695, NB loss:4.8103\n",
      "Pretrain epoch [2/147], ZINB loss:0.4097, NB loss:4.9039\n",
      "Pretrain epoch [3/147], ZINB loss:0.3961, NB loss:4.8744\n",
      "Pretrain epoch [4/147], ZINB loss:0.4068, NB loss:4.7783\n",
      "Pretrain epoch [5/147], ZINB loss:0.4013, NB loss:4.8156\n",
      "Pretrain epoch [6/147], ZINB loss:0.3917, NB loss:4.7845\n",
      "Pretrain epoch [7/147], ZINB loss:0.3931, NB loss:4.7965\n",
      "Pretrain epoch [8/147], ZINB loss:0.3886, NB loss:4.8885\n",
      "Pretrain epoch [9/147], ZINB loss:0.4061, NB loss:4.8254\n",
      "Pretrain epoch [10/147], ZINB loss:0.3933, NB loss:4.8526\n",
      "Pretrain epoch [11/147], ZINB loss:0.3818, NB loss:4.7819\n",
      "Pretrain epoch [12/147], ZINB loss:0.3984, NB loss:4.8220\n",
      "Pretrain epoch [13/147], ZINB loss:0.3986, NB loss:4.8222\n",
      "Pretrain epoch [14/147], ZINB loss:0.3961, NB loss:4.8442\n",
      "Pretrain epoch [15/147], ZINB loss:0.3940, NB loss:4.8208\n",
      "Pretrain epoch [16/147], ZINB loss:0.3903, NB loss:4.7841\n",
      "Pretrain epoch [17/147], ZINB loss:0.3856, NB loss:4.8772\n",
      "Pretrain epoch [18/147], ZINB loss:0.3949, NB loss:4.8501\n",
      "Pretrain epoch [19/147], ZINB loss:0.4042, NB loss:4.8822\n",
      "Pretrain epoch [20/147], ZINB loss:0.4112, NB loss:4.8168\n",
      "Pretrain epoch [21/147], ZINB loss:0.3690, NB loss:4.7807\n",
      "Pretrain epoch [22/147], ZINB loss:0.3799, NB loss:4.8477\n",
      "Pretrain epoch [23/147], ZINB loss:0.3944, NB loss:4.7791\n",
      "Pretrain epoch [24/147], ZINB loss:0.3905, NB loss:4.7619\n",
      "Pretrain epoch [25/147], ZINB loss:0.4014, NB loss:4.8039\n",
      "Pretrain epoch [26/147], ZINB loss:0.3917, NB loss:4.8303\n",
      "Pretrain epoch [27/147], ZINB loss:0.4208, NB loss:4.7525\n",
      "Pretrain epoch [1/148], ZINB loss:0.4046, NB loss:4.8371\n",
      "Pretrain epoch [2/148], ZINB loss:0.3891, NB loss:4.7975\n",
      "Pretrain epoch [3/148], ZINB loss:0.3893, NB loss:4.8457\n",
      "Pretrain epoch [4/148], ZINB loss:0.3961, NB loss:4.8733\n",
      "Pretrain epoch [5/148], ZINB loss:0.3642, NB loss:4.7916\n",
      "Pretrain epoch [6/148], ZINB loss:0.4088, NB loss:4.8409\n",
      "Pretrain epoch [7/148], ZINB loss:0.3989, NB loss:4.8966\n",
      "Pretrain epoch [8/148], ZINB loss:0.3869, NB loss:4.8547\n",
      "Pretrain epoch [9/148], ZINB loss:0.3876, NB loss:4.7683\n",
      "Pretrain epoch [10/148], ZINB loss:0.3954, NB loss:4.6770\n",
      "Pretrain epoch [11/148], ZINB loss:0.4256, NB loss:4.8817\n",
      "Pretrain epoch [12/148], ZINB loss:0.3873, NB loss:4.7972\n",
      "Pretrain epoch [13/148], ZINB loss:0.4116, NB loss:4.7818\n",
      "Pretrain epoch [14/148], ZINB loss:0.3701, NB loss:4.8318\n",
      "Pretrain epoch [15/148], ZINB loss:0.3779, NB loss:4.8115\n",
      "Pretrain epoch [16/148], ZINB loss:0.3889, NB loss:4.8127\n",
      "Pretrain epoch [17/148], ZINB loss:0.4020, NB loss:4.8512\n",
      "Pretrain epoch [18/148], ZINB loss:0.3991, NB loss:4.6862\n",
      "Pretrain epoch [19/148], ZINB loss:0.3963, NB loss:4.9168\n",
      "Pretrain epoch [20/148], ZINB loss:0.3848, NB loss:4.7962\n",
      "Pretrain epoch [21/148], ZINB loss:0.3805, NB loss:4.8312\n",
      "Pretrain epoch [22/148], ZINB loss:0.3892, NB loss:4.8632\n",
      "Pretrain epoch [23/148], ZINB loss:0.3940, NB loss:4.8244\n",
      "Pretrain epoch [24/148], ZINB loss:0.3987, NB loss:4.7988\n",
      "Pretrain epoch [25/148], ZINB loss:0.3941, NB loss:4.8139\n",
      "Pretrain epoch [26/148], ZINB loss:0.3939, NB loss:4.8417\n",
      "Pretrain epoch [27/148], ZINB loss:0.4607, NB loss:4.9802\n",
      "Pretrain epoch [1/149], ZINB loss:0.3897, NB loss:4.7855\n",
      "Pretrain epoch [2/149], ZINB loss:0.3867, NB loss:4.7513\n",
      "Pretrain epoch [3/149], ZINB loss:0.4019, NB loss:4.7629\n",
      "Pretrain epoch [4/149], ZINB loss:0.4163, NB loss:4.7502\n",
      "Pretrain epoch [5/149], ZINB loss:0.3894, NB loss:4.7913\n",
      "Pretrain epoch [6/149], ZINB loss:0.3982, NB loss:4.8030\n",
      "Pretrain epoch [7/149], ZINB loss:0.3902, NB loss:4.9165\n",
      "Pretrain epoch [8/149], ZINB loss:0.3928, NB loss:4.8279\n",
      "Pretrain epoch [9/149], ZINB loss:0.4042, NB loss:4.8201\n",
      "Pretrain epoch [10/149], ZINB loss:0.4136, NB loss:4.8351\n",
      "Pretrain epoch [11/149], ZINB loss:0.3869, NB loss:4.8328\n",
      "Pretrain epoch [12/149], ZINB loss:0.3903, NB loss:4.8394\n",
      "Pretrain epoch [13/149], ZINB loss:0.4072, NB loss:4.8475\n",
      "Pretrain epoch [14/149], ZINB loss:0.3818, NB loss:4.8173\n",
      "Pretrain epoch [15/149], ZINB loss:0.4020, NB loss:4.8269\n",
      "Pretrain epoch [16/149], ZINB loss:0.3826, NB loss:4.8692\n",
      "Pretrain epoch [17/149], ZINB loss:0.4021, NB loss:4.7991\n",
      "Pretrain epoch [18/149], ZINB loss:0.3898, NB loss:4.8545\n",
      "Pretrain epoch [19/149], ZINB loss:0.3886, NB loss:4.7983\n",
      "Pretrain epoch [20/149], ZINB loss:0.3809, NB loss:4.7828\n",
      "Pretrain epoch [21/149], ZINB loss:0.4010, NB loss:4.8062\n",
      "Pretrain epoch [22/149], ZINB loss:0.3948, NB loss:4.7927\n",
      "Pretrain epoch [23/149], ZINB loss:0.4081, NB loss:4.8201\n",
      "Pretrain epoch [24/149], ZINB loss:0.3811, NB loss:4.8040\n",
      "Pretrain epoch [25/149], ZINB loss:0.4033, NB loss:4.8222\n",
      "Pretrain epoch [26/149], ZINB loss:0.3967, NB loss:4.8543\n",
      "Pretrain epoch [27/149], ZINB loss:0.3516, NB loss:5.5532\n",
      "Pretrain epoch [1/150], ZINB loss:0.4064, NB loss:4.7938\n",
      "Pretrain epoch [2/150], ZINB loss:0.3894, NB loss:4.8777\n",
      "Pretrain epoch [3/150], ZINB loss:0.4118, NB loss:4.7919\n",
      "Pretrain epoch [4/150], ZINB loss:0.3969, NB loss:4.7722\n",
      "Pretrain epoch [5/150], ZINB loss:0.3919, NB loss:4.7934\n",
      "Pretrain epoch [6/150], ZINB loss:0.3966, NB loss:4.8333\n",
      "Pretrain epoch [7/150], ZINB loss:0.3919, NB loss:4.8559\n",
      "Pretrain epoch [8/150], ZINB loss:0.3956, NB loss:4.7179\n",
      "Pretrain epoch [9/150], ZINB loss:0.3843, NB loss:4.8416\n",
      "Pretrain epoch [10/150], ZINB loss:0.3852, NB loss:4.7152\n",
      "Pretrain epoch [11/150], ZINB loss:0.4027, NB loss:4.8446\n",
      "Pretrain epoch [12/150], ZINB loss:0.3933, NB loss:4.8089\n",
      "Pretrain epoch [13/150], ZINB loss:0.3813, NB loss:4.7964\n",
      "Pretrain epoch [14/150], ZINB loss:0.3981, NB loss:4.8242\n",
      "Pretrain epoch [15/150], ZINB loss:0.4032, NB loss:4.8441\n",
      "Pretrain epoch [16/150], ZINB loss:0.3760, NB loss:4.7664\n",
      "Pretrain epoch [17/150], ZINB loss:0.3845, NB loss:4.7536\n",
      "Pretrain epoch [18/150], ZINB loss:0.4053, NB loss:4.8453\n",
      "Pretrain epoch [19/150], ZINB loss:0.4021, NB loss:4.7446\n",
      "Pretrain epoch [20/150], ZINB loss:0.3927, NB loss:4.8998\n",
      "Pretrain epoch [21/150], ZINB loss:0.3981, NB loss:4.8442\n",
      "Pretrain epoch [22/150], ZINB loss:0.3847, NB loss:4.7772\n",
      "Pretrain epoch [23/150], ZINB loss:0.3729, NB loss:4.8544\n",
      "Pretrain epoch [24/150], ZINB loss:0.3760, NB loss:4.8567\n",
      "Pretrain epoch [25/150], ZINB loss:0.4051, NB loss:4.8682\n",
      "Pretrain epoch [26/150], ZINB loss:0.3975, NB loss:4.8263\n",
      "Pretrain epoch [27/150], ZINB loss:0.3057, NB loss:5.4386\n",
      "Pretrain epoch [1/151], ZINB loss:0.3881, NB loss:4.8687\n",
      "Pretrain epoch [2/151], ZINB loss:0.3893, NB loss:4.7957\n",
      "Pretrain epoch [3/151], ZINB loss:0.3977, NB loss:4.8054\n",
      "Pretrain epoch [4/151], ZINB loss:0.3768, NB loss:4.8375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [5/151], ZINB loss:0.3884, NB loss:4.8177\n",
      "Pretrain epoch [6/151], ZINB loss:0.3917, NB loss:4.8004\n",
      "Pretrain epoch [7/151], ZINB loss:0.3832, NB loss:4.8404\n",
      "Pretrain epoch [8/151], ZINB loss:0.4016, NB loss:4.8063\n",
      "Pretrain epoch [9/151], ZINB loss:0.3917, NB loss:4.8341\n",
      "Pretrain epoch [10/151], ZINB loss:0.3849, NB loss:4.8485\n",
      "Pretrain epoch [11/151], ZINB loss:0.3829, NB loss:4.8223\n",
      "Pretrain epoch [12/151], ZINB loss:0.4034, NB loss:4.8191\n",
      "Pretrain epoch [13/151], ZINB loss:0.3846, NB loss:4.7959\n",
      "Pretrain epoch [14/151], ZINB loss:0.3967, NB loss:4.7970\n",
      "Pretrain epoch [15/151], ZINB loss:0.4013, NB loss:4.8246\n",
      "Pretrain epoch [16/151], ZINB loss:0.3980, NB loss:4.8044\n",
      "Pretrain epoch [17/151], ZINB loss:0.3992, NB loss:4.8570\n",
      "Pretrain epoch [18/151], ZINB loss:0.3877, NB loss:4.8163\n",
      "Pretrain epoch [19/151], ZINB loss:0.3935, NB loss:4.7439\n",
      "Pretrain epoch [20/151], ZINB loss:0.4006, NB loss:4.7355\n",
      "Pretrain epoch [21/151], ZINB loss:0.3958, NB loss:4.7889\n",
      "Pretrain epoch [22/151], ZINB loss:0.3955, NB loss:4.8038\n",
      "Pretrain epoch [23/151], ZINB loss:0.4061, NB loss:4.8001\n",
      "Pretrain epoch [24/151], ZINB loss:0.3701, NB loss:4.8140\n",
      "Pretrain epoch [25/151], ZINB loss:0.3873, NB loss:4.8251\n",
      "Pretrain epoch [26/151], ZINB loss:0.4146, NB loss:4.7700\n",
      "Pretrain epoch [27/151], ZINB loss:0.3350, NB loss:4.5990\n",
      "Pretrain epoch [1/152], ZINB loss:0.3944, NB loss:4.8239\n",
      "Pretrain epoch [2/152], ZINB loss:0.3853, NB loss:4.8378\n",
      "Pretrain epoch [3/152], ZINB loss:0.4045, NB loss:4.7520\n",
      "Pretrain epoch [4/152], ZINB loss:0.4099, NB loss:4.7506\n",
      "Pretrain epoch [5/152], ZINB loss:0.3965, NB loss:4.7577\n",
      "Pretrain epoch [6/152], ZINB loss:0.3936, NB loss:4.7934\n",
      "Pretrain epoch [7/152], ZINB loss:0.3911, NB loss:4.8185\n",
      "Pretrain epoch [8/152], ZINB loss:0.4076, NB loss:4.7628\n",
      "Pretrain epoch [9/152], ZINB loss:0.3906, NB loss:4.8723\n",
      "Pretrain epoch [10/152], ZINB loss:0.3896, NB loss:4.8481\n",
      "Pretrain epoch [11/152], ZINB loss:0.3726, NB loss:4.7547\n",
      "Pretrain epoch [12/152], ZINB loss:0.3971, NB loss:4.7656\n",
      "Pretrain epoch [13/152], ZINB loss:0.3952, NB loss:4.7973\n",
      "Pretrain epoch [14/152], ZINB loss:0.4042, NB loss:4.8294\n",
      "Pretrain epoch [15/152], ZINB loss:0.4043, NB loss:4.8663\n",
      "Pretrain epoch [16/152], ZINB loss:0.3975, NB loss:4.7995\n",
      "Pretrain epoch [17/152], ZINB loss:0.3970, NB loss:4.8005\n",
      "Pretrain epoch [18/152], ZINB loss:0.3883, NB loss:4.8418\n",
      "Pretrain epoch [19/152], ZINB loss:0.4009, NB loss:4.7596\n",
      "Pretrain epoch [20/152], ZINB loss:0.3817, NB loss:4.7928\n",
      "Pretrain epoch [21/152], ZINB loss:0.3851, NB loss:4.8449\n",
      "Pretrain epoch [22/152], ZINB loss:0.3813, NB loss:4.8370\n",
      "Pretrain epoch [23/152], ZINB loss:0.3939, NB loss:4.8831\n",
      "Pretrain epoch [24/152], ZINB loss:0.3910, NB loss:4.8339\n",
      "Pretrain epoch [25/152], ZINB loss:0.3785, NB loss:4.7763\n",
      "Pretrain epoch [26/152], ZINB loss:0.3729, NB loss:4.7471\n",
      "Pretrain epoch [27/152], ZINB loss:0.3508, NB loss:5.0047\n",
      "Pretrain epoch [1/153], ZINB loss:0.4036, NB loss:4.7955\n",
      "Pretrain epoch [2/153], ZINB loss:0.3818, NB loss:4.7672\n",
      "Pretrain epoch [3/153], ZINB loss:0.3895, NB loss:4.7448\n",
      "Pretrain epoch [4/153], ZINB loss:0.3969, NB loss:4.7732\n",
      "Pretrain epoch [5/153], ZINB loss:0.4061, NB loss:4.8103\n",
      "Pretrain epoch [6/153], ZINB loss:0.3940, NB loss:4.8415\n",
      "Pretrain epoch [7/153], ZINB loss:0.3890, NB loss:4.7655\n",
      "Pretrain epoch [8/153], ZINB loss:0.3861, NB loss:4.8347\n",
      "Pretrain epoch [9/153], ZINB loss:0.3700, NB loss:4.8476\n",
      "Pretrain epoch [10/153], ZINB loss:0.3890, NB loss:4.8134\n",
      "Pretrain epoch [11/153], ZINB loss:0.3965, NB loss:4.8173\n",
      "Pretrain epoch [12/153], ZINB loss:0.3694, NB loss:4.8003\n",
      "Pretrain epoch [13/153], ZINB loss:0.3835, NB loss:4.8447\n",
      "Pretrain epoch [14/153], ZINB loss:0.3947, NB loss:4.7929\n",
      "Pretrain epoch [15/153], ZINB loss:0.4215, NB loss:4.7707\n",
      "Pretrain epoch [16/153], ZINB loss:0.3891, NB loss:4.7842\n",
      "Pretrain epoch [17/153], ZINB loss:0.3914, NB loss:4.7724\n",
      "Pretrain epoch [18/153], ZINB loss:0.4028, NB loss:4.8428\n",
      "Pretrain epoch [19/153], ZINB loss:0.3843, NB loss:4.8269\n",
      "Pretrain epoch [20/153], ZINB loss:0.4025, NB loss:4.7745\n",
      "Pretrain epoch [21/153], ZINB loss:0.3980, NB loss:4.7819\n",
      "Pretrain epoch [22/153], ZINB loss:0.3948, NB loss:4.8536\n",
      "Pretrain epoch [23/153], ZINB loss:0.3955, NB loss:4.8057\n",
      "Pretrain epoch [24/153], ZINB loss:0.3988, NB loss:4.7860\n",
      "Pretrain epoch [25/153], ZINB loss:0.3982, NB loss:4.8208\n",
      "Pretrain epoch [26/153], ZINB loss:0.3760, NB loss:4.7966\n",
      "Pretrain epoch [27/153], ZINB loss:0.3658, NB loss:4.3670\n",
      "Pretrain epoch [1/154], ZINB loss:0.3899, NB loss:4.8102\n",
      "Pretrain epoch [2/154], ZINB loss:0.3752, NB loss:4.7964\n",
      "Pretrain epoch [3/154], ZINB loss:0.3941, NB loss:4.8093\n",
      "Pretrain epoch [4/154], ZINB loss:0.3870, NB loss:4.8450\n",
      "Pretrain epoch [5/154], ZINB loss:0.3752, NB loss:4.8301\n",
      "Pretrain epoch [6/154], ZINB loss:0.3982, NB loss:4.7939\n",
      "Pretrain epoch [7/154], ZINB loss:0.4027, NB loss:4.8171\n",
      "Pretrain epoch [8/154], ZINB loss:0.3937, NB loss:4.8027\n",
      "Pretrain epoch [9/154], ZINB loss:0.3859, NB loss:4.7470\n",
      "Pretrain epoch [10/154], ZINB loss:0.4034, NB loss:4.8128\n",
      "Pretrain epoch [11/154], ZINB loss:0.3862, NB loss:4.8279\n",
      "Pretrain epoch [12/154], ZINB loss:0.3774, NB loss:4.8431\n",
      "Pretrain epoch [13/154], ZINB loss:0.3920, NB loss:4.8376\n",
      "Pretrain epoch [14/154], ZINB loss:0.3976, NB loss:4.7703\n",
      "Pretrain epoch [15/154], ZINB loss:0.4052, NB loss:4.8029\n",
      "Pretrain epoch [16/154], ZINB loss:0.3808, NB loss:4.7385\n",
      "Pretrain epoch [17/154], ZINB loss:0.4172, NB loss:4.7942\n",
      "Pretrain epoch [18/154], ZINB loss:0.3881, NB loss:4.7882\n",
      "Pretrain epoch [19/154], ZINB loss:0.3845, NB loss:4.7907\n",
      "Pretrain epoch [20/154], ZINB loss:0.4128, NB loss:4.6979\n",
      "Pretrain epoch [21/154], ZINB loss:0.4014, NB loss:4.8416\n",
      "Pretrain epoch [22/154], ZINB loss:0.3699, NB loss:4.7699\n",
      "Pretrain epoch [23/154], ZINB loss:0.3844, NB loss:4.7841\n",
      "Pretrain epoch [24/154], ZINB loss:0.3948, NB loss:4.7484\n",
      "Pretrain epoch [25/154], ZINB loss:0.3955, NB loss:4.7773\n",
      "Pretrain epoch [26/154], ZINB loss:0.4060, NB loss:4.8810\n",
      "Pretrain epoch [27/154], ZINB loss:0.3397, NB loss:4.8344\n",
      "Pretrain epoch [1/155], ZINB loss:0.3953, NB loss:4.8202\n",
      "Pretrain epoch [2/155], ZINB loss:0.4076, NB loss:4.7863\n",
      "Pretrain epoch [3/155], ZINB loss:0.4027, NB loss:4.8572\n",
      "Pretrain epoch [4/155], ZINB loss:0.3815, NB loss:4.8328\n",
      "Pretrain epoch [5/155], ZINB loss:0.3912, NB loss:4.7842\n",
      "Pretrain epoch [6/155], ZINB loss:0.3842, NB loss:4.7539\n",
      "Pretrain epoch [7/155], ZINB loss:0.3971, NB loss:4.7750\n",
      "Pretrain epoch [8/155], ZINB loss:0.3876, NB loss:4.7778\n",
      "Pretrain epoch [9/155], ZINB loss:0.3926, NB loss:4.8066\n",
      "Pretrain epoch [10/155], ZINB loss:0.4161, NB loss:4.8160\n",
      "Pretrain epoch [11/155], ZINB loss:0.3849, NB loss:4.7826\n",
      "Pretrain epoch [12/155], ZINB loss:0.3835, NB loss:4.7491\n",
      "Pretrain epoch [13/155], ZINB loss:0.3826, NB loss:4.7313\n",
      "Pretrain epoch [14/155], ZINB loss:0.3849, NB loss:4.7956\n",
      "Pretrain epoch [15/155], ZINB loss:0.3855, NB loss:4.7626\n",
      "Pretrain epoch [16/155], ZINB loss:0.4039, NB loss:4.8073\n",
      "Pretrain epoch [17/155], ZINB loss:0.4002, NB loss:4.8229\n",
      "Pretrain epoch [18/155], ZINB loss:0.4063, NB loss:4.8083\n",
      "Pretrain epoch [19/155], ZINB loss:0.4027, NB loss:4.7594\n",
      "Pretrain epoch [20/155], ZINB loss:0.4045, NB loss:4.8171\n",
      "Pretrain epoch [21/155], ZINB loss:0.3708, NB loss:4.8153\n",
      "Pretrain epoch [22/155], ZINB loss:0.3847, NB loss:4.7626\n",
      "Pretrain epoch [23/155], ZINB loss:0.3821, NB loss:4.7547\n",
      "Pretrain epoch [24/155], ZINB loss:0.3900, NB loss:4.8410\n",
      "Pretrain epoch [25/155], ZINB loss:0.3887, NB loss:4.8530\n",
      "Pretrain epoch [26/155], ZINB loss:0.3864, NB loss:4.8067\n",
      "Pretrain epoch [27/155], ZINB loss:0.3655, NB loss:4.4484\n",
      "Pretrain epoch [1/156], ZINB loss:0.3678, NB loss:4.7315\n",
      "Pretrain epoch [2/156], ZINB loss:0.3977, NB loss:4.7559\n",
      "Pretrain epoch [3/156], ZINB loss:0.4007, NB loss:4.7721\n",
      "Pretrain epoch [4/156], ZINB loss:0.3925, NB loss:4.7970\n",
      "Pretrain epoch [5/156], ZINB loss:0.3875, NB loss:4.7820\n",
      "Pretrain epoch [6/156], ZINB loss:0.3940, NB loss:4.7366\n",
      "Pretrain epoch [7/156], ZINB loss:0.4087, NB loss:4.8157\n",
      "Pretrain epoch [8/156], ZINB loss:0.3896, NB loss:4.8394\n",
      "Pretrain epoch [9/156], ZINB loss:0.3917, NB loss:4.8316\n",
      "Pretrain epoch [10/156], ZINB loss:0.3937, NB loss:4.7797\n",
      "Pretrain epoch [11/156], ZINB loss:0.3976, NB loss:4.7606\n",
      "Pretrain epoch [12/156], ZINB loss:0.3797, NB loss:4.7960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [13/156], ZINB loss:0.3620, NB loss:4.7526\n",
      "Pretrain epoch [14/156], ZINB loss:0.4160, NB loss:4.7926\n",
      "Pretrain epoch [15/156], ZINB loss:0.3945, NB loss:4.7854\n",
      "Pretrain epoch [16/156], ZINB loss:0.3955, NB loss:4.7830\n",
      "Pretrain epoch [17/156], ZINB loss:0.3931, NB loss:4.8698\n",
      "Pretrain epoch [18/156], ZINB loss:0.4013, NB loss:4.7657\n",
      "Pretrain epoch [19/156], ZINB loss:0.3963, NB loss:4.7959\n",
      "Pretrain epoch [20/156], ZINB loss:0.3846, NB loss:4.7395\n",
      "Pretrain epoch [21/156], ZINB loss:0.3877, NB loss:4.8436\n",
      "Pretrain epoch [22/156], ZINB loss:0.3834, NB loss:4.8296\n",
      "Pretrain epoch [23/156], ZINB loss:0.4024, NB loss:4.7820\n",
      "Pretrain epoch [24/156], ZINB loss:0.3878, NB loss:4.8428\n",
      "Pretrain epoch [25/156], ZINB loss:0.3925, NB loss:4.7789\n",
      "Pretrain epoch [26/156], ZINB loss:0.3894, NB loss:4.8216\n",
      "Pretrain epoch [27/156], ZINB loss:0.5412, NB loss:4.9798\n",
      "Pretrain epoch [1/157], ZINB loss:0.3893, NB loss:4.7223\n",
      "Pretrain epoch [2/157], ZINB loss:0.3759, NB loss:4.7594\n",
      "Pretrain epoch [3/157], ZINB loss:0.4028, NB loss:4.7210\n",
      "Pretrain epoch [4/157], ZINB loss:0.3724, NB loss:4.7302\n",
      "Pretrain epoch [5/157], ZINB loss:0.3914, NB loss:4.8670\n",
      "Pretrain epoch [6/157], ZINB loss:0.3838, NB loss:4.7667\n",
      "Pretrain epoch [7/157], ZINB loss:0.4100, NB loss:4.8083\n",
      "Pretrain epoch [8/157], ZINB loss:0.3970, NB loss:4.8170\n",
      "Pretrain epoch [9/157], ZINB loss:0.4098, NB loss:4.7610\n",
      "Pretrain epoch [10/157], ZINB loss:0.4123, NB loss:4.8452\n",
      "Pretrain epoch [11/157], ZINB loss:0.3842, NB loss:4.7244\n",
      "Pretrain epoch [12/157], ZINB loss:0.3803, NB loss:4.8179\n",
      "Pretrain epoch [13/157], ZINB loss:0.3930, NB loss:4.7393\n",
      "Pretrain epoch [14/157], ZINB loss:0.3884, NB loss:4.8412\n",
      "Pretrain epoch [15/157], ZINB loss:0.3877, NB loss:4.8404\n",
      "Pretrain epoch [16/157], ZINB loss:0.3987, NB loss:4.7973\n",
      "Pretrain epoch [17/157], ZINB loss:0.4038, NB loss:4.7387\n",
      "Pretrain epoch [18/157], ZINB loss:0.3925, NB loss:4.8313\n",
      "Pretrain epoch [19/157], ZINB loss:0.4028, NB loss:4.7860\n",
      "Pretrain epoch [20/157], ZINB loss:0.3884, NB loss:4.8125\n",
      "Pretrain epoch [21/157], ZINB loss:0.3875, NB loss:4.8515\n",
      "Pretrain epoch [22/157], ZINB loss:0.3987, NB loss:4.7746\n",
      "Pretrain epoch [23/157], ZINB loss:0.4033, NB loss:4.7866\n",
      "Pretrain epoch [24/157], ZINB loss:0.3836, NB loss:4.7510\n",
      "Pretrain epoch [25/157], ZINB loss:0.3735, NB loss:4.8277\n",
      "Pretrain epoch [26/157], ZINB loss:0.3928, NB loss:4.8057\n",
      "Pretrain epoch [27/157], ZINB loss:0.3811, NB loss:5.8073\n",
      "Pretrain epoch [1/158], ZINB loss:0.4000, NB loss:4.7276\n",
      "Pretrain epoch [2/158], ZINB loss:0.3961, NB loss:4.8414\n",
      "Pretrain epoch [3/158], ZINB loss:0.3897, NB loss:4.7889\n",
      "Pretrain epoch [4/158], ZINB loss:0.3732, NB loss:4.7322\n",
      "Pretrain epoch [5/158], ZINB loss:0.4177, NB loss:4.8341\n",
      "Pretrain epoch [6/158], ZINB loss:0.3874, NB loss:4.8143\n",
      "Pretrain epoch [7/158], ZINB loss:0.3768, NB loss:4.8564\n",
      "Pretrain epoch [8/158], ZINB loss:0.3802, NB loss:4.8126\n",
      "Pretrain epoch [9/158], ZINB loss:0.3907, NB loss:4.7689\n",
      "Pretrain epoch [10/158], ZINB loss:0.3833, NB loss:4.8660\n",
      "Pretrain epoch [11/158], ZINB loss:0.3939, NB loss:4.7765\n",
      "Pretrain epoch [12/158], ZINB loss:0.3989, NB loss:4.7996\n",
      "Pretrain epoch [13/158], ZINB loss:0.3858, NB loss:4.7311\n",
      "Pretrain epoch [14/158], ZINB loss:0.3906, NB loss:4.8217\n",
      "Pretrain epoch [15/158], ZINB loss:0.3986, NB loss:4.7757\n",
      "Pretrain epoch [16/158], ZINB loss:0.4097, NB loss:4.8038\n",
      "Pretrain epoch [17/158], ZINB loss:0.3809, NB loss:4.7872\n",
      "Pretrain epoch [18/158], ZINB loss:0.3767, NB loss:4.7878\n",
      "Pretrain epoch [19/158], ZINB loss:0.3908, NB loss:4.7662\n",
      "Pretrain epoch [20/158], ZINB loss:0.3917, NB loss:4.8192\n",
      "Pretrain epoch [21/158], ZINB loss:0.4133, NB loss:4.8351\n",
      "Pretrain epoch [22/158], ZINB loss:0.4027, NB loss:4.7133\n",
      "Pretrain epoch [23/158], ZINB loss:0.4008, NB loss:4.7435\n",
      "Pretrain epoch [24/158], ZINB loss:0.3904, NB loss:4.7595\n",
      "Pretrain epoch [25/158], ZINB loss:0.3856, NB loss:4.7639\n",
      "Pretrain epoch [26/158], ZINB loss:0.3897, NB loss:4.7329\n",
      "Pretrain epoch [27/158], ZINB loss:0.3077, NB loss:4.9522\n",
      "Pretrain epoch [1/159], ZINB loss:0.4044, NB loss:4.7785\n",
      "Pretrain epoch [2/159], ZINB loss:0.3684, NB loss:4.7693\n",
      "Pretrain epoch [3/159], ZINB loss:0.3807, NB loss:4.7904\n",
      "Pretrain epoch [4/159], ZINB loss:0.4074, NB loss:4.8486\n",
      "Pretrain epoch [5/159], ZINB loss:0.3938, NB loss:4.7441\n",
      "Pretrain epoch [6/159], ZINB loss:0.3987, NB loss:4.7694\n",
      "Pretrain epoch [7/159], ZINB loss:0.3851, NB loss:4.8019\n",
      "Pretrain epoch [8/159], ZINB loss:0.3787, NB loss:4.8069\n",
      "Pretrain epoch [9/159], ZINB loss:0.3880, NB loss:4.7792\n",
      "Pretrain epoch [10/159], ZINB loss:0.3875, NB loss:4.8667\n",
      "Pretrain epoch [11/159], ZINB loss:0.3797, NB loss:4.7591\n",
      "Pretrain epoch [12/159], ZINB loss:0.3969, NB loss:4.7599\n",
      "Pretrain epoch [13/159], ZINB loss:0.3957, NB loss:4.7720\n",
      "Pretrain epoch [14/159], ZINB loss:0.3910, NB loss:4.7894\n",
      "Pretrain epoch [15/159], ZINB loss:0.4006, NB loss:4.7456\n",
      "Pretrain epoch [16/159], ZINB loss:0.4036, NB loss:4.7827\n",
      "Pretrain epoch [17/159], ZINB loss:0.3996, NB loss:4.7628\n",
      "Pretrain epoch [18/159], ZINB loss:0.4004, NB loss:4.7839\n",
      "Pretrain epoch [19/159], ZINB loss:0.3972, NB loss:4.7767\n",
      "Pretrain epoch [20/159], ZINB loss:0.3818, NB loss:4.7675\n",
      "Pretrain epoch [21/159], ZINB loss:0.3947, NB loss:4.7650\n",
      "Pretrain epoch [22/159], ZINB loss:0.3860, NB loss:4.7317\n",
      "Pretrain epoch [23/159], ZINB loss:0.3958, NB loss:4.8245\n",
      "Pretrain epoch [24/159], ZINB loss:0.3826, NB loss:4.7931\n",
      "Pretrain epoch [25/159], ZINB loss:0.4053, NB loss:4.8036\n",
      "Pretrain epoch [26/159], ZINB loss:0.3801, NB loss:4.7954\n",
      "Pretrain epoch [27/159], ZINB loss:0.3682, NB loss:4.6871\n",
      "Pretrain epoch [1/160], ZINB loss:0.3924, NB loss:4.7884\n",
      "Pretrain epoch [2/160], ZINB loss:0.3880, NB loss:4.8324\n",
      "Pretrain epoch [3/160], ZINB loss:0.3772, NB loss:4.8452\n",
      "Pretrain epoch [4/160], ZINB loss:0.3816, NB loss:4.8459\n",
      "Pretrain epoch [5/160], ZINB loss:0.3956, NB loss:4.7645\n",
      "Pretrain epoch [6/160], ZINB loss:0.3767, NB loss:4.7752\n",
      "Pretrain epoch [7/160], ZINB loss:0.4075, NB loss:4.7265\n",
      "Pretrain epoch [8/160], ZINB loss:0.4007, NB loss:4.7161\n",
      "Pretrain epoch [9/160], ZINB loss:0.4035, NB loss:4.8285\n",
      "Pretrain epoch [10/160], ZINB loss:0.3802, NB loss:4.7878\n",
      "Pretrain epoch [11/160], ZINB loss:0.4140, NB loss:4.7365\n",
      "Pretrain epoch [12/160], ZINB loss:0.3839, NB loss:4.7996\n",
      "Pretrain epoch [13/160], ZINB loss:0.3808, NB loss:4.7702\n",
      "Pretrain epoch [14/160], ZINB loss:0.4072, NB loss:4.7533\n",
      "Pretrain epoch [15/160], ZINB loss:0.3897, NB loss:4.7745\n",
      "Pretrain epoch [16/160], ZINB loss:0.3913, NB loss:4.7447\n",
      "Pretrain epoch [17/160], ZINB loss:0.3955, NB loss:4.7500\n",
      "Pretrain epoch [18/160], ZINB loss:0.4046, NB loss:4.7494\n",
      "Pretrain epoch [19/160], ZINB loss:0.3883, NB loss:4.8045\n",
      "Pretrain epoch [20/160], ZINB loss:0.3817, NB loss:4.8165\n",
      "Pretrain epoch [21/160], ZINB loss:0.3901, NB loss:4.8158\n",
      "Pretrain epoch [22/160], ZINB loss:0.3973, NB loss:4.7984\n",
      "Pretrain epoch [23/160], ZINB loss:0.3739, NB loss:4.7608\n",
      "Pretrain epoch [24/160], ZINB loss:0.3940, NB loss:4.7779\n",
      "Pretrain epoch [25/160], ZINB loss:0.3885, NB loss:4.7677\n",
      "Pretrain epoch [26/160], ZINB loss:0.4083, NB loss:4.7448\n",
      "Pretrain epoch [27/160], ZINB loss:0.4059, NB loss:4.8759\n",
      "Pretrain epoch [1/161], ZINB loss:0.3949, NB loss:4.7663\n",
      "Pretrain epoch [2/161], ZINB loss:0.3847, NB loss:4.7639\n",
      "Pretrain epoch [3/161], ZINB loss:0.3817, NB loss:4.7777\n",
      "Pretrain epoch [4/161], ZINB loss:0.4016, NB loss:4.8180\n",
      "Pretrain epoch [5/161], ZINB loss:0.3854, NB loss:4.6870\n",
      "Pretrain epoch [6/161], ZINB loss:0.3807, NB loss:4.7832\n",
      "Pretrain epoch [7/161], ZINB loss:0.3924, NB loss:4.7493\n",
      "Pretrain epoch [8/161], ZINB loss:0.3909, NB loss:4.7708\n",
      "Pretrain epoch [9/161], ZINB loss:0.3777, NB loss:4.7535\n",
      "Pretrain epoch [10/161], ZINB loss:0.3899, NB loss:4.7934\n",
      "Pretrain epoch [11/161], ZINB loss:0.4232, NB loss:4.8008\n",
      "Pretrain epoch [12/161], ZINB loss:0.3874, NB loss:4.8003\n",
      "Pretrain epoch [13/161], ZINB loss:0.3789, NB loss:4.8066\n",
      "Pretrain epoch [14/161], ZINB loss:0.3968, NB loss:4.7835\n",
      "Pretrain epoch [15/161], ZINB loss:0.4105, NB loss:4.8379\n",
      "Pretrain epoch [16/161], ZINB loss:0.4009, NB loss:4.6466\n",
      "Pretrain epoch [17/161], ZINB loss:0.3856, NB loss:4.7615\n",
      "Pretrain epoch [18/161], ZINB loss:0.3927, NB loss:4.7849\n",
      "Pretrain epoch [19/161], ZINB loss:0.3835, NB loss:4.8031\n",
      "Pretrain epoch [20/161], ZINB loss:0.3965, NB loss:4.7368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [21/161], ZINB loss:0.4031, NB loss:4.7938\n",
      "Pretrain epoch [22/161], ZINB loss:0.3667, NB loss:4.7624\n",
      "Pretrain epoch [23/161], ZINB loss:0.3973, NB loss:4.8309\n",
      "Pretrain epoch [24/161], ZINB loss:0.4108, NB loss:4.8044\n",
      "Pretrain epoch [25/161], ZINB loss:0.3893, NB loss:4.7358\n",
      "Pretrain epoch [26/161], ZINB loss:0.3887, NB loss:4.8219\n",
      "Pretrain epoch [27/161], ZINB loss:0.3045, NB loss:5.5488\n",
      "Pretrain epoch [1/162], ZINB loss:0.3865, NB loss:4.7543\n",
      "Pretrain epoch [2/162], ZINB loss:0.3853, NB loss:4.7733\n",
      "Pretrain epoch [3/162], ZINB loss:0.3918, NB loss:4.8372\n",
      "Pretrain epoch [4/162], ZINB loss:0.3798, NB loss:4.7677\n",
      "Pretrain epoch [5/162], ZINB loss:0.3932, NB loss:4.7974\n",
      "Pretrain epoch [6/162], ZINB loss:0.3970, NB loss:4.7454\n",
      "Pretrain epoch [7/162], ZINB loss:0.3996, NB loss:4.7952\n",
      "Pretrain epoch [8/162], ZINB loss:0.3741, NB loss:4.8025\n",
      "Pretrain epoch [9/162], ZINB loss:0.3892, NB loss:4.7203\n",
      "Pretrain epoch [10/162], ZINB loss:0.3989, NB loss:4.7650\n",
      "Pretrain epoch [11/162], ZINB loss:0.3890, NB loss:4.7872\n",
      "Pretrain epoch [12/162], ZINB loss:0.3769, NB loss:4.7789\n",
      "Pretrain epoch [13/162], ZINB loss:0.3971, NB loss:4.8309\n",
      "Pretrain epoch [14/162], ZINB loss:0.3851, NB loss:4.7093\n",
      "Pretrain epoch [15/162], ZINB loss:0.3930, NB loss:4.7517\n",
      "Pretrain epoch [16/162], ZINB loss:0.3937, NB loss:4.8486\n",
      "Pretrain epoch [17/162], ZINB loss:0.3972, NB loss:4.8020\n",
      "Pretrain epoch [18/162], ZINB loss:0.3935, NB loss:4.7761\n",
      "Pretrain epoch [19/162], ZINB loss:0.3758, NB loss:4.8288\n",
      "Pretrain epoch [20/162], ZINB loss:0.4060, NB loss:4.7598\n",
      "Pretrain epoch [21/162], ZINB loss:0.4181, NB loss:4.7450\n",
      "Pretrain epoch [22/162], ZINB loss:0.4086, NB loss:4.7627\n",
      "Pretrain epoch [23/162], ZINB loss:0.3758, NB loss:4.7197\n",
      "Pretrain epoch [24/162], ZINB loss:0.3784, NB loss:4.7390\n",
      "Pretrain epoch [25/162], ZINB loss:0.3991, NB loss:4.8050\n",
      "Pretrain epoch [26/162], ZINB loss:0.4021, NB loss:4.7086\n",
      "Pretrain epoch [27/162], ZINB loss:0.3162, NB loss:4.9522\n",
      "Pretrain epoch [1/163], ZINB loss:0.3766, NB loss:4.6914\n",
      "Pretrain epoch [2/163], ZINB loss:0.3919, NB loss:4.7006\n",
      "Pretrain epoch [3/163], ZINB loss:0.4020, NB loss:4.7311\n",
      "Pretrain epoch [4/163], ZINB loss:0.3951, NB loss:4.8271\n",
      "Pretrain epoch [5/163], ZINB loss:0.3770, NB loss:4.7780\n",
      "Pretrain epoch [6/163], ZINB loss:0.3821, NB loss:4.7372\n",
      "Pretrain epoch [7/163], ZINB loss:0.3990, NB loss:4.7640\n",
      "Pretrain epoch [8/163], ZINB loss:0.3936, NB loss:4.7441\n",
      "Pretrain epoch [9/163], ZINB loss:0.3974, NB loss:4.8491\n",
      "Pretrain epoch [10/163], ZINB loss:0.3859, NB loss:4.8410\n",
      "Pretrain epoch [11/163], ZINB loss:0.4024, NB loss:4.7468\n",
      "Pretrain epoch [12/163], ZINB loss:0.4047, NB loss:4.7592\n",
      "Pretrain epoch [13/163], ZINB loss:0.4049, NB loss:4.8113\n",
      "Pretrain epoch [14/163], ZINB loss:0.3980, NB loss:4.7666\n",
      "Pretrain epoch [15/163], ZINB loss:0.4068, NB loss:4.7862\n",
      "Pretrain epoch [16/163], ZINB loss:0.3830, NB loss:4.7944\n",
      "Pretrain epoch [17/163], ZINB loss:0.3893, NB loss:4.8104\n",
      "Pretrain epoch [18/163], ZINB loss:0.3956, NB loss:4.7213\n",
      "Pretrain epoch [19/163], ZINB loss:0.3710, NB loss:4.7854\n",
      "Pretrain epoch [20/163], ZINB loss:0.3754, NB loss:4.8013\n",
      "Pretrain epoch [21/163], ZINB loss:0.3889, NB loss:4.7613\n",
      "Pretrain epoch [22/163], ZINB loss:0.3861, NB loss:4.7530\n",
      "Pretrain epoch [23/163], ZINB loss:0.3962, NB loss:4.8079\n",
      "Pretrain epoch [24/163], ZINB loss:0.3918, NB loss:4.7483\n",
      "Pretrain epoch [25/163], ZINB loss:0.3958, NB loss:4.7573\n",
      "Pretrain epoch [26/163], ZINB loss:0.3951, NB loss:4.7559\n",
      "Pretrain epoch [27/163], ZINB loss:0.5163, NB loss:4.6696\n",
      "Pretrain epoch [1/164], ZINB loss:0.3988, NB loss:4.7509\n",
      "Pretrain epoch [2/164], ZINB loss:0.3662, NB loss:4.7497\n",
      "Pretrain epoch [3/164], ZINB loss:0.3917, NB loss:4.7798\n",
      "Pretrain epoch [4/164], ZINB loss:0.3736, NB loss:4.8159\n",
      "Pretrain epoch [5/164], ZINB loss:0.3976, NB loss:4.7741\n",
      "Pretrain epoch [6/164], ZINB loss:0.3969, NB loss:4.7783\n",
      "Pretrain epoch [7/164], ZINB loss:0.3937, NB loss:4.7258\n",
      "Pretrain epoch [8/164], ZINB loss:0.3938, NB loss:4.8346\n",
      "Pretrain epoch [9/164], ZINB loss:0.4078, NB loss:4.8401\n",
      "Pretrain epoch [10/164], ZINB loss:0.3838, NB loss:4.7299\n",
      "Pretrain epoch [11/164], ZINB loss:0.3958, NB loss:4.7469\n",
      "Pretrain epoch [12/164], ZINB loss:0.4019, NB loss:4.8489\n",
      "Pretrain epoch [13/164], ZINB loss:0.4030, NB loss:4.7393\n",
      "Pretrain epoch [14/164], ZINB loss:0.3746, NB loss:4.7474\n",
      "Pretrain epoch [15/164], ZINB loss:0.3815, NB loss:4.7772\n",
      "Pretrain epoch [16/164], ZINB loss:0.3861, NB loss:4.7016\n",
      "Pretrain epoch [17/164], ZINB loss:0.4033, NB loss:4.8006\n",
      "Pretrain epoch [18/164], ZINB loss:0.4351, NB loss:4.7340\n",
      "Pretrain epoch [19/164], ZINB loss:0.3995, NB loss:4.7242\n",
      "Pretrain epoch [20/164], ZINB loss:0.3994, NB loss:4.7643\n",
      "Pretrain epoch [21/164], ZINB loss:0.3929, NB loss:4.8167\n",
      "Pretrain epoch [22/164], ZINB loss:0.3897, NB loss:4.7056\n",
      "Pretrain epoch [23/164], ZINB loss:0.3817, NB loss:4.8041\n",
      "Pretrain epoch [24/164], ZINB loss:0.3834, NB loss:4.7337\n",
      "Pretrain epoch [25/164], ZINB loss:0.3797, NB loss:4.7734\n",
      "Pretrain epoch [26/164], ZINB loss:0.3812, NB loss:4.7724\n",
      "Pretrain epoch [27/164], ZINB loss:0.4435, NB loss:4.5759\n",
      "Pretrain epoch [1/165], ZINB loss:0.3954, NB loss:4.7864\n",
      "Pretrain epoch [2/165], ZINB loss:0.4016, NB loss:4.8191\n",
      "Pretrain epoch [3/165], ZINB loss:0.3892, NB loss:4.7792\n",
      "Pretrain epoch [4/165], ZINB loss:0.3914, NB loss:4.7785\n",
      "Pretrain epoch [5/165], ZINB loss:0.3972, NB loss:4.7650\n",
      "Pretrain epoch [6/165], ZINB loss:0.3831, NB loss:4.7379\n",
      "Pretrain epoch [7/165], ZINB loss:0.3838, NB loss:4.7721\n",
      "Pretrain epoch [8/165], ZINB loss:0.3934, NB loss:4.7339\n",
      "Pretrain epoch [9/165], ZINB loss:0.3886, NB loss:4.6837\n",
      "Pretrain epoch [10/165], ZINB loss:0.4071, NB loss:4.7128\n",
      "Pretrain epoch [11/165], ZINB loss:0.4048, NB loss:4.7555\n",
      "Pretrain epoch [12/165], ZINB loss:0.4054, NB loss:4.7358\n",
      "Pretrain epoch [13/165], ZINB loss:0.3969, NB loss:4.7974\n",
      "Pretrain epoch [14/165], ZINB loss:0.3905, NB loss:4.7242\n",
      "Pretrain epoch [15/165], ZINB loss:0.3809, NB loss:4.7613\n",
      "Pretrain epoch [16/165], ZINB loss:0.3898, NB loss:4.7650\n",
      "Pretrain epoch [17/165], ZINB loss:0.4075, NB loss:4.8009\n",
      "Pretrain epoch [18/165], ZINB loss:0.3925, NB loss:4.8222\n",
      "Pretrain epoch [19/165], ZINB loss:0.3918, NB loss:4.7025\n",
      "Pretrain epoch [20/165], ZINB loss:0.3687, NB loss:4.7548\n",
      "Pretrain epoch [21/165], ZINB loss:0.3898, NB loss:4.7704\n",
      "Pretrain epoch [22/165], ZINB loss:0.3955, NB loss:4.8296\n",
      "Pretrain epoch [23/165], ZINB loss:0.3810, NB loss:4.8070\n",
      "Pretrain epoch [24/165], ZINB loss:0.3922, NB loss:4.8306\n",
      "Pretrain epoch [25/165], ZINB loss:0.3878, NB loss:4.7840\n",
      "Pretrain epoch [26/165], ZINB loss:0.3942, NB loss:4.6736\n",
      "Pretrain epoch [27/165], ZINB loss:0.3556, NB loss:4.5432\n",
      "Pretrain epoch [1/166], ZINB loss:0.3991, NB loss:4.7725\n",
      "Pretrain epoch [2/166], ZINB loss:0.3956, NB loss:4.6799\n",
      "Pretrain epoch [3/166], ZINB loss:0.4024, NB loss:4.7651\n",
      "Pretrain epoch [4/166], ZINB loss:0.3873, NB loss:4.7769\n",
      "Pretrain epoch [5/166], ZINB loss:0.3882, NB loss:4.7768\n",
      "Pretrain epoch [6/166], ZINB loss:0.3778, NB loss:4.7911\n",
      "Pretrain epoch [7/166], ZINB loss:0.3853, NB loss:4.8085\n",
      "Pretrain epoch [8/166], ZINB loss:0.3895, NB loss:4.7128\n",
      "Pretrain epoch [9/166], ZINB loss:0.4132, NB loss:4.7541\n",
      "Pretrain epoch [10/166], ZINB loss:0.3844, NB loss:4.7184\n",
      "Pretrain epoch [11/166], ZINB loss:0.4151, NB loss:4.7862\n",
      "Pretrain epoch [12/166], ZINB loss:0.3822, NB loss:4.7558\n",
      "Pretrain epoch [13/166], ZINB loss:0.3857, NB loss:4.7824\n",
      "Pretrain epoch [14/166], ZINB loss:0.3892, NB loss:4.7746\n",
      "Pretrain epoch [15/166], ZINB loss:0.3896, NB loss:4.7865\n",
      "Pretrain epoch [16/166], ZINB loss:0.4001, NB loss:4.7289\n",
      "Pretrain epoch [17/166], ZINB loss:0.3751, NB loss:4.7901\n",
      "Pretrain epoch [18/166], ZINB loss:0.3936, NB loss:4.7820\n",
      "Pretrain epoch [19/166], ZINB loss:0.3870, NB loss:4.7783\n",
      "Pretrain epoch [20/166], ZINB loss:0.4009, NB loss:4.8119\n",
      "Pretrain epoch [21/166], ZINB loss:0.4128, NB loss:4.7897\n",
      "Pretrain epoch [22/166], ZINB loss:0.3846, NB loss:4.7238\n",
      "Pretrain epoch [23/166], ZINB loss:0.3990, NB loss:4.6950\n",
      "Pretrain epoch [24/166], ZINB loss:0.3804, NB loss:4.7557\n",
      "Pretrain epoch [25/166], ZINB loss:0.3769, NB loss:4.7071\n",
      "Pretrain epoch [26/166], ZINB loss:0.3984, NB loss:4.7999\n",
      "Pretrain epoch [27/166], ZINB loss:0.2508, NB loss:4.8856\n",
      "Pretrain epoch [1/167], ZINB loss:0.3947, NB loss:4.7725\n",
      "Pretrain epoch [2/167], ZINB loss:0.3859, NB loss:4.8023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [3/167], ZINB loss:0.3934, NB loss:4.8052\n",
      "Pretrain epoch [4/167], ZINB loss:0.3844, NB loss:4.7333\n",
      "Pretrain epoch [5/167], ZINB loss:0.4156, NB loss:4.7661\n",
      "Pretrain epoch [6/167], ZINB loss:0.3891, NB loss:4.7811\n",
      "Pretrain epoch [7/167], ZINB loss:0.4080, NB loss:4.6921\n",
      "Pretrain epoch [8/167], ZINB loss:0.3841, NB loss:4.7254\n",
      "Pretrain epoch [9/167], ZINB loss:0.3838, NB loss:4.7641\n",
      "Pretrain epoch [10/167], ZINB loss:0.3744, NB loss:4.6375\n",
      "Pretrain epoch [11/167], ZINB loss:0.4071, NB loss:4.7622\n",
      "Pretrain epoch [12/167], ZINB loss:0.3803, NB loss:4.7285\n",
      "Pretrain epoch [13/167], ZINB loss:0.3934, NB loss:4.7521\n",
      "Pretrain epoch [14/167], ZINB loss:0.4033, NB loss:4.7681\n",
      "Pretrain epoch [15/167], ZINB loss:0.3873, NB loss:4.7738\n",
      "Pretrain epoch [16/167], ZINB loss:0.3847, NB loss:4.8189\n",
      "Pretrain epoch [17/167], ZINB loss:0.3941, NB loss:4.8005\n",
      "Pretrain epoch [18/167], ZINB loss:0.3986, NB loss:4.7483\n",
      "Pretrain epoch [19/167], ZINB loss:0.3996, NB loss:4.7218\n",
      "Pretrain epoch [20/167], ZINB loss:0.4089, NB loss:4.7587\n",
      "Pretrain epoch [21/167], ZINB loss:0.3692, NB loss:4.7541\n",
      "Pretrain epoch [22/167], ZINB loss:0.3812, NB loss:4.7570\n",
      "Pretrain epoch [23/167], ZINB loss:0.3854, NB loss:4.7828\n",
      "Pretrain epoch [24/167], ZINB loss:0.3785, NB loss:4.7083\n",
      "Pretrain epoch [25/167], ZINB loss:0.4084, NB loss:4.8224\n",
      "Pretrain epoch [26/167], ZINB loss:0.3788, NB loss:4.7949\n",
      "Pretrain epoch [27/167], ZINB loss:0.3251, NB loss:5.0189\n",
      "Pretrain epoch [1/168], ZINB loss:0.4002, NB loss:4.7713\n",
      "Pretrain epoch [2/168], ZINB loss:0.3940, NB loss:4.7475\n",
      "Pretrain epoch [3/168], ZINB loss:0.3877, NB loss:4.7530\n",
      "Pretrain epoch [4/168], ZINB loss:0.3814, NB loss:4.7075\n",
      "Pretrain epoch [5/168], ZINB loss:0.3903, NB loss:4.7478\n",
      "Pretrain epoch [6/168], ZINB loss:0.3804, NB loss:4.7854\n",
      "Pretrain epoch [7/168], ZINB loss:0.3890, NB loss:4.7167\n",
      "Pretrain epoch [8/168], ZINB loss:0.3813, NB loss:4.7776\n",
      "Pretrain epoch [9/168], ZINB loss:0.3869, NB loss:4.7033\n",
      "Pretrain epoch [10/168], ZINB loss:0.3899, NB loss:4.7102\n",
      "Pretrain epoch [11/168], ZINB loss:0.3879, NB loss:4.6816\n",
      "Pretrain epoch [12/168], ZINB loss:0.3917, NB loss:4.7251\n",
      "Pretrain epoch [13/168], ZINB loss:0.3784, NB loss:4.8300\n",
      "Pretrain epoch [14/168], ZINB loss:0.3976, NB loss:4.8110\n",
      "Pretrain epoch [15/168], ZINB loss:0.3970, NB loss:4.7863\n",
      "Pretrain epoch [16/168], ZINB loss:0.3897, NB loss:4.7663\n",
      "Pretrain epoch [17/168], ZINB loss:0.3928, NB loss:4.7686\n",
      "Pretrain epoch [18/168], ZINB loss:0.3915, NB loss:4.7694\n",
      "Pretrain epoch [19/168], ZINB loss:0.4074, NB loss:4.7931\n",
      "Pretrain epoch [20/168], ZINB loss:0.3836, NB loss:4.7203\n",
      "Pretrain epoch [21/168], ZINB loss:0.4110, NB loss:4.7597\n",
      "Pretrain epoch [22/168], ZINB loss:0.3940, NB loss:4.7965\n",
      "Pretrain epoch [23/168], ZINB loss:0.4044, NB loss:4.7903\n",
      "Pretrain epoch [24/168], ZINB loss:0.3665, NB loss:4.7763\n",
      "Pretrain epoch [25/168], ZINB loss:0.3911, NB loss:4.7375\n",
      "Pretrain epoch [26/168], ZINB loss:0.3987, NB loss:4.7461\n",
      "Pretrain epoch [27/168], ZINB loss:0.4777, NB loss:4.4108\n",
      "Pretrain epoch [1/169], ZINB loss:0.3958, NB loss:4.7865\n",
      "Pretrain epoch [2/169], ZINB loss:0.3921, NB loss:4.7885\n",
      "Pretrain epoch [3/169], ZINB loss:0.4007, NB loss:4.7571\n",
      "Pretrain epoch [4/169], ZINB loss:0.3826, NB loss:4.8308\n",
      "Pretrain epoch [5/169], ZINB loss:0.3863, NB loss:4.7694\n",
      "Pretrain epoch [6/169], ZINB loss:0.3891, NB loss:4.7588\n",
      "Pretrain epoch [7/169], ZINB loss:0.3912, NB loss:4.7149\n",
      "Pretrain epoch [8/169], ZINB loss:0.3641, NB loss:4.7714\n",
      "Pretrain epoch [9/169], ZINB loss:0.3798, NB loss:4.7460\n",
      "Pretrain epoch [10/169], ZINB loss:0.3937, NB loss:4.7758\n",
      "Pretrain epoch [11/169], ZINB loss:0.3775, NB loss:4.6911\n",
      "Pretrain epoch [12/169], ZINB loss:0.3935, NB loss:4.7040\n",
      "Pretrain epoch [13/169], ZINB loss:0.3900, NB loss:4.7627\n",
      "Pretrain epoch [14/169], ZINB loss:0.3971, NB loss:4.7643\n",
      "Pretrain epoch [15/169], ZINB loss:0.3929, NB loss:4.7568\n",
      "Pretrain epoch [16/169], ZINB loss:0.4039, NB loss:4.7479\n",
      "Pretrain epoch [17/169], ZINB loss:0.4039, NB loss:4.7370\n",
      "Pretrain epoch [18/169], ZINB loss:0.3766, NB loss:4.7841\n",
      "Pretrain epoch [19/169], ZINB loss:0.3925, NB loss:4.7877\n",
      "Pretrain epoch [20/169], ZINB loss:0.3900, NB loss:4.7330\n",
      "Pretrain epoch [21/169], ZINB loss:0.3812, NB loss:4.7954\n",
      "Pretrain epoch [22/169], ZINB loss:0.3957, NB loss:4.7225\n",
      "Pretrain epoch [23/169], ZINB loss:0.4086, NB loss:4.7355\n",
      "Pretrain epoch [24/169], ZINB loss:0.4095, NB loss:4.7411\n",
      "Pretrain epoch [25/169], ZINB loss:0.3852, NB loss:4.7597\n",
      "Pretrain epoch [26/169], ZINB loss:0.4022, NB loss:4.6722\n",
      "Pretrain epoch [27/169], ZINB loss:0.8223, NB loss:5.0993\n",
      "Pretrain epoch [1/170], ZINB loss:0.3869, NB loss:4.7493\n",
      "Pretrain epoch [2/170], ZINB loss:0.3901, NB loss:4.7758\n",
      "Pretrain epoch [3/170], ZINB loss:0.4121, NB loss:4.8099\n",
      "Pretrain epoch [4/170], ZINB loss:0.3936, NB loss:4.8175\n",
      "Pretrain epoch [5/170], ZINB loss:0.4077, NB loss:4.7083\n",
      "Pretrain epoch [6/170], ZINB loss:0.3811, NB loss:4.7574\n",
      "Pretrain epoch [7/170], ZINB loss:0.3912, NB loss:4.7952\n",
      "Pretrain epoch [8/170], ZINB loss:0.3994, NB loss:4.7478\n",
      "Pretrain epoch [9/170], ZINB loss:0.4198, NB loss:4.7181\n",
      "Pretrain epoch [10/170], ZINB loss:0.3964, NB loss:4.8346\n",
      "Pretrain epoch [11/170], ZINB loss:0.3854, NB loss:4.7668\n",
      "Pretrain epoch [12/170], ZINB loss:0.3858, NB loss:4.7555\n",
      "Pretrain epoch [13/170], ZINB loss:0.4100, NB loss:4.7050\n",
      "Pretrain epoch [14/170], ZINB loss:0.3906, NB loss:4.6854\n",
      "Pretrain epoch [15/170], ZINB loss:0.3787, NB loss:4.7877\n",
      "Pretrain epoch [16/170], ZINB loss:0.3889, NB loss:4.7004\n",
      "Pretrain epoch [17/170], ZINB loss:0.3897, NB loss:4.6923\n",
      "Pretrain epoch [18/170], ZINB loss:0.4029, NB loss:4.6979\n",
      "Pretrain epoch [19/170], ZINB loss:0.4092, NB loss:4.7711\n",
      "Pretrain epoch [20/170], ZINB loss:0.3886, NB loss:4.8031\n",
      "Pretrain epoch [21/170], ZINB loss:0.3875, NB loss:4.7269\n",
      "Pretrain epoch [22/170], ZINB loss:0.3729, NB loss:4.7482\n",
      "Pretrain epoch [23/170], ZINB loss:0.3989, NB loss:4.7573\n",
      "Pretrain epoch [24/170], ZINB loss:0.4002, NB loss:4.7413\n",
      "Pretrain epoch [25/170], ZINB loss:0.4206, NB loss:4.7717\n",
      "Pretrain epoch [26/170], ZINB loss:0.3995, NB loss:4.7584\n",
      "Pretrain epoch [27/170], ZINB loss:0.4184, NB loss:4.6250\n",
      "Pretrain epoch [1/171], ZINB loss:0.3914, NB loss:4.7357\n",
      "Pretrain epoch [2/171], ZINB loss:0.3767, NB loss:4.7987\n",
      "Pretrain epoch [3/171], ZINB loss:0.4345, NB loss:4.7822\n",
      "Pretrain epoch [4/171], ZINB loss:0.3799, NB loss:4.7819\n",
      "Pretrain epoch [5/171], ZINB loss:0.4087, NB loss:4.6883\n",
      "Pretrain epoch [6/171], ZINB loss:0.3972, NB loss:4.7595\n",
      "Pretrain epoch [7/171], ZINB loss:0.3928, NB loss:4.7338\n",
      "Pretrain epoch [8/171], ZINB loss:0.3822, NB loss:4.7581\n",
      "Pretrain epoch [9/171], ZINB loss:0.4021, NB loss:4.7415\n",
      "Pretrain epoch [10/171], ZINB loss:0.4063, NB loss:4.7227\n",
      "Pretrain epoch [11/171], ZINB loss:0.3823, NB loss:4.7757\n",
      "Pretrain epoch [12/171], ZINB loss:0.3954, NB loss:4.7987\n",
      "Pretrain epoch [13/171], ZINB loss:0.4171, NB loss:4.7978\n",
      "Pretrain epoch [14/171], ZINB loss:0.3954, NB loss:4.6588\n",
      "Pretrain epoch [15/171], ZINB loss:0.3861, NB loss:4.7774\n",
      "Pretrain epoch [16/171], ZINB loss:0.3874, NB loss:4.7362\n",
      "Pretrain epoch [17/171], ZINB loss:0.4008, NB loss:4.6550\n",
      "Pretrain epoch [18/171], ZINB loss:0.3768, NB loss:4.7672\n",
      "Pretrain epoch [19/171], ZINB loss:0.3884, NB loss:4.6931\n",
      "Pretrain epoch [20/171], ZINB loss:0.4072, NB loss:4.7838\n",
      "Pretrain epoch [21/171], ZINB loss:0.3943, NB loss:4.7797\n",
      "Pretrain epoch [22/171], ZINB loss:0.3893, NB loss:4.7220\n",
      "Pretrain epoch [23/171], ZINB loss:0.4016, NB loss:4.7449\n",
      "Pretrain epoch [24/171], ZINB loss:0.4051, NB loss:4.7061\n",
      "Pretrain epoch [25/171], ZINB loss:0.4040, NB loss:4.7812\n",
      "Pretrain epoch [26/171], ZINB loss:0.3741, NB loss:4.7858\n",
      "Pretrain epoch [27/171], ZINB loss:0.3744, NB loss:5.0544\n",
      "Pretrain epoch [1/172], ZINB loss:0.3884, NB loss:4.7679\n",
      "Pretrain epoch [2/172], ZINB loss:0.3905, NB loss:4.6867\n",
      "Pretrain epoch [3/172], ZINB loss:0.3787, NB loss:4.7404\n",
      "Pretrain epoch [4/172], ZINB loss:0.4028, NB loss:4.7667\n",
      "Pretrain epoch [5/172], ZINB loss:0.3979, NB loss:4.6984\n",
      "Pretrain epoch [6/172], ZINB loss:0.4144, NB loss:4.8080\n",
      "Pretrain epoch [7/172], ZINB loss:0.3790, NB loss:4.7258\n",
      "Pretrain epoch [8/172], ZINB loss:0.4097, NB loss:4.7120\n",
      "Pretrain epoch [9/172], ZINB loss:0.4018, NB loss:4.7382\n",
      "Pretrain epoch [10/172], ZINB loss:0.3990, NB loss:4.7391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [11/172], ZINB loss:0.4031, NB loss:4.7454\n",
      "Pretrain epoch [12/172], ZINB loss:0.3831, NB loss:4.7786\n",
      "Pretrain epoch [13/172], ZINB loss:0.3789, NB loss:4.8126\n",
      "Pretrain epoch [14/172], ZINB loss:0.4097, NB loss:4.7136\n",
      "Pretrain epoch [15/172], ZINB loss:0.3683, NB loss:4.6700\n",
      "Pretrain epoch [16/172], ZINB loss:0.4015, NB loss:4.7979\n",
      "Pretrain epoch [17/172], ZINB loss:0.4156, NB loss:4.7270\n",
      "Pretrain epoch [18/172], ZINB loss:0.3711, NB loss:4.7395\n",
      "Pretrain epoch [19/172], ZINB loss:0.3801, NB loss:4.7380\n",
      "Pretrain epoch [20/172], ZINB loss:0.4050, NB loss:4.8236\n",
      "Pretrain epoch [21/172], ZINB loss:0.3869, NB loss:4.7083\n",
      "Pretrain epoch [22/172], ZINB loss:0.3851, NB loss:4.8141\n",
      "Pretrain epoch [23/172], ZINB loss:0.3792, NB loss:4.6990\n",
      "Pretrain epoch [24/172], ZINB loss:0.4028, NB loss:4.7784\n",
      "Pretrain epoch [25/172], ZINB loss:0.3991, NB loss:4.7772\n",
      "Pretrain epoch [26/172], ZINB loss:0.4002, NB loss:4.6948\n",
      "Pretrain epoch [27/172], ZINB loss:0.3338, NB loss:4.7519\n",
      "Pretrain epoch [1/173], ZINB loss:0.3869, NB loss:4.8567\n",
      "Pretrain epoch [2/173], ZINB loss:0.4180, NB loss:4.7105\n",
      "Pretrain epoch [3/173], ZINB loss:0.3997, NB loss:4.7859\n",
      "Pretrain epoch [4/173], ZINB loss:0.3705, NB loss:4.7265\n",
      "Pretrain epoch [5/173], ZINB loss:0.3979, NB loss:4.7716\n",
      "Pretrain epoch [6/173], ZINB loss:0.4083, NB loss:4.7432\n",
      "Pretrain epoch [7/173], ZINB loss:0.3843, NB loss:4.7406\n",
      "Pretrain epoch [8/173], ZINB loss:0.3754, NB loss:4.7558\n",
      "Pretrain epoch [9/173], ZINB loss:0.3942, NB loss:4.7395\n",
      "Pretrain epoch [10/173], ZINB loss:0.3912, NB loss:4.7486\n",
      "Pretrain epoch [11/173], ZINB loss:0.3883, NB loss:4.7649\n",
      "Pretrain epoch [12/173], ZINB loss:0.4112, NB loss:4.7540\n",
      "Pretrain epoch [13/173], ZINB loss:0.3854, NB loss:4.7568\n",
      "Pretrain epoch [14/173], ZINB loss:0.3846, NB loss:4.7516\n",
      "Pretrain epoch [15/173], ZINB loss:0.3918, NB loss:4.6247\n",
      "Pretrain epoch [16/173], ZINB loss:0.4015, NB loss:4.7350\n",
      "Pretrain epoch [17/173], ZINB loss:0.3889, NB loss:4.7909\n",
      "Pretrain epoch [18/173], ZINB loss:0.3995, NB loss:4.6904\n",
      "Pretrain epoch [19/173], ZINB loss:0.3748, NB loss:4.6802\n",
      "Pretrain epoch [20/173], ZINB loss:0.3909, NB loss:4.7161\n",
      "Pretrain epoch [21/173], ZINB loss:0.3914, NB loss:4.8055\n",
      "Pretrain epoch [22/173], ZINB loss:0.3941, NB loss:4.8285\n",
      "Pretrain epoch [23/173], ZINB loss:0.3795, NB loss:4.7143\n",
      "Pretrain epoch [24/173], ZINB loss:0.3888, NB loss:4.7573\n",
      "Pretrain epoch [25/173], ZINB loss:0.4055, NB loss:4.7066\n",
      "Pretrain epoch [26/173], ZINB loss:0.3980, NB loss:4.6958\n",
      "Pretrain epoch [27/173], ZINB loss:0.4493, NB loss:4.1579\n",
      "Pretrain epoch [1/174], ZINB loss:0.4052, NB loss:4.6806\n",
      "Pretrain epoch [2/174], ZINB loss:0.3758, NB loss:4.6931\n",
      "Pretrain epoch [3/174], ZINB loss:0.4040, NB loss:4.6872\n",
      "Pretrain epoch [4/174], ZINB loss:0.4078, NB loss:4.8184\n",
      "Pretrain epoch [5/174], ZINB loss:0.4057, NB loss:4.6845\n",
      "Pretrain epoch [6/174], ZINB loss:0.3841, NB loss:4.7598\n",
      "Pretrain epoch [7/174], ZINB loss:0.3993, NB loss:4.6731\n",
      "Pretrain epoch [8/174], ZINB loss:0.3965, NB loss:4.7373\n",
      "Pretrain epoch [9/174], ZINB loss:0.3798, NB loss:4.7414\n",
      "Pretrain epoch [10/174], ZINB loss:0.3779, NB loss:4.7558\n",
      "Pretrain epoch [11/174], ZINB loss:0.4299, NB loss:4.6540\n",
      "Pretrain epoch [12/174], ZINB loss:0.3990, NB loss:4.7137\n",
      "Pretrain epoch [13/174], ZINB loss:0.3805, NB loss:4.7690\n",
      "Pretrain epoch [14/174], ZINB loss:0.3968, NB loss:4.7939\n",
      "Pretrain epoch [15/174], ZINB loss:0.3800, NB loss:4.7628\n",
      "Pretrain epoch [16/174], ZINB loss:0.3850, NB loss:4.7812\n",
      "Pretrain epoch [17/174], ZINB loss:0.4059, NB loss:4.7805\n",
      "Pretrain epoch [18/174], ZINB loss:0.3842, NB loss:4.7502\n",
      "Pretrain epoch [19/174], ZINB loss:0.3800, NB loss:4.7337\n",
      "Pretrain epoch [20/174], ZINB loss:0.3837, NB loss:4.7563\n",
      "Pretrain epoch [21/174], ZINB loss:0.3995, NB loss:4.7582\n",
      "Pretrain epoch [22/174], ZINB loss:0.3805, NB loss:4.7935\n",
      "Pretrain epoch [23/174], ZINB loss:0.3916, NB loss:4.7439\n",
      "Pretrain epoch [24/174], ZINB loss:0.3817, NB loss:4.7296\n",
      "Pretrain epoch [25/174], ZINB loss:0.3962, NB loss:4.8125\n",
      "Pretrain epoch [26/174], ZINB loss:0.3923, NB loss:4.7186\n",
      "Pretrain epoch [27/174], ZINB loss:0.3598, NB loss:4.4868\n",
      "Pretrain epoch [1/175], ZINB loss:0.3817, NB loss:4.6948\n",
      "Pretrain epoch [2/175], ZINB loss:0.4220, NB loss:4.7366\n",
      "Pretrain epoch [3/175], ZINB loss:0.3761, NB loss:4.7733\n",
      "Pretrain epoch [4/175], ZINB loss:0.3879, NB loss:4.7095\n",
      "Pretrain epoch [5/175], ZINB loss:0.4013, NB loss:4.6812\n",
      "Pretrain epoch [6/175], ZINB loss:0.3824, NB loss:4.7952\n",
      "Pretrain epoch [7/175], ZINB loss:0.4000, NB loss:4.7432\n",
      "Pretrain epoch [8/175], ZINB loss:0.3740, NB loss:4.7801\n",
      "Pretrain epoch [9/175], ZINB loss:0.3917, NB loss:4.7786\n",
      "Pretrain epoch [10/175], ZINB loss:0.3957, NB loss:4.6899\n",
      "Pretrain epoch [11/175], ZINB loss:0.3860, NB loss:4.7619\n",
      "Pretrain epoch [12/175], ZINB loss:0.4126, NB loss:4.7757\n",
      "Pretrain epoch [13/175], ZINB loss:0.3840, NB loss:4.7474\n",
      "Pretrain epoch [14/175], ZINB loss:0.3967, NB loss:4.7308\n",
      "Pretrain epoch [15/175], ZINB loss:0.3884, NB loss:4.7269\n",
      "Pretrain epoch [16/175], ZINB loss:0.3733, NB loss:4.7669\n",
      "Pretrain epoch [17/175], ZINB loss:0.4020, NB loss:4.6575\n",
      "Pretrain epoch [18/175], ZINB loss:0.3920, NB loss:4.7149\n",
      "Pretrain epoch [19/175], ZINB loss:0.3875, NB loss:4.7198\n",
      "Pretrain epoch [20/175], ZINB loss:0.3971, NB loss:4.7574\n",
      "Pretrain epoch [21/175], ZINB loss:0.3934, NB loss:4.7721\n",
      "Pretrain epoch [22/175], ZINB loss:0.3802, NB loss:4.7470\n",
      "Pretrain epoch [23/175], ZINB loss:0.3856, NB loss:4.8059\n",
      "Pretrain epoch [24/175], ZINB loss:0.3906, NB loss:4.6775\n",
      "Pretrain epoch [25/175], ZINB loss:0.4106, NB loss:4.7351\n",
      "Pretrain epoch [26/175], ZINB loss:0.4058, NB loss:4.7335\n",
      "Pretrain epoch [27/175], ZINB loss:0.4916, NB loss:5.4094\n",
      "Pretrain epoch [1/176], ZINB loss:0.3821, NB loss:4.6331\n",
      "Pretrain epoch [2/176], ZINB loss:0.3848, NB loss:4.7116\n",
      "Pretrain epoch [3/176], ZINB loss:0.4043, NB loss:4.7004\n",
      "Pretrain epoch [4/176], ZINB loss:0.3933, NB loss:4.8081\n",
      "Pretrain epoch [5/176], ZINB loss:0.4073, NB loss:4.7216\n",
      "Pretrain epoch [6/176], ZINB loss:0.3794, NB loss:4.7771\n",
      "Pretrain epoch [7/176], ZINB loss:0.3841, NB loss:4.7994\n",
      "Pretrain epoch [8/176], ZINB loss:0.3940, NB loss:4.7306\n",
      "Pretrain epoch [9/176], ZINB loss:0.4000, NB loss:4.7194\n",
      "Pretrain epoch [10/176], ZINB loss:0.3843, NB loss:4.7740\n",
      "Pretrain epoch [11/176], ZINB loss:0.3973, NB loss:4.7113\n",
      "Pretrain epoch [12/176], ZINB loss:0.3883, NB loss:4.7692\n",
      "Pretrain epoch [13/176], ZINB loss:0.4062, NB loss:4.7222\n",
      "Pretrain epoch [14/176], ZINB loss:0.3897, NB loss:4.7360\n",
      "Pretrain epoch [15/176], ZINB loss:0.4123, NB loss:4.7053\n",
      "Pretrain epoch [16/176], ZINB loss:0.3798, NB loss:4.7306\n",
      "Pretrain epoch [17/176], ZINB loss:0.3943, NB loss:4.6886\n",
      "Pretrain epoch [18/176], ZINB loss:0.4042, NB loss:4.7295\n",
      "Pretrain epoch [19/176], ZINB loss:0.3907, NB loss:4.7755\n",
      "Pretrain epoch [20/176], ZINB loss:0.3972, NB loss:4.7363\n",
      "Pretrain epoch [21/176], ZINB loss:0.3786, NB loss:4.7198\n",
      "Pretrain epoch [22/176], ZINB loss:0.3910, NB loss:4.7619\n",
      "Pretrain epoch [23/176], ZINB loss:0.3989, NB loss:4.7450\n",
      "Pretrain epoch [24/176], ZINB loss:0.3936, NB loss:4.7538\n",
      "Pretrain epoch [25/176], ZINB loss:0.3925, NB loss:4.7469\n",
      "Pretrain epoch [26/176], ZINB loss:0.3928, NB loss:4.7602\n",
      "Pretrain epoch [27/176], ZINB loss:0.4469, NB loss:4.5611\n",
      "Pretrain epoch [1/177], ZINB loss:0.4048, NB loss:4.7751\n",
      "Pretrain epoch [2/177], ZINB loss:0.3924, NB loss:4.7150\n",
      "Pretrain epoch [3/177], ZINB loss:0.3773, NB loss:4.6989\n",
      "Pretrain epoch [4/177], ZINB loss:0.3843, NB loss:4.7502\n",
      "Pretrain epoch [5/177], ZINB loss:0.3818, NB loss:4.7296\n",
      "Pretrain epoch [6/177], ZINB loss:0.4027, NB loss:4.7483\n",
      "Pretrain epoch [7/177], ZINB loss:0.3825, NB loss:4.7140\n",
      "Pretrain epoch [8/177], ZINB loss:0.3905, NB loss:4.6869\n",
      "Pretrain epoch [9/177], ZINB loss:0.4162, NB loss:4.7335\n",
      "Pretrain epoch [10/177], ZINB loss:0.4044, NB loss:4.7353\n",
      "Pretrain epoch [11/177], ZINB loss:0.3987, NB loss:4.7540\n",
      "Pretrain epoch [12/177], ZINB loss:0.3935, NB loss:4.7178\n",
      "Pretrain epoch [13/177], ZINB loss:0.3813, NB loss:4.7427\n",
      "Pretrain epoch [14/177], ZINB loss:0.3824, NB loss:4.7716\n",
      "Pretrain epoch [15/177], ZINB loss:0.4023, NB loss:4.7103\n",
      "Pretrain epoch [16/177], ZINB loss:0.4085, NB loss:4.6973\n",
      "Pretrain epoch [17/177], ZINB loss:0.3860, NB loss:4.7438\n",
      "Pretrain epoch [18/177], ZINB loss:0.3828, NB loss:4.6895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [19/177], ZINB loss:0.3916, NB loss:4.7168\n",
      "Pretrain epoch [20/177], ZINB loss:0.3851, NB loss:4.8151\n",
      "Pretrain epoch [21/177], ZINB loss:0.3883, NB loss:4.7339\n",
      "Pretrain epoch [22/177], ZINB loss:0.3828, NB loss:4.6933\n",
      "Pretrain epoch [23/177], ZINB loss:0.3972, NB loss:4.6666\n",
      "Pretrain epoch [24/177], ZINB loss:0.3900, NB loss:4.7490\n",
      "Pretrain epoch [25/177], ZINB loss:0.4164, NB loss:4.7992\n",
      "Pretrain epoch [26/177], ZINB loss:0.3954, NB loss:4.8114\n",
      "Pretrain epoch [27/177], ZINB loss:0.3367, NB loss:4.5113\n",
      "Pretrain epoch [1/178], ZINB loss:0.4040, NB loss:4.7522\n",
      "Pretrain epoch [2/178], ZINB loss:0.3857, NB loss:4.7238\n",
      "Pretrain epoch [3/178], ZINB loss:0.3856, NB loss:4.7214\n",
      "Pretrain epoch [4/178], ZINB loss:0.3763, NB loss:4.7227\n",
      "Pretrain epoch [5/178], ZINB loss:0.3859, NB loss:4.7857\n",
      "Pretrain epoch [6/178], ZINB loss:0.3893, NB loss:4.6648\n",
      "Pretrain epoch [7/178], ZINB loss:0.3941, NB loss:4.7152\n",
      "Pretrain epoch [8/178], ZINB loss:0.3839, NB loss:4.7081\n",
      "Pretrain epoch [9/178], ZINB loss:0.3871, NB loss:4.7539\n",
      "Pretrain epoch [10/178], ZINB loss:0.3851, NB loss:4.6961\n",
      "Pretrain epoch [11/178], ZINB loss:0.3907, NB loss:4.7654\n",
      "Pretrain epoch [12/178], ZINB loss:0.3927, NB loss:4.7581\n",
      "Pretrain epoch [13/178], ZINB loss:0.3909, NB loss:4.6986\n",
      "Pretrain epoch [14/178], ZINB loss:0.3811, NB loss:4.7462\n",
      "Pretrain epoch [15/178], ZINB loss:0.4014, NB loss:4.6924\n",
      "Pretrain epoch [16/178], ZINB loss:0.3958, NB loss:4.7055\n",
      "Pretrain epoch [17/178], ZINB loss:0.3957, NB loss:4.7801\n",
      "Pretrain epoch [18/178], ZINB loss:0.3959, NB loss:4.7341\n",
      "Pretrain epoch [19/178], ZINB loss:0.4218, NB loss:4.7111\n",
      "Pretrain epoch [20/178], ZINB loss:0.3881, NB loss:4.7631\n",
      "Pretrain epoch [21/178], ZINB loss:0.3790, NB loss:4.8047\n",
      "Pretrain epoch [22/178], ZINB loss:0.4049, NB loss:4.6850\n",
      "Pretrain epoch [23/178], ZINB loss:0.3938, NB loss:4.7736\n",
      "Pretrain epoch [24/178], ZINB loss:0.4029, NB loss:4.7443\n",
      "Pretrain epoch [25/178], ZINB loss:0.3904, NB loss:4.7397\n",
      "Pretrain epoch [26/178], ZINB loss:0.3864, NB loss:4.6820\n",
      "Pretrain epoch [27/178], ZINB loss:0.4482, NB loss:4.9964\n",
      "Pretrain epoch [1/179], ZINB loss:0.3822, NB loss:4.7841\n",
      "Pretrain epoch [2/179], ZINB loss:0.3912, NB loss:4.7416\n",
      "Pretrain epoch [3/179], ZINB loss:0.3923, NB loss:4.6829\n",
      "Pretrain epoch [4/179], ZINB loss:0.4143, NB loss:4.6631\n",
      "Pretrain epoch [5/179], ZINB loss:0.3778, NB loss:4.7890\n",
      "Pretrain epoch [6/179], ZINB loss:0.3848, NB loss:4.7108\n",
      "Pretrain epoch [7/179], ZINB loss:0.3916, NB loss:4.7054\n",
      "Pretrain epoch [8/179], ZINB loss:0.3822, NB loss:4.7422\n",
      "Pretrain epoch [9/179], ZINB loss:0.3892, NB loss:4.7743\n",
      "Pretrain epoch [10/179], ZINB loss:0.3806, NB loss:4.7297\n",
      "Pretrain epoch [11/179], ZINB loss:0.3962, NB loss:4.7464\n",
      "Pretrain epoch [12/179], ZINB loss:0.3773, NB loss:4.7345\n",
      "Pretrain epoch [13/179], ZINB loss:0.3957, NB loss:4.6745\n",
      "Pretrain epoch [14/179], ZINB loss:0.3912, NB loss:4.7089\n",
      "Pretrain epoch [15/179], ZINB loss:0.4008, NB loss:4.7368\n",
      "Pretrain epoch [16/179], ZINB loss:0.3884, NB loss:4.6901\n",
      "Pretrain epoch [17/179], ZINB loss:0.3914, NB loss:4.6725\n",
      "Pretrain epoch [18/179], ZINB loss:0.3954, NB loss:4.7516\n",
      "Pretrain epoch [19/179], ZINB loss:0.4020, NB loss:4.7602\n",
      "Pretrain epoch [20/179], ZINB loss:0.3938, NB loss:4.6992\n",
      "Pretrain epoch [21/179], ZINB loss:0.3892, NB loss:4.7356\n",
      "Pretrain epoch [22/179], ZINB loss:0.4148, NB loss:4.7371\n",
      "Pretrain epoch [23/179], ZINB loss:0.3830, NB loss:4.8052\n",
      "Pretrain epoch [24/179], ZINB loss:0.3935, NB loss:4.7279\n",
      "Pretrain epoch [25/179], ZINB loss:0.4100, NB loss:4.7440\n",
      "Pretrain epoch [26/179], ZINB loss:0.3955, NB loss:4.7801\n",
      "Pretrain epoch [27/179], ZINB loss:0.4106, NB loss:5.0072\n",
      "Pretrain epoch [1/180], ZINB loss:0.3770, NB loss:4.7696\n",
      "Pretrain epoch [2/180], ZINB loss:0.4013, NB loss:4.6847\n",
      "Pretrain epoch [3/180], ZINB loss:0.3950, NB loss:4.7974\n",
      "Pretrain epoch [4/180], ZINB loss:0.4084, NB loss:4.6699\n",
      "Pretrain epoch [5/180], ZINB loss:0.3980, NB loss:4.7371\n",
      "Pretrain epoch [6/180], ZINB loss:0.3849, NB loss:4.7207\n",
      "Pretrain epoch [7/180], ZINB loss:0.3774, NB loss:4.7171\n",
      "Pretrain epoch [8/180], ZINB loss:0.3910, NB loss:4.7973\n",
      "Pretrain epoch [9/180], ZINB loss:0.3933, NB loss:4.6894\n",
      "Pretrain epoch [10/180], ZINB loss:0.3814, NB loss:4.6999\n",
      "Pretrain epoch [11/180], ZINB loss:0.4014, NB loss:4.7568\n",
      "Pretrain epoch [12/180], ZINB loss:0.4074, NB loss:4.7866\n",
      "Pretrain epoch [13/180], ZINB loss:0.3816, NB loss:4.7101\n",
      "Pretrain epoch [14/180], ZINB loss:0.4018, NB loss:4.7037\n",
      "Pretrain epoch [15/180], ZINB loss:0.3810, NB loss:4.7091\n",
      "Pretrain epoch [16/180], ZINB loss:0.3575, NB loss:4.6663\n",
      "Pretrain epoch [17/180], ZINB loss:0.4176, NB loss:4.7376\n",
      "Pretrain epoch [18/180], ZINB loss:0.3836, NB loss:4.7567\n",
      "Pretrain epoch [19/180], ZINB loss:0.3962, NB loss:4.6230\n",
      "Pretrain epoch [20/180], ZINB loss:0.4039, NB loss:4.7016\n",
      "Pretrain epoch [21/180], ZINB loss:0.3999, NB loss:4.7482\n",
      "Pretrain epoch [22/180], ZINB loss:0.3983, NB loss:4.7660\n",
      "Pretrain epoch [23/180], ZINB loss:0.3819, NB loss:4.7406\n",
      "Pretrain epoch [24/180], ZINB loss:0.3985, NB loss:4.7469\n",
      "Pretrain epoch [25/180], ZINB loss:0.4031, NB loss:4.7808\n",
      "Pretrain epoch [26/180], ZINB loss:0.3850, NB loss:4.7165\n",
      "Pretrain epoch [27/180], ZINB loss:0.3035, NB loss:4.9846\n",
      "Pretrain epoch [1/181], ZINB loss:0.3972, NB loss:4.6815\n",
      "Pretrain epoch [2/181], ZINB loss:0.3907, NB loss:4.7903\n",
      "Pretrain epoch [3/181], ZINB loss:0.4147, NB loss:4.7799\n",
      "Pretrain epoch [4/181], ZINB loss:0.3950, NB loss:4.6997\n",
      "Pretrain epoch [5/181], ZINB loss:0.3910, NB loss:4.7088\n",
      "Pretrain epoch [6/181], ZINB loss:0.3671, NB loss:4.7493\n",
      "Pretrain epoch [7/181], ZINB loss:0.3910, NB loss:4.7191\n",
      "Pretrain epoch [8/181], ZINB loss:0.3977, NB loss:4.7575\n",
      "Pretrain epoch [9/181], ZINB loss:0.4180, NB loss:4.6537\n",
      "Pretrain epoch [10/181], ZINB loss:0.3845, NB loss:4.7070\n",
      "Pretrain epoch [11/181], ZINB loss:0.3725, NB loss:4.7278\n",
      "Pretrain epoch [12/181], ZINB loss:0.4054, NB loss:4.7096\n",
      "Pretrain epoch [13/181], ZINB loss:0.3721, NB loss:4.7787\n",
      "Pretrain epoch [14/181], ZINB loss:0.3985, NB loss:4.7193\n",
      "Pretrain epoch [15/181], ZINB loss:0.3732, NB loss:4.7567\n",
      "Pretrain epoch [16/181], ZINB loss:0.3716, NB loss:4.7808\n",
      "Pretrain epoch [17/181], ZINB loss:0.3819, NB loss:4.7383\n",
      "Pretrain epoch [18/181], ZINB loss:0.4032, NB loss:4.6357\n",
      "Pretrain epoch [19/181], ZINB loss:0.3937, NB loss:4.7111\n",
      "Pretrain epoch [20/181], ZINB loss:0.4097, NB loss:4.7440\n",
      "Pretrain epoch [21/181], ZINB loss:0.3917, NB loss:4.6705\n",
      "Pretrain epoch [22/181], ZINB loss:0.3977, NB loss:4.7374\n",
      "Pretrain epoch [23/181], ZINB loss:0.3932, NB loss:4.7025\n",
      "Pretrain epoch [24/181], ZINB loss:0.4116, NB loss:4.7905\n",
      "Pretrain epoch [25/181], ZINB loss:0.3745, NB loss:4.7058\n",
      "Pretrain epoch [26/181], ZINB loss:0.3882, NB loss:4.7158\n",
      "Pretrain epoch [27/181], ZINB loss:0.5210, NB loss:4.5215\n",
      "Pretrain epoch [1/182], ZINB loss:0.3817, NB loss:4.7341\n",
      "Pretrain epoch [2/182], ZINB loss:0.3958, NB loss:4.6993\n",
      "Pretrain epoch [3/182], ZINB loss:0.4024, NB loss:4.6860\n",
      "Pretrain epoch [4/182], ZINB loss:0.3903, NB loss:4.7075\n",
      "Pretrain epoch [5/182], ZINB loss:0.3923, NB loss:4.7215\n",
      "Pretrain epoch [6/182], ZINB loss:0.4107, NB loss:4.7975\n",
      "Pretrain epoch [7/182], ZINB loss:0.3863, NB loss:4.7262\n",
      "Pretrain epoch [8/182], ZINB loss:0.4087, NB loss:4.6851\n",
      "Pretrain epoch [9/182], ZINB loss:0.3721, NB loss:4.7705\n",
      "Pretrain epoch [10/182], ZINB loss:0.3946, NB loss:4.6674\n",
      "Pretrain epoch [11/182], ZINB loss:0.4072, NB loss:4.7327\n",
      "Pretrain epoch [12/182], ZINB loss:0.3812, NB loss:4.7059\n",
      "Pretrain epoch [13/182], ZINB loss:0.3957, NB loss:4.6718\n",
      "Pretrain epoch [14/182], ZINB loss:0.3904, NB loss:4.7194\n",
      "Pretrain epoch [15/182], ZINB loss:0.3796, NB loss:4.7332\n",
      "Pretrain epoch [16/182], ZINB loss:0.3920, NB loss:4.7393\n",
      "Pretrain epoch [17/182], ZINB loss:0.4092, NB loss:4.7198\n",
      "Pretrain epoch [18/182], ZINB loss:0.3978, NB loss:4.7360\n",
      "Pretrain epoch [19/182], ZINB loss:0.3896, NB loss:4.7608\n",
      "Pretrain epoch [20/182], ZINB loss:0.3964, NB loss:4.7072\n",
      "Pretrain epoch [21/182], ZINB loss:0.4152, NB loss:4.7031\n",
      "Pretrain epoch [22/182], ZINB loss:0.3934, NB loss:4.7512\n",
      "Pretrain epoch [23/182], ZINB loss:0.4009, NB loss:4.7614\n",
      "Pretrain epoch [24/182], ZINB loss:0.4105, NB loss:4.6878\n",
      "Pretrain epoch [25/182], ZINB loss:0.3808, NB loss:4.7382\n",
      "Pretrain epoch [26/182], ZINB loss:0.3707, NB loss:4.7606\n",
      "Pretrain epoch [27/182], ZINB loss:0.3878, NB loss:4.6784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [1/183], ZINB loss:0.3790, NB loss:4.6713\n",
      "Pretrain epoch [2/183], ZINB loss:0.3979, NB loss:4.7322\n",
      "Pretrain epoch [3/183], ZINB loss:0.4215, NB loss:4.7473\n",
      "Pretrain epoch [4/183], ZINB loss:0.3902, NB loss:4.8111\n",
      "Pretrain epoch [5/183], ZINB loss:0.3837, NB loss:4.7693\n",
      "Pretrain epoch [6/183], ZINB loss:0.3967, NB loss:4.7358\n",
      "Pretrain epoch [7/183], ZINB loss:0.3978, NB loss:4.7221\n",
      "Pretrain epoch [8/183], ZINB loss:0.3852, NB loss:4.6822\n",
      "Pretrain epoch [9/183], ZINB loss:0.3834, NB loss:4.7023\n",
      "Pretrain epoch [10/183], ZINB loss:0.4127, NB loss:4.7322\n",
      "Pretrain epoch [11/183], ZINB loss:0.3945, NB loss:4.6933\n",
      "Pretrain epoch [12/183], ZINB loss:0.3953, NB loss:4.7164\n",
      "Pretrain epoch [13/183], ZINB loss:0.3936, NB loss:4.8073\n",
      "Pretrain epoch [14/183], ZINB loss:0.4020, NB loss:4.7538\n",
      "Pretrain epoch [15/183], ZINB loss:0.3921, NB loss:4.6670\n",
      "Pretrain epoch [16/183], ZINB loss:0.3760, NB loss:4.6508\n",
      "Pretrain epoch [17/183], ZINB loss:0.3932, NB loss:4.7532\n",
      "Pretrain epoch [18/183], ZINB loss:0.3842, NB loss:4.6791\n",
      "Pretrain epoch [19/183], ZINB loss:0.3910, NB loss:4.7023\n",
      "Pretrain epoch [20/183], ZINB loss:0.3907, NB loss:4.7914\n",
      "Pretrain epoch [21/183], ZINB loss:0.3936, NB loss:4.7356\n",
      "Pretrain epoch [22/183], ZINB loss:0.3981, NB loss:4.7212\n",
      "Pretrain epoch [23/183], ZINB loss:0.3905, NB loss:4.6734\n",
      "Pretrain epoch [24/183], ZINB loss:0.3937, NB loss:4.7460\n",
      "Pretrain epoch [25/183], ZINB loss:0.4002, NB loss:4.6694\n",
      "Pretrain epoch [26/183], ZINB loss:0.3826, NB loss:4.6912\n",
      "Pretrain epoch [27/183], ZINB loss:0.5216, NB loss:4.7105\n",
      "Pretrain epoch [1/184], ZINB loss:0.3666, NB loss:4.7021\n",
      "Pretrain epoch [2/184], ZINB loss:0.4004, NB loss:4.6815\n",
      "Pretrain epoch [3/184], ZINB loss:0.3865, NB loss:4.7511\n",
      "Pretrain epoch [4/184], ZINB loss:0.3982, NB loss:4.7663\n",
      "Pretrain epoch [5/184], ZINB loss:0.4115, NB loss:4.7792\n",
      "Pretrain epoch [6/184], ZINB loss:0.4006, NB loss:4.7260\n",
      "Pretrain epoch [7/184], ZINB loss:0.3946, NB loss:4.6781\n",
      "Pretrain epoch [8/184], ZINB loss:0.3868, NB loss:4.7911\n",
      "Pretrain epoch [9/184], ZINB loss:0.3929, NB loss:4.6562\n",
      "Pretrain epoch [10/184], ZINB loss:0.3858, NB loss:4.6816\n",
      "Pretrain epoch [11/184], ZINB loss:0.3712, NB loss:4.7100\n",
      "Pretrain epoch [12/184], ZINB loss:0.4266, NB loss:4.7515\n",
      "Pretrain epoch [13/184], ZINB loss:0.3907, NB loss:4.7022\n",
      "Pretrain epoch [14/184], ZINB loss:0.3949, NB loss:4.7193\n",
      "Pretrain epoch [15/184], ZINB loss:0.3991, NB loss:4.6946\n",
      "Pretrain epoch [16/184], ZINB loss:0.4035, NB loss:4.7922\n",
      "Pretrain epoch [17/184], ZINB loss:0.3863, NB loss:4.6865\n",
      "Pretrain epoch [18/184], ZINB loss:0.3766, NB loss:4.6904\n",
      "Pretrain epoch [19/184], ZINB loss:0.3938, NB loss:4.6678\n",
      "Pretrain epoch [20/184], ZINB loss:0.3968, NB loss:4.6913\n",
      "Pretrain epoch [21/184], ZINB loss:0.4064, NB loss:4.6817\n",
      "Pretrain epoch [22/184], ZINB loss:0.3877, NB loss:4.6977\n",
      "Pretrain epoch [23/184], ZINB loss:0.3956, NB loss:4.7605\n",
      "Pretrain epoch [24/184], ZINB loss:0.3882, NB loss:4.7411\n",
      "Pretrain epoch [25/184], ZINB loss:0.4043, NB loss:4.7276\n",
      "Pretrain epoch [26/184], ZINB loss:0.3751, NB loss:4.7754\n",
      "Pretrain epoch [27/184], ZINB loss:0.3973, NB loss:4.7096\n",
      "Pretrain epoch [1/185], ZINB loss:0.3892, NB loss:4.7106\n",
      "Pretrain epoch [2/185], ZINB loss:0.3836, NB loss:4.7813\n",
      "Pretrain epoch [3/185], ZINB loss:0.3936, NB loss:4.7199\n",
      "Pretrain epoch [4/185], ZINB loss:0.3933, NB loss:4.7344\n",
      "Pretrain epoch [5/185], ZINB loss:0.4176, NB loss:4.6620\n",
      "Pretrain epoch [6/185], ZINB loss:0.4066, NB loss:4.6906\n",
      "Pretrain epoch [7/185], ZINB loss:0.4013, NB loss:4.7265\n",
      "Pretrain epoch [8/185], ZINB loss:0.3892, NB loss:4.7370\n",
      "Pretrain epoch [9/185], ZINB loss:0.3918, NB loss:4.6640\n",
      "Pretrain epoch [10/185], ZINB loss:0.3818, NB loss:4.7670\n",
      "Pretrain epoch [11/185], ZINB loss:0.4094, NB loss:4.7551\n",
      "Pretrain epoch [12/185], ZINB loss:0.3985, NB loss:4.7375\n",
      "Pretrain epoch [13/185], ZINB loss:0.3939, NB loss:4.7178\n",
      "Pretrain epoch [14/185], ZINB loss:0.3777, NB loss:4.7062\n",
      "Pretrain epoch [15/185], ZINB loss:0.3904, NB loss:4.6646\n",
      "Pretrain epoch [16/185], ZINB loss:0.3896, NB loss:4.7722\n",
      "Pretrain epoch [17/185], ZINB loss:0.3818, NB loss:4.6696\n",
      "Pretrain epoch [18/185], ZINB loss:0.4033, NB loss:4.7229\n",
      "Pretrain epoch [19/185], ZINB loss:0.3913, NB loss:4.7488\n",
      "Pretrain epoch [20/185], ZINB loss:0.3767, NB loss:4.6793\n",
      "Pretrain epoch [21/185], ZINB loss:0.4014, NB loss:4.8038\n",
      "Pretrain epoch [22/185], ZINB loss:0.3990, NB loss:4.6786\n",
      "Pretrain epoch [23/185], ZINB loss:0.3830, NB loss:4.7937\n",
      "Pretrain epoch [24/185], ZINB loss:0.3869, NB loss:4.6864\n",
      "Pretrain epoch [25/185], ZINB loss:0.3807, NB loss:4.6582\n",
      "Pretrain epoch [26/185], ZINB loss:0.3946, NB loss:4.6724\n",
      "Pretrain epoch [27/185], ZINB loss:0.3817, NB loss:4.4963\n",
      "Pretrain epoch [1/186], ZINB loss:0.4001, NB loss:4.6858\n",
      "Pretrain epoch [2/186], ZINB loss:0.3992, NB loss:4.7679\n",
      "Pretrain epoch [3/186], ZINB loss:0.4072, NB loss:4.7189\n",
      "Pretrain epoch [4/186], ZINB loss:0.3799, NB loss:4.6880\n",
      "Pretrain epoch [5/186], ZINB loss:0.3900, NB loss:4.7388\n",
      "Pretrain epoch [6/186], ZINB loss:0.3894, NB loss:4.7163\n",
      "Pretrain epoch [7/186], ZINB loss:0.3847, NB loss:4.7560\n",
      "Pretrain epoch [8/186], ZINB loss:0.3853, NB loss:4.7236\n",
      "Pretrain epoch [9/186], ZINB loss:0.3795, NB loss:4.7080\n",
      "Pretrain epoch [10/186], ZINB loss:0.3973, NB loss:4.7099\n",
      "Pretrain epoch [11/186], ZINB loss:0.3784, NB loss:4.6316\n",
      "Pretrain epoch [12/186], ZINB loss:0.3953, NB loss:4.6692\n",
      "Pretrain epoch [13/186], ZINB loss:0.4213, NB loss:4.7299\n",
      "Pretrain epoch [14/186], ZINB loss:0.3945, NB loss:4.7137\n",
      "Pretrain epoch [15/186], ZINB loss:0.3891, NB loss:4.6933\n",
      "Pretrain epoch [16/186], ZINB loss:0.3804, NB loss:4.7463\n",
      "Pretrain epoch [17/186], ZINB loss:0.4033, NB loss:4.8140\n",
      "Pretrain epoch [18/186], ZINB loss:0.4067, NB loss:4.6876\n",
      "Pretrain epoch [19/186], ZINB loss:0.3886, NB loss:4.6577\n",
      "Pretrain epoch [20/186], ZINB loss:0.3941, NB loss:4.7268\n",
      "Pretrain epoch [21/186], ZINB loss:0.3814, NB loss:4.7367\n",
      "Pretrain epoch [22/186], ZINB loss:0.3854, NB loss:4.7608\n",
      "Pretrain epoch [23/186], ZINB loss:0.3872, NB loss:4.7488\n",
      "Pretrain epoch [24/186], ZINB loss:0.3967, NB loss:4.6677\n",
      "Pretrain epoch [25/186], ZINB loss:0.3968, NB loss:4.7042\n",
      "Pretrain epoch [26/186], ZINB loss:0.3890, NB loss:4.6961\n",
      "Pretrain epoch [27/186], ZINB loss:0.4202, NB loss:4.7465\n",
      "Pretrain epoch [1/187], ZINB loss:0.3753, NB loss:4.6758\n",
      "Pretrain epoch [2/187], ZINB loss:0.4065, NB loss:4.6932\n",
      "Pretrain epoch [3/187], ZINB loss:0.3693, NB loss:4.7271\n",
      "Pretrain epoch [4/187], ZINB loss:0.3899, NB loss:4.7054\n",
      "Pretrain epoch [5/187], ZINB loss:0.3913, NB loss:4.7087\n",
      "Pretrain epoch [6/187], ZINB loss:0.3831, NB loss:4.6644\n",
      "Pretrain epoch [7/187], ZINB loss:0.3818, NB loss:4.7503\n",
      "Pretrain epoch [8/187], ZINB loss:0.3800, NB loss:4.7029\n",
      "Pretrain epoch [9/187], ZINB loss:0.4150, NB loss:4.7411\n",
      "Pretrain epoch [10/187], ZINB loss:0.3930, NB loss:4.7130\n",
      "Pretrain epoch [11/187], ZINB loss:0.4111, NB loss:4.6914\n",
      "Pretrain epoch [12/187], ZINB loss:0.3873, NB loss:4.6851\n",
      "Pretrain epoch [13/187], ZINB loss:0.3791, NB loss:4.6298\n",
      "Pretrain epoch [14/187], ZINB loss:0.3784, NB loss:4.7313\n",
      "Pretrain epoch [15/187], ZINB loss:0.3971, NB loss:4.7368\n",
      "Pretrain epoch [16/187], ZINB loss:0.3945, NB loss:4.7270\n",
      "Pretrain epoch [17/187], ZINB loss:0.4132, NB loss:4.7106\n",
      "Pretrain epoch [18/187], ZINB loss:0.3826, NB loss:4.7130\n",
      "Pretrain epoch [19/187], ZINB loss:0.3995, NB loss:4.7169\n",
      "Pretrain epoch [20/187], ZINB loss:0.3946, NB loss:4.7197\n",
      "Pretrain epoch [21/187], ZINB loss:0.4051, NB loss:4.7059\n",
      "Pretrain epoch [22/187], ZINB loss:0.3894, NB loss:4.6855\n",
      "Pretrain epoch [23/187], ZINB loss:0.3740, NB loss:4.7648\n",
      "Pretrain epoch [24/187], ZINB loss:0.3655, NB loss:4.7105\n",
      "Pretrain epoch [25/187], ZINB loss:0.4050, NB loss:4.7782\n",
      "Pretrain epoch [26/187], ZINB loss:0.4178, NB loss:4.7614\n",
      "Pretrain epoch [27/187], ZINB loss:0.3161, NB loss:4.7947\n",
      "Pretrain epoch [1/188], ZINB loss:0.3912, NB loss:4.6847\n",
      "Pretrain epoch [2/188], ZINB loss:0.4014, NB loss:4.7036\n",
      "Pretrain epoch [3/188], ZINB loss:0.3867, NB loss:4.7022\n",
      "Pretrain epoch [4/188], ZINB loss:0.3981, NB loss:4.7087\n",
      "Pretrain epoch [5/188], ZINB loss:0.3885, NB loss:4.6734\n",
      "Pretrain epoch [6/188], ZINB loss:0.3986, NB loss:4.6578\n",
      "Pretrain epoch [7/188], ZINB loss:0.3849, NB loss:4.6945\n",
      "Pretrain epoch [8/188], ZINB loss:0.4268, NB loss:4.7196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [9/188], ZINB loss:0.4034, NB loss:4.6926\n",
      "Pretrain epoch [10/188], ZINB loss:0.3872, NB loss:4.6857\n",
      "Pretrain epoch [11/188], ZINB loss:0.3967, NB loss:4.7919\n",
      "Pretrain epoch [12/188], ZINB loss:0.3842, NB loss:4.7219\n",
      "Pretrain epoch [13/188], ZINB loss:0.4033, NB loss:4.6608\n",
      "Pretrain epoch [14/188], ZINB loss:0.3883, NB loss:4.7047\n",
      "Pretrain epoch [15/188], ZINB loss:0.3755, NB loss:4.6935\n",
      "Pretrain epoch [16/188], ZINB loss:0.3913, NB loss:4.6746\n",
      "Pretrain epoch [17/188], ZINB loss:0.3805, NB loss:4.7694\n",
      "Pretrain epoch [18/188], ZINB loss:0.3846, NB loss:4.7012\n",
      "Pretrain epoch [19/188], ZINB loss:0.3886, NB loss:4.7523\n",
      "Pretrain epoch [20/188], ZINB loss:0.3846, NB loss:4.7345\n",
      "Pretrain epoch [21/188], ZINB loss:0.3942, NB loss:4.7704\n",
      "Pretrain epoch [22/188], ZINB loss:0.3942, NB loss:4.7451\n",
      "Pretrain epoch [23/188], ZINB loss:0.3899, NB loss:4.7181\n",
      "Pretrain epoch [24/188], ZINB loss:0.3986, NB loss:4.7392\n",
      "Pretrain epoch [25/188], ZINB loss:0.3795, NB loss:4.7101\n",
      "Pretrain epoch [26/188], ZINB loss:0.3791, NB loss:4.6963\n",
      "Pretrain epoch [27/188], ZINB loss:0.3675, NB loss:4.4741\n",
      "Pretrain epoch [1/189], ZINB loss:0.3877, NB loss:4.6807\n",
      "Pretrain epoch [2/189], ZINB loss:0.4041, NB loss:4.7170\n",
      "Pretrain epoch [3/189], ZINB loss:0.3982, NB loss:4.7508\n",
      "Pretrain epoch [4/189], ZINB loss:0.3861, NB loss:4.6154\n",
      "Pretrain epoch [5/189], ZINB loss:0.3973, NB loss:4.6784\n",
      "Pretrain epoch [6/189], ZINB loss:0.4028, NB loss:4.6891\n",
      "Pretrain epoch [7/189], ZINB loss:0.4041, NB loss:4.7743\n",
      "Pretrain epoch [8/189], ZINB loss:0.3792, NB loss:4.6692\n",
      "Pretrain epoch [9/189], ZINB loss:0.3941, NB loss:4.7064\n",
      "Pretrain epoch [10/189], ZINB loss:0.3843, NB loss:4.7031\n",
      "Pretrain epoch [11/189], ZINB loss:0.3925, NB loss:4.7003\n",
      "Pretrain epoch [12/189], ZINB loss:0.3896, NB loss:4.8274\n",
      "Pretrain epoch [13/189], ZINB loss:0.3838, NB loss:4.6886\n",
      "Pretrain epoch [14/189], ZINB loss:0.3973, NB loss:4.7113\n",
      "Pretrain epoch [15/189], ZINB loss:0.3741, NB loss:4.7043\n",
      "Pretrain epoch [16/189], ZINB loss:0.3966, NB loss:4.7162\n",
      "Pretrain epoch [17/189], ZINB loss:0.3936, NB loss:4.7337\n",
      "Pretrain epoch [18/189], ZINB loss:0.3933, NB loss:4.6808\n",
      "Pretrain epoch [19/189], ZINB loss:0.3883, NB loss:4.7049\n",
      "Pretrain epoch [20/189], ZINB loss:0.4174, NB loss:4.6458\n",
      "Pretrain epoch [21/189], ZINB loss:0.4092, NB loss:4.6036\n",
      "Pretrain epoch [22/189], ZINB loss:0.3980, NB loss:4.8065\n",
      "Pretrain epoch [23/189], ZINB loss:0.3767, NB loss:4.7894\n",
      "Pretrain epoch [24/189], ZINB loss:0.3884, NB loss:4.7024\n",
      "Pretrain epoch [25/189], ZINB loss:0.3654, NB loss:4.6990\n",
      "Pretrain epoch [26/189], ZINB loss:0.3772, NB loss:4.7491\n",
      "Pretrain epoch [27/189], ZINB loss:0.4085, NB loss:4.6336\n",
      "Pretrain epoch [1/190], ZINB loss:0.3849, NB loss:4.6806\n",
      "Pretrain epoch [2/190], ZINB loss:0.3980, NB loss:4.6926\n",
      "Pretrain epoch [3/190], ZINB loss:0.3822, NB loss:4.7534\n",
      "Pretrain epoch [4/190], ZINB loss:0.4037, NB loss:4.6942\n",
      "Pretrain epoch [5/190], ZINB loss:0.3886, NB loss:4.6620\n",
      "Pretrain epoch [6/190], ZINB loss:0.3809, NB loss:4.7362\n",
      "Pretrain epoch [7/190], ZINB loss:0.3890, NB loss:4.7130\n",
      "Pretrain epoch [8/190], ZINB loss:0.3897, NB loss:4.6790\n",
      "Pretrain epoch [9/190], ZINB loss:0.4074, NB loss:4.6952\n",
      "Pretrain epoch [10/190], ZINB loss:0.4073, NB loss:4.6746\n",
      "Pretrain epoch [11/190], ZINB loss:0.3805, NB loss:4.6901\n",
      "Pretrain epoch [12/190], ZINB loss:0.3697, NB loss:4.7105\n",
      "Pretrain epoch [13/190], ZINB loss:0.4015, NB loss:4.7421\n",
      "Pretrain epoch [14/190], ZINB loss:0.3973, NB loss:4.6964\n",
      "Pretrain epoch [15/190], ZINB loss:0.3653, NB loss:4.7002\n",
      "Pretrain epoch [16/190], ZINB loss:0.3977, NB loss:4.6800\n",
      "Pretrain epoch [17/190], ZINB loss:0.3872, NB loss:4.7727\n",
      "Pretrain epoch [18/190], ZINB loss:0.3997, NB loss:4.6745\n",
      "Pretrain epoch [19/190], ZINB loss:0.3982, NB loss:4.7011\n",
      "Pretrain epoch [20/190], ZINB loss:0.3999, NB loss:4.7465\n",
      "Pretrain epoch [21/190], ZINB loss:0.3948, NB loss:4.6539\n",
      "Pretrain epoch [22/190], ZINB loss:0.3870, NB loss:4.6820\n",
      "Pretrain epoch [23/190], ZINB loss:0.3841, NB loss:4.7776\n",
      "Pretrain epoch [24/190], ZINB loss:0.3983, NB loss:4.7741\n",
      "Pretrain epoch [25/190], ZINB loss:0.3817, NB loss:4.6947\n",
      "Pretrain epoch [26/190], ZINB loss:0.4040, NB loss:4.7292\n",
      "Pretrain epoch [27/190], ZINB loss:0.4624, NB loss:4.3777\n",
      "Pretrain epoch [1/191], ZINB loss:0.3992, NB loss:4.7140\n",
      "Pretrain epoch [2/191], ZINB loss:0.3911, NB loss:4.7121\n",
      "Pretrain epoch [3/191], ZINB loss:0.3821, NB loss:4.7256\n",
      "Pretrain epoch [4/191], ZINB loss:0.3812, NB loss:4.6871\n",
      "Pretrain epoch [5/191], ZINB loss:0.3825, NB loss:4.7300\n",
      "Pretrain epoch [6/191], ZINB loss:0.4127, NB loss:4.6428\n",
      "Pretrain epoch [7/191], ZINB loss:0.3817, NB loss:4.6735\n",
      "Pretrain epoch [8/191], ZINB loss:0.3896, NB loss:4.7456\n",
      "Pretrain epoch [9/191], ZINB loss:0.3953, NB loss:4.6288\n",
      "Pretrain epoch [10/191], ZINB loss:0.3926, NB loss:4.7270\n",
      "Pretrain epoch [11/191], ZINB loss:0.3969, NB loss:4.6893\n",
      "Pretrain epoch [12/191], ZINB loss:0.3797, NB loss:4.7264\n",
      "Pretrain epoch [13/191], ZINB loss:0.4014, NB loss:4.7838\n",
      "Pretrain epoch [14/191], ZINB loss:0.3851, NB loss:4.6873\n",
      "Pretrain epoch [15/191], ZINB loss:0.4001, NB loss:4.6541\n",
      "Pretrain epoch [16/191], ZINB loss:0.3905, NB loss:4.7081\n",
      "Pretrain epoch [17/191], ZINB loss:0.4009, NB loss:4.6588\n",
      "Pretrain epoch [18/191], ZINB loss:0.3851, NB loss:4.7029\n",
      "Pretrain epoch [19/191], ZINB loss:0.3991, NB loss:4.8355\n",
      "Pretrain epoch [20/191], ZINB loss:0.3883, NB loss:4.7149\n",
      "Pretrain epoch [21/191], ZINB loss:0.4031, NB loss:4.7102\n",
      "Pretrain epoch [22/191], ZINB loss:0.3926, NB loss:4.7698\n",
      "Pretrain epoch [23/191], ZINB loss:0.3952, NB loss:4.6515\n",
      "Pretrain epoch [24/191], ZINB loss:0.3822, NB loss:4.6885\n",
      "Pretrain epoch [25/191], ZINB loss:0.3909, NB loss:4.6848\n",
      "Pretrain epoch [26/191], ZINB loss:0.3850, NB loss:4.6898\n",
      "Pretrain epoch [27/191], ZINB loss:0.4041, NB loss:4.6890\n",
      "Pretrain epoch [1/192], ZINB loss:0.3949, NB loss:4.6772\n",
      "Pretrain epoch [2/192], ZINB loss:0.3912, NB loss:4.6491\n",
      "Pretrain epoch [3/192], ZINB loss:0.4020, NB loss:4.6857\n",
      "Pretrain epoch [4/192], ZINB loss:0.4131, NB loss:4.7237\n",
      "Pretrain epoch [5/192], ZINB loss:0.3870, NB loss:4.7659\n",
      "Pretrain epoch [6/192], ZINB loss:0.3952, NB loss:4.7586\n",
      "Pretrain epoch [7/192], ZINB loss:0.3751, NB loss:4.6873\n",
      "Pretrain epoch [8/192], ZINB loss:0.4237, NB loss:4.7194\n",
      "Pretrain epoch [9/192], ZINB loss:0.3808, NB loss:4.7291\n",
      "Pretrain epoch [10/192], ZINB loss:0.4001, NB loss:4.7267\n",
      "Pretrain epoch [11/192], ZINB loss:0.3998, NB loss:4.6301\n",
      "Pretrain epoch [12/192], ZINB loss:0.3808, NB loss:4.7095\n",
      "Pretrain epoch [13/192], ZINB loss:0.3904, NB loss:4.6996\n",
      "Pretrain epoch [14/192], ZINB loss:0.3891, NB loss:4.7373\n",
      "Pretrain epoch [15/192], ZINB loss:0.3938, NB loss:4.7448\n",
      "Pretrain epoch [16/192], ZINB loss:0.3967, NB loss:4.8029\n",
      "Pretrain epoch [17/192], ZINB loss:0.3933, NB loss:4.6507\n",
      "Pretrain epoch [18/192], ZINB loss:0.4114, NB loss:4.7376\n",
      "Pretrain epoch [19/192], ZINB loss:0.3779, NB loss:4.6391\n",
      "Pretrain epoch [20/192], ZINB loss:0.3785, NB loss:4.7382\n",
      "Pretrain epoch [21/192], ZINB loss:0.3692, NB loss:4.7705\n",
      "Pretrain epoch [22/192], ZINB loss:0.3849, NB loss:4.6255\n",
      "Pretrain epoch [23/192], ZINB loss:0.4029, NB loss:4.7408\n",
      "Pretrain epoch [24/192], ZINB loss:0.3850, NB loss:4.7253\n",
      "Pretrain epoch [25/192], ZINB loss:0.3983, NB loss:4.6219\n",
      "Pretrain epoch [26/192], ZINB loss:0.3896, NB loss:4.6343\n",
      "Pretrain epoch [27/192], ZINB loss:0.4053, NB loss:4.7539\n",
      "Pretrain epoch [1/193], ZINB loss:0.3841, NB loss:4.7453\n",
      "Pretrain epoch [2/193], ZINB loss:0.3889, NB loss:4.6651\n",
      "Pretrain epoch [3/193], ZINB loss:0.3841, NB loss:4.7742\n",
      "Pretrain epoch [4/193], ZINB loss:0.3761, NB loss:4.6342\n",
      "Pretrain epoch [5/193], ZINB loss:0.3825, NB loss:4.6894\n",
      "Pretrain epoch [6/193], ZINB loss:0.4026, NB loss:4.6115\n",
      "Pretrain epoch [7/193], ZINB loss:0.4007, NB loss:4.7640\n",
      "Pretrain epoch [8/193], ZINB loss:0.3602, NB loss:4.6847\n",
      "Pretrain epoch [9/193], ZINB loss:0.3853, NB loss:4.7561\n",
      "Pretrain epoch [10/193], ZINB loss:0.3991, NB loss:4.7780\n",
      "Pretrain epoch [11/193], ZINB loss:0.4074, NB loss:4.7608\n",
      "Pretrain epoch [12/193], ZINB loss:0.3983, NB loss:4.6819\n",
      "Pretrain epoch [13/193], ZINB loss:0.3923, NB loss:4.6629\n",
      "Pretrain epoch [14/193], ZINB loss:0.4034, NB loss:4.6635\n",
      "Pretrain epoch [15/193], ZINB loss:0.4032, NB loss:4.6424\n",
      "Pretrain epoch [16/193], ZINB loss:0.4027, NB loss:4.6803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [17/193], ZINB loss:0.3948, NB loss:4.7124\n",
      "Pretrain epoch [18/193], ZINB loss:0.3901, NB loss:4.6914\n",
      "Pretrain epoch [19/193], ZINB loss:0.3889, NB loss:4.6434\n",
      "Pretrain epoch [20/193], ZINB loss:0.3919, NB loss:4.7525\n",
      "Pretrain epoch [21/193], ZINB loss:0.3819, NB loss:4.6902\n",
      "Pretrain epoch [22/193], ZINB loss:0.3830, NB loss:4.7164\n",
      "Pretrain epoch [23/193], ZINB loss:0.4090, NB loss:4.7160\n",
      "Pretrain epoch [24/193], ZINB loss:0.3772, NB loss:4.7166\n",
      "Pretrain epoch [25/193], ZINB loss:0.4006, NB loss:4.7448\n",
      "Pretrain epoch [26/193], ZINB loss:0.4080, NB loss:4.6755\n",
      "Pretrain epoch [27/193], ZINB loss:0.3547, NB loss:5.5926\n",
      "Pretrain epoch [1/194], ZINB loss:0.4114, NB loss:4.7611\n",
      "Pretrain epoch [2/194], ZINB loss:0.3980, NB loss:4.8102\n",
      "Pretrain epoch [3/194], ZINB loss:0.3835, NB loss:4.6356\n",
      "Pretrain epoch [4/194], ZINB loss:0.3997, NB loss:4.6719\n",
      "Pretrain epoch [5/194], ZINB loss:0.3966, NB loss:4.7070\n",
      "Pretrain epoch [6/194], ZINB loss:0.4051, NB loss:4.7711\n",
      "Pretrain epoch [7/194], ZINB loss:0.3962, NB loss:4.7449\n",
      "Pretrain epoch [8/194], ZINB loss:0.3998, NB loss:4.7335\n",
      "Pretrain epoch [9/194], ZINB loss:0.3869, NB loss:4.6991\n",
      "Pretrain epoch [10/194], ZINB loss:0.3802, NB loss:4.6562\n",
      "Pretrain epoch [11/194], ZINB loss:0.3966, NB loss:4.7448\n",
      "Pretrain epoch [12/194], ZINB loss:0.3746, NB loss:4.6896\n",
      "Pretrain epoch [13/194], ZINB loss:0.3972, NB loss:4.6585\n",
      "Pretrain epoch [14/194], ZINB loss:0.3923, NB loss:4.6524\n",
      "Pretrain epoch [15/194], ZINB loss:0.3806, NB loss:4.7437\n",
      "Pretrain epoch [16/194], ZINB loss:0.4017, NB loss:4.6631\n",
      "Pretrain epoch [17/194], ZINB loss:0.3733, NB loss:4.7171\n",
      "Pretrain epoch [18/194], ZINB loss:0.3768, NB loss:4.6507\n",
      "Pretrain epoch [19/194], ZINB loss:0.3984, NB loss:4.7555\n",
      "Pretrain epoch [20/194], ZINB loss:0.3784, NB loss:4.6807\n",
      "Pretrain epoch [21/194], ZINB loss:0.3804, NB loss:4.6734\n",
      "Pretrain epoch [22/194], ZINB loss:0.4016, NB loss:4.7467\n",
      "Pretrain epoch [23/194], ZINB loss:0.3939, NB loss:4.7025\n",
      "Pretrain epoch [24/194], ZINB loss:0.3838, NB loss:4.6192\n",
      "Pretrain epoch [25/194], ZINB loss:0.3943, NB loss:4.6523\n",
      "Pretrain epoch [26/194], ZINB loss:0.4096, NB loss:4.6905\n",
      "Pretrain epoch [27/194], ZINB loss:0.3115, NB loss:4.7802\n",
      "Pretrain epoch [1/195], ZINB loss:0.3990, NB loss:4.6962\n",
      "Pretrain epoch [2/195], ZINB loss:0.4067, NB loss:4.7268\n",
      "Pretrain epoch [3/195], ZINB loss:0.3783, NB loss:4.6776\n",
      "Pretrain epoch [4/195], ZINB loss:0.3938, NB loss:4.6620\n",
      "Pretrain epoch [5/195], ZINB loss:0.3956, NB loss:4.7156\n",
      "Pretrain epoch [6/195], ZINB loss:0.3858, NB loss:4.7175\n",
      "Pretrain epoch [7/195], ZINB loss:0.3880, NB loss:4.6752\n",
      "Pretrain epoch [8/195], ZINB loss:0.3871, NB loss:4.7102\n",
      "Pretrain epoch [9/195], ZINB loss:0.4063, NB loss:4.6691\n",
      "Pretrain epoch [10/195], ZINB loss:0.3997, NB loss:4.7146\n",
      "Pretrain epoch [11/195], ZINB loss:0.3881, NB loss:4.7044\n",
      "Pretrain epoch [12/195], ZINB loss:0.3925, NB loss:4.6963\n",
      "Pretrain epoch [13/195], ZINB loss:0.3751, NB loss:4.5967\n",
      "Pretrain epoch [14/195], ZINB loss:0.3951, NB loss:4.7070\n",
      "Pretrain epoch [15/195], ZINB loss:0.3899, NB loss:4.7296\n",
      "Pretrain epoch [16/195], ZINB loss:0.3817, NB loss:4.7260\n",
      "Pretrain epoch [17/195], ZINB loss:0.3864, NB loss:4.7040\n",
      "Pretrain epoch [18/195], ZINB loss:0.3904, NB loss:4.7115\n",
      "Pretrain epoch [19/195], ZINB loss:0.3874, NB loss:4.6743\n",
      "Pretrain epoch [20/195], ZINB loss:0.3820, NB loss:4.6968\n",
      "Pretrain epoch [21/195], ZINB loss:0.3924, NB loss:4.7068\n",
      "Pretrain epoch [22/195], ZINB loss:0.4054, NB loss:4.6777\n",
      "Pretrain epoch [23/195], ZINB loss:0.4049, NB loss:4.7118\n",
      "Pretrain epoch [24/195], ZINB loss:0.3986, NB loss:4.7580\n",
      "Pretrain epoch [25/195], ZINB loss:0.3782, NB loss:4.7077\n",
      "Pretrain epoch [26/195], ZINB loss:0.3944, NB loss:4.6985\n",
      "Pretrain epoch [27/195], ZINB loss:0.3190, NB loss:4.4612\n",
      "Pretrain epoch [1/196], ZINB loss:0.4015, NB loss:4.7380\n",
      "Pretrain epoch [2/196], ZINB loss:0.3899, NB loss:4.7544\n",
      "Pretrain epoch [3/196], ZINB loss:0.4007, NB loss:4.7373\n",
      "Pretrain epoch [4/196], ZINB loss:0.3961, NB loss:4.6493\n",
      "Pretrain epoch [5/196], ZINB loss:0.3817, NB loss:4.6042\n",
      "Pretrain epoch [6/196], ZINB loss:0.4028, NB loss:4.6990\n",
      "Pretrain epoch [7/196], ZINB loss:0.3794, NB loss:4.7124\n",
      "Pretrain epoch [8/196], ZINB loss:0.4036, NB loss:4.6298\n",
      "Pretrain epoch [9/196], ZINB loss:0.3668, NB loss:4.7501\n",
      "Pretrain epoch [10/196], ZINB loss:0.4115, NB loss:4.6506\n",
      "Pretrain epoch [11/196], ZINB loss:0.3932, NB loss:4.7323\n",
      "Pretrain epoch [12/196], ZINB loss:0.3818, NB loss:4.6687\n",
      "Pretrain epoch [13/196], ZINB loss:0.3803, NB loss:4.7312\n",
      "Pretrain epoch [14/196], ZINB loss:0.4082, NB loss:4.6823\n",
      "Pretrain epoch [15/196], ZINB loss:0.3886, NB loss:4.6739\n",
      "Pretrain epoch [16/196], ZINB loss:0.3940, NB loss:4.7434\n",
      "Pretrain epoch [17/196], ZINB loss:0.3805, NB loss:4.6736\n",
      "Pretrain epoch [18/196], ZINB loss:0.3800, NB loss:4.6435\n",
      "Pretrain epoch [19/196], ZINB loss:0.3743, NB loss:4.7003\n",
      "Pretrain epoch [20/196], ZINB loss:0.3848, NB loss:4.7129\n",
      "Pretrain epoch [21/196], ZINB loss:0.4070, NB loss:4.7440\n",
      "Pretrain epoch [22/196], ZINB loss:0.3890, NB loss:4.6177\n",
      "Pretrain epoch [23/196], ZINB loss:0.4049, NB loss:4.7558\n",
      "Pretrain epoch [24/196], ZINB loss:0.3835, NB loss:4.7094\n",
      "Pretrain epoch [25/196], ZINB loss:0.3893, NB loss:4.7434\n",
      "Pretrain epoch [26/196], ZINB loss:0.3961, NB loss:4.6556\n",
      "Pretrain epoch [27/196], ZINB loss:0.3678, NB loss:4.7949\n",
      "Pretrain epoch [1/197], ZINB loss:0.4076, NB loss:4.6688\n",
      "Pretrain epoch [2/197], ZINB loss:0.3944, NB loss:4.7189\n",
      "Pretrain epoch [3/197], ZINB loss:0.3843, NB loss:4.7686\n",
      "Pretrain epoch [4/197], ZINB loss:0.3670, NB loss:4.7219\n",
      "Pretrain epoch [5/197], ZINB loss:0.3886, NB loss:4.7423\n",
      "Pretrain epoch [6/197], ZINB loss:0.4007, NB loss:4.7737\n",
      "Pretrain epoch [7/197], ZINB loss:0.3946, NB loss:4.6780\n",
      "Pretrain epoch [8/197], ZINB loss:0.3787, NB loss:4.7056\n",
      "Pretrain epoch [9/197], ZINB loss:0.4051, NB loss:4.6177\n",
      "Pretrain epoch [10/197], ZINB loss:0.4087, NB loss:4.6212\n",
      "Pretrain epoch [11/197], ZINB loss:0.3929, NB loss:4.6792\n",
      "Pretrain epoch [12/197], ZINB loss:0.4017, NB loss:4.6591\n",
      "Pretrain epoch [13/197], ZINB loss:0.3922, NB loss:4.7363\n",
      "Pretrain epoch [14/197], ZINB loss:0.4000, NB loss:4.6873\n",
      "Pretrain epoch [15/197], ZINB loss:0.3923, NB loss:4.7277\n",
      "Pretrain epoch [16/197], ZINB loss:0.3997, NB loss:4.7334\n",
      "Pretrain epoch [17/197], ZINB loss:0.3860, NB loss:4.6458\n",
      "Pretrain epoch [18/197], ZINB loss:0.3729, NB loss:4.6937\n",
      "Pretrain epoch [19/197], ZINB loss:0.3829, NB loss:4.7138\n",
      "Pretrain epoch [20/197], ZINB loss:0.3697, NB loss:4.6512\n",
      "Pretrain epoch [21/197], ZINB loss:0.3882, NB loss:4.6902\n",
      "Pretrain epoch [22/197], ZINB loss:0.3889, NB loss:4.6993\n",
      "Pretrain epoch [23/197], ZINB loss:0.3943, NB loss:4.6536\n",
      "Pretrain epoch [24/197], ZINB loss:0.3978, NB loss:4.6982\n",
      "Pretrain epoch [25/197], ZINB loss:0.3916, NB loss:4.6497\n",
      "Pretrain epoch [26/197], ZINB loss:0.3834, NB loss:4.7289\n",
      "Pretrain epoch [27/197], ZINB loss:0.5795, NB loss:4.6987\n",
      "Pretrain epoch [1/198], ZINB loss:0.3946, NB loss:4.6258\n",
      "Pretrain epoch [2/198], ZINB loss:0.3958, NB loss:4.7557\n",
      "Pretrain epoch [3/198], ZINB loss:0.3959, NB loss:4.6179\n",
      "Pretrain epoch [4/198], ZINB loss:0.3969, NB loss:4.7484\n",
      "Pretrain epoch [5/198], ZINB loss:0.3689, NB loss:4.6703\n",
      "Pretrain epoch [6/198], ZINB loss:0.3944, NB loss:4.6433\n",
      "Pretrain epoch [7/198], ZINB loss:0.3980, NB loss:4.7195\n",
      "Pretrain epoch [8/198], ZINB loss:0.3975, NB loss:4.6499\n",
      "Pretrain epoch [9/198], ZINB loss:0.3859, NB loss:4.7206\n",
      "Pretrain epoch [10/198], ZINB loss:0.3934, NB loss:4.6713\n",
      "Pretrain epoch [11/198], ZINB loss:0.3906, NB loss:4.7586\n",
      "Pretrain epoch [12/198], ZINB loss:0.3863, NB loss:4.6762\n",
      "Pretrain epoch [13/198], ZINB loss:0.4213, NB loss:4.6969\n",
      "Pretrain epoch [14/198], ZINB loss:0.3862, NB loss:4.6881\n",
      "Pretrain epoch [15/198], ZINB loss:0.4112, NB loss:4.6877\n",
      "Pretrain epoch [16/198], ZINB loss:0.3730, NB loss:4.7213\n",
      "Pretrain epoch [17/198], ZINB loss:0.4170, NB loss:4.6912\n",
      "Pretrain epoch [18/198], ZINB loss:0.3783, NB loss:4.7257\n",
      "Pretrain epoch [19/198], ZINB loss:0.3774, NB loss:4.6560\n",
      "Pretrain epoch [20/198], ZINB loss:0.3843, NB loss:4.7331\n",
      "Pretrain epoch [21/198], ZINB loss:0.3965, NB loss:4.7063\n",
      "Pretrain epoch [22/198], ZINB loss:0.3806, NB loss:4.6903\n",
      "Pretrain epoch [23/198], ZINB loss:0.3762, NB loss:4.6753\n",
      "Pretrain epoch [24/198], ZINB loss:0.4033, NB loss:4.6328\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [25/198], ZINB loss:0.3912, NB loss:4.7105\n",
      "Pretrain epoch [26/198], ZINB loss:0.3933, NB loss:4.7506\n",
      "Pretrain epoch [27/198], ZINB loss:0.3266, NB loss:4.5733\n",
      "Pretrain epoch [1/199], ZINB loss:0.3849, NB loss:4.6722\n",
      "Pretrain epoch [2/199], ZINB loss:0.3931, NB loss:4.6647\n",
      "Pretrain epoch [3/199], ZINB loss:0.3660, NB loss:4.7369\n",
      "Pretrain epoch [4/199], ZINB loss:0.3972, NB loss:4.6809\n",
      "Pretrain epoch [5/199], ZINB loss:0.4173, NB loss:4.6794\n",
      "Pretrain epoch [6/199], ZINB loss:0.4094, NB loss:4.7522\n",
      "Pretrain epoch [7/199], ZINB loss:0.3901, NB loss:4.6934\n",
      "Pretrain epoch [8/199], ZINB loss:0.3939, NB loss:4.7019\n",
      "Pretrain epoch [9/199], ZINB loss:0.4040, NB loss:4.7722\n",
      "Pretrain epoch [10/199], ZINB loss:0.3933, NB loss:4.6746\n",
      "Pretrain epoch [11/199], ZINB loss:0.3794, NB loss:4.7084\n",
      "Pretrain epoch [12/199], ZINB loss:0.4016, NB loss:4.6637\n",
      "Pretrain epoch [13/199], ZINB loss:0.3874, NB loss:4.6154\n",
      "Pretrain epoch [14/199], ZINB loss:0.4005, NB loss:4.6430\n",
      "Pretrain epoch [15/199], ZINB loss:0.3806, NB loss:4.6458\n",
      "Pretrain epoch [16/199], ZINB loss:0.3927, NB loss:4.7137\n",
      "Pretrain epoch [17/199], ZINB loss:0.3841, NB loss:4.6438\n",
      "Pretrain epoch [18/199], ZINB loss:0.3885, NB loss:4.7050\n",
      "Pretrain epoch [19/199], ZINB loss:0.3877, NB loss:4.6632\n",
      "Pretrain epoch [20/199], ZINB loss:0.3965, NB loss:4.7511\n",
      "Pretrain epoch [21/199], ZINB loss:0.3909, NB loss:4.7884\n",
      "Pretrain epoch [22/199], ZINB loss:0.4006, NB loss:4.7620\n",
      "Pretrain epoch [23/199], ZINB loss:0.3991, NB loss:4.6299\n",
      "Pretrain epoch [24/199], ZINB loss:0.3936, NB loss:4.6799\n",
      "Pretrain epoch [25/199], ZINB loss:0.3956, NB loss:4.7028\n",
      "Pretrain epoch [26/199], ZINB loss:0.4004, NB loss:4.6520\n",
      "Pretrain epoch [27/199], ZINB loss:0.2794, NB loss:4.9187\n",
      "Pretrain epoch [1/200], ZINB loss:0.4081, NB loss:4.6825\n",
      "Pretrain epoch [2/200], ZINB loss:0.3865, NB loss:4.6742\n",
      "Pretrain epoch [3/200], ZINB loss:0.4031, NB loss:4.7252\n",
      "Pretrain epoch [4/200], ZINB loss:0.3770, NB loss:4.6576\n",
      "Pretrain epoch [5/200], ZINB loss:0.3922, NB loss:4.7179\n",
      "Pretrain epoch [6/200], ZINB loss:0.3824, NB loss:4.7285\n",
      "Pretrain epoch [7/200], ZINB loss:0.4157, NB loss:4.6767\n",
      "Pretrain epoch [8/200], ZINB loss:0.4061, NB loss:4.6549\n",
      "Pretrain epoch [9/200], ZINB loss:0.4034, NB loss:4.7138\n",
      "Pretrain epoch [10/200], ZINB loss:0.3939, NB loss:4.6991\n",
      "Pretrain epoch [11/200], ZINB loss:0.4091, NB loss:4.7165\n",
      "Pretrain epoch [12/200], ZINB loss:0.3820, NB loss:4.6450\n",
      "Pretrain epoch [13/200], ZINB loss:0.3902, NB loss:4.6623\n",
      "Pretrain epoch [14/200], ZINB loss:0.3720, NB loss:4.7080\n",
      "Pretrain epoch [15/200], ZINB loss:0.3841, NB loss:4.7066\n",
      "Pretrain epoch [16/200], ZINB loss:0.3910, NB loss:4.7036\n",
      "Pretrain epoch [17/200], ZINB loss:0.3884, NB loss:4.7256\n",
      "Pretrain epoch [18/200], ZINB loss:0.3852, NB loss:4.6882\n",
      "Pretrain epoch [19/200], ZINB loss:0.3785, NB loss:4.5968\n",
      "Pretrain epoch [20/200], ZINB loss:0.3957, NB loss:4.6636\n",
      "Pretrain epoch [21/200], ZINB loss:0.4013, NB loss:4.6690\n",
      "Pretrain epoch [22/200], ZINB loss:0.3709, NB loss:4.7758\n",
      "Pretrain epoch [23/200], ZINB loss:0.3744, NB loss:4.7734\n",
      "Pretrain epoch [24/200], ZINB loss:0.3947, NB loss:4.6687\n",
      "Pretrain epoch [25/200], ZINB loss:0.3946, NB loss:4.6658\n",
      "Pretrain epoch [26/200], ZINB loss:0.4144, NB loss:4.6469\n",
      "Pretrain epoch [27/200], ZINB loss:0.3862, NB loss:4.6331\n",
      "Pretrain epoch [1/201], ZINB loss:0.4068, NB loss:4.7643\n",
      "Pretrain epoch [2/201], ZINB loss:0.3916, NB loss:4.6978\n",
      "Pretrain epoch [3/201], ZINB loss:0.3971, NB loss:4.6723\n",
      "Pretrain epoch [4/201], ZINB loss:0.3850, NB loss:4.6800\n",
      "Pretrain epoch [5/201], ZINB loss:0.3712, NB loss:4.6663\n",
      "Pretrain epoch [6/201], ZINB loss:0.3805, NB loss:4.6592\n",
      "Pretrain epoch [7/201], ZINB loss:0.3897, NB loss:4.6492\n",
      "Pretrain epoch [8/201], ZINB loss:0.3865, NB loss:4.6482\n",
      "Pretrain epoch [9/201], ZINB loss:0.3856, NB loss:4.6840\n",
      "Pretrain epoch [10/201], ZINB loss:0.3583, NB loss:4.7448\n",
      "Pretrain epoch [11/201], ZINB loss:0.3942, NB loss:4.6282\n",
      "Pretrain epoch [12/201], ZINB loss:0.3861, NB loss:4.6931\n",
      "Pretrain epoch [13/201], ZINB loss:0.3878, NB loss:4.6177\n",
      "Pretrain epoch [14/201], ZINB loss:0.4201, NB loss:4.6314\n",
      "Pretrain epoch [15/201], ZINB loss:0.4035, NB loss:4.7030\n",
      "Pretrain epoch [16/201], ZINB loss:0.4074, NB loss:4.7486\n",
      "Pretrain epoch [17/201], ZINB loss:0.3878, NB loss:4.7209\n",
      "Pretrain epoch [18/201], ZINB loss:0.4072, NB loss:4.6351\n",
      "Pretrain epoch [19/201], ZINB loss:0.3975, NB loss:4.6778\n",
      "Pretrain epoch [20/201], ZINB loss:0.3899, NB loss:4.6555\n",
      "Pretrain epoch [21/201], ZINB loss:0.3980, NB loss:4.7476\n",
      "Pretrain epoch [22/201], ZINB loss:0.3939, NB loss:4.6858\n",
      "Pretrain epoch [23/201], ZINB loss:0.3934, NB loss:4.7586\n",
      "Pretrain epoch [24/201], ZINB loss:0.3856, NB loss:4.7508\n",
      "Pretrain epoch [25/201], ZINB loss:0.3731, NB loss:4.6940\n",
      "Pretrain epoch [26/201], ZINB loss:0.4046, NB loss:4.6764\n",
      "Pretrain epoch [27/201], ZINB loss:0.3454, NB loss:4.7573\n",
      "Pretrain epoch [1/202], ZINB loss:0.4037, NB loss:4.7280, latent MSE loss:1.39094925, KL loss:0.00796125\n",
      "Pretrain epoch [2/202], ZINB loss:0.3902, NB loss:4.7887, latent MSE loss:0.63788694, KL loss:0.00649847\n",
      "Pretrain epoch [3/202], ZINB loss:0.4194, NB loss:4.6960, latent MSE loss:0.27740785, KL loss:0.00452620\n",
      "Pretrain epoch [4/202], ZINB loss:0.4609, NB loss:4.6819, latent MSE loss:0.17716669, KL loss:0.00324253\n",
      "Pretrain epoch [5/202], ZINB loss:0.4721, NB loss:4.6481, latent MSE loss:0.12547676, KL loss:0.00285186\n",
      "Pretrain epoch [6/202], ZINB loss:0.5051, NB loss:4.6327, latent MSE loss:0.11582720, KL loss:0.00253712\n",
      "Pretrain epoch [7/202], ZINB loss:0.4918, NB loss:4.7256, latent MSE loss:0.10257532, KL loss:0.00262592\n",
      "Pretrain epoch [8/202], ZINB loss:0.4822, NB loss:4.6302, latent MSE loss:0.09905273, KL loss:0.00260271\n",
      "Pretrain epoch [9/202], ZINB loss:0.4777, NB loss:4.7653, latent MSE loss:0.08500772, KL loss:0.00273390\n",
      "Pretrain epoch [10/202], ZINB loss:0.4644, NB loss:4.6989, latent MSE loss:0.07644316, KL loss:0.00279869\n",
      "Pretrain epoch [11/202], ZINB loss:0.4580, NB loss:4.6835, latent MSE loss:0.07399469, KL loss:0.00283245\n",
      "Pretrain epoch [12/202], ZINB loss:0.4706, NB loss:4.7053, latent MSE loss:0.07329523, KL loss:0.00297131\n",
      "Pretrain epoch [13/202], ZINB loss:0.4452, NB loss:4.6942, latent MSE loss:0.06803274, KL loss:0.00298530\n",
      "Pretrain epoch [14/202], ZINB loss:0.4651, NB loss:4.6453, latent MSE loss:0.06561331, KL loss:0.00315020\n",
      "Pretrain epoch [15/202], ZINB loss:0.4547, NB loss:4.6158, latent MSE loss:0.06278183, KL loss:0.00331404\n",
      "Pretrain epoch [16/202], ZINB loss:0.4312, NB loss:4.7378, latent MSE loss:0.05487236, KL loss:0.00365358\n",
      "Pretrain epoch [17/202], ZINB loss:0.4409, NB loss:4.6875, latent MSE loss:0.05144165, KL loss:0.00391998\n",
      "Pretrain epoch [18/202], ZINB loss:0.4269, NB loss:4.6563, latent MSE loss:0.04787658, KL loss:0.00419674\n",
      "Pretrain epoch [19/202], ZINB loss:0.4449, NB loss:4.6956, latent MSE loss:0.04458000, KL loss:0.00449956\n",
      "Pretrain epoch [20/202], ZINB loss:0.4501, NB loss:4.7202, latent MSE loss:0.04299396, KL loss:0.00466063\n",
      "Pretrain epoch [21/202], ZINB loss:0.4394, NB loss:4.6182, latent MSE loss:0.03754482, KL loss:0.00477960\n",
      "Pretrain epoch [22/202], ZINB loss:0.4418, NB loss:4.7160, latent MSE loss:0.03612963, KL loss:0.00495288\n",
      "Pretrain epoch [23/202], ZINB loss:0.4649, NB loss:4.6796, latent MSE loss:0.03198716, KL loss:0.00492461\n",
      "Pretrain epoch [24/202], ZINB loss:0.4161, NB loss:4.6918, latent MSE loss:0.03120181, KL loss:0.00505048\n",
      "Pretrain epoch [25/202], ZINB loss:0.4412, NB loss:4.6426, latent MSE loss:0.02741145, KL loss:0.00509153\n",
      "Pretrain epoch [26/202], ZINB loss:0.4210, NB loss:4.6677, latent MSE loss:0.02528000, KL loss:0.00513988\n",
      "Pretrain epoch [27/202], ZINB loss:0.4546, NB loss:4.9295, latent MSE loss:0.03173966, KL loss:0.00004332\n",
      "Pretrain epoch [1/203], ZINB loss:0.4405, NB loss:4.7019, latent MSE loss:0.02534471, KL loss:0.00542689\n",
      "Pretrain epoch [2/203], ZINB loss:0.4227, NB loss:4.7059, latent MSE loss:0.02424302, KL loss:0.00522179\n",
      "Pretrain epoch [3/203], ZINB loss:0.4433, NB loss:4.6449, latent MSE loss:0.02199410, KL loss:0.00503077\n",
      "Pretrain epoch [4/203], ZINB loss:0.4348, NB loss:4.6697, latent MSE loss:0.02272897, KL loss:0.00530176\n",
      "Pretrain epoch [5/203], ZINB loss:0.4330, NB loss:4.7002, latent MSE loss:0.02026257, KL loss:0.00544951\n",
      "Pretrain epoch [6/203], ZINB loss:0.4675, NB loss:4.6490, latent MSE loss:0.02011024, KL loss:0.00543611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [7/203], ZINB loss:0.4172, NB loss:4.6577, latent MSE loss:0.01991048, KL loss:0.00548785\n",
      "Pretrain epoch [8/203], ZINB loss:0.4440, NB loss:4.6562, latent MSE loss:0.02057032, KL loss:0.00548430\n",
      "Pretrain epoch [9/203], ZINB loss:0.4192, NB loss:4.7090, latent MSE loss:0.01767373, KL loss:0.00556250\n",
      "Pretrain epoch [10/203], ZINB loss:0.4396, NB loss:4.6806, latent MSE loss:0.01855915, KL loss:0.00559204\n",
      "Pretrain epoch [11/203], ZINB loss:0.4188, NB loss:4.6576, latent MSE loss:0.01616689, KL loss:0.00555502\n",
      "Pretrain epoch [12/203], ZINB loss:0.4239, NB loss:4.6842, latent MSE loss:0.01646357, KL loss:0.00548004\n",
      "Pretrain epoch [13/203], ZINB loss:0.4332, NB loss:4.6906, latent MSE loss:0.01515420, KL loss:0.00542812\n",
      "Pretrain epoch [14/203], ZINB loss:0.4180, NB loss:4.7094, latent MSE loss:0.01396909, KL loss:0.00557205\n",
      "Pretrain epoch [15/203], ZINB loss:0.4090, NB loss:4.7727, latent MSE loss:0.01320106, KL loss:0.00586077\n",
      "Pretrain epoch [16/203], ZINB loss:0.4124, NB loss:4.6828, latent MSE loss:0.01223941, KL loss:0.00564347\n",
      "Pretrain epoch [17/203], ZINB loss:0.4234, NB loss:4.7035, latent MSE loss:0.01168483, KL loss:0.00571750\n",
      "Pretrain epoch [18/203], ZINB loss:0.4192, NB loss:4.6378, latent MSE loss:0.01201470, KL loss:0.00551925\n",
      "Pretrain epoch [19/203], ZINB loss:0.4364, NB loss:4.7343, latent MSE loss:0.01281395, KL loss:0.00577633\n",
      "Pretrain epoch [20/203], ZINB loss:0.4126, NB loss:4.6758, latent MSE loss:0.01148322, KL loss:0.00571840\n",
      "Pretrain epoch [21/203], ZINB loss:0.4418, NB loss:4.7334, latent MSE loss:0.00964520, KL loss:0.00559756\n",
      "Pretrain epoch [22/203], ZINB loss:0.4210, NB loss:4.7360, latent MSE loss:0.01100762, KL loss:0.00597294\n",
      "Pretrain epoch [23/203], ZINB loss:0.4496, NB loss:4.6631, latent MSE loss:0.01266445, KL loss:0.00569032\n",
      "Pretrain epoch [24/203], ZINB loss:0.4177, NB loss:4.5826, latent MSE loss:0.00968044, KL loss:0.00560651\n",
      "Pretrain epoch [25/203], ZINB loss:0.4466, NB loss:4.6700, latent MSE loss:0.01064938, KL loss:0.00593324\n",
      "Pretrain epoch [26/203], ZINB loss:0.4201, NB loss:4.6975, latent MSE loss:0.00961616, KL loss:0.00590153\n",
      "Pretrain epoch [27/203], ZINB loss:0.3962, NB loss:4.3907, latent MSE loss:0.00829559, KL loss:0.00003943\n",
      "Pretrain epoch [1/204], ZINB loss:0.4251, NB loss:4.6976, latent MSE loss:0.00945457, KL loss:0.00583158\n",
      "Pretrain epoch [2/204], ZINB loss:0.4214, NB loss:4.6286, latent MSE loss:0.01052662, KL loss:0.00575081\n",
      "Pretrain epoch [3/204], ZINB loss:0.4184, NB loss:4.6872, latent MSE loss:0.01084958, KL loss:0.00587135\n",
      "Pretrain epoch [4/204], ZINB loss:0.4319, NB loss:4.7541, latent MSE loss:0.01020273, KL loss:0.00591295\n",
      "Pretrain epoch [5/204], ZINB loss:0.4386, NB loss:4.7162, latent MSE loss:0.01046110, KL loss:0.00579178\n",
      "Pretrain epoch [6/204], ZINB loss:0.4396, NB loss:4.7374, latent MSE loss:0.00952274, KL loss:0.00596395\n",
      "Pretrain epoch [7/204], ZINB loss:0.4054, NB loss:4.6962, latent MSE loss:0.00849600, KL loss:0.00586355\n",
      "Pretrain epoch [8/204], ZINB loss:0.4240, NB loss:4.7148, latent MSE loss:0.00851138, KL loss:0.00589554\n",
      "Pretrain epoch [9/204], ZINB loss:0.4262, NB loss:4.7237, latent MSE loss:0.00760517, KL loss:0.00601916\n",
      "Pretrain epoch [10/204], ZINB loss:0.4029, NB loss:4.7244, latent MSE loss:0.00797062, KL loss:0.00594242\n",
      "Pretrain epoch [11/204], ZINB loss:0.4284, NB loss:4.6538, latent MSE loss:0.00776174, KL loss:0.00574182\n",
      "Pretrain epoch [12/204], ZINB loss:0.4400, NB loss:4.6655, latent MSE loss:0.00855229, KL loss:0.00571092\n",
      "Pretrain epoch [13/204], ZINB loss:0.4193, NB loss:4.6757, latent MSE loss:0.00881237, KL loss:0.00589319\n",
      "Pretrain epoch [14/204], ZINB loss:0.4248, NB loss:4.5882, latent MSE loss:0.00822552, KL loss:0.00578224\n",
      "Pretrain epoch [15/204], ZINB loss:0.4140, NB loss:4.6774, latent MSE loss:0.00812143, KL loss:0.00594619\n",
      "Pretrain epoch [16/204], ZINB loss:0.4318, NB loss:4.7424, latent MSE loss:0.00733234, KL loss:0.00596345\n",
      "Pretrain epoch [17/204], ZINB loss:0.4376, NB loss:4.6607, latent MSE loss:0.00720739, KL loss:0.00575283\n",
      "Pretrain epoch [18/204], ZINB loss:0.4185, NB loss:4.7629, latent MSE loss:0.00685345, KL loss:0.00584501\n",
      "Pretrain epoch [19/204], ZINB loss:0.4160, NB loss:4.6931, latent MSE loss:0.00672595, KL loss:0.00564073\n",
      "Pretrain epoch [20/204], ZINB loss:0.4346, NB loss:4.6417, latent MSE loss:0.00713431, KL loss:0.00589641\n",
      "Pretrain epoch [21/204], ZINB loss:0.4215, NB loss:4.6769, latent MSE loss:0.00583091, KL loss:0.00570638\n",
      "Pretrain epoch [22/204], ZINB loss:0.4200, NB loss:4.6518, latent MSE loss:0.00653660, KL loss:0.00584685\n",
      "Pretrain epoch [23/204], ZINB loss:0.4151, NB loss:4.6877, latent MSE loss:0.00598931, KL loss:0.00587886\n",
      "Pretrain epoch [24/204], ZINB loss:0.4374, NB loss:4.6477, latent MSE loss:0.00598764, KL loss:0.00593611\n",
      "Pretrain epoch [25/204], ZINB loss:0.4041, NB loss:4.6885, latent MSE loss:0.00537241, KL loss:0.00577258\n",
      "Pretrain epoch [26/204], ZINB loss:0.4088, NB loss:4.5638, latent MSE loss:0.00612361, KL loss:0.00570995\n",
      "Pretrain epoch [27/204], ZINB loss:0.4272, NB loss:4.4617, latent MSE loss:0.00460745, KL loss:0.00003982\n",
      "Pretrain epoch [1/205], ZINB loss:0.4427, NB loss:4.6270, latent MSE loss:0.00634135, KL loss:0.00560372\n",
      "Pretrain epoch [2/205], ZINB loss:0.4105, NB loss:4.6910, latent MSE loss:0.00541679, KL loss:0.00589170\n",
      "Pretrain epoch [3/205], ZINB loss:0.4167, NB loss:4.7256, latent MSE loss:0.00479951, KL loss:0.00570793\n",
      "Pretrain epoch [4/205], ZINB loss:0.4258, NB loss:4.7047, latent MSE loss:0.00509131, KL loss:0.00598961\n",
      "Pretrain epoch [5/205], ZINB loss:0.4269, NB loss:4.6874, latent MSE loss:0.00503671, KL loss:0.00572069\n",
      "Pretrain epoch [6/205], ZINB loss:0.4290, NB loss:4.6673, latent MSE loss:0.00483615, KL loss:0.00564976\n",
      "Pretrain epoch [7/205], ZINB loss:0.4227, NB loss:4.6447, latent MSE loss:0.00459601, KL loss:0.00599663\n",
      "Pretrain epoch [8/205], ZINB loss:0.3970, NB loss:4.6534, latent MSE loss:0.00380380, KL loss:0.00571841\n",
      "Pretrain epoch [9/205], ZINB loss:0.4271, NB loss:4.6722, latent MSE loss:0.00438523, KL loss:0.00565181\n",
      "Pretrain epoch [10/205], ZINB loss:0.4288, NB loss:4.6755, latent MSE loss:0.00429775, KL loss:0.00567203\n",
      "Pretrain epoch [11/205], ZINB loss:0.4046, NB loss:4.6437, latent MSE loss:0.00419067, KL loss:0.00557767\n",
      "Pretrain epoch [12/205], ZINB loss:0.4194, NB loss:4.6851, latent MSE loss:0.00408141, KL loss:0.00591097\n",
      "Pretrain epoch [13/205], ZINB loss:0.4126, NB loss:4.6898, latent MSE loss:0.00379302, KL loss:0.00544000\n",
      "Pretrain epoch [14/205], ZINB loss:0.4222, NB loss:4.6975, latent MSE loss:0.00422762, KL loss:0.00566552\n",
      "Pretrain epoch [15/205], ZINB loss:0.4201, NB loss:4.6313, latent MSE loss:0.00428053, KL loss:0.00559575\n",
      "Pretrain epoch [16/205], ZINB loss:0.4172, NB loss:4.7067, latent MSE loss:0.00566338, KL loss:0.00537864\n",
      "Pretrain epoch [17/205], ZINB loss:0.4350, NB loss:4.7795, latent MSE loss:0.00631117, KL loss:0.00597556\n",
      "Pretrain epoch [18/205], ZINB loss:0.4149, NB loss:4.6471, latent MSE loss:0.00456013, KL loss:0.00535227\n",
      "Pretrain epoch [19/205], ZINB loss:0.4040, NB loss:4.6310, latent MSE loss:0.00404994, KL loss:0.00530433\n",
      "Pretrain epoch [20/205], ZINB loss:0.3935, NB loss:4.6749, latent MSE loss:0.00317285, KL loss:0.00535771\n",
      "Pretrain epoch [21/205], ZINB loss:0.4067, NB loss:4.6459, latent MSE loss:0.00366862, KL loss:0.00545189\n",
      "Pretrain epoch [22/205], ZINB loss:0.4015, NB loss:4.6948, latent MSE loss:0.00391521, KL loss:0.00530632\n",
      "Pretrain epoch [23/205], ZINB loss:0.4172, NB loss:4.7875, latent MSE loss:0.00461733, KL loss:0.00530526\n",
      "Pretrain epoch [24/205], ZINB loss:0.4145, NB loss:4.6823, latent MSE loss:0.00355793, KL loss:0.00532614\n",
      "Pretrain epoch [25/205], ZINB loss:0.4030, NB loss:4.6493, latent MSE loss:0.00342785, KL loss:0.00517406\n",
      "Pretrain epoch [26/205], ZINB loss:0.4190, NB loss:4.7190, latent MSE loss:0.00413136, KL loss:0.00526970\n",
      "Pretrain epoch [27/205], ZINB loss:0.4026, NB loss:4.9653, latent MSE loss:0.00254840, KL loss:0.00004467\n",
      "Pretrain epoch [1/206], ZINB loss:0.4079, NB loss:4.7136, latent MSE loss:0.00388086, KL loss:0.00505985\n",
      "Pretrain epoch [2/206], ZINB loss:0.3964, NB loss:4.6755, latent MSE loss:0.00363750, KL loss:0.00493972\n",
      "Pretrain epoch [3/206], ZINB loss:0.4131, NB loss:4.7296, latent MSE loss:0.00393780, KL loss:0.00530454\n",
      "Pretrain epoch [4/206], ZINB loss:0.4247, NB loss:4.6611, latent MSE loss:0.00382333, KL loss:0.00504056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [5/206], ZINB loss:0.4207, NB loss:4.6650, latent MSE loss:0.00344262, KL loss:0.00499818\n",
      "Pretrain epoch [6/206], ZINB loss:0.3978, NB loss:4.6783, latent MSE loss:0.00330984, KL loss:0.00489309\n",
      "Pretrain epoch [7/206], ZINB loss:0.4335, NB loss:4.6735, latent MSE loss:0.00461957, KL loss:0.00485306\n",
      "Pretrain epoch [8/206], ZINB loss:0.4099, NB loss:4.6709, latent MSE loss:0.00393671, KL loss:0.00476359\n",
      "Pretrain epoch [9/206], ZINB loss:0.4127, NB loss:4.6033, latent MSE loss:0.00315021, KL loss:0.00456141\n",
      "Pretrain epoch [10/206], ZINB loss:0.3995, NB loss:4.7388, latent MSE loss:0.00420952, KL loss:0.00485844\n",
      "Pretrain epoch [11/206], ZINB loss:0.4243, NB loss:4.6961, latent MSE loss:0.00480634, KL loss:0.00473043\n",
      "Pretrain epoch [12/206], ZINB loss:0.4326, NB loss:4.6748, latent MSE loss:0.00337308, KL loss:0.00493967\n",
      "Pretrain epoch [13/206], ZINB loss:0.4073, NB loss:4.6529, latent MSE loss:0.00351352, KL loss:0.00464166\n",
      "Pretrain epoch [14/206], ZINB loss:0.4257, NB loss:4.6539, latent MSE loss:0.00356992, KL loss:0.00482495\n",
      "Pretrain epoch [15/206], ZINB loss:0.4099, NB loss:4.6320, latent MSE loss:0.00310532, KL loss:0.00471391\n",
      "Pretrain epoch [16/206], ZINB loss:0.4065, NB loss:4.6821, latent MSE loss:0.00330998, KL loss:0.00459233\n",
      "Pretrain epoch [17/206], ZINB loss:0.4238, NB loss:4.7126, latent MSE loss:0.00390744, KL loss:0.00480084\n",
      "Pretrain epoch [18/206], ZINB loss:0.4145, NB loss:4.6655, latent MSE loss:0.00376029, KL loss:0.00409976\n",
      "Pretrain epoch [19/206], ZINB loss:0.4137, NB loss:4.6489, latent MSE loss:0.00382653, KL loss:0.00437988\n",
      "Pretrain epoch [20/206], ZINB loss:0.4036, NB loss:4.6616, latent MSE loss:0.00290620, KL loss:0.00501234\n",
      "Pretrain epoch [21/206], ZINB loss:0.4032, NB loss:4.6941, latent MSE loss:0.00295605, KL loss:0.00458607\n",
      "Pretrain epoch [22/206], ZINB loss:0.4122, NB loss:4.7057, latent MSE loss:0.00331179, KL loss:0.00495587\n",
      "Pretrain epoch [23/206], ZINB loss:0.4346, NB loss:4.6848, latent MSE loss:0.00361643, KL loss:0.00479495\n",
      "Pretrain epoch [24/206], ZINB loss:0.4158, NB loss:4.6907, latent MSE loss:0.00326864, KL loss:0.00433167\n",
      "Pretrain epoch [25/206], ZINB loss:0.4190, NB loss:4.7236, latent MSE loss:0.00329625, KL loss:0.00484979\n",
      "Pretrain epoch [26/206], ZINB loss:0.4099, NB loss:4.6810, latent MSE loss:0.00314656, KL loss:0.00435414\n",
      "Pretrain epoch [27/206], ZINB loss:0.3216, NB loss:4.6605, latent MSE loss:0.00111544, KL loss:0.00003074\n",
      "Pretrain epoch [1/207], ZINB loss:0.4290, NB loss:4.6475, latent MSE loss:0.00341079, KL loss:0.00442029\n",
      "Pretrain epoch [2/207], ZINB loss:0.3940, NB loss:4.6545, latent MSE loss:0.00298920, KL loss:0.00423496\n",
      "Pretrain epoch [3/207], ZINB loss:0.4024, NB loss:4.7373, latent MSE loss:0.00283828, KL loss:0.00436732\n",
      "Pretrain epoch [4/207], ZINB loss:0.4111, NB loss:4.7026, latent MSE loss:0.00288225, KL loss:0.00466252\n",
      "Pretrain epoch [5/207], ZINB loss:0.4133, NB loss:4.7278, latent MSE loss:0.00375488, KL loss:0.00433112\n",
      "Pretrain epoch [6/207], ZINB loss:0.4138, NB loss:4.7927, latent MSE loss:0.00309613, KL loss:0.00446953\n",
      "Pretrain epoch [7/207], ZINB loss:0.4020, NB loss:4.7149, latent MSE loss:0.00297244, KL loss:0.00438871\n",
      "Pretrain epoch [8/207], ZINB loss:0.4106, NB loss:4.6626, latent MSE loss:0.00326557, KL loss:0.00464255\n",
      "Pretrain epoch [9/207], ZINB loss:0.4178, NB loss:4.6375, latent MSE loss:0.00296372, KL loss:0.00413254\n",
      "Pretrain epoch [10/207], ZINB loss:0.4241, NB loss:4.6625, latent MSE loss:0.00327312, KL loss:0.00402557\n",
      "Pretrain epoch [11/207], ZINB loss:0.3944, NB loss:4.7707, latent MSE loss:0.00283869, KL loss:0.00438697\n",
      "Pretrain epoch [12/207], ZINB loss:0.4150, NB loss:4.6054, latent MSE loss:0.00281332, KL loss:0.00419548\n",
      "Pretrain epoch [13/207], ZINB loss:0.4053, NB loss:4.6574, latent MSE loss:0.00265069, KL loss:0.00380225\n",
      "Pretrain epoch [14/207], ZINB loss:0.4084, NB loss:4.6211, latent MSE loss:0.00277765, KL loss:0.00436707\n",
      "Pretrain epoch [15/207], ZINB loss:0.4109, NB loss:4.6295, latent MSE loss:0.00272320, KL loss:0.00432408\n",
      "Pretrain epoch [16/207], ZINB loss:0.4173, NB loss:4.6480, latent MSE loss:0.00302639, KL loss:0.00405775\n",
      "Pretrain epoch [17/207], ZINB loss:0.4096, NB loss:4.7367, latent MSE loss:0.00448869, KL loss:0.00462665\n",
      "Pretrain epoch [18/207], ZINB loss:0.4181, NB loss:4.6612, latent MSE loss:0.00375885, KL loss:0.00450486\n",
      "Pretrain epoch [19/207], ZINB loss:0.4162, NB loss:4.6547, latent MSE loss:0.00333285, KL loss:0.00407328\n",
      "Pretrain epoch [20/207], ZINB loss:0.4177, NB loss:4.6371, latent MSE loss:0.00364336, KL loss:0.00415060\n",
      "Pretrain epoch [21/207], ZINB loss:0.4065, NB loss:4.6682, latent MSE loss:0.00311918, KL loss:0.00392927\n",
      "Pretrain epoch [22/207], ZINB loss:0.4214, NB loss:4.6494, latent MSE loss:0.00312168, KL loss:0.00408605\n",
      "Pretrain epoch [23/207], ZINB loss:0.4056, NB loss:4.6771, latent MSE loss:0.00266083, KL loss:0.00432855\n",
      "Pretrain epoch [24/207], ZINB loss:0.4202, NB loss:4.7184, latent MSE loss:0.00268058, KL loss:0.00402972\n",
      "Pretrain epoch [25/207], ZINB loss:0.4338, NB loss:4.6676, latent MSE loss:0.00310343, KL loss:0.00426708\n",
      "Pretrain epoch [26/207], ZINB loss:0.4314, NB loss:4.6605, latent MSE loss:0.00324108, KL loss:0.00381211\n",
      "Pretrain epoch [27/207], ZINB loss:0.3438, NB loss:5.6489, latent MSE loss:0.00261499, KL loss:0.00007179\n",
      "Pretrain epoch [1/208], ZINB loss:0.4136, NB loss:4.6426, latent MSE loss:0.00281749, KL loss:0.00400830\n",
      "Pretrain epoch [2/208], ZINB loss:0.4059, NB loss:4.6285, latent MSE loss:0.00293004, KL loss:0.00406039\n",
      "Pretrain epoch [3/208], ZINB loss:0.4344, NB loss:4.7421, latent MSE loss:0.00301683, KL loss:0.00436593\n",
      "Pretrain epoch [4/208], ZINB loss:0.3929, NB loss:4.6732, latent MSE loss:0.00238123, KL loss:0.00387178\n",
      "Pretrain epoch [5/208], ZINB loss:0.4183, NB loss:4.6599, latent MSE loss:0.00259276, KL loss:0.00382994\n",
      "Pretrain epoch [6/208], ZINB loss:0.4025, NB loss:4.7220, latent MSE loss:0.00281746, KL loss:0.00390879\n",
      "Pretrain epoch [7/208], ZINB loss:0.4089, NB loss:4.6496, latent MSE loss:0.00268637, KL loss:0.00397988\n",
      "Pretrain epoch [8/208], ZINB loss:0.4138, NB loss:4.6384, latent MSE loss:0.00287576, KL loss:0.00380089\n",
      "Pretrain epoch [9/208], ZINB loss:0.4141, NB loss:4.7056, latent MSE loss:0.00271372, KL loss:0.00395201\n",
      "Pretrain epoch [10/208], ZINB loss:0.4275, NB loss:4.6802, latent MSE loss:0.00307562, KL loss:0.00408458\n",
      "Pretrain epoch [11/208], ZINB loss:0.4333, NB loss:4.6676, latent MSE loss:0.00310962, KL loss:0.00402567\n",
      "Pretrain epoch [12/208], ZINB loss:0.4108, NB loss:4.7177, latent MSE loss:0.00307472, KL loss:0.00404823\n",
      "Pretrain epoch [13/208], ZINB loss:0.4042, NB loss:4.6459, latent MSE loss:0.00249131, KL loss:0.00372347\n",
      "Pretrain epoch [14/208], ZINB loss:0.3996, NB loss:4.6992, latent MSE loss:0.00275517, KL loss:0.00380248\n",
      "Pretrain epoch [15/208], ZINB loss:0.4039, NB loss:4.7180, latent MSE loss:0.00313386, KL loss:0.00381947\n",
      "Pretrain epoch [16/208], ZINB loss:0.4099, NB loss:4.6855, latent MSE loss:0.00326482, KL loss:0.00417480\n",
      "Pretrain epoch [17/208], ZINB loss:0.4238, NB loss:4.5728, latent MSE loss:0.00302550, KL loss:0.00421766\n",
      "Pretrain epoch [18/208], ZINB loss:0.4035, NB loss:4.6844, latent MSE loss:0.00307470, KL loss:0.00379978\n",
      "Pretrain epoch [19/208], ZINB loss:0.4115, NB loss:4.6971, latent MSE loss:0.00276724, KL loss:0.00371979\n",
      "Pretrain epoch [20/208], ZINB loss:0.4130, NB loss:4.6243, latent MSE loss:0.00231655, KL loss:0.00348210\n",
      "Pretrain epoch [21/208], ZINB loss:0.4275, NB loss:4.6753, latent MSE loss:0.00280178, KL loss:0.00390625\n",
      "Pretrain epoch [22/208], ZINB loss:0.4068, NB loss:4.7485, latent MSE loss:0.00293978, KL loss:0.00426321\n",
      "Pretrain epoch [23/208], ZINB loss:0.3939, NB loss:4.6530, latent MSE loss:0.00231702, KL loss:0.00342745\n",
      "Pretrain epoch [24/208], ZINB loss:0.4053, NB loss:4.7294, latent MSE loss:0.00262436, KL loss:0.00400336\n",
      "Pretrain epoch [25/208], ZINB loss:0.4155, NB loss:4.7167, latent MSE loss:0.00261134, KL loss:0.00366107\n",
      "Pretrain epoch [26/208], ZINB loss:0.4293, NB loss:4.6637, latent MSE loss:0.00249817, KL loss:0.00401933\n",
      "Pretrain epoch [27/208], ZINB loss:0.5204, NB loss:4.3693, latent MSE loss:0.00240110, KL loss:0.00003567\n",
      "Pretrain epoch [1/209], ZINB loss:0.4112, NB loss:4.6256, latent MSE loss:0.00404417, KL loss:0.00417579\n",
      "Pretrain epoch [2/209], ZINB loss:0.4079, NB loss:4.6781, latent MSE loss:0.00450840, KL loss:0.00373956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [3/209], ZINB loss:0.4265, NB loss:4.7167, latent MSE loss:0.00430692, KL loss:0.00374460\n",
      "Pretrain epoch [4/209], ZINB loss:0.4053, NB loss:4.6946, latent MSE loss:0.00330324, KL loss:0.00357858\n",
      "Pretrain epoch [5/209], ZINB loss:0.4190, NB loss:4.7171, latent MSE loss:0.00379881, KL loss:0.00401743\n",
      "Pretrain epoch [6/209], ZINB loss:0.4225, NB loss:4.6162, latent MSE loss:0.00310878, KL loss:0.00367373\n",
      "Pretrain epoch [7/209], ZINB loss:0.4388, NB loss:4.6443, latent MSE loss:0.00356813, KL loss:0.00399279\n",
      "Pretrain epoch [8/209], ZINB loss:0.4245, NB loss:4.6347, latent MSE loss:0.00372501, KL loss:0.00393525\n",
      "Pretrain epoch [9/209], ZINB loss:0.4066, NB loss:4.6891, latent MSE loss:0.00298574, KL loss:0.00365896\n",
      "Pretrain epoch [10/209], ZINB loss:0.3984, NB loss:4.6599, latent MSE loss:0.00274115, KL loss:0.00357090\n",
      "Pretrain epoch [11/209], ZINB loss:0.4245, NB loss:4.6187, latent MSE loss:0.00334388, KL loss:0.00384153\n",
      "Pretrain epoch [12/209], ZINB loss:0.4226, NB loss:4.7223, latent MSE loss:0.00281790, KL loss:0.00413813\n",
      "Pretrain epoch [13/209], ZINB loss:0.4137, NB loss:4.6701, latent MSE loss:0.00299822, KL loss:0.00339760\n",
      "Pretrain epoch [14/209], ZINB loss:0.4223, NB loss:4.6539, latent MSE loss:0.00296770, KL loss:0.00416161\n",
      "Pretrain epoch [15/209], ZINB loss:0.3958, NB loss:4.6843, latent MSE loss:0.00280070, KL loss:0.00420933\n",
      "Pretrain epoch [16/209], ZINB loss:0.4125, NB loss:4.6874, latent MSE loss:0.00271594, KL loss:0.00346429\n",
      "Pretrain epoch [17/209], ZINB loss:0.4098, NB loss:4.6983, latent MSE loss:0.00257313, KL loss:0.00364608\n",
      "Pretrain epoch [18/209], ZINB loss:0.4227, NB loss:4.6937, latent MSE loss:0.00264795, KL loss:0.00387075\n",
      "Pretrain epoch [19/209], ZINB loss:0.3983, NB loss:4.7015, latent MSE loss:0.00269686, KL loss:0.00350955\n",
      "Pretrain epoch [20/209], ZINB loss:0.4247, NB loss:4.6965, latent MSE loss:0.00338818, KL loss:0.00384474\n",
      "Pretrain epoch [21/209], ZINB loss:0.4268, NB loss:4.6638, latent MSE loss:0.00281976, KL loss:0.00361963\n",
      "Pretrain epoch [22/209], ZINB loss:0.4026, NB loss:4.6543, latent MSE loss:0.00266497, KL loss:0.00377806\n",
      "Pretrain epoch [23/209], ZINB loss:0.4182, NB loss:4.7089, latent MSE loss:0.00268045, KL loss:0.00363427\n",
      "Pretrain epoch [24/209], ZINB loss:0.3899, NB loss:4.6889, latent MSE loss:0.00199735, KL loss:0.00371635\n",
      "Pretrain epoch [25/209], ZINB loss:0.4010, NB loss:4.6333, latent MSE loss:0.00214676, KL loss:0.00358134\n",
      "Pretrain epoch [26/209], ZINB loss:0.4184, NB loss:4.7003, latent MSE loss:0.00311960, KL loss:0.00362632\n",
      "Pretrain epoch [27/209], ZINB loss:0.3258, NB loss:4.4881, latent MSE loss:0.00183233, KL loss:0.00006975\n",
      "Pretrain epoch [1/210], ZINB loss:0.4275, NB loss:4.6357, latent MSE loss:0.00285825, KL loss:0.00400885\n",
      "Pretrain epoch [2/210], ZINB loss:0.4150, NB loss:4.5759, latent MSE loss:0.00242312, KL loss:0.00338247\n",
      "Pretrain epoch [3/210], ZINB loss:0.4161, NB loss:4.6990, latent MSE loss:0.00274339, KL loss:0.00369763\n",
      "Pretrain epoch [4/210], ZINB loss:0.4129, NB loss:4.6472, latent MSE loss:0.00182418, KL loss:0.00366421\n",
      "Pretrain epoch [5/210], ZINB loss:0.3979, NB loss:4.5914, latent MSE loss:0.00225542, KL loss:0.00338969\n",
      "Pretrain epoch [6/210], ZINB loss:0.4037, NB loss:4.7259, latent MSE loss:0.00213157, KL loss:0.00372572\n",
      "Pretrain epoch [7/210], ZINB loss:0.4110, NB loss:4.6257, latent MSE loss:0.00217972, KL loss:0.00413588\n",
      "Pretrain epoch [8/210], ZINB loss:0.4067, NB loss:4.7135, latent MSE loss:0.00246868, KL loss:0.00379886\n",
      "Pretrain epoch [9/210], ZINB loss:0.4013, NB loss:4.6832, latent MSE loss:0.00222950, KL loss:0.00345595\n",
      "Pretrain epoch [10/210], ZINB loss:0.4083, NB loss:4.6817, latent MSE loss:0.00235701, KL loss:0.00360477\n",
      "Pretrain epoch [11/210], ZINB loss:0.4189, NB loss:4.6582, latent MSE loss:0.00251682, KL loss:0.00396119\n",
      "Pretrain epoch [12/210], ZINB loss:0.4348, NB loss:4.6536, latent MSE loss:0.00300582, KL loss:0.00354635\n",
      "Pretrain epoch [13/210], ZINB loss:0.3986, NB loss:4.6532, latent MSE loss:0.00207362, KL loss:0.00325261\n",
      "Pretrain epoch [14/210], ZINB loss:0.4024, NB loss:4.7208, latent MSE loss:0.00205239, KL loss:0.00399998\n",
      "Pretrain epoch [15/210], ZINB loss:0.4387, NB loss:4.6811, latent MSE loss:0.00301459, KL loss:0.00360005\n",
      "Pretrain epoch [16/210], ZINB loss:0.4029, NB loss:4.7153, latent MSE loss:0.00237127, KL loss:0.00388993\n",
      "Pretrain epoch [17/210], ZINB loss:0.3982, NB loss:4.6561, latent MSE loss:0.00216665, KL loss:0.00341626\n",
      "Pretrain epoch [18/210], ZINB loss:0.4113, NB loss:4.6065, latent MSE loss:0.00273112, KL loss:0.00369351\n",
      "Pretrain epoch [19/210], ZINB loss:0.4318, NB loss:4.6608, latent MSE loss:0.00424512, KL loss:0.00382466\n",
      "Pretrain epoch [20/210], ZINB loss:0.4247, NB loss:4.7573, latent MSE loss:0.00293647, KL loss:0.00440890\n",
      "Pretrain epoch [21/210], ZINB loss:0.4313, NB loss:4.6715, latent MSE loss:0.00299901, KL loss:0.00356306\n",
      "Pretrain epoch [22/210], ZINB loss:0.4076, NB loss:4.7475, latent MSE loss:0.00270900, KL loss:0.00348667\n",
      "Pretrain epoch [23/210], ZINB loss:0.4022, NB loss:4.6578, latent MSE loss:0.00233429, KL loss:0.00359075\n",
      "Pretrain epoch [24/210], ZINB loss:0.3965, NB loss:4.7156, latent MSE loss:0.00218112, KL loss:0.00363069\n",
      "Pretrain epoch [25/210], ZINB loss:0.4037, NB loss:4.6564, latent MSE loss:0.00174223, KL loss:0.00329909\n",
      "Pretrain epoch [26/210], ZINB loss:0.4168, NB loss:4.7128, latent MSE loss:0.00201466, KL loss:0.00337839\n",
      "Pretrain epoch [27/210], ZINB loss:0.3491, NB loss:4.9471, latent MSE loss:0.00185981, KL loss:0.00006295\n",
      "Pretrain epoch [1/211], ZINB loss:0.4114, NB loss:4.6796, latent MSE loss:0.00262938, KL loss:0.00336682\n",
      "Pretrain epoch [2/211], ZINB loss:0.4030, NB loss:4.7221, latent MSE loss:0.00321454, KL loss:0.00361873\n",
      "Pretrain epoch [3/211], ZINB loss:0.4014, NB loss:4.6265, latent MSE loss:0.00242345, KL loss:0.00331025\n",
      "Pretrain epoch [4/211], ZINB loss:0.4146, NB loss:4.6800, latent MSE loss:0.00254583, KL loss:0.00341278\n",
      "Pretrain epoch [5/211], ZINB loss:0.4191, NB loss:4.7046, latent MSE loss:0.00262529, KL loss:0.00335398\n",
      "Pretrain epoch [6/211], ZINB loss:0.4132, NB loss:4.6383, latent MSE loss:0.00278750, KL loss:0.00366891\n",
      "Pretrain epoch [7/211], ZINB loss:0.4194, NB loss:4.6453, latent MSE loss:0.00259793, KL loss:0.00339423\n",
      "Pretrain epoch [8/211], ZINB loss:0.4275, NB loss:4.6862, latent MSE loss:0.00244979, KL loss:0.00345055\n",
      "Pretrain epoch [9/211], ZINB loss:0.4244, NB loss:4.6915, latent MSE loss:0.00209198, KL loss:0.00423270\n",
      "Pretrain epoch [10/211], ZINB loss:0.4042, NB loss:4.6436, latent MSE loss:0.00224166, KL loss:0.00294953\n",
      "Pretrain epoch [11/211], ZINB loss:0.4323, NB loss:4.6499, latent MSE loss:0.00279756, KL loss:0.00338511\n",
      "Pretrain epoch [12/211], ZINB loss:0.4089, NB loss:4.6390, latent MSE loss:0.00212400, KL loss:0.00316364\n",
      "Pretrain epoch [13/211], ZINB loss:0.4077, NB loss:4.7082, latent MSE loss:0.00196822, KL loss:0.00342744\n",
      "Pretrain epoch [14/211], ZINB loss:0.3973, NB loss:4.6882, latent MSE loss:0.00238477, KL loss:0.00385365\n",
      "Pretrain epoch [15/211], ZINB loss:0.4005, NB loss:4.6649, latent MSE loss:0.00188368, KL loss:0.00335726\n",
      "Pretrain epoch [16/211], ZINB loss:0.4196, NB loss:4.6398, latent MSE loss:0.00186239, KL loss:0.00328104\n",
      "Pretrain epoch [17/211], ZINB loss:0.4150, NB loss:4.7068, latent MSE loss:0.00236553, KL loss:0.00327961\n",
      "Pretrain epoch [18/211], ZINB loss:0.4219, NB loss:4.6747, latent MSE loss:0.00230835, KL loss:0.00384526\n",
      "Pretrain epoch [19/211], ZINB loss:0.4103, NB loss:4.7370, latent MSE loss:0.00196639, KL loss:0.00392982\n",
      "Pretrain epoch [20/211], ZINB loss:0.4315, NB loss:4.6302, latent MSE loss:0.00188959, KL loss:0.00388253\n",
      "Pretrain epoch [21/211], ZINB loss:0.4061, NB loss:4.6649, latent MSE loss:0.00187810, KL loss:0.00341987\n",
      "Pretrain epoch [22/211], ZINB loss:0.4058, NB loss:4.6532, latent MSE loss:0.00208863, KL loss:0.00369474\n",
      "Pretrain epoch [23/211], ZINB loss:0.3985, NB loss:4.7225, latent MSE loss:0.00185816, KL loss:0.00386808\n",
      "Pretrain epoch [24/211], ZINB loss:0.4029, NB loss:4.6391, latent MSE loss:0.00214078, KL loss:0.00311538\n",
      "Pretrain epoch [25/211], ZINB loss:0.4126, NB loss:4.6359, latent MSE loss:0.00188236, KL loss:0.00352318\n",
      "Pretrain epoch [26/211], ZINB loss:0.3952, NB loss:4.7178, latent MSE loss:0.00180203, KL loss:0.00344319\n",
      "Pretrain epoch [27/211], ZINB loss:0.3531, NB loss:4.6933, latent MSE loss:0.00114646, KL loss:0.00003547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [1/212], ZINB loss:0.4110, NB loss:4.6068, latent MSE loss:0.00175417, KL loss:0.00355053\n",
      "Pretrain epoch [2/212], ZINB loss:0.4150, NB loss:4.6618, latent MSE loss:0.00240191, KL loss:0.00366084\n",
      "Pretrain epoch [3/212], ZINB loss:0.4063, NB loss:4.6396, latent MSE loss:0.00165256, KL loss:0.00363601\n",
      "Pretrain epoch [4/212], ZINB loss:0.3990, NB loss:4.6793, latent MSE loss:0.00171787, KL loss:0.00304429\n",
      "Pretrain epoch [5/212], ZINB loss:0.4196, NB loss:4.6579, latent MSE loss:0.00221318, KL loss:0.00367089\n",
      "Pretrain epoch [6/212], ZINB loss:0.4156, NB loss:4.6968, latent MSE loss:0.00162926, KL loss:0.00342747\n",
      "Pretrain epoch [7/212], ZINB loss:0.4162, NB loss:4.6683, latent MSE loss:0.00223004, KL loss:0.00330553\n",
      "Pretrain epoch [8/212], ZINB loss:0.4223, NB loss:4.5994, latent MSE loss:0.00225546, KL loss:0.00335386\n",
      "Pretrain epoch [9/212], ZINB loss:0.4126, NB loss:4.6824, latent MSE loss:0.00195785, KL loss:0.00334716\n",
      "Pretrain epoch [10/212], ZINB loss:0.4111, NB loss:4.6502, latent MSE loss:0.00187225, KL loss:0.00348035\n",
      "Pretrain epoch [11/212], ZINB loss:0.4022, NB loss:4.6461, latent MSE loss:0.00177729, KL loss:0.00354221\n",
      "Pretrain epoch [12/212], ZINB loss:0.4081, NB loss:4.7413, latent MSE loss:0.00211870, KL loss:0.00382428\n",
      "Pretrain epoch [13/212], ZINB loss:0.4055, NB loss:4.5450, latent MSE loss:0.00180947, KL loss:0.00332993\n",
      "Pretrain epoch [14/212], ZINB loss:0.4151, NB loss:4.7008, latent MSE loss:0.00206680, KL loss:0.00364430\n",
      "Pretrain epoch [15/212], ZINB loss:0.3944, NB loss:4.7298, latent MSE loss:0.00139682, KL loss:0.00366130\n",
      "Pretrain epoch [16/212], ZINB loss:0.4258, NB loss:4.7395, latent MSE loss:0.00237069, KL loss:0.00408448\n",
      "Pretrain epoch [17/212], ZINB loss:0.4063, NB loss:4.6848, latent MSE loss:0.00184843, KL loss:0.00339822\n",
      "Pretrain epoch [18/212], ZINB loss:0.3992, NB loss:4.6647, latent MSE loss:0.00171505, KL loss:0.00305523\n",
      "Pretrain epoch [19/212], ZINB loss:0.4155, NB loss:4.6309, latent MSE loss:0.00191933, KL loss:0.00321971\n",
      "Pretrain epoch [20/212], ZINB loss:0.4293, NB loss:4.7238, latent MSE loss:0.00206555, KL loss:0.00388497\n",
      "Pretrain epoch [21/212], ZINB loss:0.4121, NB loss:4.6506, latent MSE loss:0.00163264, KL loss:0.00307770\n",
      "Pretrain epoch [22/212], ZINB loss:0.4093, NB loss:4.6712, latent MSE loss:0.00162884, KL loss:0.00375053\n",
      "Pretrain epoch [23/212], ZINB loss:0.4015, NB loss:4.6909, latent MSE loss:0.00138031, KL loss:0.00295695\n",
      "Pretrain epoch [24/212], ZINB loss:0.4155, NB loss:4.6586, latent MSE loss:0.00144865, KL loss:0.00368242\n",
      "Pretrain epoch [25/212], ZINB loss:0.4224, NB loss:4.6476, latent MSE loss:0.00153469, KL loss:0.00347707\n",
      "Pretrain epoch [26/212], ZINB loss:0.3859, NB loss:4.7622, latent MSE loss:0.00124213, KL loss:0.00301112\n",
      "Pretrain epoch [27/212], ZINB loss:0.4048, NB loss:4.5849, latent MSE loss:0.00097695, KL loss:0.00002689\n",
      "Pretrain epoch [1/213], ZINB loss:0.4023, NB loss:4.6819, latent MSE loss:0.00180225, KL loss:0.00341125\n",
      "Pretrain epoch [2/213], ZINB loss:0.4106, NB loss:4.6772, latent MSE loss:0.00190031, KL loss:0.00345475\n",
      "Pretrain epoch [3/213], ZINB loss:0.4168, NB loss:4.6083, latent MSE loss:0.00180866, KL loss:0.00357100\n",
      "Pretrain epoch [4/213], ZINB loss:0.4233, NB loss:4.7083, latent MSE loss:0.00187905, KL loss:0.00372701\n",
      "Pretrain epoch [5/213], ZINB loss:0.3935, NB loss:4.6435, latent MSE loss:0.00165991, KL loss:0.00311299\n",
      "Pretrain epoch [6/213], ZINB loss:0.4219, NB loss:4.6624, latent MSE loss:0.00169520, KL loss:0.00361229\n",
      "Pretrain epoch [7/213], ZINB loss:0.4071, NB loss:4.6976, latent MSE loss:0.00191696, KL loss:0.00367536\n",
      "Pretrain epoch [8/213], ZINB loss:0.3910, NB loss:4.5785, latent MSE loss:0.00128658, KL loss:0.00295385\n",
      "Pretrain epoch [9/213], ZINB loss:0.4163, NB loss:4.6449, latent MSE loss:0.00171705, KL loss:0.00334247\n",
      "Pretrain epoch [10/213], ZINB loss:0.4243, NB loss:4.6210, latent MSE loss:0.00166314, KL loss:0.00323796\n",
      "Pretrain epoch [11/213], ZINB loss:0.4097, NB loss:4.7141, latent MSE loss:0.00147025, KL loss:0.00325715\n",
      "Pretrain epoch [12/213], ZINB loss:0.4048, NB loss:4.6066, latent MSE loss:0.00164690, KL loss:0.00327312\n",
      "Pretrain epoch [13/213], ZINB loss:0.4025, NB loss:4.6612, latent MSE loss:0.00137863, KL loss:0.00329896\n",
      "Pretrain epoch [14/213], ZINB loss:0.4104, NB loss:4.6618, latent MSE loss:0.00130319, KL loss:0.00317499\n",
      "Pretrain epoch [15/213], ZINB loss:0.4031, NB loss:4.6429, latent MSE loss:0.00134476, KL loss:0.00290981\n",
      "Pretrain epoch [16/213], ZINB loss:0.3953, NB loss:4.6393, latent MSE loss:0.00127227, KL loss:0.00312197\n",
      "Pretrain epoch [17/213], ZINB loss:0.3935, NB loss:4.6540, latent MSE loss:0.00120456, KL loss:0.00310965\n",
      "Pretrain epoch [18/213], ZINB loss:0.3906, NB loss:4.7423, latent MSE loss:0.00146204, KL loss:0.00292649\n",
      "Pretrain epoch [19/213], ZINB loss:0.4073, NB loss:4.6719, latent MSE loss:0.00157703, KL loss:0.00317028\n",
      "Pretrain epoch [20/213], ZINB loss:0.4362, NB loss:4.6863, latent MSE loss:0.00177971, KL loss:0.00359902\n",
      "Pretrain epoch [21/213], ZINB loss:0.4261, NB loss:4.6450, latent MSE loss:0.00162939, KL loss:0.00325873\n",
      "Pretrain epoch [22/213], ZINB loss:0.4233, NB loss:4.6950, latent MSE loss:0.00146295, KL loss:0.00432218\n",
      "Pretrain epoch [23/213], ZINB loss:0.4189, NB loss:4.6623, latent MSE loss:0.00155888, KL loss:0.00335669\n",
      "Pretrain epoch [24/213], ZINB loss:0.4112, NB loss:4.7343, latent MSE loss:0.00127436, KL loss:0.00312127\n",
      "Pretrain epoch [25/213], ZINB loss:0.4046, NB loss:4.6960, latent MSE loss:0.00129296, KL loss:0.00323173\n",
      "Pretrain epoch [26/213], ZINB loss:0.4129, NB loss:4.7477, latent MSE loss:0.00151824, KL loss:0.00388914\n",
      "Pretrain epoch [27/213], ZINB loss:0.4159, NB loss:4.5446, latent MSE loss:0.00100210, KL loss:0.00007413\n",
      "Pretrain epoch [1/214], ZINB loss:0.3871, NB loss:4.6529, latent MSE loss:0.00167650, KL loss:0.00306356\n",
      "Pretrain epoch [2/214], ZINB loss:0.4195, NB loss:4.5927, latent MSE loss:0.00157660, KL loss:0.00293533\n",
      "Pretrain epoch [3/214], ZINB loss:0.3972, NB loss:4.7029, latent MSE loss:0.00187687, KL loss:0.00315710\n",
      "Pretrain epoch [4/214], ZINB loss:0.4257, NB loss:4.6652, latent MSE loss:0.00202854, KL loss:0.00358058\n",
      "Pretrain epoch [5/214], ZINB loss:0.4153, NB loss:4.6961, latent MSE loss:0.00189329, KL loss:0.00367648\n",
      "Pretrain epoch [6/214], ZINB loss:0.4023, NB loss:4.6526, latent MSE loss:0.00192951, KL loss:0.00325551\n",
      "Pretrain epoch [7/214], ZINB loss:0.4081, NB loss:4.6994, latent MSE loss:0.00231766, KL loss:0.00328453\n",
      "Pretrain epoch [8/214], ZINB loss:0.3869, NB loss:4.7253, latent MSE loss:0.00199190, KL loss:0.00305128\n",
      "Pretrain epoch [9/214], ZINB loss:0.4100, NB loss:4.7281, latent MSE loss:0.00272477, KL loss:0.00338064\n",
      "Pretrain epoch [10/214], ZINB loss:0.4153, NB loss:4.6207, latent MSE loss:0.00340392, KL loss:0.00397140\n",
      "Pretrain epoch [11/214], ZINB loss:0.4109, NB loss:4.6634, latent MSE loss:0.00258752, KL loss:0.00354555\n",
      "Pretrain epoch [12/214], ZINB loss:0.3890, NB loss:4.6549, latent MSE loss:0.00185713, KL loss:0.00324124\n",
      "Pretrain epoch [13/214], ZINB loss:0.4003, NB loss:4.6822, latent MSE loss:0.00255709, KL loss:0.00305173\n",
      "Pretrain epoch [14/214], ZINB loss:0.3867, NB loss:4.7184, latent MSE loss:0.00226128, KL loss:0.00335771\n",
      "Pretrain epoch [15/214], ZINB loss:0.4294, NB loss:4.6302, latent MSE loss:0.00248955, KL loss:0.00346519\n",
      "Pretrain epoch [16/214], ZINB loss:0.3978, NB loss:4.7226, latent MSE loss:0.00186498, KL loss:0.00348641\n",
      "Pretrain epoch [17/214], ZINB loss:0.4009, NB loss:4.6135, latent MSE loss:0.00257936, KL loss:0.00367420\n",
      "Pretrain epoch [18/214], ZINB loss:0.4012, NB loss:4.6705, latent MSE loss:0.00222036, KL loss:0.00291382\n",
      "Pretrain epoch [19/214], ZINB loss:0.4187, NB loss:4.6632, latent MSE loss:0.00219411, KL loss:0.00368152\n",
      "Pretrain epoch [20/214], ZINB loss:0.3974, NB loss:4.6051, latent MSE loss:0.00217447, KL loss:0.00363682\n",
      "Pretrain epoch [21/214], ZINB loss:0.4067, NB loss:4.7169, latent MSE loss:0.00199974, KL loss:0.00329266\n",
      "Pretrain epoch [22/214], ZINB loss:0.4179, NB loss:4.5781, latent MSE loss:0.00193518, KL loss:0.00326884\n",
      "Pretrain epoch [23/214], ZINB loss:0.4106, NB loss:4.6886, latent MSE loss:0.00207860, KL loss:0.00336418\n",
      "Pretrain epoch [24/214], ZINB loss:0.4088, NB loss:4.6844, latent MSE loss:0.00201843, KL loss:0.00344217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [25/214], ZINB loss:0.4051, NB loss:4.6958, latent MSE loss:0.00168335, KL loss:0.00352184\n",
      "Pretrain epoch [26/214], ZINB loss:0.4370, NB loss:4.6206, latent MSE loss:0.00219544, KL loss:0.00348873\n",
      "Pretrain epoch [27/214], ZINB loss:0.3279, NB loss:4.5318, latent MSE loss:0.00276990, KL loss:0.00005380\n",
      "Pretrain epoch [1/215], ZINB loss:0.4146, NB loss:4.6366, latent MSE loss:0.00292765, KL loss:0.00363430\n",
      "Pretrain epoch [2/215], ZINB loss:0.3971, NB loss:4.6620, latent MSE loss:0.00357197, KL loss:0.00348042\n",
      "Pretrain epoch [3/215], ZINB loss:0.4092, NB loss:4.7327, latent MSE loss:0.00270777, KL loss:0.00348982\n",
      "Pretrain epoch [4/215], ZINB loss:0.4308, NB loss:4.6455, latent MSE loss:0.00307510, KL loss:0.00320143\n",
      "Pretrain epoch [5/215], ZINB loss:0.3971, NB loss:4.7081, latent MSE loss:0.00258250, KL loss:0.00354194\n",
      "Pretrain epoch [6/215], ZINB loss:0.3986, NB loss:4.5995, latent MSE loss:0.00248956, KL loss:0.00307230\n",
      "Pretrain epoch [7/215], ZINB loss:0.4115, NB loss:4.6180, latent MSE loss:0.00310572, KL loss:0.00285145\n",
      "Pretrain epoch [8/215], ZINB loss:0.4174, NB loss:4.5961, latent MSE loss:0.00257722, KL loss:0.00387397\n",
      "Pretrain epoch [9/215], ZINB loss:0.3964, NB loss:4.6663, latent MSE loss:0.00241119, KL loss:0.00314409\n",
      "Pretrain epoch [10/215], ZINB loss:0.4023, NB loss:4.6314, latent MSE loss:0.00237638, KL loss:0.00303165\n",
      "Pretrain epoch [11/215], ZINB loss:0.4217, NB loss:4.7121, latent MSE loss:0.00285606, KL loss:0.00373325\n",
      "Pretrain epoch [12/215], ZINB loss:0.4087, NB loss:4.7904, latent MSE loss:0.00246209, KL loss:0.00332194\n",
      "Pretrain epoch [13/215], ZINB loss:0.4054, NB loss:4.5744, latent MSE loss:0.00321912, KL loss:0.00320909\n",
      "Pretrain epoch [14/215], ZINB loss:0.4162, NB loss:4.6864, latent MSE loss:0.00261168, KL loss:0.00343958\n",
      "Pretrain epoch [15/215], ZINB loss:0.4066, NB loss:4.6821, latent MSE loss:0.00196111, KL loss:0.00345679\n",
      "Pretrain epoch [16/215], ZINB loss:0.3964, NB loss:4.6798, latent MSE loss:0.00191766, KL loss:0.00345690\n",
      "Pretrain epoch [17/215], ZINB loss:0.3852, NB loss:4.7042, latent MSE loss:0.00184697, KL loss:0.00336882\n",
      "Pretrain epoch [18/215], ZINB loss:0.3829, NB loss:4.6246, latent MSE loss:0.00184104, KL loss:0.00280247\n",
      "Pretrain epoch [19/215], ZINB loss:0.4014, NB loss:4.6790, latent MSE loss:0.00243932, KL loss:0.00350788\n",
      "Pretrain epoch [20/215], ZINB loss:0.4021, NB loss:4.6569, latent MSE loss:0.00194017, KL loss:0.00363051\n",
      "Pretrain epoch [21/215], ZINB loss:0.4068, NB loss:4.6129, latent MSE loss:0.00222922, KL loss:0.00334525\n",
      "Pretrain epoch [22/215], ZINB loss:0.4029, NB loss:4.6994, latent MSE loss:0.00184322, KL loss:0.00332877\n",
      "Pretrain epoch [23/215], ZINB loss:0.3885, NB loss:4.6851, latent MSE loss:0.00162423, KL loss:0.00322992\n",
      "Pretrain epoch [24/215], ZINB loss:0.4187, NB loss:4.7460, latent MSE loss:0.00167443, KL loss:0.00337405\n",
      "Pretrain epoch [25/215], ZINB loss:0.3975, NB loss:4.6585, latent MSE loss:0.00154878, KL loss:0.00309460\n",
      "Pretrain epoch [26/215], ZINB loss:0.4114, NB loss:4.6293, latent MSE loss:0.00172646, KL loss:0.00347527\n",
      "Pretrain epoch [27/215], ZINB loss:0.7377, NB loss:4.9024, latent MSE loss:0.00392454, KL loss:0.00004511\n",
      "Pretrain epoch [1/216], ZINB loss:0.4198, NB loss:4.6233, latent MSE loss:0.00539140, KL loss:0.00359155\n",
      "Pretrain epoch [2/216], ZINB loss:0.4163, NB loss:4.6334, latent MSE loss:0.00681559, KL loss:0.00387512\n",
      "Pretrain epoch [3/216], ZINB loss:0.4100, NB loss:4.7617, latent MSE loss:0.00514589, KL loss:0.00468356\n",
      "Pretrain epoch [4/216], ZINB loss:0.4122, NB loss:4.6450, latent MSE loss:0.00408910, KL loss:0.00393589\n",
      "Pretrain epoch [5/216], ZINB loss:0.3997, NB loss:4.6272, latent MSE loss:0.00353376, KL loss:0.00390834\n",
      "Pretrain epoch [6/216], ZINB loss:0.4219, NB loss:4.6552, latent MSE loss:0.00625396, KL loss:0.00359708\n",
      "Pretrain epoch [7/216], ZINB loss:0.4437, NB loss:4.7344, latent MSE loss:0.00659959, KL loss:0.00402639\n",
      "Pretrain epoch [8/216], ZINB loss:0.4070, NB loss:4.6378, latent MSE loss:0.00425449, KL loss:0.00368160\n",
      "Pretrain epoch [9/216], ZINB loss:0.4133, NB loss:4.6774, latent MSE loss:0.00362058, KL loss:0.00356096\n",
      "Pretrain epoch [10/216], ZINB loss:0.4038, NB loss:4.7146, latent MSE loss:0.00408794, KL loss:0.00403173\n",
      "Pretrain epoch [11/216], ZINB loss:0.4068, NB loss:4.6470, latent MSE loss:0.00326155, KL loss:0.00395191\n",
      "Pretrain epoch [12/216], ZINB loss:0.4166, NB loss:4.5966, latent MSE loss:0.00362572, KL loss:0.00402287\n",
      "Pretrain epoch [13/216], ZINB loss:0.4011, NB loss:4.7383, latent MSE loss:0.00288059, KL loss:0.00376485\n",
      "Pretrain epoch [14/216], ZINB loss:0.4091, NB loss:4.6173, latent MSE loss:0.00272956, KL loss:0.00375954\n",
      "Pretrain epoch [15/216], ZINB loss:0.4207, NB loss:4.6672, latent MSE loss:0.00293397, KL loss:0.00399015\n",
      "Pretrain epoch [16/216], ZINB loss:0.4113, NB loss:4.6203, latent MSE loss:0.00272359, KL loss:0.00404746\n",
      "Pretrain epoch [17/216], ZINB loss:0.3938, NB loss:4.6970, latent MSE loss:0.00277455, KL loss:0.00371318\n",
      "Pretrain epoch [18/216], ZINB loss:0.4119, NB loss:4.7083, latent MSE loss:0.00248732, KL loss:0.00370341\n",
      "Pretrain epoch [19/216], ZINB loss:0.3958, NB loss:4.7002, latent MSE loss:0.00261003, KL loss:0.00379555\n",
      "Pretrain epoch [20/216], ZINB loss:0.3900, NB loss:4.7031, latent MSE loss:0.00175848, KL loss:0.00315853\n",
      "Pretrain epoch [21/216], ZINB loss:0.4093, NB loss:4.7146, latent MSE loss:0.00204312, KL loss:0.00337178\n",
      "Pretrain epoch [22/216], ZINB loss:0.4062, NB loss:4.6359, latent MSE loss:0.00211913, KL loss:0.00328118\n",
      "Pretrain epoch [23/216], ZINB loss:0.4059, NB loss:4.6508, latent MSE loss:0.00198400, KL loss:0.00327065\n",
      "Pretrain epoch [24/216], ZINB loss:0.3978, NB loss:4.6514, latent MSE loss:0.00190413, KL loss:0.00347723\n",
      "Pretrain epoch [25/216], ZINB loss:0.4166, NB loss:4.6399, latent MSE loss:0.00163140, KL loss:0.00377540\n",
      "Pretrain epoch [26/216], ZINB loss:0.3973, NB loss:4.5890, latent MSE loss:0.00152205, KL loss:0.00349654\n",
      "Pretrain epoch [27/216], ZINB loss:0.3897, NB loss:4.4999, latent MSE loss:0.00192961, KL loss:0.00004398\n",
      "Pretrain epoch [1/217], ZINB loss:0.3953, NB loss:4.6313, latent MSE loss:0.00174601, KL loss:0.00353518\n",
      "Pretrain epoch [2/217], ZINB loss:0.3978, NB loss:4.5515, latent MSE loss:0.00151822, KL loss:0.00279072\n",
      "Pretrain epoch [3/217], ZINB loss:0.4050, NB loss:4.6519, latent MSE loss:0.00170709, KL loss:0.00351333\n",
      "Pretrain epoch [4/217], ZINB loss:0.3852, NB loss:4.6846, latent MSE loss:0.00162083, KL loss:0.00359842\n",
      "Pretrain epoch [5/217], ZINB loss:0.4068, NB loss:4.6929, latent MSE loss:0.00158440, KL loss:0.00381146\n",
      "Pretrain epoch [6/217], ZINB loss:0.3954, NB loss:4.5789, latent MSE loss:0.00144360, KL loss:0.00283966\n",
      "Pretrain epoch [7/217], ZINB loss:0.4355, NB loss:4.6239, latent MSE loss:0.00162946, KL loss:0.00355233\n",
      "Pretrain epoch [8/217], ZINB loss:0.3893, NB loss:4.6376, latent MSE loss:0.00131753, KL loss:0.00316268\n",
      "Pretrain epoch [9/217], ZINB loss:0.4157, NB loss:4.7051, latent MSE loss:0.00139892, KL loss:0.00403010\n",
      "Pretrain epoch [10/217], ZINB loss:0.4083, NB loss:4.6873, latent MSE loss:0.00149738, KL loss:0.00389980\n",
      "Pretrain epoch [11/217], ZINB loss:0.4095, NB loss:4.7873, latent MSE loss:0.00138274, KL loss:0.00380137\n",
      "Pretrain epoch [12/217], ZINB loss:0.3939, NB loss:4.7159, latent MSE loss:0.00117748, KL loss:0.00325670\n",
      "Pretrain epoch [13/217], ZINB loss:0.4156, NB loss:4.6350, latent MSE loss:0.00154079, KL loss:0.00338563\n",
      "Pretrain epoch [14/217], ZINB loss:0.3888, NB loss:4.6527, latent MSE loss:0.00130655, KL loss:0.00314272\n",
      "Pretrain epoch [15/217], ZINB loss:0.3983, NB loss:4.7667, latent MSE loss:0.00133809, KL loss:0.00340231\n",
      "Pretrain epoch [16/217], ZINB loss:0.4195, NB loss:4.6218, latent MSE loss:0.00136921, KL loss:0.00333315\n",
      "Pretrain epoch [17/217], ZINB loss:0.3987, NB loss:4.6658, latent MSE loss:0.00125693, KL loss:0.00311781\n",
      "Pretrain epoch [18/217], ZINB loss:0.4010, NB loss:4.6424, latent MSE loss:0.00117579, KL loss:0.00360655\n",
      "Pretrain epoch [19/217], ZINB loss:0.4043, NB loss:4.6709, latent MSE loss:0.00154936, KL loss:0.00313272\n",
      "Pretrain epoch [20/217], ZINB loss:0.3965, NB loss:4.6948, latent MSE loss:0.00113239, KL loss:0.00336252\n",
      "Pretrain epoch [21/217], ZINB loss:0.4098, NB loss:4.6228, latent MSE loss:0.00111144, KL loss:0.00310935\n",
      "Pretrain epoch [22/217], ZINB loss:0.3934, NB loss:4.6725, latent MSE loss:0.00108509, KL loss:0.00300158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [23/217], ZINB loss:0.4208, NB loss:4.5772, latent MSE loss:0.00112173, KL loss:0.00331852\n",
      "Pretrain epoch [24/217], ZINB loss:0.3927, NB loss:4.6578, latent MSE loss:0.00121429, KL loss:0.00337840\n",
      "Pretrain epoch [25/217], ZINB loss:0.4059, NB loss:4.7252, latent MSE loss:0.00145419, KL loss:0.00370325\n",
      "Pretrain epoch [26/217], ZINB loss:0.4279, NB loss:4.6653, latent MSE loss:0.00134485, KL loss:0.00369302\n",
      "Pretrain epoch [27/217], ZINB loss:0.5065, NB loss:5.2638, latent MSE loss:0.00268669, KL loss:0.00005143\n",
      "Pretrain epoch [1/218], ZINB loss:0.3934, NB loss:4.6629, latent MSE loss:0.00151939, KL loss:0.00346424\n",
      "Pretrain epoch [2/218], ZINB loss:0.3872, NB loss:4.6509, latent MSE loss:0.00140940, KL loss:0.00318034\n",
      "Pretrain epoch [3/218], ZINB loss:0.4221, NB loss:4.6904, latent MSE loss:0.00139140, KL loss:0.00323282\n",
      "Pretrain epoch [4/218], ZINB loss:0.4176, NB loss:4.6981, latent MSE loss:0.00147145, KL loss:0.00357767\n",
      "Pretrain epoch [5/218], ZINB loss:0.4101, NB loss:4.6420, latent MSE loss:0.00141949, KL loss:0.00342857\n",
      "Pretrain epoch [6/218], ZINB loss:0.4079, NB loss:4.6814, latent MSE loss:0.00130319, KL loss:0.00329229\n",
      "Pretrain epoch [7/218], ZINB loss:0.4344, NB loss:4.6796, latent MSE loss:0.00122963, KL loss:0.00331381\n",
      "Pretrain epoch [8/218], ZINB loss:0.4074, NB loss:4.7836, latent MSE loss:0.00127684, KL loss:0.00340082\n",
      "Pretrain epoch [9/218], ZINB loss:0.4152, NB loss:4.6353, latent MSE loss:0.00132575, KL loss:0.00318053\n",
      "Pretrain epoch [10/218], ZINB loss:0.4011, NB loss:4.6113, latent MSE loss:0.00131667, KL loss:0.00291868\n",
      "Pretrain epoch [11/218], ZINB loss:0.4116, NB loss:4.6473, latent MSE loss:0.00114586, KL loss:0.00285214\n",
      "Pretrain epoch [12/218], ZINB loss:0.3986, NB loss:4.7090, latent MSE loss:0.00131388, KL loss:0.00312205\n",
      "Pretrain epoch [13/218], ZINB loss:0.3800, NB loss:4.6044, latent MSE loss:0.00087750, KL loss:0.00252430\n",
      "Pretrain epoch [14/218], ZINB loss:0.4008, NB loss:4.6176, latent MSE loss:0.00100214, KL loss:0.00308004\n",
      "Pretrain epoch [15/218], ZINB loss:0.3901, NB loss:4.6597, latent MSE loss:0.00112885, KL loss:0.00349458\n",
      "Pretrain epoch [16/218], ZINB loss:0.4034, NB loss:4.6573, latent MSE loss:0.00094580, KL loss:0.00297174\n",
      "Pretrain epoch [17/218], ZINB loss:0.4023, NB loss:4.6410, latent MSE loss:0.00093916, KL loss:0.00281296\n",
      "Pretrain epoch [18/218], ZINB loss:0.4055, NB loss:4.6763, latent MSE loss:0.00106711, KL loss:0.00343209\n",
      "Pretrain epoch [19/218], ZINB loss:0.3920, NB loss:4.7011, latent MSE loss:0.00107461, KL loss:0.00294519\n",
      "Pretrain epoch [20/218], ZINB loss:0.4095, NB loss:4.6819, latent MSE loss:0.00142846, KL loss:0.00367428\n",
      "Pretrain epoch [21/218], ZINB loss:0.4070, NB loss:4.6334, latent MSE loss:0.00102649, KL loss:0.00337899\n",
      "Pretrain epoch [22/218], ZINB loss:0.3991, NB loss:4.6565, latent MSE loss:0.00099365, KL loss:0.00300143\n",
      "Pretrain epoch [23/218], ZINB loss:0.3937, NB loss:4.6611, latent MSE loss:0.00113764, KL loss:0.00330762\n",
      "Pretrain epoch [24/218], ZINB loss:0.4051, NB loss:4.7017, latent MSE loss:0.00090555, KL loss:0.00340473\n",
      "Pretrain epoch [25/218], ZINB loss:0.4101, NB loss:4.6244, latent MSE loss:0.00098163, KL loss:0.00328224\n",
      "Pretrain epoch [26/218], ZINB loss:0.3837, NB loss:4.6434, latent MSE loss:0.00076439, KL loss:0.00276681\n",
      "Pretrain epoch [27/218], ZINB loss:0.4115, NB loss:4.7735, latent MSE loss:0.00106591, KL loss:0.00004160\n",
      "Pretrain epoch [1/219], ZINB loss:0.4053, NB loss:4.6108, latent MSE loss:0.00110165, KL loss:0.00269866\n",
      "Pretrain epoch [2/219], ZINB loss:0.4139, NB loss:4.6460, latent MSE loss:0.00090866, KL loss:0.00292502\n",
      "Pretrain epoch [3/219], ZINB loss:0.3901, NB loss:4.6874, latent MSE loss:0.00098545, KL loss:0.00292935\n",
      "Pretrain epoch [4/219], ZINB loss:0.3973, NB loss:4.6560, latent MSE loss:0.00108146, KL loss:0.00304806\n",
      "Pretrain epoch [5/219], ZINB loss:0.3851, NB loss:4.7283, latent MSE loss:0.00106378, KL loss:0.00316816\n",
      "Pretrain epoch [6/219], ZINB loss:0.4049, NB loss:4.6351, latent MSE loss:0.00113482, KL loss:0.00279888\n",
      "Pretrain epoch [7/219], ZINB loss:0.4072, NB loss:4.6581, latent MSE loss:0.00119866, KL loss:0.00306623\n",
      "Pretrain epoch [8/219], ZINB loss:0.3979, NB loss:4.6731, latent MSE loss:0.00124004, KL loss:0.00286826\n",
      "Pretrain epoch [9/219], ZINB loss:0.4113, NB loss:4.6713, latent MSE loss:0.00128394, KL loss:0.00315454\n",
      "Pretrain epoch [10/219], ZINB loss:0.4025, NB loss:4.5690, latent MSE loss:0.00088860, KL loss:0.00263602\n",
      "Pretrain epoch [11/219], ZINB loss:0.4266, NB loss:4.7269, latent MSE loss:0.00109094, KL loss:0.00354769\n",
      "Pretrain epoch [12/219], ZINB loss:0.4044, NB loss:4.6647, latent MSE loss:0.00109704, KL loss:0.00359202\n",
      "Pretrain epoch [13/219], ZINB loss:0.3975, NB loss:4.6207, latent MSE loss:0.00091002, KL loss:0.00273881\n",
      "Pretrain epoch [14/219], ZINB loss:0.3912, NB loss:4.5052, latent MSE loss:0.00078333, KL loss:0.00241447\n",
      "Pretrain epoch [15/219], ZINB loss:0.3993, NB loss:4.7431, latent MSE loss:0.00104265, KL loss:0.00297713\n",
      "Pretrain epoch [16/219], ZINB loss:0.4001, NB loss:4.6966, latent MSE loss:0.00088895, KL loss:0.00291904\n",
      "Pretrain epoch [17/219], ZINB loss:0.4024, NB loss:4.6416, latent MSE loss:0.00087497, KL loss:0.00315756\n",
      "Pretrain epoch [18/219], ZINB loss:0.4028, NB loss:4.6514, latent MSE loss:0.00092053, KL loss:0.00304560\n",
      "Pretrain epoch [19/219], ZINB loss:0.4099, NB loss:4.6287, latent MSE loss:0.00109497, KL loss:0.00301512\n",
      "Pretrain epoch [20/219], ZINB loss:0.4110, NB loss:4.6108, latent MSE loss:0.00088598, KL loss:0.00289955\n",
      "Pretrain epoch [21/219], ZINB loss:0.3970, NB loss:4.6728, latent MSE loss:0.00114617, KL loss:0.00305295\n",
      "Pretrain epoch [22/219], ZINB loss:0.3887, NB loss:4.7292, latent MSE loss:0.00088201, KL loss:0.00287909\n",
      "Pretrain epoch [23/219], ZINB loss:0.4112, NB loss:4.6467, latent MSE loss:0.00109644, KL loss:0.00297078\n",
      "Pretrain epoch [24/219], ZINB loss:0.3902, NB loss:4.6636, latent MSE loss:0.00082388, KL loss:0.00284113\n",
      "Pretrain epoch [25/219], ZINB loss:0.3919, NB loss:4.7411, latent MSE loss:0.00083396, KL loss:0.00319069\n",
      "Pretrain epoch [26/219], ZINB loss:0.4057, NB loss:4.6824, latent MSE loss:0.00094466, KL loss:0.00270692\n",
      "Pretrain epoch [27/219], ZINB loss:0.4055, NB loss:4.7428, latent MSE loss:0.00057483, KL loss:0.00002201\n",
      "Pretrain epoch [1/220], ZINB loss:0.3954, NB loss:4.6709, latent MSE loss:0.00125538, KL loss:0.00279014\n",
      "Pretrain epoch [2/220], ZINB loss:0.4156, NB loss:4.5868, latent MSE loss:0.00126008, KL loss:0.00334392\n",
      "Pretrain epoch [3/220], ZINB loss:0.3746, NB loss:4.6226, latent MSE loss:0.00111033, KL loss:0.00236964\n",
      "Pretrain epoch [4/220], ZINB loss:0.4109, NB loss:4.7381, latent MSE loss:0.00124600, KL loss:0.00298876\n",
      "Pretrain epoch [5/220], ZINB loss:0.4077, NB loss:4.6633, latent MSE loss:0.00109110, KL loss:0.00339489\n",
      "Pretrain epoch [6/220], ZINB loss:0.4089, NB loss:4.5484, latent MSE loss:0.00111104, KL loss:0.00277653\n",
      "Pretrain epoch [7/220], ZINB loss:0.4115, NB loss:4.6855, latent MSE loss:0.00109975, KL loss:0.00301950\n",
      "Pretrain epoch [8/220], ZINB loss:0.3966, NB loss:4.6527, latent MSE loss:0.00079516, KL loss:0.00250912\n",
      "Pretrain epoch [9/220], ZINB loss:0.3825, NB loss:4.7243, latent MSE loss:0.00083134, KL loss:0.00314207\n",
      "Pretrain epoch [10/220], ZINB loss:0.3853, NB loss:4.6577, latent MSE loss:0.00105016, KL loss:0.00297888\n",
      "Pretrain epoch [11/220], ZINB loss:0.3940, NB loss:4.6111, latent MSE loss:0.00096487, KL loss:0.00268984\n",
      "Pretrain epoch [12/220], ZINB loss:0.4045, NB loss:4.6671, latent MSE loss:0.00096647, KL loss:0.00338702\n",
      "Pretrain epoch [13/220], ZINB loss:0.4039, NB loss:4.6808, latent MSE loss:0.00085312, KL loss:0.00289927\n",
      "Pretrain epoch [14/220], ZINB loss:0.4077, NB loss:4.6884, latent MSE loss:0.00079571, KL loss:0.00290084\n",
      "Pretrain epoch [15/220], ZINB loss:0.3898, NB loss:4.5818, latent MSE loss:0.00073370, KL loss:0.00246036\n",
      "Pretrain epoch [16/220], ZINB loss:0.4068, NB loss:4.6707, latent MSE loss:0.00101431, KL loss:0.00248498\n",
      "Pretrain epoch [17/220], ZINB loss:0.3967, NB loss:4.6220, latent MSE loss:0.00092476, KL loss:0.00262666\n",
      "Pretrain epoch [18/220], ZINB loss:0.4083, NB loss:4.6972, latent MSE loss:0.00087500, KL loss:0.00328882\n",
      "Pretrain epoch [19/220], ZINB loss:0.4165, NB loss:4.6725, latent MSE loss:0.00073045, KL loss:0.00277877\n",
      "Pretrain epoch [20/220], ZINB loss:0.4239, NB loss:4.6884, latent MSE loss:0.00091194, KL loss:0.00300787\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [21/220], ZINB loss:0.3924, NB loss:4.6096, latent MSE loss:0.00081272, KL loss:0.00259722\n",
      "Pretrain epoch [22/220], ZINB loss:0.3952, NB loss:4.7102, latent MSE loss:0.00090919, KL loss:0.00297789\n",
      "Pretrain epoch [23/220], ZINB loss:0.4064, NB loss:4.6696, latent MSE loss:0.00102599, KL loss:0.00270372\n",
      "Pretrain epoch [24/220], ZINB loss:0.4151, NB loss:4.6413, latent MSE loss:0.00099270, KL loss:0.00313453\n",
      "Pretrain epoch [25/220], ZINB loss:0.4037, NB loss:4.6425, latent MSE loss:0.00087136, KL loss:0.00257981\n",
      "Pretrain epoch [26/220], ZINB loss:0.3921, NB loss:4.7236, latent MSE loss:0.00086039, KL loss:0.00309200\n",
      "Pretrain epoch [27/220], ZINB loss:0.4026, NB loss:5.1709, latent MSE loss:0.00054508, KL loss:0.00001566\n",
      "Pretrain epoch [1/221], ZINB loss:0.3986, NB loss:4.6628, latent MSE loss:0.00093552, KL loss:0.00282109\n",
      "Pretrain epoch [2/221], ZINB loss:0.4010, NB loss:4.6987, latent MSE loss:0.00112804, KL loss:0.00300766\n",
      "Pretrain epoch [3/221], ZINB loss:0.3951, NB loss:4.7299, latent MSE loss:0.00129799, KL loss:0.00319049\n",
      "Pretrain epoch [4/221], ZINB loss:0.4151, NB loss:4.6562, latent MSE loss:0.00152120, KL loss:0.00315939\n",
      "Pretrain epoch [5/221], ZINB loss:0.3969, NB loss:4.6971, latent MSE loss:0.00181458, KL loss:0.00281594\n",
      "Pretrain epoch [6/221], ZINB loss:0.4102, NB loss:4.6100, latent MSE loss:0.00246534, KL loss:0.00296454\n",
      "Pretrain epoch [7/221], ZINB loss:0.4141, NB loss:4.6429, latent MSE loss:0.00257616, KL loss:0.00306837\n",
      "Pretrain epoch [8/221], ZINB loss:0.4168, NB loss:4.6273, latent MSE loss:0.00209533, KL loss:0.00302223\n",
      "Pretrain epoch [9/221], ZINB loss:0.4012, NB loss:4.6846, latent MSE loss:0.00138452, KL loss:0.00283838\n",
      "Pretrain epoch [10/221], ZINB loss:0.4004, NB loss:4.6804, latent MSE loss:0.00146315, KL loss:0.00267809\n",
      "Pretrain epoch [11/221], ZINB loss:0.3849, NB loss:4.6918, latent MSE loss:0.00162698, KL loss:0.00273011\n",
      "Pretrain epoch [12/221], ZINB loss:0.4059, NB loss:4.5739, latent MSE loss:0.00161861, KL loss:0.00260700\n",
      "Pretrain epoch [13/221], ZINB loss:0.4141, NB loss:4.6891, latent MSE loss:0.00131647, KL loss:0.00316451\n",
      "Pretrain epoch [14/221], ZINB loss:0.3976, NB loss:4.5977, latent MSE loss:0.00122600, KL loss:0.00232578\n",
      "Pretrain epoch [15/221], ZINB loss:0.4129, NB loss:4.6110, latent MSE loss:0.00140435, KL loss:0.00288085\n",
      "Pretrain epoch [16/221], ZINB loss:0.4037, NB loss:4.6569, latent MSE loss:0.00113633, KL loss:0.00259794\n",
      "Pretrain epoch [17/221], ZINB loss:0.3997, NB loss:4.7152, latent MSE loss:0.00142346, KL loss:0.00312947\n",
      "Pretrain epoch [18/221], ZINB loss:0.3976, NB loss:4.6987, latent MSE loss:0.00114438, KL loss:0.00246266\n",
      "Pretrain epoch [19/221], ZINB loss:0.4131, NB loss:4.6770, latent MSE loss:0.00109188, KL loss:0.00295155\n",
      "Pretrain epoch [20/221], ZINB loss:0.4103, NB loss:4.5893, latent MSE loss:0.00120584, KL loss:0.00286465\n",
      "Pretrain epoch [21/221], ZINB loss:0.3986, NB loss:4.7080, latent MSE loss:0.00131615, KL loss:0.00323281\n",
      "Pretrain epoch [22/221], ZINB loss:0.4007, NB loss:4.6069, latent MSE loss:0.00089044, KL loss:0.00296772\n",
      "Pretrain epoch [23/221], ZINB loss:0.3968, NB loss:4.6087, latent MSE loss:0.00089691, KL loss:0.00265107\n",
      "Pretrain epoch [24/221], ZINB loss:0.4008, NB loss:4.6652, latent MSE loss:0.00103505, KL loss:0.00353726\n",
      "Pretrain epoch [25/221], ZINB loss:0.4079, NB loss:4.7287, latent MSE loss:0.00108970, KL loss:0.00291095\n",
      "Pretrain epoch [26/221], ZINB loss:0.3907, NB loss:4.6022, latent MSE loss:0.00090512, KL loss:0.00243750\n",
      "Pretrain epoch [27/221], ZINB loss:0.4013, NB loss:4.8090, latent MSE loss:0.00095987, KL loss:0.00005220\n",
      "Pretrain epoch [1/222], ZINB loss:0.3901, NB loss:4.6620, latent MSE loss:0.00127570, KL loss:0.00300566\n",
      "Pretrain epoch [2/222], ZINB loss:0.3957, NB loss:4.6466, latent MSE loss:0.00138924, KL loss:0.00321470\n",
      "Pretrain epoch [3/222], ZINB loss:0.4113, NB loss:4.5929, latent MSE loss:0.00165907, KL loss:0.00294024\n",
      "Pretrain epoch [4/222], ZINB loss:0.3912, NB loss:4.6682, latent MSE loss:0.00111729, KL loss:0.00282457\n",
      "Pretrain epoch [5/222], ZINB loss:0.4091, NB loss:4.6943, latent MSE loss:0.00139057, KL loss:0.00310470\n",
      "Pretrain epoch [6/222], ZINB loss:0.3856, NB loss:4.6963, latent MSE loss:0.00122874, KL loss:0.00261691\n",
      "Pretrain epoch [7/222], ZINB loss:0.3933, NB loss:4.6202, latent MSE loss:0.00100424, KL loss:0.00276512\n",
      "Pretrain epoch [8/222], ZINB loss:0.3811, NB loss:4.6772, latent MSE loss:0.00132810, KL loss:0.00265322\n",
      "Pretrain epoch [9/222], ZINB loss:0.3886, NB loss:4.6503, latent MSE loss:0.00135527, KL loss:0.00264087\n",
      "Pretrain epoch [10/222], ZINB loss:0.4173, NB loss:4.6599, latent MSE loss:0.00125999, KL loss:0.00333847\n",
      "Pretrain epoch [11/222], ZINB loss:0.3908, NB loss:4.6861, latent MSE loss:0.00116821, KL loss:0.00259636\n",
      "Pretrain epoch [12/222], ZINB loss:0.4151, NB loss:4.6027, latent MSE loss:0.00121749, KL loss:0.00316322\n",
      "Pretrain epoch [13/222], ZINB loss:0.3955, NB loss:4.6482, latent MSE loss:0.00097483, KL loss:0.00294793\n",
      "Pretrain epoch [14/222], ZINB loss:0.4161, NB loss:4.5951, latent MSE loss:0.00114344, KL loss:0.00260930\n",
      "Pretrain epoch [15/222], ZINB loss:0.4236, NB loss:4.6835, latent MSE loss:0.00132038, KL loss:0.00281780\n",
      "Pretrain epoch [16/222], ZINB loss:0.3976, NB loss:4.6837, latent MSE loss:0.00092252, KL loss:0.00285803\n",
      "Pretrain epoch [17/222], ZINB loss:0.4077, NB loss:4.6798, latent MSE loss:0.00120024, KL loss:0.00258131\n",
      "Pretrain epoch [18/222], ZINB loss:0.3951, NB loss:4.6401, latent MSE loss:0.00096240, KL loss:0.00306326\n",
      "Pretrain epoch [19/222], ZINB loss:0.4228, NB loss:4.7618, latent MSE loss:0.00106712, KL loss:0.00341760\n",
      "Pretrain epoch [20/222], ZINB loss:0.4108, NB loss:4.5989, latent MSE loss:0.00100162, KL loss:0.00259449\n",
      "Pretrain epoch [21/222], ZINB loss:0.4061, NB loss:4.6682, latent MSE loss:0.00103152, KL loss:0.00295665\n",
      "Pretrain epoch [22/222], ZINB loss:0.4277, NB loss:4.7003, latent MSE loss:0.00095230, KL loss:0.00307317\n",
      "Pretrain epoch [23/222], ZINB loss:0.3815, NB loss:4.6528, latent MSE loss:0.00098223, KL loss:0.00244568\n",
      "Pretrain epoch [24/222], ZINB loss:0.4031, NB loss:4.6329, latent MSE loss:0.00105548, KL loss:0.00311616\n",
      "Pretrain epoch [25/222], ZINB loss:0.3859, NB loss:4.6304, latent MSE loss:0.00076960, KL loss:0.00241058\n",
      "Pretrain epoch [26/222], ZINB loss:0.3936, NB loss:4.6155, latent MSE loss:0.00107915, KL loss:0.00308900\n",
      "Pretrain epoch [27/222], ZINB loss:0.3854, NB loss:4.5891, latent MSE loss:0.00060038, KL loss:0.00001848\n",
      "Pretrain epoch [1/223], ZINB loss:0.3947, NB loss:4.7215, latent MSE loss:0.00265815, KL loss:0.00257664\n",
      "Pretrain epoch [2/223], ZINB loss:0.4093, NB loss:4.6329, latent MSE loss:0.00283639, KL loss:0.00285799\n",
      "Pretrain epoch [3/223], ZINB loss:0.4034, NB loss:4.6310, latent MSE loss:0.00164851, KL loss:0.00283876\n",
      "Pretrain epoch [4/223], ZINB loss:0.4045, NB loss:4.6827, latent MSE loss:0.00265864, KL loss:0.00272573\n",
      "Pretrain epoch [5/223], ZINB loss:0.3889, NB loss:4.6611, latent MSE loss:0.00209429, KL loss:0.00299567\n",
      "Pretrain epoch [6/223], ZINB loss:0.4122, NB loss:4.7348, latent MSE loss:0.00177643, KL loss:0.00301171\n",
      "Pretrain epoch [7/223], ZINB loss:0.4001, NB loss:4.6509, latent MSE loss:0.00242830, KL loss:0.00286226\n",
      "Pretrain epoch [8/223], ZINB loss:0.3944, NB loss:4.6580, latent MSE loss:0.00116545, KL loss:0.00273133\n",
      "Pretrain epoch [9/223], ZINB loss:0.4083, NB loss:4.6574, latent MSE loss:0.00221848, KL loss:0.00264879\n",
      "Pretrain epoch [10/223], ZINB loss:0.4024, NB loss:4.6515, latent MSE loss:0.00113476, KL loss:0.00279546\n",
      "Pretrain epoch [11/223], ZINB loss:0.4048, NB loss:4.6034, latent MSE loss:0.00191964, KL loss:0.00281538\n",
      "Pretrain epoch [12/223], ZINB loss:0.3959, NB loss:4.6451, latent MSE loss:0.00096375, KL loss:0.00277725\n",
      "Pretrain epoch [13/223], ZINB loss:0.4011, NB loss:4.6101, latent MSE loss:0.00163676, KL loss:0.00246718\n",
      "Pretrain epoch [14/223], ZINB loss:0.4142, NB loss:4.5952, latent MSE loss:0.00130691, KL loss:0.00300707\n",
      "Pretrain epoch [15/223], ZINB loss:0.3971, NB loss:4.6517, latent MSE loss:0.00155302, KL loss:0.00263222\n",
      "Pretrain epoch [16/223], ZINB loss:0.3897, NB loss:4.6387, latent MSE loss:0.00116698, KL loss:0.00243227\n",
      "Pretrain epoch [17/223], ZINB loss:0.4004, NB loss:4.6327, latent MSE loss:0.00113402, KL loss:0.00274163\n",
      "Pretrain epoch [18/223], ZINB loss:0.3966, NB loss:4.7498, latent MSE loss:0.00115871, KL loss:0.00270779\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [19/223], ZINB loss:0.3802, NB loss:4.6459, latent MSE loss:0.00123312, KL loss:0.00231677\n",
      "Pretrain epoch [20/223], ZINB loss:0.3963, NB loss:4.6696, latent MSE loss:0.00119343, KL loss:0.00291027\n",
      "Pretrain epoch [21/223], ZINB loss:0.3848, NB loss:4.5985, latent MSE loss:0.00086438, KL loss:0.00224954\n",
      "Pretrain epoch [22/223], ZINB loss:0.4064, NB loss:4.6636, latent MSE loss:0.00133175, KL loss:0.00291328\n",
      "Pretrain epoch [23/223], ZINB loss:0.4131, NB loss:4.6790, latent MSE loss:0.00094781, KL loss:0.00268000\n",
      "Pretrain epoch [24/223], ZINB loss:0.4259, NB loss:4.6239, latent MSE loss:0.00096426, KL loss:0.00268445\n",
      "Pretrain epoch [25/223], ZINB loss:0.4130, NB loss:4.6984, latent MSE loss:0.00104753, KL loss:0.00325573\n",
      "Pretrain epoch [26/223], ZINB loss:0.3891, NB loss:4.6276, latent MSE loss:0.00085081, KL loss:0.00265944\n",
      "Pretrain epoch [27/223], ZINB loss:0.3949, NB loss:4.2430, latent MSE loss:0.00130012, KL loss:0.00005268\n",
      "Pretrain epoch [1/224], ZINB loss:0.4071, NB loss:4.7069, latent MSE loss:0.00128069, KL loss:0.00255494\n",
      "Pretrain epoch [2/224], ZINB loss:0.3982, NB loss:4.6384, latent MSE loss:0.00173295, KL loss:0.00306910\n",
      "Pretrain epoch [3/224], ZINB loss:0.4121, NB loss:4.6452, latent MSE loss:0.00155176, KL loss:0.00284456\n",
      "Pretrain epoch [4/224], ZINB loss:0.4152, NB loss:4.6851, latent MSE loss:0.00173761, KL loss:0.00315399\n",
      "Pretrain epoch [5/224], ZINB loss:0.3879, NB loss:4.6225, latent MSE loss:0.00113154, KL loss:0.00273890\n",
      "Pretrain epoch [6/224], ZINB loss:0.4230, NB loss:4.6351, latent MSE loss:0.00116038, KL loss:0.00260995\n",
      "Pretrain epoch [7/224], ZINB loss:0.3860, NB loss:4.5881, latent MSE loss:0.00152635, KL loss:0.00253204\n",
      "Pretrain epoch [8/224], ZINB loss:0.4147, NB loss:4.6805, latent MSE loss:0.00187041, KL loss:0.00302656\n",
      "Pretrain epoch [9/224], ZINB loss:0.4075, NB loss:4.6421, latent MSE loss:0.00185142, KL loss:0.00302092\n",
      "Pretrain epoch [10/224], ZINB loss:0.3875, NB loss:4.6789, latent MSE loss:0.00155424, KL loss:0.00278162\n",
      "Pretrain epoch [11/224], ZINB loss:0.4017, NB loss:4.6391, latent MSE loss:0.00154888, KL loss:0.00297755\n",
      "Pretrain epoch [12/224], ZINB loss:0.3791, NB loss:4.5837, latent MSE loss:0.00122245, KL loss:0.00248101\n",
      "Pretrain epoch [13/224], ZINB loss:0.4159, NB loss:4.6335, latent MSE loss:0.00128145, KL loss:0.00286603\n",
      "Pretrain epoch [14/224], ZINB loss:0.3797, NB loss:4.5792, latent MSE loss:0.00147732, KL loss:0.00243566\n",
      "Pretrain epoch [15/224], ZINB loss:0.4206, NB loss:4.5965, latent MSE loss:0.00153928, KL loss:0.00291838\n",
      "Pretrain epoch [16/224], ZINB loss:0.3913, NB loss:4.6351, latent MSE loss:0.00139157, KL loss:0.00278546\n",
      "Pretrain epoch [17/224], ZINB loss:0.4058, NB loss:4.7282, latent MSE loss:0.00139539, KL loss:0.00297816\n",
      "Pretrain epoch [18/224], ZINB loss:0.4072, NB loss:4.6305, latent MSE loss:0.00179335, KL loss:0.00327409\n",
      "Pretrain epoch [19/224], ZINB loss:0.3959, NB loss:4.6504, latent MSE loss:0.00117049, KL loss:0.00268800\n",
      "Pretrain epoch [20/224], ZINB loss:0.4118, NB loss:4.6141, latent MSE loss:0.00119282, KL loss:0.00271265\n",
      "Pretrain epoch [21/224], ZINB loss:0.3850, NB loss:4.6660, latent MSE loss:0.00099355, KL loss:0.00298972\n",
      "Pretrain epoch [22/224], ZINB loss:0.4058, NB loss:4.6550, latent MSE loss:0.00141964, KL loss:0.00327205\n",
      "Pretrain epoch [23/224], ZINB loss:0.3989, NB loss:4.7176, latent MSE loss:0.00120345, KL loss:0.00287446\n",
      "Pretrain epoch [24/224], ZINB loss:0.4210, NB loss:4.6912, latent MSE loss:0.00093575, KL loss:0.00311146\n",
      "Pretrain epoch [25/224], ZINB loss:0.4028, NB loss:4.6881, latent MSE loss:0.00107118, KL loss:0.00276433\n",
      "Pretrain epoch [26/224], ZINB loss:0.4032, NB loss:4.7179, latent MSE loss:0.00084144, KL loss:0.00277954\n",
      "Pretrain epoch [27/224], ZINB loss:0.3396, NB loss:4.5190, latent MSE loss:0.00090024, KL loss:0.00005592\n",
      "Pretrain epoch [1/225], ZINB loss:0.4030, NB loss:4.6096, latent MSE loss:0.00117229, KL loss:0.00274428\n",
      "Pretrain epoch [2/225], ZINB loss:0.3824, NB loss:4.6260, latent MSE loss:0.00107594, KL loss:0.00286254\n",
      "Pretrain epoch [3/225], ZINB loss:0.4032, NB loss:4.6797, latent MSE loss:0.00090301, KL loss:0.00286444\n",
      "Pretrain epoch [4/225], ZINB loss:0.3897, NB loss:4.6141, latent MSE loss:0.00083147, KL loss:0.00228723\n",
      "Pretrain epoch [5/225], ZINB loss:0.4198, NB loss:4.6438, latent MSE loss:0.00085950, KL loss:0.00320889\n",
      "Pretrain epoch [6/225], ZINB loss:0.4031, NB loss:4.6521, latent MSE loss:0.00087082, KL loss:0.00298633\n",
      "Pretrain epoch [7/225], ZINB loss:0.4107, NB loss:4.6224, latent MSE loss:0.00080851, KL loss:0.00275034\n",
      "Pretrain epoch [8/225], ZINB loss:0.4131, NB loss:4.6030, latent MSE loss:0.00072659, KL loss:0.00297250\n",
      "Pretrain epoch [9/225], ZINB loss:0.4036, NB loss:4.6720, latent MSE loss:0.00074295, KL loss:0.00258332\n",
      "Pretrain epoch [10/225], ZINB loss:0.3935, NB loss:4.6619, latent MSE loss:0.00068734, KL loss:0.00269246\n",
      "Pretrain epoch [11/225], ZINB loss:0.4383, NB loss:4.6310, latent MSE loss:0.00082296, KL loss:0.00324063\n",
      "Pretrain epoch [12/225], ZINB loss:0.3935, NB loss:4.6568, latent MSE loss:0.00066069, KL loss:0.00240214\n",
      "Pretrain epoch [13/225], ZINB loss:0.3971, NB loss:4.6334, latent MSE loss:0.00072501, KL loss:0.00265904\n",
      "Pretrain epoch [14/225], ZINB loss:0.3858, NB loss:4.6294, latent MSE loss:0.00061931, KL loss:0.00240134\n",
      "Pretrain epoch [15/225], ZINB loss:0.4015, NB loss:4.6835, latent MSE loss:0.00068215, KL loss:0.00253102\n",
      "Pretrain epoch [16/225], ZINB loss:0.4027, NB loss:4.6585, latent MSE loss:0.00074911, KL loss:0.00270743\n",
      "Pretrain epoch [17/225], ZINB loss:0.3893, NB loss:4.6678, latent MSE loss:0.00065664, KL loss:0.00265364\n",
      "Pretrain epoch [18/225], ZINB loss:0.3972, NB loss:4.6473, latent MSE loss:0.00063427, KL loss:0.00245939\n",
      "Pretrain epoch [19/225], ZINB loss:0.4002, NB loss:4.6840, latent MSE loss:0.00063046, KL loss:0.00281437\n",
      "Pretrain epoch [20/225], ZINB loss:0.4005, NB loss:4.6269, latent MSE loss:0.00066014, KL loss:0.00253580\n",
      "Pretrain epoch [21/225], ZINB loss:0.3858, NB loss:4.6911, latent MSE loss:0.00066753, KL loss:0.00245114\n",
      "Pretrain epoch [22/225], ZINB loss:0.3828, NB loss:4.6472, latent MSE loss:0.00051998, KL loss:0.00248612\n",
      "Pretrain epoch [23/225], ZINB loss:0.3857, NB loss:4.6424, latent MSE loss:0.00060679, KL loss:0.00251239\n",
      "Pretrain epoch [24/225], ZINB loss:0.4192, NB loss:4.6654, latent MSE loss:0.00071585, KL loss:0.00319025\n",
      "Pretrain epoch [25/225], ZINB loss:0.3986, NB loss:4.6937, latent MSE loss:0.00050855, KL loss:0.00249604\n",
      "Pretrain epoch [26/225], ZINB loss:0.4071, NB loss:4.6709, latent MSE loss:0.00061397, KL loss:0.00258497\n",
      "Pretrain epoch [27/225], ZINB loss:0.4335, NB loss:4.4320, latent MSE loss:0.00023674, KL loss:0.00001286\n",
      "Pretrain epoch [1/226], ZINB loss:0.4089, NB loss:4.6735, latent MSE loss:0.00077693, KL loss:0.00266091\n",
      "Pretrain epoch [2/226], ZINB loss:0.3870, NB loss:4.5992, latent MSE loss:0.00064059, KL loss:0.00237656\n",
      "Pretrain epoch [3/226], ZINB loss:0.4023, NB loss:4.6504, latent MSE loss:0.00073343, KL loss:0.00262701\n",
      "Pretrain epoch [4/226], ZINB loss:0.3906, NB loss:4.6593, latent MSE loss:0.00052284, KL loss:0.00238510\n",
      "Pretrain epoch [5/226], ZINB loss:0.3987, NB loss:4.6365, latent MSE loss:0.00059214, KL loss:0.00236075\n",
      "Pretrain epoch [6/226], ZINB loss:0.4052, NB loss:4.7181, latent MSE loss:0.00060744, KL loss:0.00276416\n",
      "Pretrain epoch [7/226], ZINB loss:0.4078, NB loss:4.6829, latent MSE loss:0.00059224, KL loss:0.00260190\n",
      "Pretrain epoch [8/226], ZINB loss:0.3962, NB loss:4.6362, latent MSE loss:0.00061477, KL loss:0.00240795\n",
      "Pretrain epoch [9/226], ZINB loss:0.3931, NB loss:4.6623, latent MSE loss:0.00090353, KL loss:0.00281782\n",
      "Pretrain epoch [10/226], ZINB loss:0.4135, NB loss:4.6576, latent MSE loss:0.00067100, KL loss:0.00278227\n",
      "Pretrain epoch [11/226], ZINB loss:0.3933, NB loss:4.5386, latent MSE loss:0.00054830, KL loss:0.00252007\n",
      "Pretrain epoch [12/226], ZINB loss:0.4071, NB loss:4.6274, latent MSE loss:0.00068822, KL loss:0.00301050\n",
      "Pretrain epoch [13/226], ZINB loss:0.4010, NB loss:4.6753, latent MSE loss:0.00055325, KL loss:0.00290682\n",
      "Pretrain epoch [14/226], ZINB loss:0.3983, NB loss:4.6325, latent MSE loss:0.00071174, KL loss:0.00243654\n",
      "Pretrain epoch [15/226], ZINB loss:0.4117, NB loss:4.6771, latent MSE loss:0.00071080, KL loss:0.00281105\n",
      "Pretrain epoch [16/226], ZINB loss:0.3915, NB loss:4.6424, latent MSE loss:0.00056538, KL loss:0.00229753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [17/226], ZINB loss:0.3934, NB loss:4.6536, latent MSE loss:0.00064630, KL loss:0.00253211\n",
      "Pretrain epoch [18/226], ZINB loss:0.3791, NB loss:4.6820, latent MSE loss:0.00064310, KL loss:0.00288743\n",
      "Pretrain epoch [19/226], ZINB loss:0.4132, NB loss:4.6970, latent MSE loss:0.00073397, KL loss:0.00283774\n",
      "Pretrain epoch [20/226], ZINB loss:0.4301, NB loss:4.6856, latent MSE loss:0.00070328, KL loss:0.00274216\n",
      "Pretrain epoch [21/226], ZINB loss:0.4000, NB loss:4.6173, latent MSE loss:0.00061756, KL loss:0.00231971\n",
      "Pretrain epoch [22/226], ZINB loss:0.4100, NB loss:4.5555, latent MSE loss:0.00055526, KL loss:0.00253030\n",
      "Pretrain epoch [23/226], ZINB loss:0.3973, NB loss:4.6413, latent MSE loss:0.00072983, KL loss:0.00241719\n",
      "Pretrain epoch [24/226], ZINB loss:0.3834, NB loss:4.6050, latent MSE loss:0.00056068, KL loss:0.00213228\n",
      "Pretrain epoch [25/226], ZINB loss:0.3899, NB loss:4.6968, latent MSE loss:0.00065851, KL loss:0.00287093\n",
      "Pretrain epoch [26/226], ZINB loss:0.3976, NB loss:4.6697, latent MSE loss:0.00060344, KL loss:0.00248782\n",
      "Pretrain epoch [27/226], ZINB loss:0.5383, NB loss:4.4830, latent MSE loss:0.00085338, KL loss:0.00001756\n",
      "Pretrain epoch [1/227], ZINB loss:0.3974, NB loss:4.5929, latent MSE loss:0.00142076, KL loss:0.00242754\n",
      "Pretrain epoch [2/227], ZINB loss:0.4267, NB loss:4.6498, latent MSE loss:0.00185477, KL loss:0.00252776\n",
      "Pretrain epoch [3/227], ZINB loss:0.4039, NB loss:4.6672, latent MSE loss:0.00121835, KL loss:0.00280421\n",
      "Pretrain epoch [4/227], ZINB loss:0.4078, NB loss:4.6525, latent MSE loss:0.00129514, KL loss:0.00312316\n",
      "Pretrain epoch [5/227], ZINB loss:0.3927, NB loss:4.6306, latent MSE loss:0.00162219, KL loss:0.00261193\n",
      "Pretrain epoch [6/227], ZINB loss:0.4049, NB loss:4.6865, latent MSE loss:0.00167708, KL loss:0.00239816\n",
      "Pretrain epoch [7/227], ZINB loss:0.4090, NB loss:4.6990, latent MSE loss:0.00174098, KL loss:0.00253237\n",
      "Pretrain epoch [8/227], ZINB loss:0.3977, NB loss:4.6429, latent MSE loss:0.00123288, KL loss:0.00297826\n",
      "Pretrain epoch [9/227], ZINB loss:0.3921, NB loss:4.5932, latent MSE loss:0.00117110, KL loss:0.00267941\n",
      "Pretrain epoch [10/227], ZINB loss:0.3842, NB loss:4.6691, latent MSE loss:0.00127981, KL loss:0.00247599\n",
      "Pretrain epoch [11/227], ZINB loss:0.4052, NB loss:4.6300, latent MSE loss:0.00157687, KL loss:0.00287640\n",
      "Pretrain epoch [12/227], ZINB loss:0.4329, NB loss:4.6117, latent MSE loss:0.00154376, KL loss:0.00291752\n",
      "Pretrain epoch [13/227], ZINB loss:0.4112, NB loss:4.7144, latent MSE loss:0.00109516, KL loss:0.00283188\n",
      "Pretrain epoch [14/227], ZINB loss:0.3946, NB loss:4.6014, latent MSE loss:0.00127606, KL loss:0.00256649\n",
      "Pretrain epoch [15/227], ZINB loss:0.4183, NB loss:4.6278, latent MSE loss:0.00124043, KL loss:0.00268998\n",
      "Pretrain epoch [16/227], ZINB loss:0.4007, NB loss:4.6749, latent MSE loss:0.00103578, KL loss:0.00244478\n",
      "Pretrain epoch [17/227], ZINB loss:0.3823, NB loss:4.7073, latent MSE loss:0.00092728, KL loss:0.00251631\n",
      "Pretrain epoch [18/227], ZINB loss:0.4089, NB loss:4.6570, latent MSE loss:0.00082930, KL loss:0.00279805\n",
      "Pretrain epoch [19/227], ZINB loss:0.4064, NB loss:4.6423, latent MSE loss:0.00099755, KL loss:0.00284728\n",
      "Pretrain epoch [20/227], ZINB loss:0.3875, NB loss:4.5947, latent MSE loss:0.00087754, KL loss:0.00218537\n",
      "Pretrain epoch [21/227], ZINB loss:0.3818, NB loss:4.6310, latent MSE loss:0.00077436, KL loss:0.00225980\n",
      "Pretrain epoch [22/227], ZINB loss:0.3973, NB loss:4.6308, latent MSE loss:0.00070433, KL loss:0.00239888\n",
      "Pretrain epoch [23/227], ZINB loss:0.4014, NB loss:4.6919, latent MSE loss:0.00092888, KL loss:0.00259681\n",
      "Pretrain epoch [24/227], ZINB loss:0.4029, NB loss:4.6616, latent MSE loss:0.00088449, KL loss:0.00265639\n",
      "Pretrain epoch [25/227], ZINB loss:0.3975, NB loss:4.5773, latent MSE loss:0.00090551, KL loss:0.00219314\n",
      "Pretrain epoch [26/227], ZINB loss:0.4059, NB loss:4.6948, latent MSE loss:0.00099608, KL loss:0.00265289\n",
      "Pretrain epoch [27/227], ZINB loss:0.3790, NB loss:4.9571, latent MSE loss:0.00054104, KL loss:0.00005724\n",
      "Pretrain epoch [1/228], ZINB loss:0.4072, NB loss:4.6974, latent MSE loss:0.00110162, KL loss:0.00253839\n",
      "Pretrain epoch [2/228], ZINB loss:0.3890, NB loss:4.6506, latent MSE loss:0.00098666, KL loss:0.00256152\n",
      "Pretrain epoch [3/228], ZINB loss:0.4203, NB loss:4.6967, latent MSE loss:0.00098750, KL loss:0.00306055\n",
      "Pretrain epoch [4/228], ZINB loss:0.4075, NB loss:4.6205, latent MSE loss:0.00094705, KL loss:0.00230056\n",
      "Pretrain epoch [5/228], ZINB loss:0.3896, NB loss:4.6732, latent MSE loss:0.00088117, KL loss:0.00254550\n",
      "Pretrain epoch [6/228], ZINB loss:0.4042, NB loss:4.6354, latent MSE loss:0.00088373, KL loss:0.00274821\n",
      "Pretrain epoch [7/228], ZINB loss:0.3912, NB loss:4.6814, latent MSE loss:0.00082388, KL loss:0.00249404\n",
      "Pretrain epoch [8/228], ZINB loss:0.4029, NB loss:4.7384, latent MSE loss:0.00092012, KL loss:0.00225820\n",
      "Pretrain epoch [9/228], ZINB loss:0.3964, NB loss:4.5933, latent MSE loss:0.00088508, KL loss:0.00225482\n",
      "Pretrain epoch [10/228], ZINB loss:0.4029, NB loss:4.6586, latent MSE loss:0.00084679, KL loss:0.00287447\n",
      "Pretrain epoch [11/228], ZINB loss:0.3937, NB loss:4.6552, latent MSE loss:0.00078424, KL loss:0.00299088\n",
      "Pretrain epoch [12/228], ZINB loss:0.3954, NB loss:4.6444, latent MSE loss:0.00082963, KL loss:0.00289452\n",
      "Pretrain epoch [13/228], ZINB loss:0.3998, NB loss:4.6110, latent MSE loss:0.00079733, KL loss:0.00238269\n",
      "Pretrain epoch [14/228], ZINB loss:0.4069, NB loss:4.6402, latent MSE loss:0.00074678, KL loss:0.00280601\n",
      "Pretrain epoch [15/228], ZINB loss:0.4006, NB loss:4.5927, latent MSE loss:0.00072607, KL loss:0.00244604\n",
      "Pretrain epoch [16/228], ZINB loss:0.4148, NB loss:4.6322, latent MSE loss:0.00073499, KL loss:0.00215813\n",
      "Pretrain epoch [17/228], ZINB loss:0.3959, NB loss:4.5707, latent MSE loss:0.00064164, KL loss:0.00243021\n",
      "Pretrain epoch [18/228], ZINB loss:0.3988, NB loss:4.6850, latent MSE loss:0.00061812, KL loss:0.00259518\n",
      "Pretrain epoch [19/228], ZINB loss:0.3950, NB loss:4.6251, latent MSE loss:0.00076937, KL loss:0.00242830\n",
      "Pretrain epoch [20/228], ZINB loss:0.4115, NB loss:4.6029, latent MSE loss:0.00069237, KL loss:0.00238817\n",
      "Pretrain epoch [21/228], ZINB loss:0.3911, NB loss:4.7101, latent MSE loss:0.00074688, KL loss:0.00262913\n",
      "Pretrain epoch [22/228], ZINB loss:0.3886, NB loss:4.6293, latent MSE loss:0.00069863, KL loss:0.00205725\n",
      "Pretrain epoch [23/228], ZINB loss:0.4020, NB loss:4.6245, latent MSE loss:0.00073522, KL loss:0.00232401\n",
      "Pretrain epoch [24/228], ZINB loss:0.3737, NB loss:4.6907, latent MSE loss:0.00054775, KL loss:0.00231700\n",
      "Pretrain epoch [25/228], ZINB loss:0.4160, NB loss:4.6327, latent MSE loss:0.00072249, KL loss:0.00280704\n",
      "Pretrain epoch [26/228], ZINB loss:0.4148, NB loss:4.6118, latent MSE loss:0.00068380, KL loss:0.00251826\n",
      "Pretrain epoch [27/228], ZINB loss:0.4199, NB loss:4.5102, latent MSE loss:0.00107304, KL loss:0.00005607\n",
      "Pretrain epoch [1/229], ZINB loss:0.4196, NB loss:4.6797, latent MSE loss:0.00139684, KL loss:0.00246185\n",
      "Pretrain epoch [2/229], ZINB loss:0.4110, NB loss:4.6210, latent MSE loss:0.00169274, KL loss:0.00247908\n",
      "Pretrain epoch [3/229], ZINB loss:0.3807, NB loss:4.6709, latent MSE loss:0.00101016, KL loss:0.00280059\n",
      "Pretrain epoch [4/229], ZINB loss:0.4159, NB loss:4.7003, latent MSE loss:0.00123104, KL loss:0.00263469\n",
      "Pretrain epoch [5/229], ZINB loss:0.4006, NB loss:4.6735, latent MSE loss:0.00111852, KL loss:0.00264569\n",
      "Pretrain epoch [6/229], ZINB loss:0.4012, NB loss:4.6273, latent MSE loss:0.00097534, KL loss:0.00251063\n",
      "Pretrain epoch [7/229], ZINB loss:0.4160, NB loss:4.6466, latent MSE loss:0.00126613, KL loss:0.00285697\n",
      "Pretrain epoch [8/229], ZINB loss:0.4097, NB loss:4.5866, latent MSE loss:0.00095218, KL loss:0.00267886\n",
      "Pretrain epoch [9/229], ZINB loss:0.3999, NB loss:4.6654, latent MSE loss:0.00102808, KL loss:0.00228390\n",
      "Pretrain epoch [10/229], ZINB loss:0.3851, NB loss:4.6556, latent MSE loss:0.00098995, KL loss:0.00221282\n",
      "Pretrain epoch [11/229], ZINB loss:0.4069, NB loss:4.7308, latent MSE loss:0.00080183, KL loss:0.00255319\n",
      "Pretrain epoch [12/229], ZINB loss:0.4092, NB loss:4.6220, latent MSE loss:0.00104140, KL loss:0.00253280\n",
      "Pretrain epoch [13/229], ZINB loss:0.3796, NB loss:4.5795, latent MSE loss:0.00083004, KL loss:0.00205587\n",
      "Pretrain epoch [14/229], ZINB loss:0.3914, NB loss:4.6905, latent MSE loss:0.00071489, KL loss:0.00239102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [15/229], ZINB loss:0.3991, NB loss:4.6107, latent MSE loss:0.00075934, KL loss:0.00215730\n",
      "Pretrain epoch [16/229], ZINB loss:0.3999, NB loss:4.6036, latent MSE loss:0.00075886, KL loss:0.00238192\n",
      "Pretrain epoch [17/229], ZINB loss:0.3909, NB loss:4.6677, latent MSE loss:0.00065483, KL loss:0.00247305\n",
      "Pretrain epoch [18/229], ZINB loss:0.3988, NB loss:4.6865, latent MSE loss:0.00079373, KL loss:0.00270168\n",
      "Pretrain epoch [19/229], ZINB loss:0.3996, NB loss:4.6243, latent MSE loss:0.00069772, KL loss:0.00271275\n",
      "Pretrain epoch [20/229], ZINB loss:0.3976, NB loss:4.6421, latent MSE loss:0.00064505, KL loss:0.00250005\n",
      "Pretrain epoch [21/229], ZINB loss:0.4033, NB loss:4.5930, latent MSE loss:0.00056687, KL loss:0.00238878\n",
      "Pretrain epoch [22/229], ZINB loss:0.4058, NB loss:4.6833, latent MSE loss:0.00067327, KL loss:0.00243815\n",
      "Pretrain epoch [23/229], ZINB loss:0.3916, NB loss:4.6701, latent MSE loss:0.00057646, KL loss:0.00239091\n",
      "Pretrain epoch [24/229], ZINB loss:0.3898, NB loss:4.6138, latent MSE loss:0.00060727, KL loss:0.00221630\n",
      "Pretrain epoch [25/229], ZINB loss:0.4139, NB loss:4.5867, latent MSE loss:0.00058506, KL loss:0.00236809\n",
      "Pretrain epoch [26/229], ZINB loss:0.3863, NB loss:4.6292, latent MSE loss:0.00055056, KL loss:0.00221005\n",
      "Pretrain epoch [27/229], ZINB loss:0.3901, NB loss:4.4803, latent MSE loss:0.00040068, KL loss:0.00005202\n",
      "Pretrain epoch [1/230], ZINB loss:0.4050, NB loss:4.7270, latent MSE loss:0.00070039, KL loss:0.00272549\n",
      "Pretrain epoch [2/230], ZINB loss:0.3975, NB loss:4.6184, latent MSE loss:0.00070973, KL loss:0.00287222\n",
      "Pretrain epoch [3/230], ZINB loss:0.3946, NB loss:4.6450, latent MSE loss:0.00071403, KL loss:0.00242847\n",
      "Pretrain epoch [4/230], ZINB loss:0.4052, NB loss:4.6479, latent MSE loss:0.00056442, KL loss:0.00240496\n",
      "Pretrain epoch [5/230], ZINB loss:0.3945, NB loss:4.6767, latent MSE loss:0.00058237, KL loss:0.00228364\n",
      "Pretrain epoch [6/230], ZINB loss:0.4113, NB loss:4.7058, latent MSE loss:0.00051552, KL loss:0.00268843\n",
      "Pretrain epoch [7/230], ZINB loss:0.3971, NB loss:4.6866, latent MSE loss:0.00052477, KL loss:0.00264470\n",
      "Pretrain epoch [8/230], ZINB loss:0.4187, NB loss:4.6573, latent MSE loss:0.00073079, KL loss:0.00269489\n",
      "Pretrain epoch [9/230], ZINB loss:0.3922, NB loss:4.6341, latent MSE loss:0.00044350, KL loss:0.00236600\n",
      "Pretrain epoch [10/230], ZINB loss:0.3967, NB loss:4.6763, latent MSE loss:0.00051570, KL loss:0.00237976\n",
      "Pretrain epoch [11/230], ZINB loss:0.4366, NB loss:4.6348, latent MSE loss:0.00060502, KL loss:0.00266466\n",
      "Pretrain epoch [12/230], ZINB loss:0.3838, NB loss:4.6882, latent MSE loss:0.00046058, KL loss:0.00249427\n",
      "Pretrain epoch [13/230], ZINB loss:0.3949, NB loss:4.6415, latent MSE loss:0.00043049, KL loss:0.00219691\n",
      "Pretrain epoch [14/230], ZINB loss:0.3951, NB loss:4.6451, latent MSE loss:0.00054196, KL loss:0.00257906\n",
      "Pretrain epoch [15/230], ZINB loss:0.3894, NB loss:4.6538, latent MSE loss:0.00061201, KL loss:0.00238701\n",
      "Pretrain epoch [16/230], ZINB loss:0.4019, NB loss:4.6020, latent MSE loss:0.00046025, KL loss:0.00212227\n",
      "Pretrain epoch [17/230], ZINB loss:0.3969, NB loss:4.6234, latent MSE loss:0.00054323, KL loss:0.00232013\n",
      "Pretrain epoch [18/230], ZINB loss:0.3818, NB loss:4.6073, latent MSE loss:0.00052857, KL loss:0.00230482\n",
      "Pretrain epoch [19/230], ZINB loss:0.4190, NB loss:4.6058, latent MSE loss:0.00056480, KL loss:0.00262086\n",
      "Pretrain epoch [20/230], ZINB loss:0.4015, NB loss:4.6033, latent MSE loss:0.00050520, KL loss:0.00238564\n",
      "Pretrain epoch [21/230], ZINB loss:0.4041, NB loss:4.6491, latent MSE loss:0.00058730, KL loss:0.00248260\n",
      "Pretrain epoch [22/230], ZINB loss:0.3902, NB loss:4.5419, latent MSE loss:0.00045116, KL loss:0.00233716\n",
      "Pretrain epoch [23/230], ZINB loss:0.3822, NB loss:4.6527, latent MSE loss:0.00052993, KL loss:0.00288418\n",
      "Pretrain epoch [24/230], ZINB loss:0.4019, NB loss:4.6247, latent MSE loss:0.00064381, KL loss:0.00237377\n",
      "Pretrain epoch [25/230], ZINB loss:0.3902, NB loss:4.6238, latent MSE loss:0.00055118, KL loss:0.00224083\n",
      "Pretrain epoch [26/230], ZINB loss:0.4059, NB loss:4.6500, latent MSE loss:0.00057999, KL loss:0.00236959\n",
      "Pretrain epoch [27/230], ZINB loss:0.2604, NB loss:4.4729, latent MSE loss:0.00040428, KL loss:0.00004618\n",
      "Pretrain epoch [1/231], ZINB loss:0.4074, NB loss:4.6964, latent MSE loss:0.00081040, KL loss:0.00219068\n",
      "Pretrain epoch [2/231], ZINB loss:0.3922, NB loss:4.6345, latent MSE loss:0.00065637, KL loss:0.00218497\n",
      "Pretrain epoch [3/231], ZINB loss:0.4076, NB loss:4.5977, latent MSE loss:0.00081607, KL loss:0.00250197\n",
      "Pretrain epoch [4/231], ZINB loss:0.3742, NB loss:4.6620, latent MSE loss:0.00058497, KL loss:0.00217308\n",
      "Pretrain epoch [5/231], ZINB loss:0.4278, NB loss:4.6291, latent MSE loss:0.00073815, KL loss:0.00285170\n",
      "Pretrain epoch [6/231], ZINB loss:0.3826, NB loss:4.6549, latent MSE loss:0.00067222, KL loss:0.00230223\n",
      "Pretrain epoch [7/231], ZINB loss:0.3801, NB loss:4.6445, latent MSE loss:0.00072251, KL loss:0.00251567\n",
      "Pretrain epoch [8/231], ZINB loss:0.3891, NB loss:4.6366, latent MSE loss:0.00068262, KL loss:0.00266558\n",
      "Pretrain epoch [9/231], ZINB loss:0.3954, NB loss:4.7043, latent MSE loss:0.00061912, KL loss:0.00237515\n",
      "Pretrain epoch [10/231], ZINB loss:0.4096, NB loss:4.6753, latent MSE loss:0.00059204, KL loss:0.00262789\n",
      "Pretrain epoch [11/231], ZINB loss:0.3941, NB loss:4.6201, latent MSE loss:0.00072121, KL loss:0.00228871\n",
      "Pretrain epoch [12/231], ZINB loss:0.4096, NB loss:4.6208, latent MSE loss:0.00070173, KL loss:0.00237888\n",
      "Pretrain epoch [13/231], ZINB loss:0.4126, NB loss:4.5457, latent MSE loss:0.00074800, KL loss:0.00246127\n",
      "Pretrain epoch [14/231], ZINB loss:0.4006, NB loss:4.6392, latent MSE loss:0.00056069, KL loss:0.00215146\n",
      "Pretrain epoch [15/231], ZINB loss:0.4057, NB loss:4.5932, latent MSE loss:0.00058870, KL loss:0.00241363\n",
      "Pretrain epoch [16/231], ZINB loss:0.4186, NB loss:4.5730, latent MSE loss:0.00054716, KL loss:0.00272932\n",
      "Pretrain epoch [17/231], ZINB loss:0.3920, NB loss:4.6154, latent MSE loss:0.00064063, KL loss:0.00215704\n",
      "Pretrain epoch [18/231], ZINB loss:0.4055, NB loss:4.6655, latent MSE loss:0.00061412, KL loss:0.00225630\n",
      "Pretrain epoch [19/231], ZINB loss:0.3963, NB loss:4.6507, latent MSE loss:0.00070954, KL loss:0.00239161\n",
      "Pretrain epoch [20/231], ZINB loss:0.3932, NB loss:4.6908, latent MSE loss:0.00061034, KL loss:0.00253619\n",
      "Pretrain epoch [21/231], ZINB loss:0.3884, NB loss:4.6710, latent MSE loss:0.00053978, KL loss:0.00254769\n",
      "Pretrain epoch [22/231], ZINB loss:0.3954, NB loss:4.6891, latent MSE loss:0.00058896, KL loss:0.00226012\n",
      "Pretrain epoch [23/231], ZINB loss:0.4163, NB loss:4.5869, latent MSE loss:0.00050811, KL loss:0.00223877\n",
      "Pretrain epoch [24/231], ZINB loss:0.4057, NB loss:4.6079, latent MSE loss:0.00049972, KL loss:0.00244803\n",
      "Pretrain epoch [25/231], ZINB loss:0.3935, NB loss:4.7092, latent MSE loss:0.00046920, KL loss:0.00235360\n",
      "Pretrain epoch [26/231], ZINB loss:0.3784, NB loss:4.6516, latent MSE loss:0.00048499, KL loss:0.00260751\n",
      "Pretrain epoch [27/231], ZINB loss:0.3524, NB loss:5.3887, latent MSE loss:0.00052551, KL loss:0.00004905\n",
      "Pretrain epoch [1/232], ZINB loss:0.3871, NB loss:4.6372, latent MSE loss:0.00088396, KL loss:0.00208970\n",
      "Pretrain epoch [2/232], ZINB loss:0.3992, NB loss:4.6832, latent MSE loss:0.00128569, KL loss:0.00210281\n",
      "Pretrain epoch [3/232], ZINB loss:0.4119, NB loss:4.6302, latent MSE loss:0.00092166, KL loss:0.00239745\n",
      "Pretrain epoch [4/232], ZINB loss:0.3994, NB loss:4.6189, latent MSE loss:0.00064041, KL loss:0.00206362\n",
      "Pretrain epoch [5/232], ZINB loss:0.3951, NB loss:4.5846, latent MSE loss:0.00070374, KL loss:0.00282588\n",
      "Pretrain epoch [6/232], ZINB loss:0.3988, NB loss:4.6822, latent MSE loss:0.00095484, KL loss:0.00249745\n",
      "Pretrain epoch [7/232], ZINB loss:0.4002, NB loss:4.6234, latent MSE loss:0.00098631, KL loss:0.00232653\n",
      "Pretrain epoch [8/232], ZINB loss:0.4026, NB loss:4.6502, latent MSE loss:0.00067128, KL loss:0.00248877\n",
      "Pretrain epoch [9/232], ZINB loss:0.3964, NB loss:4.6765, latent MSE loss:0.00046819, KL loss:0.00239034\n",
      "Pretrain epoch [10/232], ZINB loss:0.3983, NB loss:4.5978, latent MSE loss:0.00073166, KL loss:0.00210791\n",
      "Pretrain epoch [11/232], ZINB loss:0.4025, NB loss:4.5910, latent MSE loss:0.00082260, KL loss:0.00254036\n",
      "Pretrain epoch [12/232], ZINB loss:0.4092, NB loss:4.6483, latent MSE loss:0.00075750, KL loss:0.00249030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [13/232], ZINB loss:0.4007, NB loss:4.7244, latent MSE loss:0.00058751, KL loss:0.00270494\n",
      "Pretrain epoch [14/232], ZINB loss:0.3972, NB loss:4.6255, latent MSE loss:0.00063413, KL loss:0.00231104\n",
      "Pretrain epoch [15/232], ZINB loss:0.4025, NB loss:4.6443, latent MSE loss:0.00063347, KL loss:0.00287249\n",
      "Pretrain epoch [16/232], ZINB loss:0.4044, NB loss:4.5775, latent MSE loss:0.00057727, KL loss:0.00233474\n",
      "Pretrain epoch [17/232], ZINB loss:0.4026, NB loss:4.7294, latent MSE loss:0.00048649, KL loss:0.00220682\n",
      "Pretrain epoch [18/232], ZINB loss:0.3968, NB loss:4.6748, latent MSE loss:0.00048671, KL loss:0.00243618\n",
      "Pretrain epoch [19/232], ZINB loss:0.4032, NB loss:4.5801, latent MSE loss:0.00056117, KL loss:0.00219623\n",
      "Pretrain epoch [20/232], ZINB loss:0.3970, NB loss:4.6363, latent MSE loss:0.00067642, KL loss:0.00228228\n",
      "Pretrain epoch [21/232], ZINB loss:0.3844, NB loss:4.6859, latent MSE loss:0.00063536, KL loss:0.00243873\n",
      "Pretrain epoch [22/232], ZINB loss:0.3981, NB loss:4.6925, latent MSE loss:0.00060107, KL loss:0.00236782\n",
      "Pretrain epoch [23/232], ZINB loss:0.4093, NB loss:4.6175, latent MSE loss:0.00054169, KL loss:0.00233619\n",
      "Pretrain epoch [24/232], ZINB loss:0.3892, NB loss:4.6364, latent MSE loss:0.00049552, KL loss:0.00230677\n",
      "Pretrain epoch [25/232], ZINB loss:0.4083, NB loss:4.6364, latent MSE loss:0.00054451, KL loss:0.00233140\n",
      "Pretrain epoch [26/232], ZINB loss:0.3820, NB loss:4.5917, latent MSE loss:0.00058739, KL loss:0.00215449\n",
      "Pretrain epoch [27/232], ZINB loss:0.4496, NB loss:5.2424, latent MSE loss:0.00158823, KL loss:0.00004115\n",
      "Pretrain epoch [1/233], ZINB loss:0.4064, NB loss:4.6414, latent MSE loss:0.00141013, KL loss:0.00243160\n",
      "Pretrain epoch [2/233], ZINB loss:0.4004, NB loss:4.5994, latent MSE loss:0.00195548, KL loss:0.00225580\n",
      "Pretrain epoch [3/233], ZINB loss:0.4054, NB loss:4.6518, latent MSE loss:0.00177331, KL loss:0.00269206\n",
      "Pretrain epoch [4/233], ZINB loss:0.3827, NB loss:4.6116, latent MSE loss:0.00120079, KL loss:0.00213279\n",
      "Pretrain epoch [5/233], ZINB loss:0.4068, NB loss:4.6311, latent MSE loss:0.00155818, KL loss:0.00241489\n",
      "Pretrain epoch [6/233], ZINB loss:0.3840, NB loss:4.5966, latent MSE loss:0.00120815, KL loss:0.00209821\n",
      "Pretrain epoch [7/233], ZINB loss:0.4062, NB loss:4.6317, latent MSE loss:0.00132782, KL loss:0.00259396\n",
      "Pretrain epoch [8/233], ZINB loss:0.4184, NB loss:4.6223, latent MSE loss:0.00161616, KL loss:0.00292346\n",
      "Pretrain epoch [9/233], ZINB loss:0.4156, NB loss:4.5754, latent MSE loss:0.00116624, KL loss:0.00243709\n",
      "Pretrain epoch [10/233], ZINB loss:0.4023, NB loss:4.7267, latent MSE loss:0.00121030, KL loss:0.00253461\n",
      "Pretrain epoch [11/233], ZINB loss:0.3983, NB loss:4.6210, latent MSE loss:0.00125839, KL loss:0.00205222\n",
      "Pretrain epoch [12/233], ZINB loss:0.4187, NB loss:4.6747, latent MSE loss:0.00115471, KL loss:0.00217733\n",
      "Pretrain epoch [13/233], ZINB loss:0.3850, NB loss:4.6061, latent MSE loss:0.00117172, KL loss:0.00217524\n",
      "Pretrain epoch [14/233], ZINB loss:0.4017, NB loss:4.5657, latent MSE loss:0.00126314, KL loss:0.00253026\n",
      "Pretrain epoch [15/233], ZINB loss:0.4091, NB loss:4.6011, latent MSE loss:0.00106768, KL loss:0.00218890\n",
      "Pretrain epoch [16/233], ZINB loss:0.3961, NB loss:4.6519, latent MSE loss:0.00095340, KL loss:0.00224033\n",
      "Pretrain epoch [17/233], ZINB loss:0.4130, NB loss:4.6053, latent MSE loss:0.00097703, KL loss:0.00223934\n",
      "Pretrain epoch [18/233], ZINB loss:0.4285, NB loss:4.7197, latent MSE loss:0.00098553, KL loss:0.00258875\n",
      "Pretrain epoch [19/233], ZINB loss:0.3951, NB loss:4.7156, latent MSE loss:0.00093664, KL loss:0.00243998\n",
      "Pretrain epoch [20/233], ZINB loss:0.4007, NB loss:4.6192, latent MSE loss:0.00106862, KL loss:0.00282914\n",
      "Pretrain epoch [21/233], ZINB loss:0.3961, NB loss:4.6681, latent MSE loss:0.00085541, KL loss:0.00285389\n",
      "Pretrain epoch [22/233], ZINB loss:0.3949, NB loss:4.6870, latent MSE loss:0.00110060, KL loss:0.00279547\n",
      "Pretrain epoch [23/233], ZINB loss:0.4048, NB loss:4.6705, latent MSE loss:0.00092450, KL loss:0.00251764\n",
      "Pretrain epoch [24/233], ZINB loss:0.4032, NB loss:4.6321, latent MSE loss:0.00074320, KL loss:0.00239380\n",
      "Pretrain epoch [25/233], ZINB loss:0.4008, NB loss:4.6406, latent MSE loss:0.00075077, KL loss:0.00240221\n",
      "Pretrain epoch [26/233], ZINB loss:0.3825, NB loss:4.6838, latent MSE loss:0.00072732, KL loss:0.00228502\n",
      "Pretrain epoch [27/233], ZINB loss:0.4680, NB loss:4.7725, latent MSE loss:0.00085243, KL loss:0.00003769\n",
      "Pretrain epoch [1/234], ZINB loss:0.4105, NB loss:4.6468, latent MSE loss:0.00099830, KL loss:0.00208088\n",
      "Pretrain epoch [2/234], ZINB loss:0.4002, NB loss:4.6425, latent MSE loss:0.00116229, KL loss:0.00218711\n",
      "Pretrain epoch [3/234], ZINB loss:0.4075, NB loss:4.5645, latent MSE loss:0.00114597, KL loss:0.00279655\n",
      "Pretrain epoch [4/234], ZINB loss:0.4165, NB loss:4.6608, latent MSE loss:0.00092080, KL loss:0.00231767\n",
      "Pretrain epoch [5/234], ZINB loss:0.4006, NB loss:4.6985, latent MSE loss:0.00092805, KL loss:0.00247975\n",
      "Pretrain epoch [6/234], ZINB loss:0.4067, NB loss:4.6430, latent MSE loss:0.00130208, KL loss:0.00272249\n",
      "Pretrain epoch [7/234], ZINB loss:0.3665, NB loss:4.6604, latent MSE loss:0.00096042, KL loss:0.00213150\n",
      "Pretrain epoch [8/234], ZINB loss:0.3998, NB loss:4.6438, latent MSE loss:0.00107382, KL loss:0.00234426\n",
      "Pretrain epoch [9/234], ZINB loss:0.4123, NB loss:4.6442, latent MSE loss:0.00091109, KL loss:0.00241212\n",
      "Pretrain epoch [10/234], ZINB loss:0.4067, NB loss:4.6401, latent MSE loss:0.00124489, KL loss:0.00229153\n",
      "Pretrain epoch [11/234], ZINB loss:0.4151, NB loss:4.6994, latent MSE loss:0.00083940, KL loss:0.00237095\n",
      "Pretrain epoch [12/234], ZINB loss:0.4115, NB loss:4.6152, latent MSE loss:0.00090135, KL loss:0.00251290\n",
      "Pretrain epoch [13/234], ZINB loss:0.3963, NB loss:4.6198, latent MSE loss:0.00071658, KL loss:0.00195900\n",
      "Pretrain epoch [14/234], ZINB loss:0.4028, NB loss:4.6489, latent MSE loss:0.00078074, KL loss:0.00212961\n",
      "Pretrain epoch [15/234], ZINB loss:0.3984, NB loss:4.6232, latent MSE loss:0.00076176, KL loss:0.00229672\n",
      "Pretrain epoch [16/234], ZINB loss:0.3924, NB loss:4.6456, latent MSE loss:0.00093612, KL loss:0.00240411\n",
      "Pretrain epoch [17/234], ZINB loss:0.4106, NB loss:4.6884, latent MSE loss:0.00087479, KL loss:0.00290538\n",
      "Pretrain epoch [18/234], ZINB loss:0.4105, NB loss:4.6302, latent MSE loss:0.00083244, KL loss:0.00264802\n",
      "Pretrain epoch [19/234], ZINB loss:0.3738, NB loss:4.6186, latent MSE loss:0.00081601, KL loss:0.00185813\n",
      "Pretrain epoch [20/234], ZINB loss:0.3961, NB loss:4.5862, latent MSE loss:0.00072911, KL loss:0.00247288\n",
      "Pretrain epoch [21/234], ZINB loss:0.3989, NB loss:4.6177, latent MSE loss:0.00070275, KL loss:0.00204969\n",
      "Pretrain epoch [22/234], ZINB loss:0.4101, NB loss:4.6054, latent MSE loss:0.00094098, KL loss:0.00214721\n",
      "Pretrain epoch [23/234], ZINB loss:0.3998, NB loss:4.6628, latent MSE loss:0.00074746, KL loss:0.00228673\n",
      "Pretrain epoch [24/234], ZINB loss:0.3825, NB loss:4.6632, latent MSE loss:0.00082395, KL loss:0.00209131\n",
      "Pretrain epoch [25/234], ZINB loss:0.3811, NB loss:4.6089, latent MSE loss:0.00069328, KL loss:0.00238915\n",
      "Pretrain epoch [26/234], ZINB loss:0.4127, NB loss:4.6095, latent MSE loss:0.00069023, KL loss:0.00230684\n",
      "Pretrain epoch [27/234], ZINB loss:0.4135, NB loss:4.5476, latent MSE loss:0.00058358, KL loss:0.00001244\n",
      "Pretrain epoch [1/235], ZINB loss:0.4181, NB loss:4.7027, latent MSE loss:0.00133046, KL loss:0.00318763\n",
      "Pretrain epoch [2/235], ZINB loss:0.3845, NB loss:4.6314, latent MSE loss:0.00112037, KL loss:0.00243572\n",
      "Pretrain epoch [3/235], ZINB loss:0.3974, NB loss:4.6570, latent MSE loss:0.00106095, KL loss:0.00254058\n",
      "Pretrain epoch [4/235], ZINB loss:0.4137, NB loss:4.6006, latent MSE loss:0.00132029, KL loss:0.00259164\n",
      "Pretrain epoch [5/235], ZINB loss:0.4129, NB loss:4.5641, latent MSE loss:0.00123824, KL loss:0.00246860\n",
      "Pretrain epoch [6/235], ZINB loss:0.4053, NB loss:4.6626, latent MSE loss:0.00095814, KL loss:0.00224215\n",
      "Pretrain epoch [7/235], ZINB loss:0.3950, NB loss:4.6335, latent MSE loss:0.00095178, KL loss:0.00219164\n",
      "Pretrain epoch [8/235], ZINB loss:0.3950, NB loss:4.5665, latent MSE loss:0.00100542, KL loss:0.00220232\n",
      "Pretrain epoch [9/235], ZINB loss:0.4115, NB loss:4.6963, latent MSE loss:0.00086363, KL loss:0.00233297\n",
      "Pretrain epoch [10/235], ZINB loss:0.3970, NB loss:4.6519, latent MSE loss:0.00081392, KL loss:0.00215144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [11/235], ZINB loss:0.3927, NB loss:4.6266, latent MSE loss:0.00086595, KL loss:0.00203173\n",
      "Pretrain epoch [12/235], ZINB loss:0.3978, NB loss:4.6584, latent MSE loss:0.00060848, KL loss:0.00201278\n",
      "Pretrain epoch [13/235], ZINB loss:0.3918, NB loss:4.6269, latent MSE loss:0.00084901, KL loss:0.00234805\n",
      "Pretrain epoch [14/235], ZINB loss:0.4133, NB loss:4.6200, latent MSE loss:0.00054095, KL loss:0.00253756\n",
      "Pretrain epoch [15/235], ZINB loss:0.4041, NB loss:4.5581, latent MSE loss:0.00064483, KL loss:0.00192584\n",
      "Pretrain epoch [16/235], ZINB loss:0.3883, NB loss:4.6524, latent MSE loss:0.00084322, KL loss:0.00219243\n",
      "Pretrain epoch [17/235], ZINB loss:0.3917, NB loss:4.5840, latent MSE loss:0.00075677, KL loss:0.00253528\n",
      "Pretrain epoch [18/235], ZINB loss:0.3838, NB loss:4.6215, latent MSE loss:0.00074198, KL loss:0.00203140\n",
      "Pretrain epoch [19/235], ZINB loss:0.3975, NB loss:4.6054, latent MSE loss:0.00070111, KL loss:0.00206855\n",
      "Pretrain epoch [20/235], ZINB loss:0.3988, NB loss:4.6571, latent MSE loss:0.00059170, KL loss:0.00234703\n",
      "Pretrain epoch [21/235], ZINB loss:0.3928, NB loss:4.6655, latent MSE loss:0.00061596, KL loss:0.00218196\n",
      "Pretrain epoch [22/235], ZINB loss:0.3955, NB loss:4.7012, latent MSE loss:0.00066370, KL loss:0.00230711\n",
      "Pretrain epoch [23/235], ZINB loss:0.4030, NB loss:4.6612, latent MSE loss:0.00059727, KL loss:0.00234085\n",
      "Pretrain epoch [24/235], ZINB loss:0.3846, NB loss:4.6000, latent MSE loss:0.00062396, KL loss:0.00221216\n",
      "Pretrain epoch [25/235], ZINB loss:0.4136, NB loss:4.6897, latent MSE loss:0.00047954, KL loss:0.00223671\n",
      "Pretrain epoch [26/235], ZINB loss:0.4111, NB loss:4.6399, latent MSE loss:0.00050041, KL loss:0.00226743\n",
      "Pretrain epoch [27/235], ZINB loss:0.3547, NB loss:4.9803, latent MSE loss:0.00046683, KL loss:0.00000885\n",
      "Pretrain epoch [1/236], ZINB loss:0.4094, NB loss:4.5946, latent MSE loss:0.00080802, KL loss:0.00223370\n",
      "Pretrain epoch [2/236], ZINB loss:0.3991, NB loss:4.6673, latent MSE loss:0.00082252, KL loss:0.00250045\n",
      "Pretrain epoch [3/236], ZINB loss:0.3924, NB loss:4.6470, latent MSE loss:0.00076425, KL loss:0.00226769\n",
      "Pretrain epoch [4/236], ZINB loss:0.3863, NB loss:4.6707, latent MSE loss:0.00067017, KL loss:0.00251390\n",
      "Pretrain epoch [5/236], ZINB loss:0.4149, NB loss:4.6248, latent MSE loss:0.00057714, KL loss:0.00256208\n",
      "Pretrain epoch [6/236], ZINB loss:0.4093, NB loss:4.6347, latent MSE loss:0.00055848, KL loss:0.00257864\n",
      "Pretrain epoch [7/236], ZINB loss:0.4088, NB loss:4.6990, latent MSE loss:0.00089260, KL loss:0.00254034\n",
      "Pretrain epoch [8/236], ZINB loss:0.4119, NB loss:4.5810, latent MSE loss:0.00081031, KL loss:0.00210927\n",
      "Pretrain epoch [9/236], ZINB loss:0.3849, NB loss:4.6546, latent MSE loss:0.00074036, KL loss:0.00240002\n",
      "Pretrain epoch [10/236], ZINB loss:0.3832, NB loss:4.6732, latent MSE loss:0.00071874, KL loss:0.00276407\n",
      "Pretrain epoch [11/236], ZINB loss:0.4015, NB loss:4.6262, latent MSE loss:0.00056581, KL loss:0.00236178\n",
      "Pretrain epoch [12/236], ZINB loss:0.3993, NB loss:4.6811, latent MSE loss:0.00087683, KL loss:0.00231953\n",
      "Pretrain epoch [13/236], ZINB loss:0.3875, NB loss:4.6384, latent MSE loss:0.00058717, KL loss:0.00187228\n",
      "Pretrain epoch [14/236], ZINB loss:0.4132, NB loss:4.6798, latent MSE loss:0.00058634, KL loss:0.00243680\n",
      "Pretrain epoch [15/236], ZINB loss:0.3802, NB loss:4.6674, latent MSE loss:0.00061429, KL loss:0.00192281\n",
      "Pretrain epoch [16/236], ZINB loss:0.3885, NB loss:4.6086, latent MSE loss:0.00058161, KL loss:0.00259806\n",
      "Pretrain epoch [17/236], ZINB loss:0.4078, NB loss:4.6220, latent MSE loss:0.00058392, KL loss:0.00260350\n",
      "Pretrain epoch [18/236], ZINB loss:0.4057, NB loss:4.5675, latent MSE loss:0.00053465, KL loss:0.00194572\n",
      "Pretrain epoch [19/236], ZINB loss:0.4026, NB loss:4.5785, latent MSE loss:0.00055838, KL loss:0.00182813\n",
      "Pretrain epoch [20/236], ZINB loss:0.3910, NB loss:4.5682, latent MSE loss:0.00052457, KL loss:0.00195760\n",
      "Pretrain epoch [21/236], ZINB loss:0.4141, NB loss:4.6818, latent MSE loss:0.00056662, KL loss:0.00251752\n",
      "Pretrain epoch [22/236], ZINB loss:0.4122, NB loss:4.5801, latent MSE loss:0.00041119, KL loss:0.00199786\n",
      "Pretrain epoch [23/236], ZINB loss:0.3912, NB loss:4.6636, latent MSE loss:0.00059300, KL loss:0.00225549\n",
      "Pretrain epoch [24/236], ZINB loss:0.3905, NB loss:4.6089, latent MSE loss:0.00058838, KL loss:0.00201350\n",
      "Pretrain epoch [25/236], ZINB loss:0.3965, NB loss:4.6525, latent MSE loss:0.00061262, KL loss:0.00204890\n",
      "Pretrain epoch [26/236], ZINB loss:0.4101, NB loss:4.6246, latent MSE loss:0.00063206, KL loss:0.00202815\n",
      "Pretrain epoch [27/236], ZINB loss:0.3100, NB loss:4.7344, latent MSE loss:0.00035713, KL loss:0.00006945\n",
      "Pretrain epoch [1/237], ZINB loss:0.4232, NB loss:4.6251, latent MSE loss:0.00064586, KL loss:0.00228049\n",
      "Pretrain epoch [2/237], ZINB loss:0.3967, NB loss:4.6281, latent MSE loss:0.00059706, KL loss:0.00196584\n",
      "Pretrain epoch [3/237], ZINB loss:0.3847, NB loss:4.5930, latent MSE loss:0.00063743, KL loss:0.00201675\n",
      "Pretrain epoch [4/237], ZINB loss:0.3959, NB loss:4.6157, latent MSE loss:0.00051155, KL loss:0.00206451\n",
      "Pretrain epoch [5/237], ZINB loss:0.3948, NB loss:4.6896, latent MSE loss:0.00051455, KL loss:0.00240978\n",
      "Pretrain epoch [6/237], ZINB loss:0.4120, NB loss:4.6640, latent MSE loss:0.00053879, KL loss:0.00201883\n",
      "Pretrain epoch [7/237], ZINB loss:0.3876, NB loss:4.6232, latent MSE loss:0.00047781, KL loss:0.00190248\n",
      "Pretrain epoch [8/237], ZINB loss:0.3815, NB loss:4.6225, latent MSE loss:0.00043271, KL loss:0.00214419\n",
      "Pretrain epoch [9/237], ZINB loss:0.4010, NB loss:4.6343, latent MSE loss:0.00049992, KL loss:0.00231989\n",
      "Pretrain epoch [10/237], ZINB loss:0.4088, NB loss:4.6524, latent MSE loss:0.00050176, KL loss:0.00225499\n",
      "Pretrain epoch [11/237], ZINB loss:0.3790, NB loss:4.5249, latent MSE loss:0.00045760, KL loss:0.00189572\n",
      "Pretrain epoch [12/237], ZINB loss:0.3822, NB loss:4.6284, latent MSE loss:0.00042590, KL loss:0.00211644\n",
      "Pretrain epoch [13/237], ZINB loss:0.4016, NB loss:4.7371, latent MSE loss:0.00043151, KL loss:0.00222120\n",
      "Pretrain epoch [14/237], ZINB loss:0.4039, NB loss:4.6225, latent MSE loss:0.00041160, KL loss:0.00222312\n",
      "Pretrain epoch [15/237], ZINB loss:0.3941, NB loss:4.6208, latent MSE loss:0.00039817, KL loss:0.00209669\n",
      "Pretrain epoch [16/237], ZINB loss:0.3965, NB loss:4.6838, latent MSE loss:0.00040844, KL loss:0.00223364\n",
      "Pretrain epoch [17/237], ZINB loss:0.3964, NB loss:4.6555, latent MSE loss:0.00039581, KL loss:0.00241045\n",
      "Pretrain epoch [18/237], ZINB loss:0.3915, NB loss:4.5793, latent MSE loss:0.00031729, KL loss:0.00180629\n",
      "Pretrain epoch [19/237], ZINB loss:0.4081, NB loss:4.6465, latent MSE loss:0.00042603, KL loss:0.00222363\n",
      "Pretrain epoch [20/237], ZINB loss:0.4172, NB loss:4.7037, latent MSE loss:0.00047170, KL loss:0.00290129\n",
      "Pretrain epoch [21/237], ZINB loss:0.4043, NB loss:4.6043, latent MSE loss:0.00055764, KL loss:0.00216982\n",
      "Pretrain epoch [22/237], ZINB loss:0.3939, NB loss:4.6130, latent MSE loss:0.00034667, KL loss:0.00189315\n",
      "Pretrain epoch [23/237], ZINB loss:0.3991, NB loss:4.5991, latent MSE loss:0.00040741, KL loss:0.00201087\n",
      "Pretrain epoch [24/237], ZINB loss:0.3959, NB loss:4.6038, latent MSE loss:0.00036236, KL loss:0.00224732\n",
      "Pretrain epoch [25/237], ZINB loss:0.4008, NB loss:4.6823, latent MSE loss:0.00036875, KL loss:0.00234905\n",
      "Pretrain epoch [26/237], ZINB loss:0.4102, NB loss:4.6056, latent MSE loss:0.00035870, KL loss:0.00200261\n",
      "Pretrain epoch [27/237], ZINB loss:0.4544, NB loss:4.7537, latent MSE loss:0.00081551, KL loss:0.00005329\n",
      "Pretrain epoch [1/238], ZINB loss:0.4073, NB loss:4.6591, latent MSE loss:0.00112014, KL loss:0.00219979\n",
      "Pretrain epoch [2/238], ZINB loss:0.3993, NB loss:4.6285, latent MSE loss:0.00099199, KL loss:0.00212213\n",
      "Pretrain epoch [3/238], ZINB loss:0.4268, NB loss:4.6206, latent MSE loss:0.00083349, KL loss:0.00265823\n",
      "Pretrain epoch [4/238], ZINB loss:0.3986, NB loss:4.6434, latent MSE loss:0.00081229, KL loss:0.00196043\n",
      "Pretrain epoch [5/238], ZINB loss:0.3975, NB loss:4.6507, latent MSE loss:0.00073956, KL loss:0.00198529\n",
      "Pretrain epoch [6/238], ZINB loss:0.3825, NB loss:4.6545, latent MSE loss:0.00068205, KL loss:0.00265278\n",
      "Pretrain epoch [7/238], ZINB loss:0.3914, NB loss:4.5467, latent MSE loss:0.00075363, KL loss:0.00187924\n",
      "Pretrain epoch [8/238], ZINB loss:0.4031, NB loss:4.6084, latent MSE loss:0.00086643, KL loss:0.00210120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [9/238], ZINB loss:0.3839, NB loss:4.6747, latent MSE loss:0.00074450, KL loss:0.00243917\n",
      "Pretrain epoch [10/238], ZINB loss:0.3959, NB loss:4.6120, latent MSE loss:0.00085105, KL loss:0.00209473\n",
      "Pretrain epoch [11/238], ZINB loss:0.4106, NB loss:4.6557, latent MSE loss:0.00105822, KL loss:0.00211054\n",
      "Pretrain epoch [12/238], ZINB loss:0.3978, NB loss:4.6701, latent MSE loss:0.00063598, KL loss:0.00237537\n",
      "Pretrain epoch [13/238], ZINB loss:0.3935, NB loss:4.6293, latent MSE loss:0.00060179, KL loss:0.00242988\n",
      "Pretrain epoch [14/238], ZINB loss:0.3958, NB loss:4.6004, latent MSE loss:0.00087047, KL loss:0.00199568\n",
      "Pretrain epoch [15/238], ZINB loss:0.4056, NB loss:4.5800, latent MSE loss:0.00064532, KL loss:0.00226599\n",
      "Pretrain epoch [16/238], ZINB loss:0.4081, NB loss:4.5574, latent MSE loss:0.00090657, KL loss:0.00185452\n",
      "Pretrain epoch [17/238], ZINB loss:0.4039, NB loss:4.6914, latent MSE loss:0.00105631, KL loss:0.00242798\n",
      "Pretrain epoch [18/238], ZINB loss:0.4030, NB loss:4.6075, latent MSE loss:0.00058096, KL loss:0.00203943\n",
      "Pretrain epoch [19/238], ZINB loss:0.4009, NB loss:4.6141, latent MSE loss:0.00086478, KL loss:0.00229303\n",
      "Pretrain epoch [20/238], ZINB loss:0.3869, NB loss:4.6693, latent MSE loss:0.00074608, KL loss:0.00208145\n",
      "Pretrain epoch [21/238], ZINB loss:0.4053, NB loss:4.7267, latent MSE loss:0.00071790, KL loss:0.00218519\n",
      "Pretrain epoch [22/238], ZINB loss:0.3896, NB loss:4.6355, latent MSE loss:0.00081380, KL loss:0.00200336\n",
      "Pretrain epoch [23/238], ZINB loss:0.4026, NB loss:4.6496, latent MSE loss:0.00110063, KL loss:0.00238158\n",
      "Pretrain epoch [24/238], ZINB loss:0.3793, NB loss:4.6342, latent MSE loss:0.00087651, KL loss:0.00179630\n",
      "Pretrain epoch [25/238], ZINB loss:0.4103, NB loss:4.5694, latent MSE loss:0.00148018, KL loss:0.00204997\n",
      "Pretrain epoch [26/238], ZINB loss:0.4028, NB loss:4.6197, latent MSE loss:0.00101410, KL loss:0.00252957\n",
      "Pretrain epoch [27/238], ZINB loss:0.4424, NB loss:4.7408, latent MSE loss:0.00247916, KL loss:0.00005203\n",
      "Pretrain epoch [1/239], ZINB loss:0.4042, NB loss:4.6730, latent MSE loss:0.00293542, KL loss:0.00207319\n",
      "Pretrain epoch [2/239], ZINB loss:0.3970, NB loss:4.6003, latent MSE loss:0.00320787, KL loss:0.00186498\n",
      "Pretrain epoch [3/239], ZINB loss:0.4113, NB loss:4.6378, latent MSE loss:0.00242451, KL loss:0.00231818\n",
      "Pretrain epoch [4/239], ZINB loss:0.4090, NB loss:4.6455, latent MSE loss:0.00122433, KL loss:0.00242511\n",
      "Pretrain epoch [5/239], ZINB loss:0.4257, NB loss:4.6692, latent MSE loss:0.00259956, KL loss:0.00231968\n",
      "Pretrain epoch [6/239], ZINB loss:0.3899, NB loss:4.6422, latent MSE loss:0.00211992, KL loss:0.00213369\n",
      "Pretrain epoch [7/239], ZINB loss:0.3956, NB loss:4.6593, latent MSE loss:0.00125914, KL loss:0.00237028\n",
      "Pretrain epoch [8/239], ZINB loss:0.3917, NB loss:4.6917, latent MSE loss:0.00195032, KL loss:0.00205616\n",
      "Pretrain epoch [9/239], ZINB loss:0.3916, NB loss:4.6360, latent MSE loss:0.00180402, KL loss:0.00229209\n",
      "Pretrain epoch [10/239], ZINB loss:0.3991, NB loss:4.5569, latent MSE loss:0.00142111, KL loss:0.00191364\n",
      "Pretrain epoch [11/239], ZINB loss:0.4072, NB loss:4.6948, latent MSE loss:0.00137177, KL loss:0.00206571\n",
      "Pretrain epoch [12/239], ZINB loss:0.3773, NB loss:4.5984, latent MSE loss:0.00120046, KL loss:0.00208278\n",
      "Pretrain epoch [13/239], ZINB loss:0.3718, NB loss:4.5934, latent MSE loss:0.00082548, KL loss:0.00217826\n",
      "Pretrain epoch [14/239], ZINB loss:0.4007, NB loss:4.5830, latent MSE loss:0.00140479, KL loss:0.00249320\n",
      "Pretrain epoch [15/239], ZINB loss:0.4158, NB loss:4.5565, latent MSE loss:0.00100530, KL loss:0.00198661\n",
      "Pretrain epoch [16/239], ZINB loss:0.4191, NB loss:4.6699, latent MSE loss:0.00126474, KL loss:0.00213988\n",
      "Pretrain epoch [17/239], ZINB loss:0.4084, NB loss:4.6196, latent MSE loss:0.00139623, KL loss:0.00281905\n",
      "Pretrain epoch [18/239], ZINB loss:0.3888, NB loss:4.6414, latent MSE loss:0.00095474, KL loss:0.00217456\n",
      "Pretrain epoch [19/239], ZINB loss:0.4038, NB loss:4.6208, latent MSE loss:0.00103414, KL loss:0.00203373\n",
      "Pretrain epoch [20/239], ZINB loss:0.3723, NB loss:4.6157, latent MSE loss:0.00120035, KL loss:0.00206426\n",
      "Pretrain epoch [21/239], ZINB loss:0.3939, NB loss:4.5637, latent MSE loss:0.00077736, KL loss:0.00225112\n",
      "Pretrain epoch [22/239], ZINB loss:0.4140, NB loss:4.5864, latent MSE loss:0.00145074, KL loss:0.00211255\n",
      "Pretrain epoch [23/239], ZINB loss:0.3989, NB loss:4.6975, latent MSE loss:0.00102674, KL loss:0.00226238\n",
      "Pretrain epoch [24/239], ZINB loss:0.4169, NB loss:4.6276, latent MSE loss:0.00084572, KL loss:0.00203639\n",
      "Pretrain epoch [25/239], ZINB loss:0.3899, NB loss:4.6150, latent MSE loss:0.00076107, KL loss:0.00204650\n",
      "Pretrain epoch [26/239], ZINB loss:0.3911, NB loss:4.6737, latent MSE loss:0.00078507, KL loss:0.00245707\n",
      "Pretrain epoch [27/239], ZINB loss:0.3819, NB loss:4.3900, latent MSE loss:0.00035293, KL loss:0.00007685\n",
      "Pretrain epoch [1/240], ZINB loss:0.3932, NB loss:4.6771, latent MSE loss:0.00140515, KL loss:0.00213558\n",
      "Pretrain epoch [2/240], ZINB loss:0.3932, NB loss:4.6588, latent MSE loss:0.00131950, KL loss:0.00207107\n",
      "Pretrain epoch [3/240], ZINB loss:0.4018, NB loss:4.6098, latent MSE loss:0.00093275, KL loss:0.00216254\n",
      "Pretrain epoch [4/240], ZINB loss:0.3916, NB loss:4.6317, latent MSE loss:0.00086446, KL loss:0.00238788\n",
      "Pretrain epoch [5/240], ZINB loss:0.4051, NB loss:4.6004, latent MSE loss:0.00086375, KL loss:0.00246128\n",
      "Pretrain epoch [6/240], ZINB loss:0.3979, NB loss:4.5898, latent MSE loss:0.00105832, KL loss:0.00198631\n",
      "Pretrain epoch [7/240], ZINB loss:0.4070, NB loss:4.5837, latent MSE loss:0.00104987, KL loss:0.00212444\n",
      "Pretrain epoch [8/240], ZINB loss:0.4158, NB loss:4.6482, latent MSE loss:0.00064025, KL loss:0.00210778\n",
      "Pretrain epoch [9/240], ZINB loss:0.3901, NB loss:4.6158, latent MSE loss:0.00091440, KL loss:0.00209983\n",
      "Pretrain epoch [10/240], ZINB loss:0.4047, NB loss:4.5698, latent MSE loss:0.00086620, KL loss:0.00217628\n",
      "Pretrain epoch [11/240], ZINB loss:0.3849, NB loss:4.6682, latent MSE loss:0.00061866, KL loss:0.00216295\n",
      "Pretrain epoch [12/240], ZINB loss:0.4020, NB loss:4.6834, latent MSE loss:0.00066020, KL loss:0.00201107\n",
      "Pretrain epoch [13/240], ZINB loss:0.4241, NB loss:4.6186, latent MSE loss:0.00090826, KL loss:0.00242026\n",
      "Pretrain epoch [14/240], ZINB loss:0.3790, NB loss:4.6788, latent MSE loss:0.00057951, KL loss:0.00283277\n",
      "Pretrain epoch [15/240], ZINB loss:0.3803, NB loss:4.6230, latent MSE loss:0.00047330, KL loss:0.00189711\n",
      "Pretrain epoch [16/240], ZINB loss:0.3897, NB loss:4.5823, latent MSE loss:0.00051965, KL loss:0.00178035\n",
      "Pretrain epoch [17/240], ZINB loss:0.4071, NB loss:4.6364, latent MSE loss:0.00066883, KL loss:0.00218863\n",
      "Pretrain epoch [18/240], ZINB loss:0.3989, NB loss:4.5846, latent MSE loss:0.00053744, KL loss:0.00244343\n",
      "Pretrain epoch [19/240], ZINB loss:0.4056, NB loss:4.6268, latent MSE loss:0.00085236, KL loss:0.00216903\n",
      "Pretrain epoch [20/240], ZINB loss:0.4160, NB loss:4.6538, latent MSE loss:0.00050998, KL loss:0.00214518\n",
      "Pretrain epoch [21/240], ZINB loss:0.4010, NB loss:4.5996, latent MSE loss:0.00051216, KL loss:0.00217236\n",
      "Pretrain epoch [22/240], ZINB loss:0.3876, NB loss:4.5900, latent MSE loss:0.00048661, KL loss:0.00194824\n",
      "Pretrain epoch [23/240], ZINB loss:0.3798, NB loss:4.6708, latent MSE loss:0.00066525, KL loss:0.00200065\n",
      "Pretrain epoch [24/240], ZINB loss:0.4019, NB loss:4.5774, latent MSE loss:0.00043836, KL loss:0.00179872\n",
      "Pretrain epoch [25/240], ZINB loss:0.4050, NB loss:4.6798, latent MSE loss:0.00066583, KL loss:0.00290438\n",
      "Pretrain epoch [26/240], ZINB loss:0.3978, NB loss:4.6768, latent MSE loss:0.00052274, KL loss:0.00203708\n",
      "Pretrain epoch [27/240], ZINB loss:0.4921, NB loss:4.0674, latent MSE loss:0.00080269, KL loss:0.00006338\n",
      "Pretrain epoch [1/241], ZINB loss:0.3823, NB loss:4.6331, latent MSE loss:0.00204370, KL loss:0.00217963\n",
      "Pretrain epoch [2/241], ZINB loss:0.4026, NB loss:4.6376, latent MSE loss:0.00216996, KL loss:0.00236837\n",
      "Pretrain epoch [3/241], ZINB loss:0.4376, NB loss:4.6261, latent MSE loss:0.00250645, KL loss:0.00254847\n",
      "Pretrain epoch [4/241], ZINB loss:0.3779, NB loss:4.6744, latent MSE loss:0.00228476, KL loss:0.00235535\n",
      "Pretrain epoch [5/241], ZINB loss:0.3962, NB loss:4.6466, latent MSE loss:0.00193471, KL loss:0.00228708\n",
      "Pretrain epoch [6/241], ZINB loss:0.4019, NB loss:4.6411, latent MSE loss:0.00243929, KL loss:0.00225645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [7/241], ZINB loss:0.4179, NB loss:4.5522, latent MSE loss:0.00222461, KL loss:0.00233651\n",
      "Pretrain epoch [8/241], ZINB loss:0.3905, NB loss:4.6192, latent MSE loss:0.00168542, KL loss:0.00220299\n",
      "Pretrain epoch [9/241], ZINB loss:0.3950, NB loss:4.6311, latent MSE loss:0.00193848, KL loss:0.00220835\n",
      "Pretrain epoch [10/241], ZINB loss:0.4095, NB loss:4.6511, latent MSE loss:0.00184866, KL loss:0.00250767\n",
      "Pretrain epoch [11/241], ZINB loss:0.3898, NB loss:4.6081, latent MSE loss:0.00157047, KL loss:0.00234097\n",
      "Pretrain epoch [12/241], ZINB loss:0.3977, NB loss:4.6820, latent MSE loss:0.00175815, KL loss:0.00231721\n",
      "Pretrain epoch [13/241], ZINB loss:0.3825, NB loss:4.6089, latent MSE loss:0.00157888, KL loss:0.00256355\n",
      "Pretrain epoch [14/241], ZINB loss:0.4057, NB loss:4.6004, latent MSE loss:0.00136259, KL loss:0.00212636\n",
      "Pretrain epoch [15/241], ZINB loss:0.4071, NB loss:4.6206, latent MSE loss:0.00145083, KL loss:0.00220327\n",
      "Pretrain epoch [16/241], ZINB loss:0.4030, NB loss:4.6424, latent MSE loss:0.00150291, KL loss:0.00225778\n",
      "Pretrain epoch [17/241], ZINB loss:0.3835, NB loss:4.5963, latent MSE loss:0.00110327, KL loss:0.00212633\n",
      "Pretrain epoch [18/241], ZINB loss:0.4015, NB loss:4.6242, latent MSE loss:0.00105167, KL loss:0.00251520\n",
      "Pretrain epoch [19/241], ZINB loss:0.4188, NB loss:4.6384, latent MSE loss:0.00111448, KL loss:0.00218075\n",
      "Pretrain epoch [20/241], ZINB loss:0.4044, NB loss:4.6436, latent MSE loss:0.00100344, KL loss:0.00210068\n",
      "Pretrain epoch [21/241], ZINB loss:0.4008, NB loss:4.6734, latent MSE loss:0.00076553, KL loss:0.00217175\n",
      "Pretrain epoch [22/241], ZINB loss:0.3932, NB loss:4.6373, latent MSE loss:0.00081970, KL loss:0.00222972\n",
      "Pretrain epoch [23/241], ZINB loss:0.4042, NB loss:4.6103, latent MSE loss:0.00082564, KL loss:0.00209322\n",
      "Pretrain epoch [24/241], ZINB loss:0.4059, NB loss:4.5569, latent MSE loss:0.00077543, KL loss:0.00221837\n",
      "Pretrain epoch [25/241], ZINB loss:0.4045, NB loss:4.6202, latent MSE loss:0.00083626, KL loss:0.00227218\n",
      "Pretrain epoch [26/241], ZINB loss:0.3909, NB loss:4.6364, latent MSE loss:0.00073944, KL loss:0.00200201\n",
      "Pretrain epoch [27/241], ZINB loss:0.4823, NB loss:4.3937, latent MSE loss:0.00040876, KL loss:0.00001146\n",
      "Pretrain epoch [1/242], ZINB loss:0.3846, NB loss:4.5888, latent MSE loss:0.00105794, KL loss:0.00195173\n",
      "Pretrain epoch [2/242], ZINB loss:0.4050, NB loss:4.5904, latent MSE loss:0.00106870, KL loss:0.00201818\n",
      "Pretrain epoch [3/242], ZINB loss:0.4119, NB loss:4.6252, latent MSE loss:0.00078787, KL loss:0.00245497\n",
      "Pretrain epoch [4/242], ZINB loss:0.3870, NB loss:4.6911, latent MSE loss:0.00085787, KL loss:0.00238843\n",
      "Pretrain epoch [5/242], ZINB loss:0.4042, NB loss:4.6042, latent MSE loss:0.00098335, KL loss:0.00245513\n",
      "Pretrain epoch [6/242], ZINB loss:0.3871, NB loss:4.6489, latent MSE loss:0.00062513, KL loss:0.00236155\n",
      "Pretrain epoch [7/242], ZINB loss:0.4119, NB loss:4.6690, latent MSE loss:0.00072449, KL loss:0.00191191\n",
      "Pretrain epoch [8/242], ZINB loss:0.3947, NB loss:4.6466, latent MSE loss:0.00064256, KL loss:0.00204164\n",
      "Pretrain epoch [9/242], ZINB loss:0.4197, NB loss:4.6260, latent MSE loss:0.00078224, KL loss:0.00260414\n",
      "Pretrain epoch [10/242], ZINB loss:0.4032, NB loss:4.6353, latent MSE loss:0.00066760, KL loss:0.00265339\n",
      "Pretrain epoch [11/242], ZINB loss:0.3810, NB loss:4.6833, latent MSE loss:0.00055099, KL loss:0.00196312\n",
      "Pretrain epoch [12/242], ZINB loss:0.4065, NB loss:4.5851, latent MSE loss:0.00055698, KL loss:0.00209434\n",
      "Pretrain epoch [13/242], ZINB loss:0.4045, NB loss:4.6343, latent MSE loss:0.00041486, KL loss:0.00190422\n",
      "Pretrain epoch [14/242], ZINB loss:0.3941, NB loss:4.6258, latent MSE loss:0.00053351, KL loss:0.00257505\n",
      "Pretrain epoch [15/242], ZINB loss:0.3925, NB loss:4.6194, latent MSE loss:0.00052851, KL loss:0.00207916\n",
      "Pretrain epoch [16/242], ZINB loss:0.4251, NB loss:4.6325, latent MSE loss:0.00051426, KL loss:0.00240701\n",
      "Pretrain epoch [17/242], ZINB loss:0.4029, NB loss:4.5106, latent MSE loss:0.00054438, KL loss:0.00199673\n",
      "Pretrain epoch [18/242], ZINB loss:0.3868, NB loss:4.5973, latent MSE loss:0.00053558, KL loss:0.00192239\n",
      "Pretrain epoch [19/242], ZINB loss:0.4257, NB loss:4.6408, latent MSE loss:0.00052719, KL loss:0.00202670\n",
      "Pretrain epoch [20/242], ZINB loss:0.3742, NB loss:4.6212, latent MSE loss:0.00040599, KL loss:0.00185587\n",
      "Pretrain epoch [21/242], ZINB loss:0.3954, NB loss:4.6674, latent MSE loss:0.00051349, KL loss:0.00223137\n",
      "Pretrain epoch [22/242], ZINB loss:0.3816, NB loss:4.5666, latent MSE loss:0.00052041, KL loss:0.00215256\n",
      "Pretrain epoch [23/242], ZINB loss:0.4032, NB loss:4.6472, latent MSE loss:0.00044522, KL loss:0.00200121\n",
      "Pretrain epoch [24/242], ZINB loss:0.3840, NB loss:4.6510, latent MSE loss:0.00048074, KL loss:0.00171310\n",
      "Pretrain epoch [25/242], ZINB loss:0.3873, NB loss:4.6057, latent MSE loss:0.00046180, KL loss:0.00193394\n",
      "Pretrain epoch [26/242], ZINB loss:0.4192, NB loss:4.6277, latent MSE loss:0.00064695, KL loss:0.00257289\n",
      "Pretrain epoch [27/242], ZINB loss:0.3931, NB loss:4.7193, latent MSE loss:0.00053665, KL loss:0.00000770\n",
      "Pretrain epoch [1/243], ZINB loss:0.4120, NB loss:4.6305, latent MSE loss:0.00070022, KL loss:0.00258469\n",
      "Pretrain epoch [2/243], ZINB loss:0.3801, NB loss:4.6148, latent MSE loss:0.00060756, KL loss:0.00233332\n",
      "Pretrain epoch [3/243], ZINB loss:0.3990, NB loss:4.5850, latent MSE loss:0.00072872, KL loss:0.00194941\n",
      "Pretrain epoch [4/243], ZINB loss:0.3994, NB loss:4.6326, latent MSE loss:0.00072265, KL loss:0.00200208\n",
      "Pretrain epoch [5/243], ZINB loss:0.3886, NB loss:4.6180, latent MSE loss:0.00064094, KL loss:0.00222573\n",
      "Pretrain epoch [6/243], ZINB loss:0.4087, NB loss:4.6102, latent MSE loss:0.00082529, KL loss:0.00206044\n",
      "Pretrain epoch [7/243], ZINB loss:0.3947, NB loss:4.5330, latent MSE loss:0.00072133, KL loss:0.00208104\n",
      "Pretrain epoch [8/243], ZINB loss:0.3971, NB loss:4.5699, latent MSE loss:0.00059159, KL loss:0.00198658\n",
      "Pretrain epoch [9/243], ZINB loss:0.4033, NB loss:4.6665, latent MSE loss:0.00072800, KL loss:0.00198969\n",
      "Pretrain epoch [10/243], ZINB loss:0.3767, NB loss:4.6231, latent MSE loss:0.00061212, KL loss:0.00192961\n",
      "Pretrain epoch [11/243], ZINB loss:0.4191, NB loss:4.6573, latent MSE loss:0.00052618, KL loss:0.00236913\n",
      "Pretrain epoch [12/243], ZINB loss:0.3954, NB loss:4.6543, latent MSE loss:0.00052906, KL loss:0.00198027\n",
      "Pretrain epoch [13/243], ZINB loss:0.4064, NB loss:4.6443, latent MSE loss:0.00059974, KL loss:0.00242179\n",
      "Pretrain epoch [14/243], ZINB loss:0.3985, NB loss:4.5850, latent MSE loss:0.00046335, KL loss:0.00189465\n",
      "Pretrain epoch [15/243], ZINB loss:0.3832, NB loss:4.6045, latent MSE loss:0.00052678, KL loss:0.00209998\n",
      "Pretrain epoch [16/243], ZINB loss:0.4132, NB loss:4.6320, latent MSE loss:0.00060523, KL loss:0.00210342\n",
      "Pretrain epoch [17/243], ZINB loss:0.4006, NB loss:4.6917, latent MSE loss:0.00049940, KL loss:0.00194026\n",
      "Pretrain epoch [18/243], ZINB loss:0.3893, NB loss:4.5826, latent MSE loss:0.00042465, KL loss:0.00205436\n",
      "Pretrain epoch [19/243], ZINB loss:0.4098, NB loss:4.6297, latent MSE loss:0.00044883, KL loss:0.00232145\n",
      "Pretrain epoch [20/243], ZINB loss:0.3966, NB loss:4.6613, latent MSE loss:0.00040465, KL loss:0.00214703\n",
      "Pretrain epoch [21/243], ZINB loss:0.3972, NB loss:4.6711, latent MSE loss:0.00045443, KL loss:0.00219218\n",
      "Pretrain epoch [22/243], ZINB loss:0.4054, NB loss:4.6673, latent MSE loss:0.00045699, KL loss:0.00224602\n",
      "Pretrain epoch [23/243], ZINB loss:0.3929, NB loss:4.6838, latent MSE loss:0.00042340, KL loss:0.00182507\n",
      "Pretrain epoch [24/243], ZINB loss:0.3993, NB loss:4.6138, latent MSE loss:0.00032514, KL loss:0.00178922\n",
      "Pretrain epoch [25/243], ZINB loss:0.3925, NB loss:4.5732, latent MSE loss:0.00034001, KL loss:0.00192704\n",
      "Pretrain epoch [26/243], ZINB loss:0.4079, NB loss:4.5779, latent MSE loss:0.00038225, KL loss:0.00180046\n",
      "Pretrain epoch [27/243], ZINB loss:0.4417, NB loss:4.3913, latent MSE loss:0.00023542, KL loss:0.00006526\n",
      "Pretrain epoch [1/244], ZINB loss:0.3839, NB loss:4.6957, latent MSE loss:0.00040687, KL loss:0.00189003\n",
      "Pretrain epoch [2/244], ZINB loss:0.3912, NB loss:4.6070, latent MSE loss:0.00042455, KL loss:0.00208878\n",
      "Pretrain epoch [3/244], ZINB loss:0.3969, NB loss:4.6406, latent MSE loss:0.00044043, KL loss:0.00195472\n",
      "Pretrain epoch [4/244], ZINB loss:0.3974, NB loss:4.5830, latent MSE loss:0.00041436, KL loss:0.00202340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [5/244], ZINB loss:0.4076, NB loss:4.6086, latent MSE loss:0.00039491, KL loss:0.00240870\n",
      "Pretrain epoch [6/244], ZINB loss:0.4314, NB loss:4.5986, latent MSE loss:0.00039686, KL loss:0.00222790\n",
      "Pretrain epoch [7/244], ZINB loss:0.3903, NB loss:4.6423, latent MSE loss:0.00040634, KL loss:0.00174642\n",
      "Pretrain epoch [8/244], ZINB loss:0.3890, NB loss:4.6001, latent MSE loss:0.00034092, KL loss:0.00164330\n",
      "Pretrain epoch [9/244], ZINB loss:0.3845, NB loss:4.5909, latent MSE loss:0.00039070, KL loss:0.00186755\n",
      "Pretrain epoch [10/244], ZINB loss:0.3931, NB loss:4.6287, latent MSE loss:0.00042572, KL loss:0.00173367\n",
      "Pretrain epoch [11/244], ZINB loss:0.4031, NB loss:4.6203, latent MSE loss:0.00039612, KL loss:0.00218355\n",
      "Pretrain epoch [12/244], ZINB loss:0.3894, NB loss:4.6753, latent MSE loss:0.00039138, KL loss:0.00205136\n",
      "Pretrain epoch [13/244], ZINB loss:0.4178, NB loss:4.5935, latent MSE loss:0.00041549, KL loss:0.00198333\n",
      "Pretrain epoch [14/244], ZINB loss:0.3939, NB loss:4.6499, latent MSE loss:0.00037557, KL loss:0.00208213\n",
      "Pretrain epoch [15/244], ZINB loss:0.4305, NB loss:4.5752, latent MSE loss:0.00036305, KL loss:0.00217975\n",
      "Pretrain epoch [16/244], ZINB loss:0.4106, NB loss:4.6255, latent MSE loss:0.00037005, KL loss:0.00216793\n",
      "Pretrain epoch [17/244], ZINB loss:0.3934, NB loss:4.5675, latent MSE loss:0.00037656, KL loss:0.00213174\n",
      "Pretrain epoch [18/244], ZINB loss:0.3962, NB loss:4.6398, latent MSE loss:0.00036977, KL loss:0.00179216\n",
      "Pretrain epoch [19/244], ZINB loss:0.3858, NB loss:4.6371, latent MSE loss:0.00034668, KL loss:0.00215948\n",
      "Pretrain epoch [20/244], ZINB loss:0.3689, NB loss:4.6706, latent MSE loss:0.00032648, KL loss:0.00189137\n",
      "Pretrain epoch [21/244], ZINB loss:0.4119, NB loss:4.6260, latent MSE loss:0.00039445, KL loss:0.00262040\n",
      "Pretrain epoch [22/244], ZINB loss:0.3814, NB loss:4.6105, latent MSE loss:0.00032422, KL loss:0.00178978\n",
      "Pretrain epoch [23/244], ZINB loss:0.4266, NB loss:4.6289, latent MSE loss:0.00056818, KL loss:0.00211044\n",
      "Pretrain epoch [24/244], ZINB loss:0.3788, NB loss:4.5685, latent MSE loss:0.00028892, KL loss:0.00166625\n",
      "Pretrain epoch [25/244], ZINB loss:0.4047, NB loss:4.6164, latent MSE loss:0.00033163, KL loss:0.00195046\n",
      "Pretrain epoch [26/244], ZINB loss:0.3944, NB loss:4.6724, latent MSE loss:0.00036998, KL loss:0.00235106\n",
      "Pretrain epoch [27/244], ZINB loss:0.5160, NB loss:4.6121, latent MSE loss:0.00081229, KL loss:0.00006934\n",
      "Pretrain epoch [1/245], ZINB loss:0.3752, NB loss:4.6079, latent MSE loss:0.00115878, KL loss:0.00162450\n",
      "Pretrain epoch [2/245], ZINB loss:0.4023, NB loss:4.6099, latent MSE loss:0.00146787, KL loss:0.00203545\n",
      "Pretrain epoch [3/245], ZINB loss:0.4192, NB loss:4.6240, latent MSE loss:0.00158279, KL loss:0.00183567\n",
      "Pretrain epoch [4/245], ZINB loss:0.3885, NB loss:4.6438, latent MSE loss:0.00125964, KL loss:0.00205529\n",
      "Pretrain epoch [5/245], ZINB loss:0.4084, NB loss:4.6423, latent MSE loss:0.00110482, KL loss:0.00174031\n",
      "Pretrain epoch [6/245], ZINB loss:0.3940, NB loss:4.6183, latent MSE loss:0.00128843, KL loss:0.00226319\n",
      "Pretrain epoch [7/245], ZINB loss:0.3823, NB loss:4.6835, latent MSE loss:0.00094444, KL loss:0.00203439\n",
      "Pretrain epoch [8/245], ZINB loss:0.3844, NB loss:4.5798, latent MSE loss:0.00091473, KL loss:0.00204495\n",
      "Pretrain epoch [9/245], ZINB loss:0.3949, NB loss:4.5164, latent MSE loss:0.00110346, KL loss:0.00173855\n",
      "Pretrain epoch [10/245], ZINB loss:0.4033, NB loss:4.6407, latent MSE loss:0.00095839, KL loss:0.00215224\n",
      "Pretrain epoch [11/245], ZINB loss:0.4020, NB loss:4.6028, latent MSE loss:0.00103363, KL loss:0.00177642\n",
      "Pretrain epoch [12/245], ZINB loss:0.4094, NB loss:4.6412, latent MSE loss:0.00099652, KL loss:0.00190116\n",
      "Pretrain epoch [13/245], ZINB loss:0.3919, NB loss:4.6326, latent MSE loss:0.00088218, KL loss:0.00194841\n",
      "Pretrain epoch [14/245], ZINB loss:0.4159, NB loss:4.6826, latent MSE loss:0.00066393, KL loss:0.00241565\n",
      "Pretrain epoch [15/245], ZINB loss:0.4191, NB loss:4.6427, latent MSE loss:0.00077330, KL loss:0.00223467\n",
      "Pretrain epoch [16/245], ZINB loss:0.4007, NB loss:4.6061, latent MSE loss:0.00087479, KL loss:0.00230796\n",
      "Pretrain epoch [17/245], ZINB loss:0.4133, NB loss:4.6052, latent MSE loss:0.00064869, KL loss:0.00241275\n",
      "Pretrain epoch [18/245], ZINB loss:0.4065, NB loss:4.6278, latent MSE loss:0.00068513, KL loss:0.00193404\n",
      "Pretrain epoch [19/245], ZINB loss:0.3865, NB loss:4.5997, latent MSE loss:0.00071080, KL loss:0.00184682\n",
      "Pretrain epoch [20/245], ZINB loss:0.3818, NB loss:4.6199, latent MSE loss:0.00058748, KL loss:0.00246802\n",
      "Pretrain epoch [21/245], ZINB loss:0.3985, NB loss:4.6188, latent MSE loss:0.00062392, KL loss:0.00186578\n",
      "Pretrain epoch [22/245], ZINB loss:0.3893, NB loss:4.6227, latent MSE loss:0.00056264, KL loss:0.00201898\n",
      "Pretrain epoch [23/245], ZINB loss:0.3990, NB loss:4.5651, latent MSE loss:0.00051468, KL loss:0.00169877\n",
      "Pretrain epoch [24/245], ZINB loss:0.3966, NB loss:4.6089, latent MSE loss:0.00046124, KL loss:0.00185865\n",
      "Pretrain epoch [25/245], ZINB loss:0.4042, NB loss:4.6538, latent MSE loss:0.00049266, KL loss:0.00222082\n",
      "Pretrain epoch [26/245], ZINB loss:0.4070, NB loss:4.6446, latent MSE loss:0.00044506, KL loss:0.00205316\n",
      "Pretrain epoch [27/245], ZINB loss:0.2867, NB loss:4.3680, latent MSE loss:0.00024347, KL loss:0.00000920\n",
      "Pretrain epoch [1/246], ZINB loss:0.4021, NB loss:4.6488, latent MSE loss:0.00075657, KL loss:0.00182634\n",
      "Pretrain epoch [2/246], ZINB loss:0.3908, NB loss:4.6057, latent MSE loss:0.00065238, KL loss:0.00217717\n",
      "Pretrain epoch [3/246], ZINB loss:0.4110, NB loss:4.6427, latent MSE loss:0.00065411, KL loss:0.00226418\n",
      "Pretrain epoch [4/246], ZINB loss:0.3983, NB loss:4.5897, latent MSE loss:0.00088044, KL loss:0.00181442\n",
      "Pretrain epoch [5/246], ZINB loss:0.4023, NB loss:4.6053, latent MSE loss:0.00059748, KL loss:0.00224637\n",
      "Pretrain epoch [6/246], ZINB loss:0.3793, NB loss:4.6525, latent MSE loss:0.00046737, KL loss:0.00173498\n",
      "Pretrain epoch [7/246], ZINB loss:0.3998, NB loss:4.6147, latent MSE loss:0.00063422, KL loss:0.00229453\n",
      "Pretrain epoch [8/246], ZINB loss:0.4047, NB loss:4.6179, latent MSE loss:0.00043805, KL loss:0.00201263\n",
      "Pretrain epoch [9/246], ZINB loss:0.3981, NB loss:4.5875, latent MSE loss:0.00048786, KL loss:0.00187833\n",
      "Pretrain epoch [10/246], ZINB loss:0.4008, NB loss:4.6839, latent MSE loss:0.00050250, KL loss:0.00202742\n",
      "Pretrain epoch [11/246], ZINB loss:0.4095, NB loss:4.5995, latent MSE loss:0.00045648, KL loss:0.00192516\n",
      "Pretrain epoch [12/246], ZINB loss:0.3857, NB loss:4.6201, latent MSE loss:0.00051180, KL loss:0.00178607\n",
      "Pretrain epoch [13/246], ZINB loss:0.3848, NB loss:4.6002, latent MSE loss:0.00039957, KL loss:0.00165478\n",
      "Pretrain epoch [14/246], ZINB loss:0.3865, NB loss:4.5986, latent MSE loss:0.00046609, KL loss:0.00168279\n",
      "Pretrain epoch [15/246], ZINB loss:0.4023, NB loss:4.6683, latent MSE loss:0.00040844, KL loss:0.00232748\n",
      "Pretrain epoch [16/246], ZINB loss:0.4034, NB loss:4.6980, latent MSE loss:0.00044147, KL loss:0.00186544\n",
      "Pretrain epoch [17/246], ZINB loss:0.4118, NB loss:4.5945, latent MSE loss:0.00047681, KL loss:0.00218016\n",
      "Pretrain epoch [18/246], ZINB loss:0.3896, NB loss:4.6534, latent MSE loss:0.00036348, KL loss:0.00184330\n",
      "Pretrain epoch [19/246], ZINB loss:0.4071, NB loss:4.6159, latent MSE loss:0.00046099, KL loss:0.00208550\n",
      "Pretrain epoch [20/246], ZINB loss:0.3938, NB loss:4.5896, latent MSE loss:0.00032050, KL loss:0.00182811\n",
      "Pretrain epoch [21/246], ZINB loss:0.4111, NB loss:4.5284, latent MSE loss:0.00031859, KL loss:0.00178917\n",
      "Pretrain epoch [22/246], ZINB loss:0.3896, NB loss:4.6479, latent MSE loss:0.00028449, KL loss:0.00202031\n",
      "Pretrain epoch [23/246], ZINB loss:0.3972, NB loss:4.5649, latent MSE loss:0.00040875, KL loss:0.00176766\n",
      "Pretrain epoch [24/246], ZINB loss:0.3946, NB loss:4.6021, latent MSE loss:0.00038365, KL loss:0.00188423\n",
      "Pretrain epoch [25/246], ZINB loss:0.3930, NB loss:4.6517, latent MSE loss:0.00039889, KL loss:0.00193563\n",
      "Pretrain epoch [26/246], ZINB loss:0.4032, NB loss:4.6103, latent MSE loss:0.00033666, KL loss:0.00179833\n",
      "Pretrain epoch [27/246], ZINB loss:0.3078, NB loss:4.5098, latent MSE loss:0.00012288, KL loss:0.00001108\n",
      "Pretrain epoch [1/247], ZINB loss:0.3811, NB loss:4.6036, latent MSE loss:0.00038852, KL loss:0.00169916\n",
      "Pretrain epoch [2/247], ZINB loss:0.4151, NB loss:4.5386, latent MSE loss:0.00048060, KL loss:0.00185513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [3/247], ZINB loss:0.4036, NB loss:4.6328, latent MSE loss:0.00041727, KL loss:0.00185388\n",
      "Pretrain epoch [4/247], ZINB loss:0.3838, NB loss:4.6248, latent MSE loss:0.00039410, KL loss:0.00169842\n",
      "Pretrain epoch [5/247], ZINB loss:0.3956, NB loss:4.6012, latent MSE loss:0.00044290, KL loss:0.00214301\n",
      "Pretrain epoch [6/247], ZINB loss:0.3913, NB loss:4.6364, latent MSE loss:0.00043969, KL loss:0.00176344\n",
      "Pretrain epoch [7/247], ZINB loss:0.3961, NB loss:4.6293, latent MSE loss:0.00034104, KL loss:0.00219353\n",
      "Pretrain epoch [8/247], ZINB loss:0.3889, NB loss:4.6658, latent MSE loss:0.00030739, KL loss:0.00203284\n",
      "Pretrain epoch [9/247], ZINB loss:0.3866, NB loss:4.6653, latent MSE loss:0.00041523, KL loss:0.00170889\n",
      "Pretrain epoch [10/247], ZINB loss:0.3878, NB loss:4.6245, latent MSE loss:0.00048948, KL loss:0.00177395\n",
      "Pretrain epoch [11/247], ZINB loss:0.3938, NB loss:4.6585, latent MSE loss:0.00039453, KL loss:0.00204937\n",
      "Pretrain epoch [12/247], ZINB loss:0.3951, NB loss:4.6001, latent MSE loss:0.00041563, KL loss:0.00189550\n",
      "Pretrain epoch [13/247], ZINB loss:0.4029, NB loss:4.5445, latent MSE loss:0.00043234, KL loss:0.00176412\n",
      "Pretrain epoch [14/247], ZINB loss:0.4220, NB loss:4.6662, latent MSE loss:0.00038855, KL loss:0.00185044\n",
      "Pretrain epoch [15/247], ZINB loss:0.4168, NB loss:4.5590, latent MSE loss:0.00039272, KL loss:0.00173875\n",
      "Pretrain epoch [16/247], ZINB loss:0.4034, NB loss:4.6277, latent MSE loss:0.00041025, KL loss:0.00215149\n",
      "Pretrain epoch [17/247], ZINB loss:0.3997, NB loss:4.5919, latent MSE loss:0.00041222, KL loss:0.00158524\n",
      "Pretrain epoch [18/247], ZINB loss:0.3909, NB loss:4.5705, latent MSE loss:0.00035691, KL loss:0.00158591\n",
      "Pretrain epoch [19/247], ZINB loss:0.3902, NB loss:4.6816, latent MSE loss:0.00034239, KL loss:0.00170757\n",
      "Pretrain epoch [20/247], ZINB loss:0.4133, NB loss:4.5836, latent MSE loss:0.00044233, KL loss:0.00217536\n",
      "Pretrain epoch [21/247], ZINB loss:0.3960, NB loss:4.6032, latent MSE loss:0.00036334, KL loss:0.00166493\n",
      "Pretrain epoch [22/247], ZINB loss:0.4094, NB loss:4.6698, latent MSE loss:0.00048360, KL loss:0.00200202\n",
      "Pretrain epoch [23/247], ZINB loss:0.3925, NB loss:4.5776, latent MSE loss:0.00033540, KL loss:0.00171968\n",
      "Pretrain epoch [24/247], ZINB loss:0.3981, NB loss:4.6656, latent MSE loss:0.00046050, KL loss:0.00215353\n",
      "Pretrain epoch [25/247], ZINB loss:0.3828, NB loss:4.6080, latent MSE loss:0.00035728, KL loss:0.00186819\n",
      "Pretrain epoch [26/247], ZINB loss:0.4030, NB loss:4.6189, latent MSE loss:0.00046367, KL loss:0.00206251\n",
      "Pretrain epoch [27/247], ZINB loss:0.4452, NB loss:4.1654, latent MSE loss:0.00038975, KL loss:0.00006621\n",
      "Pretrain epoch [1/248], ZINB loss:0.4032, NB loss:4.6737, latent MSE loss:0.00053831, KL loss:0.00226498\n",
      "Pretrain epoch [2/248], ZINB loss:0.4099, NB loss:4.6172, latent MSE loss:0.00068521, KL loss:0.00181439\n",
      "Pretrain epoch [3/248], ZINB loss:0.3926, NB loss:4.6060, latent MSE loss:0.00062187, KL loss:0.00170302\n",
      "Pretrain epoch [4/248], ZINB loss:0.4043, NB loss:4.6242, latent MSE loss:0.00058275, KL loss:0.00190807\n",
      "Pretrain epoch [5/248], ZINB loss:0.3989, NB loss:4.6420, latent MSE loss:0.00058661, KL loss:0.00175779\n",
      "Pretrain epoch [6/248], ZINB loss:0.4085, NB loss:4.6105, latent MSE loss:0.00056680, KL loss:0.00203203\n",
      "Pretrain epoch [7/248], ZINB loss:0.3961, NB loss:4.6442, latent MSE loss:0.00078939, KL loss:0.00206416\n",
      "Pretrain epoch [8/248], ZINB loss:0.3972, NB loss:4.5928, latent MSE loss:0.00080737, KL loss:0.00176323\n",
      "Pretrain epoch [9/248], ZINB loss:0.3985, NB loss:4.6077, latent MSE loss:0.00064625, KL loss:0.00177830\n",
      "Pretrain epoch [10/248], ZINB loss:0.3942, NB loss:4.6466, latent MSE loss:0.00071522, KL loss:0.00218474\n",
      "Pretrain epoch [11/248], ZINB loss:0.3907, NB loss:4.6155, latent MSE loss:0.00067686, KL loss:0.00178975\n",
      "Pretrain epoch [12/248], ZINB loss:0.4230, NB loss:4.6765, latent MSE loss:0.00076197, KL loss:0.00252100\n",
      "Pretrain epoch [13/248], ZINB loss:0.3889, NB loss:4.6479, latent MSE loss:0.00073430, KL loss:0.00178602\n",
      "Pretrain epoch [14/248], ZINB loss:0.3958, NB loss:4.6122, latent MSE loss:0.00069500, KL loss:0.00183511\n",
      "Pretrain epoch [15/248], ZINB loss:0.4118, NB loss:4.5999, latent MSE loss:0.00059090, KL loss:0.00155617\n",
      "Pretrain epoch [16/248], ZINB loss:0.4058, NB loss:4.6101, latent MSE loss:0.00062449, KL loss:0.00163367\n",
      "Pretrain epoch [17/248], ZINB loss:0.4062, NB loss:4.6131, latent MSE loss:0.00054065, KL loss:0.00162935\n",
      "Pretrain epoch [18/248], ZINB loss:0.4023, NB loss:4.5909, latent MSE loss:0.00060710, KL loss:0.00204468\n",
      "Pretrain epoch [19/248], ZINB loss:0.4058, NB loss:4.6938, latent MSE loss:0.00066555, KL loss:0.00221884\n",
      "Pretrain epoch [20/248], ZINB loss:0.3931, NB loss:4.5833, latent MSE loss:0.00056188, KL loss:0.00164464\n",
      "Pretrain epoch [21/248], ZINB loss:0.3816, NB loss:4.5897, latent MSE loss:0.00052725, KL loss:0.00161066\n",
      "Pretrain epoch [22/248], ZINB loss:0.3846, NB loss:4.6050, latent MSE loss:0.00067878, KL loss:0.00179411\n",
      "Pretrain epoch [23/248], ZINB loss:0.3927, NB loss:4.5470, latent MSE loss:0.00072242, KL loss:0.00195939\n",
      "Pretrain epoch [24/248], ZINB loss:0.3908, NB loss:4.5957, latent MSE loss:0.00092787, KL loss:0.00169534\n",
      "Pretrain epoch [25/248], ZINB loss:0.3794, NB loss:4.5901, latent MSE loss:0.00053929, KL loss:0.00151382\n",
      "Pretrain epoch [26/248], ZINB loss:0.4082, NB loss:4.5639, latent MSE loss:0.00048984, KL loss:0.00177742\n",
      "Pretrain epoch [27/248], ZINB loss:0.4512, NB loss:4.7385, latent MSE loss:0.00042369, KL loss:0.00001077\n",
      "Pretrain epoch [1/249], ZINB loss:0.3915, NB loss:4.5466, latent MSE loss:0.00079077, KL loss:0.00176550\n",
      "Pretrain epoch [2/249], ZINB loss:0.3995, NB loss:4.6672, latent MSE loss:0.00081568, KL loss:0.00250113\n",
      "Pretrain epoch [3/249], ZINB loss:0.4014, NB loss:4.5718, latent MSE loss:0.00066469, KL loss:0.00170504\n",
      "Pretrain epoch [4/249], ZINB loss:0.3862, NB loss:4.6411, latent MSE loss:0.00043943, KL loss:0.00158851\n",
      "Pretrain epoch [5/249], ZINB loss:0.3830, NB loss:4.6094, latent MSE loss:0.00051622, KL loss:0.00180650\n",
      "Pretrain epoch [6/249], ZINB loss:0.4067, NB loss:4.6741, latent MSE loss:0.00054318, KL loss:0.00213293\n",
      "Pretrain epoch [7/249], ZINB loss:0.4001, NB loss:4.6539, latent MSE loss:0.00052299, KL loss:0.00238940\n",
      "Pretrain epoch [8/249], ZINB loss:0.3782, NB loss:4.6936, latent MSE loss:0.00045684, KL loss:0.00220881\n",
      "Pretrain epoch [9/249], ZINB loss:0.3862, NB loss:4.5668, latent MSE loss:0.00046047, KL loss:0.00151653\n",
      "Pretrain epoch [10/249], ZINB loss:0.4109, NB loss:4.5927, latent MSE loss:0.00059635, KL loss:0.00169313\n",
      "Pretrain epoch [11/249], ZINB loss:0.4133, NB loss:4.5989, latent MSE loss:0.00041234, KL loss:0.00171879\n",
      "Pretrain epoch [12/249], ZINB loss:0.4018, NB loss:4.6082, latent MSE loss:0.00037419, KL loss:0.00177584\n",
      "Pretrain epoch [13/249], ZINB loss:0.4075, NB loss:4.5747, latent MSE loss:0.00031830, KL loss:0.00154719\n",
      "Pretrain epoch [14/249], ZINB loss:0.3897, NB loss:4.5360, latent MSE loss:0.00037030, KL loss:0.00158831\n",
      "Pretrain epoch [15/249], ZINB loss:0.3903, NB loss:4.5464, latent MSE loss:0.00035498, KL loss:0.00153713\n",
      "Pretrain epoch [16/249], ZINB loss:0.4088, NB loss:4.5780, latent MSE loss:0.00032559, KL loss:0.00183683\n",
      "Pretrain epoch [17/249], ZINB loss:0.3877, NB loss:4.6493, latent MSE loss:0.00026075, KL loss:0.00167618\n",
      "Pretrain epoch [18/249], ZINB loss:0.3825, NB loss:4.6052, latent MSE loss:0.00040055, KL loss:0.00159084\n",
      "Pretrain epoch [19/249], ZINB loss:0.3977, NB loss:4.6346, latent MSE loss:0.00033116, KL loss:0.00185305\n",
      "Pretrain epoch [20/249], ZINB loss:0.4084, NB loss:4.6207, latent MSE loss:0.00039033, KL loss:0.00193425\n",
      "Pretrain epoch [21/249], ZINB loss:0.4112, NB loss:4.5826, latent MSE loss:0.00038637, KL loss:0.00174248\n",
      "Pretrain epoch [22/249], ZINB loss:0.3983, NB loss:4.6022, latent MSE loss:0.00039482, KL loss:0.00163884\n",
      "Pretrain epoch [23/249], ZINB loss:0.4041, NB loss:4.6913, latent MSE loss:0.00039165, KL loss:0.00168069\n",
      "Pretrain epoch [24/249], ZINB loss:0.3912, NB loss:4.5612, latent MSE loss:0.00040154, KL loss:0.00187596\n",
      "Pretrain epoch [25/249], ZINB loss:0.4072, NB loss:4.6700, latent MSE loss:0.00038478, KL loss:0.00206097\n",
      "Pretrain epoch [26/249], ZINB loss:0.3937, NB loss:4.6767, latent MSE loss:0.00037310, KL loss:0.00186453\n",
      "Pretrain epoch [27/249], ZINB loss:0.6727, NB loss:4.8941, latent MSE loss:0.00030336, KL loss:0.00001422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [1/250], ZINB loss:0.3931, NB loss:4.5868, latent MSE loss:0.00054386, KL loss:0.00160253\n",
      "Pretrain epoch [2/250], ZINB loss:0.4049, NB loss:4.5970, latent MSE loss:0.00083186, KL loss:0.00189709\n",
      "Pretrain epoch [3/250], ZINB loss:0.3967, NB loss:4.5382, latent MSE loss:0.00066033, KL loss:0.00155211\n",
      "Pretrain epoch [4/250], ZINB loss:0.4158, NB loss:4.5679, latent MSE loss:0.00053502, KL loss:0.00156995\n",
      "Pretrain epoch [5/250], ZINB loss:0.3901, NB loss:4.6049, latent MSE loss:0.00046798, KL loss:0.00151946\n",
      "Pretrain epoch [6/250], ZINB loss:0.3902, NB loss:4.6334, latent MSE loss:0.00066941, KL loss:0.00198604\n",
      "Pretrain epoch [7/250], ZINB loss:0.3981, NB loss:4.6301, latent MSE loss:0.00076013, KL loss:0.00240518\n",
      "Pretrain epoch [8/250], ZINB loss:0.3942, NB loss:4.6482, latent MSE loss:0.00069462, KL loss:0.00186549\n",
      "Pretrain epoch [9/250], ZINB loss:0.3851, NB loss:4.5679, latent MSE loss:0.00070712, KL loss:0.00154832\n",
      "Pretrain epoch [10/250], ZINB loss:0.3955, NB loss:4.6044, latent MSE loss:0.00058848, KL loss:0.00162453\n",
      "Pretrain epoch [11/250], ZINB loss:0.4192, NB loss:4.6889, latent MSE loss:0.00076729, KL loss:0.00186230\n",
      "Pretrain epoch [12/250], ZINB loss:0.3847, NB loss:4.5782, latent MSE loss:0.00067653, KL loss:0.00179370\n",
      "Pretrain epoch [13/250], ZINB loss:0.4025, NB loss:4.6745, latent MSE loss:0.00071811, KL loss:0.00160203\n",
      "Pretrain epoch [14/250], ZINB loss:0.4156, NB loss:4.5977, latent MSE loss:0.00062727, KL loss:0.00185922\n",
      "Pretrain epoch [15/250], ZINB loss:0.4104, NB loss:4.5928, latent MSE loss:0.00055654, KL loss:0.00171971\n",
      "Pretrain epoch [16/250], ZINB loss:0.3995, NB loss:4.6039, latent MSE loss:0.00050750, KL loss:0.00176505\n",
      "Pretrain epoch [17/250], ZINB loss:0.4288, NB loss:4.6926, latent MSE loss:0.00074964, KL loss:0.00239078\n",
      "Pretrain epoch [18/250], ZINB loss:0.3957, NB loss:4.6478, latent MSE loss:0.00054797, KL loss:0.00159514\n",
      "Pretrain epoch [19/250], ZINB loss:0.4032, NB loss:4.6069, latent MSE loss:0.00053656, KL loss:0.00158011\n",
      "Pretrain epoch [20/250], ZINB loss:0.3888, NB loss:4.6338, latent MSE loss:0.00047933, KL loss:0.00153097\n",
      "Pretrain epoch [21/250], ZINB loss:0.4043, NB loss:4.6150, latent MSE loss:0.00051363, KL loss:0.00171793\n",
      "Pretrain epoch [22/250], ZINB loss:0.4147, NB loss:4.5767, latent MSE loss:0.00061219, KL loss:0.00172617\n",
      "Pretrain epoch [23/250], ZINB loss:0.4001, NB loss:4.6105, latent MSE loss:0.00044329, KL loss:0.00179185\n",
      "Pretrain epoch [24/250], ZINB loss:0.3870, NB loss:4.5982, latent MSE loss:0.00044430, KL loss:0.00179648\n",
      "Pretrain epoch [25/250], ZINB loss:0.3882, NB loss:4.5869, latent MSE loss:0.00044326, KL loss:0.00182235\n",
      "Pretrain epoch [26/250], ZINB loss:0.3868, NB loss:4.6421, latent MSE loss:0.00040669, KL loss:0.00203396\n",
      "Pretrain epoch [27/250], ZINB loss:0.3328, NB loss:4.7134, latent MSE loss:0.00040739, KL loss:0.00006728\n",
      "Pretrain epoch [1/251], ZINB loss:0.4001, NB loss:4.6488, latent MSE loss:0.00105665, KL loss:0.00166351\n",
      "Pretrain epoch [2/251], ZINB loss:0.3907, NB loss:4.5739, latent MSE loss:0.00071556, KL loss:0.00161783\n",
      "Pretrain epoch [3/251], ZINB loss:0.3753, NB loss:4.6729, latent MSE loss:0.00091092, KL loss:0.00143794\n",
      "Pretrain epoch [4/251], ZINB loss:0.3864, NB loss:4.5731, latent MSE loss:0.00167409, KL loss:0.00175182\n",
      "Pretrain epoch [5/251], ZINB loss:0.3875, NB loss:4.6600, latent MSE loss:0.00149235, KL loss:0.00167169\n",
      "Pretrain epoch [6/251], ZINB loss:0.3911, NB loss:4.6361, latent MSE loss:0.00156717, KL loss:0.00193170\n",
      "Pretrain epoch [7/251], ZINB loss:0.3991, NB loss:4.5977, latent MSE loss:0.00103052, KL loss:0.00165415\n",
      "Pretrain epoch [8/251], ZINB loss:0.4043, NB loss:4.6054, latent MSE loss:0.00060087, KL loss:0.00165154\n",
      "Pretrain epoch [9/251], ZINB loss:0.4072, NB loss:4.6555, latent MSE loss:0.00065960, KL loss:0.00182317\n",
      "Pretrain epoch [10/251], ZINB loss:0.3982, NB loss:4.5519, latent MSE loss:0.00073429, KL loss:0.00162546\n",
      "Pretrain epoch [11/251], ZINB loss:0.4049, NB loss:4.6263, latent MSE loss:0.00100837, KL loss:0.00186815\n",
      "Pretrain epoch [12/251], ZINB loss:0.4231, NB loss:4.6876, latent MSE loss:0.00103271, KL loss:0.00217953\n",
      "Pretrain epoch [13/251], ZINB loss:0.3958, NB loss:4.6123, latent MSE loss:0.00068865, KL loss:0.00188619\n",
      "Pretrain epoch [14/251], ZINB loss:0.3951, NB loss:4.6590, latent MSE loss:0.00051265, KL loss:0.00209650\n",
      "Pretrain epoch [15/251], ZINB loss:0.4052, NB loss:4.6272, latent MSE loss:0.00058061, KL loss:0.00183468\n",
      "Pretrain epoch [16/251], ZINB loss:0.3849, NB loss:4.5353, latent MSE loss:0.00056261, KL loss:0.00183915\n",
      "Pretrain epoch [17/251], ZINB loss:0.4081, NB loss:4.6216, latent MSE loss:0.00054159, KL loss:0.00160348\n",
      "Pretrain epoch [18/251], ZINB loss:0.3795, NB loss:4.6260, latent MSE loss:0.00044166, KL loss:0.00200364\n",
      "Pretrain epoch [19/251], ZINB loss:0.4140, NB loss:4.5858, latent MSE loss:0.00043400, KL loss:0.00185818\n",
      "Pretrain epoch [20/251], ZINB loss:0.3917, NB loss:4.5525, latent MSE loss:0.00048033, KL loss:0.00129150\n",
      "Pretrain epoch [21/251], ZINB loss:0.4001, NB loss:4.5363, latent MSE loss:0.00037743, KL loss:0.00141228\n",
      "Pretrain epoch [22/251], ZINB loss:0.3965, NB loss:4.5892, latent MSE loss:0.00038897, KL loss:0.00159701\n",
      "Pretrain epoch [23/251], ZINB loss:0.4174, NB loss:4.5851, latent MSE loss:0.00039677, KL loss:0.00150660\n",
      "Pretrain epoch [24/251], ZINB loss:0.3883, NB loss:4.6057, latent MSE loss:0.00050781, KL loss:0.00182070\n",
      "Pretrain epoch [25/251], ZINB loss:0.4029, NB loss:4.5873, latent MSE loss:0.00043954, KL loss:0.00176596\n",
      "Pretrain epoch [26/251], ZINB loss:0.3974, NB loss:4.6656, latent MSE loss:0.00043661, KL loss:0.00214122\n",
      "Pretrain epoch [27/251], ZINB loss:0.3131, NB loss:4.7499, latent MSE loss:0.00021631, KL loss:0.00000134\n",
      "Pretrain epoch [1/252], ZINB loss:0.4069, NB loss:4.6507, latent MSE loss:0.00079843, KL loss:0.00177047\n",
      "Pretrain epoch [2/252], ZINB loss:0.4136, NB loss:4.6806, latent MSE loss:0.00056748, KL loss:0.00199952\n",
      "Pretrain epoch [3/252], ZINB loss:0.4050, NB loss:4.6596, latent MSE loss:0.00074754, KL loss:0.00173282\n",
      "Pretrain epoch [4/252], ZINB loss:0.4069, NB loss:4.5890, latent MSE loss:0.00076309, KL loss:0.00162517\n",
      "Pretrain epoch [5/252], ZINB loss:0.4134, NB loss:4.6374, latent MSE loss:0.00090186, KL loss:0.00171996\n",
      "Pretrain epoch [6/252], ZINB loss:0.3802, NB loss:4.6145, latent MSE loss:0.00075736, KL loss:0.00166039\n",
      "Pretrain epoch [7/252], ZINB loss:0.3912, NB loss:4.6569, latent MSE loss:0.00067549, KL loss:0.00171978\n",
      "Pretrain epoch [8/252], ZINB loss:0.3953, NB loss:4.5441, latent MSE loss:0.00067196, KL loss:0.00135806\n",
      "Pretrain epoch [9/252], ZINB loss:0.3976, NB loss:4.5933, latent MSE loss:0.00074030, KL loss:0.00189976\n",
      "Pretrain epoch [10/252], ZINB loss:0.3989, NB loss:4.6040, latent MSE loss:0.00056945, KL loss:0.00179847\n",
      "Pretrain epoch [11/252], ZINB loss:0.4104, NB loss:4.5412, latent MSE loss:0.00088385, KL loss:0.00161410\n",
      "Pretrain epoch [12/252], ZINB loss:0.3992, NB loss:4.6431, latent MSE loss:0.00070386, KL loss:0.00193060\n",
      "Pretrain epoch [13/252], ZINB loss:0.3956, NB loss:4.6803, latent MSE loss:0.00049143, KL loss:0.00191719\n",
      "Pretrain epoch [14/252], ZINB loss:0.4082, NB loss:4.5559, latent MSE loss:0.00051185, KL loss:0.00151561\n",
      "Pretrain epoch [15/252], ZINB loss:0.4002, NB loss:4.6590, latent MSE loss:0.00057447, KL loss:0.00213796\n",
      "Pretrain epoch [16/252], ZINB loss:0.4231, NB loss:4.6567, latent MSE loss:0.00067259, KL loss:0.00220507\n",
      "Pretrain epoch [17/252], ZINB loss:0.4052, NB loss:4.5839, latent MSE loss:0.00063664, KL loss:0.00149090\n",
      "Pretrain epoch [18/252], ZINB loss:0.3863, NB loss:4.6122, latent MSE loss:0.00043043, KL loss:0.00152288\n",
      "Pretrain epoch [19/252], ZINB loss:0.3827, NB loss:4.6079, latent MSE loss:0.00043334, KL loss:0.00216570\n",
      "Pretrain epoch [20/252], ZINB loss:0.3887, NB loss:4.5548, latent MSE loss:0.00043821, KL loss:0.00147303\n",
      "Pretrain epoch [21/252], ZINB loss:0.3867, NB loss:4.5882, latent MSE loss:0.00052781, KL loss:0.00200924\n",
      "Pretrain epoch [22/252], ZINB loss:0.3808, NB loss:4.5441, latent MSE loss:0.00052720, KL loss:0.00154471\n",
      "Pretrain epoch [23/252], ZINB loss:0.4067, NB loss:4.5545, latent MSE loss:0.00050917, KL loss:0.00177911\n",
      "Pretrain epoch [24/252], ZINB loss:0.3886, NB loss:4.6388, latent MSE loss:0.00045808, KL loss:0.00195974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [25/252], ZINB loss:0.3884, NB loss:4.5799, latent MSE loss:0.00047404, KL loss:0.00157603\n",
      "Pretrain epoch [26/252], ZINB loss:0.3908, NB loss:4.6194, latent MSE loss:0.00055404, KL loss:0.00158618\n",
      "Pretrain epoch [27/252], ZINB loss:0.2842, NB loss:4.5123, latent MSE loss:0.00032650, KL loss:0.00005227\n",
      "Pretrain epoch [1/253], ZINB loss:0.4109, NB loss:4.6323, latent MSE loss:0.00076963, KL loss:0.00193330\n",
      "Pretrain epoch [2/253], ZINB loss:0.4056, NB loss:4.6152, latent MSE loss:0.00078963, KL loss:0.00145626\n",
      "Pretrain epoch [3/253], ZINB loss:0.4149, NB loss:4.6172, latent MSE loss:0.00068918, KL loss:0.00195808\n",
      "Pretrain epoch [4/253], ZINB loss:0.4036, NB loss:4.6019, latent MSE loss:0.00057790, KL loss:0.00184509\n",
      "Pretrain epoch [5/253], ZINB loss:0.4080, NB loss:4.6349, latent MSE loss:0.00068571, KL loss:0.00168354\n",
      "Pretrain epoch [6/253], ZINB loss:0.4031, NB loss:4.6115, latent MSE loss:0.00068395, KL loss:0.00198582\n",
      "Pretrain epoch [7/253], ZINB loss:0.4138, NB loss:4.5595, latent MSE loss:0.00081961, KL loss:0.00139481\n",
      "Pretrain epoch [8/253], ZINB loss:0.3990, NB loss:4.6255, latent MSE loss:0.00060870, KL loss:0.00213855\n",
      "Pretrain epoch [9/253], ZINB loss:0.3900, NB loss:4.5906, latent MSE loss:0.00050673, KL loss:0.00203868\n",
      "Pretrain epoch [10/253], ZINB loss:0.4073, NB loss:4.6231, latent MSE loss:0.00045238, KL loss:0.00151002\n",
      "Pretrain epoch [11/253], ZINB loss:0.4018, NB loss:4.6115, latent MSE loss:0.00067755, KL loss:0.00158231\n",
      "Pretrain epoch [12/253], ZINB loss:0.3758, NB loss:4.6073, latent MSE loss:0.00058411, KL loss:0.00182090\n",
      "Pretrain epoch [13/253], ZINB loss:0.4049, NB loss:4.5207, latent MSE loss:0.00063953, KL loss:0.00148467\n",
      "Pretrain epoch [14/253], ZINB loss:0.3835, NB loss:4.5833, latent MSE loss:0.00049078, KL loss:0.00162218\n",
      "Pretrain epoch [15/253], ZINB loss:0.4152, NB loss:4.5422, latent MSE loss:0.00051937, KL loss:0.00199465\n",
      "Pretrain epoch [16/253], ZINB loss:0.3963, NB loss:4.5844, latent MSE loss:0.00066016, KL loss:0.00168080\n",
      "Pretrain epoch [17/253], ZINB loss:0.3883, NB loss:4.6289, latent MSE loss:0.00066339, KL loss:0.00152258\n",
      "Pretrain epoch [18/253], ZINB loss:0.3981, NB loss:4.6393, latent MSE loss:0.00058030, KL loss:0.00171417\n",
      "Pretrain epoch [19/253], ZINB loss:0.4114, NB loss:4.6203, latent MSE loss:0.00064016, KL loss:0.00151304\n",
      "Pretrain epoch [20/253], ZINB loss:0.3976, NB loss:4.6473, latent MSE loss:0.00056322, KL loss:0.00160919\n",
      "Pretrain epoch [21/253], ZINB loss:0.3684, NB loss:4.6366, latent MSE loss:0.00043145, KL loss:0.00190103\n",
      "Pretrain epoch [22/253], ZINB loss:0.3918, NB loss:4.5433, latent MSE loss:0.00042972, KL loss:0.00133514\n",
      "Pretrain epoch [23/253], ZINB loss:0.3961, NB loss:4.6198, latent MSE loss:0.00044289, KL loss:0.00191518\n",
      "Pretrain epoch [24/253], ZINB loss:0.3819, NB loss:4.6590, latent MSE loss:0.00040706, KL loss:0.00148524\n",
      "Pretrain epoch [25/253], ZINB loss:0.3940, NB loss:4.5994, latent MSE loss:0.00069635, KL loss:0.00182224\n",
      "Pretrain epoch [26/253], ZINB loss:0.3921, NB loss:4.6245, latent MSE loss:0.00040799, KL loss:0.00192969\n",
      "Pretrain epoch [27/253], ZINB loss:0.3962, NB loss:4.8606, latent MSE loss:0.00024155, KL loss:0.00004752\n",
      "Pretrain epoch [1/254], ZINB loss:0.3857, NB loss:4.6042, latent MSE loss:0.00057082, KL loss:0.00155371\n",
      "Pretrain epoch [2/254], ZINB loss:0.4118, NB loss:4.5841, latent MSE loss:0.00059983, KL loss:0.00186413\n",
      "Pretrain epoch [3/254], ZINB loss:0.4021, NB loss:4.5980, latent MSE loss:0.00043010, KL loss:0.00163276\n",
      "Pretrain epoch [4/254], ZINB loss:0.4049, NB loss:4.5928, latent MSE loss:0.00048172, KL loss:0.00201459\n",
      "Pretrain epoch [5/254], ZINB loss:0.4070, NB loss:4.6654, latent MSE loss:0.00056905, KL loss:0.00172952\n",
      "Pretrain epoch [6/254], ZINB loss:0.4066, NB loss:4.5770, latent MSE loss:0.00046545, KL loss:0.00192192\n",
      "Pretrain epoch [7/254], ZINB loss:0.4123, NB loss:4.5485, latent MSE loss:0.00051749, KL loss:0.00166013\n",
      "Pretrain epoch [8/254], ZINB loss:0.3996, NB loss:4.6612, latent MSE loss:0.00049971, KL loss:0.00197938\n",
      "Pretrain epoch [9/254], ZINB loss:0.3959, NB loss:4.6083, latent MSE loss:0.00044661, KL loss:0.00147798\n",
      "Pretrain epoch [10/254], ZINB loss:0.4028, NB loss:4.6386, latent MSE loss:0.00049167, KL loss:0.00143096\n",
      "Pretrain epoch [11/254], ZINB loss:0.3921, NB loss:4.5881, latent MSE loss:0.00055290, KL loss:0.00190780\n",
      "Pretrain epoch [12/254], ZINB loss:0.3934, NB loss:4.6275, latent MSE loss:0.00054512, KL loss:0.00198330\n",
      "Pretrain epoch [13/254], ZINB loss:0.3810, NB loss:4.5523, latent MSE loss:0.00042594, KL loss:0.00144082\n",
      "Pretrain epoch [14/254], ZINB loss:0.3886, NB loss:4.6262, latent MSE loss:0.00041994, KL loss:0.00161692\n",
      "Pretrain epoch [15/254], ZINB loss:0.4139, NB loss:4.6703, latent MSE loss:0.00068789, KL loss:0.00173182\n",
      "Pretrain epoch [16/254], ZINB loss:0.3956, NB loss:4.6277, latent MSE loss:0.00038312, KL loss:0.00173896\n",
      "Pretrain epoch [17/254], ZINB loss:0.3967, NB loss:4.5481, latent MSE loss:0.00066025, KL loss:0.00170613\n",
      "Pretrain epoch [18/254], ZINB loss:0.3918, NB loss:4.6702, latent MSE loss:0.00041799, KL loss:0.00186407\n",
      "Pretrain epoch [19/254], ZINB loss:0.4024, NB loss:4.5745, latent MSE loss:0.00039293, KL loss:0.00143737\n",
      "Pretrain epoch [20/254], ZINB loss:0.4071, NB loss:4.6003, latent MSE loss:0.00034936, KL loss:0.00165414\n",
      "Pretrain epoch [21/254], ZINB loss:0.4046, NB loss:4.6526, latent MSE loss:0.00030554, KL loss:0.00174064\n",
      "Pretrain epoch [22/254], ZINB loss:0.4051, NB loss:4.6235, latent MSE loss:0.00034955, KL loss:0.00147847\n",
      "Pretrain epoch [23/254], ZINB loss:0.3763, NB loss:4.5645, latent MSE loss:0.00035044, KL loss:0.00194290\n",
      "Pretrain epoch [24/254], ZINB loss:0.3837, NB loss:4.6290, latent MSE loss:0.00041603, KL loss:0.00155325\n",
      "Pretrain epoch [25/254], ZINB loss:0.3839, NB loss:4.5558, latent MSE loss:0.00034013, KL loss:0.00150626\n",
      "Pretrain epoch [26/254], ZINB loss:0.3940, NB loss:4.5582, latent MSE loss:0.00033391, KL loss:0.00155818\n",
      "Pretrain epoch [27/254], ZINB loss:0.3964, NB loss:4.3869, latent MSE loss:0.00021837, KL loss:0.00000740\n",
      "Pretrain epoch [1/255], ZINB loss:0.3896, NB loss:4.6399, latent MSE loss:0.00067363, KL loss:0.00169969\n",
      "Pretrain epoch [2/255], ZINB loss:0.3979, NB loss:4.6083, latent MSE loss:0.00047031, KL loss:0.00205247\n",
      "Pretrain epoch [3/255], ZINB loss:0.3904, NB loss:4.6131, latent MSE loss:0.00045178, KL loss:0.00151320\n",
      "Pretrain epoch [4/255], ZINB loss:0.3909, NB loss:4.5875, latent MSE loss:0.00048655, KL loss:0.00161366\n",
      "Pretrain epoch [5/255], ZINB loss:0.3906, NB loss:4.6397, latent MSE loss:0.00051759, KL loss:0.00239395\n",
      "Pretrain epoch [6/255], ZINB loss:0.3906, NB loss:4.5725, latent MSE loss:0.00056045, KL loss:0.00149119\n",
      "Pretrain epoch [7/255], ZINB loss:0.4008, NB loss:4.5704, latent MSE loss:0.00041540, KL loss:0.00152271\n",
      "Pretrain epoch [8/255], ZINB loss:0.3880, NB loss:4.5699, latent MSE loss:0.00047444, KL loss:0.00149951\n",
      "Pretrain epoch [9/255], ZINB loss:0.3966, NB loss:4.6747, latent MSE loss:0.00048623, KL loss:0.00174637\n",
      "Pretrain epoch [10/255], ZINB loss:0.4035, NB loss:4.6788, latent MSE loss:0.00061241, KL loss:0.00188703\n",
      "Pretrain epoch [11/255], ZINB loss:0.4025, NB loss:4.6304, latent MSE loss:0.00067220, KL loss:0.00178657\n",
      "Pretrain epoch [12/255], ZINB loss:0.3749, NB loss:4.6246, latent MSE loss:0.00083518, KL loss:0.00139105\n",
      "Pretrain epoch [13/255], ZINB loss:0.4047, NB loss:4.5575, latent MSE loss:0.00106670, KL loss:0.00153247\n",
      "Pretrain epoch [14/255], ZINB loss:0.3918, NB loss:4.6078, latent MSE loss:0.00110197, KL loss:0.00143013\n",
      "Pretrain epoch [15/255], ZINB loss:0.3989, NB loss:4.6390, latent MSE loss:0.00101320, KL loss:0.00198132\n",
      "Pretrain epoch [16/255], ZINB loss:0.4199, NB loss:4.5681, latent MSE loss:0.00053647, KL loss:0.00189653\n",
      "Pretrain epoch [17/255], ZINB loss:0.3884, NB loss:4.6080, latent MSE loss:0.00041912, KL loss:0.00142331\n",
      "Pretrain epoch [18/255], ZINB loss:0.4072, NB loss:4.6603, latent MSE loss:0.00085692, KL loss:0.00201338\n",
      "Pretrain epoch [19/255], ZINB loss:0.3879, NB loss:4.5901, latent MSE loss:0.00111597, KL loss:0.00166309\n",
      "Pretrain epoch [20/255], ZINB loss:0.4013, NB loss:4.6150, latent MSE loss:0.00125157, KL loss:0.00162104\n",
      "Pretrain epoch [21/255], ZINB loss:0.4157, NB loss:4.5975, latent MSE loss:0.00088799, KL loss:0.00200408\n",
      "Pretrain epoch [22/255], ZINB loss:0.4045, NB loss:4.6178, latent MSE loss:0.00035216, KL loss:0.00204404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [23/255], ZINB loss:0.3826, NB loss:4.5407, latent MSE loss:0.00055550, KL loss:0.00138080\n",
      "Pretrain epoch [24/255], ZINB loss:0.4065, NB loss:4.5627, latent MSE loss:0.00088935, KL loss:0.00159751\n",
      "Pretrain epoch [25/255], ZINB loss:0.3971, NB loss:4.5954, latent MSE loss:0.00060536, KL loss:0.00133391\n",
      "Pretrain epoch [26/255], ZINB loss:0.4096, NB loss:4.5442, latent MSE loss:0.00052675, KL loss:0.00179800\n",
      "Pretrain epoch [27/255], ZINB loss:0.3886, NB loss:4.0422, latent MSE loss:0.00057850, KL loss:0.00001264\n",
      "Pretrain epoch [1/256], ZINB loss:0.4101, NB loss:4.5700, latent MSE loss:0.00305795, KL loss:0.00194454\n",
      "Pretrain epoch [2/256], ZINB loss:0.4038, NB loss:4.5900, latent MSE loss:0.00218472, KL loss:0.00160806\n",
      "Pretrain epoch [3/256], ZINB loss:0.3998, NB loss:4.5750, latent MSE loss:0.00166519, KL loss:0.00199700\n",
      "Pretrain epoch [4/256], ZINB loss:0.3883, NB loss:4.5109, latent MSE loss:0.00191634, KL loss:0.00160367\n",
      "Pretrain epoch [5/256], ZINB loss:0.3814, NB loss:4.6089, latent MSE loss:0.00089649, KL loss:0.00178817\n",
      "Pretrain epoch [6/256], ZINB loss:0.3874, NB loss:4.6363, latent MSE loss:0.00157106, KL loss:0.00180986\n",
      "Pretrain epoch [7/256], ZINB loss:0.3858, NB loss:4.6582, latent MSE loss:0.00136232, KL loss:0.00164906\n",
      "Pretrain epoch [8/256], ZINB loss:0.3966, NB loss:4.6095, latent MSE loss:0.00113401, KL loss:0.00162532\n",
      "Pretrain epoch [9/256], ZINB loss:0.4030, NB loss:4.5571, latent MSE loss:0.00120398, KL loss:0.00168959\n",
      "Pretrain epoch [10/256], ZINB loss:0.3928, NB loss:4.5587, latent MSE loss:0.00170864, KL loss:0.00177617\n",
      "Pretrain epoch [11/256], ZINB loss:0.4032, NB loss:4.6676, latent MSE loss:0.00117398, KL loss:0.00184299\n",
      "Pretrain epoch [12/256], ZINB loss:0.3791, NB loss:4.5583, latent MSE loss:0.00077553, KL loss:0.00136196\n",
      "Pretrain epoch [13/256], ZINB loss:0.3946, NB loss:4.6191, latent MSE loss:0.00154153, KL loss:0.00168532\n",
      "Pretrain epoch [14/256], ZINB loss:0.4035, NB loss:4.6021, latent MSE loss:0.00060890, KL loss:0.00215462\n",
      "Pretrain epoch [15/256], ZINB loss:0.3971, NB loss:4.5880, latent MSE loss:0.00115307, KL loss:0.00212653\n",
      "Pretrain epoch [16/256], ZINB loss:0.4054, NB loss:4.5553, latent MSE loss:0.00066705, KL loss:0.00157493\n",
      "Pretrain epoch [17/256], ZINB loss:0.4032, NB loss:4.6157, latent MSE loss:0.00101481, KL loss:0.00166733\n",
      "Pretrain epoch [18/256], ZINB loss:0.3873, NB loss:4.5682, latent MSE loss:0.00061093, KL loss:0.00145885\n",
      "Pretrain epoch [19/256], ZINB loss:0.3976, NB loss:4.6608, latent MSE loss:0.00089147, KL loss:0.00172543\n",
      "Pretrain epoch [20/256], ZINB loss:0.3981, NB loss:4.6433, latent MSE loss:0.00058529, KL loss:0.00166824\n",
      "Pretrain epoch [21/256], ZINB loss:0.3918, NB loss:4.6827, latent MSE loss:0.00057355, KL loss:0.00145499\n",
      "Pretrain epoch [22/256], ZINB loss:0.4065, NB loss:4.5460, latent MSE loss:0.00100303, KL loss:0.00163315\n",
      "Pretrain epoch [23/256], ZINB loss:0.3908, NB loss:4.5583, latent MSE loss:0.00049636, KL loss:0.00149373\n",
      "Pretrain epoch [24/256], ZINB loss:0.3998, NB loss:4.5969, latent MSE loss:0.00058626, KL loss:0.00176329\n",
      "Pretrain epoch [25/256], ZINB loss:0.4255, NB loss:4.7226, latent MSE loss:0.00057553, KL loss:0.00186084\n",
      "Pretrain epoch [26/256], ZINB loss:0.3988, NB loss:4.5911, latent MSE loss:0.00055775, KL loss:0.00149680\n",
      "Pretrain epoch [27/256], ZINB loss:0.4092, NB loss:5.0077, latent MSE loss:0.00037103, KL loss:0.00002565\n",
      "Pretrain epoch [1/257], ZINB loss:0.3908, NB loss:4.6208, latent MSE loss:0.00115191, KL loss:0.00146898\n",
      "Pretrain epoch [2/257], ZINB loss:0.4037, NB loss:4.6398, latent MSE loss:0.00088288, KL loss:0.00202350\n",
      "Pretrain epoch [3/257], ZINB loss:0.4065, NB loss:4.6268, latent MSE loss:0.00082051, KL loss:0.00161031\n",
      "Pretrain epoch [4/257], ZINB loss:0.3715, NB loss:4.6331, latent MSE loss:0.00075658, KL loss:0.00163496\n",
      "Pretrain epoch [5/257], ZINB loss:0.3977, NB loss:4.6222, latent MSE loss:0.00068175, KL loss:0.00166960\n",
      "Pretrain epoch [6/257], ZINB loss:0.3913, NB loss:4.5632, latent MSE loss:0.00076297, KL loss:0.00160438\n",
      "Pretrain epoch [7/257], ZINB loss:0.3845, NB loss:4.5995, latent MSE loss:0.00072301, KL loss:0.00148190\n",
      "Pretrain epoch [8/257], ZINB loss:0.4080, NB loss:4.5836, latent MSE loss:0.00063299, KL loss:0.00187200\n",
      "Pretrain epoch [9/257], ZINB loss:0.4141, NB loss:4.6901, latent MSE loss:0.00065924, KL loss:0.00178597\n",
      "Pretrain epoch [10/257], ZINB loss:0.4097, NB loss:4.5879, latent MSE loss:0.00066010, KL loss:0.00188822\n",
      "Pretrain epoch [11/257], ZINB loss:0.4028, NB loss:4.5570, latent MSE loss:0.00073521, KL loss:0.00177155\n",
      "Pretrain epoch [12/257], ZINB loss:0.3893, NB loss:4.5878, latent MSE loss:0.00087514, KL loss:0.00163311\n",
      "Pretrain epoch [13/257], ZINB loss:0.3959, NB loss:4.6471, latent MSE loss:0.00077176, KL loss:0.00153191\n",
      "Pretrain epoch [14/257], ZINB loss:0.3976, NB loss:4.6582, latent MSE loss:0.00066576, KL loss:0.00210335\n",
      "Pretrain epoch [15/257], ZINB loss:0.4044, NB loss:4.6064, latent MSE loss:0.00059192, KL loss:0.00162687\n",
      "Pretrain epoch [16/257], ZINB loss:0.3917, NB loss:4.5967, latent MSE loss:0.00055826, KL loss:0.00162599\n",
      "Pretrain epoch [17/257], ZINB loss:0.3912, NB loss:4.5701, latent MSE loss:0.00055350, KL loss:0.00148376\n",
      "Pretrain epoch [18/257], ZINB loss:0.4145, NB loss:4.5742, latent MSE loss:0.00051377, KL loss:0.00151171\n",
      "Pretrain epoch [19/257], ZINB loss:0.3993, NB loss:4.5263, latent MSE loss:0.00053496, KL loss:0.00148755\n",
      "Pretrain epoch [20/257], ZINB loss:0.3986, NB loss:4.5633, latent MSE loss:0.00080036, KL loss:0.00180778\n",
      "Pretrain epoch [21/257], ZINB loss:0.4133, NB loss:4.5784, latent MSE loss:0.00056671, KL loss:0.00154891\n",
      "Pretrain epoch [22/257], ZINB loss:0.3788, NB loss:4.6381, latent MSE loss:0.00042788, KL loss:0.00152303\n",
      "Pretrain epoch [23/257], ZINB loss:0.4149, NB loss:4.5612, latent MSE loss:0.00046075, KL loss:0.00147225\n",
      "Pretrain epoch [24/257], ZINB loss:0.3832, NB loss:4.5852, latent MSE loss:0.00032824, KL loss:0.00177040\n",
      "Pretrain epoch [25/257], ZINB loss:0.3937, NB loss:4.6106, latent MSE loss:0.00040868, KL loss:0.00136848\n",
      "Pretrain epoch [26/257], ZINB loss:0.3949, NB loss:4.5923, latent MSE loss:0.00039054, KL loss:0.00143195\n",
      "Pretrain epoch [27/257], ZINB loss:0.4037, NB loss:4.6055, latent MSE loss:0.00032363, KL loss:0.00003762\n",
      "Pretrain epoch [1/258], ZINB loss:0.3902, NB loss:4.5751, latent MSE loss:0.00088905, KL loss:0.00175865\n",
      "Pretrain epoch [2/258], ZINB loss:0.4045, NB loss:4.6472, latent MSE loss:0.00052840, KL loss:0.00156021\n",
      "Pretrain epoch [3/258], ZINB loss:0.4060, NB loss:4.5988, latent MSE loss:0.00056187, KL loss:0.00200290\n",
      "Pretrain epoch [4/258], ZINB loss:0.3855, NB loss:4.5833, latent MSE loss:0.00069791, KL loss:0.00178755\n",
      "Pretrain epoch [5/258], ZINB loss:0.3920, NB loss:4.5943, latent MSE loss:0.00042551, KL loss:0.00140627\n",
      "Pretrain epoch [6/258], ZINB loss:0.3906, NB loss:4.6199, latent MSE loss:0.00064133, KL loss:0.00153420\n",
      "Pretrain epoch [7/258], ZINB loss:0.4058, NB loss:4.5614, latent MSE loss:0.00077365, KL loss:0.00146406\n",
      "Pretrain epoch [8/258], ZINB loss:0.3932, NB loss:4.6264, latent MSE loss:0.00062743, KL loss:0.00177918\n",
      "Pretrain epoch [9/258], ZINB loss:0.4010, NB loss:4.5915, latent MSE loss:0.00053387, KL loss:0.00183625\n",
      "Pretrain epoch [10/258], ZINB loss:0.4028, NB loss:4.6011, latent MSE loss:0.00055018, KL loss:0.00186467\n",
      "Pretrain epoch [11/258], ZINB loss:0.4011, NB loss:4.5697, latent MSE loss:0.00066403, KL loss:0.00175953\n",
      "Pretrain epoch [12/258], ZINB loss:0.3958, NB loss:4.5736, latent MSE loss:0.00050022, KL loss:0.00152234\n",
      "Pretrain epoch [13/258], ZINB loss:0.4248, NB loss:4.6340, latent MSE loss:0.00066182, KL loss:0.00168215\n",
      "Pretrain epoch [14/258], ZINB loss:0.3931, NB loss:4.6026, latent MSE loss:0.00060436, KL loss:0.00169216\n",
      "Pretrain epoch [15/258], ZINB loss:0.3904, NB loss:4.6448, latent MSE loss:0.00052618, KL loss:0.00214235\n",
      "Pretrain epoch [16/258], ZINB loss:0.4059, NB loss:4.5402, latent MSE loss:0.00046879, KL loss:0.00149765\n",
      "Pretrain epoch [17/258], ZINB loss:0.4081, NB loss:4.6534, latent MSE loss:0.00050996, KL loss:0.00179448\n",
      "Pretrain epoch [18/258], ZINB loss:0.3941, NB loss:4.5996, latent MSE loss:0.00067781, KL loss:0.00181417\n",
      "Pretrain epoch [19/258], ZINB loss:0.3960, NB loss:4.5425, latent MSE loss:0.00044400, KL loss:0.00139309\n",
      "Pretrain epoch [20/258], ZINB loss:0.3834, NB loss:4.5858, latent MSE loss:0.00053054, KL loss:0.00148390\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [21/258], ZINB loss:0.4105, NB loss:4.6232, latent MSE loss:0.00042628, KL loss:0.00158315\n",
      "Pretrain epoch [22/258], ZINB loss:0.4001, NB loss:4.6113, latent MSE loss:0.00048346, KL loss:0.00153250\n",
      "Pretrain epoch [23/258], ZINB loss:0.3796, NB loss:4.5818, latent MSE loss:0.00033212, KL loss:0.00159456\n",
      "Pretrain epoch [24/258], ZINB loss:0.4129, NB loss:4.5911, latent MSE loss:0.00058799, KL loss:0.00188564\n",
      "Pretrain epoch [25/258], ZINB loss:0.3906, NB loss:4.5931, latent MSE loss:0.00045524, KL loss:0.00138127\n",
      "Pretrain epoch [26/258], ZINB loss:0.3911, NB loss:4.6202, latent MSE loss:0.00042459, KL loss:0.00155811\n",
      "Pretrain epoch [27/258], ZINB loss:0.3827, NB loss:4.5780, latent MSE loss:0.00029538, KL loss:0.00004761\n",
      "Pretrain epoch [1/259], ZINB loss:0.4052, NB loss:4.6314, latent MSE loss:0.00061422, KL loss:0.00148003\n",
      "Pretrain epoch [2/259], ZINB loss:0.3923, NB loss:4.6241, latent MSE loss:0.00043215, KL loss:0.00158188\n",
      "Pretrain epoch [3/259], ZINB loss:0.4098, NB loss:4.6397, latent MSE loss:0.00047244, KL loss:0.00157474\n",
      "Pretrain epoch [4/259], ZINB loss:0.3828, NB loss:4.6055, latent MSE loss:0.00036695, KL loss:0.00199573\n",
      "Pretrain epoch [5/259], ZINB loss:0.3928, NB loss:4.5987, latent MSE loss:0.00040958, KL loss:0.00147797\n",
      "Pretrain epoch [6/259], ZINB loss:0.4050, NB loss:4.5546, latent MSE loss:0.00044406, KL loss:0.00146754\n",
      "Pretrain epoch [7/259], ZINB loss:0.4058, NB loss:4.6247, latent MSE loss:0.00044891, KL loss:0.00144479\n",
      "Pretrain epoch [8/259], ZINB loss:0.3810, NB loss:4.5606, latent MSE loss:0.00054575, KL loss:0.00135231\n",
      "Pretrain epoch [9/259], ZINB loss:0.4017, NB loss:4.6230, latent MSE loss:0.00039713, KL loss:0.00214692\n",
      "Pretrain epoch [10/259], ZINB loss:0.4196, NB loss:4.5531, latent MSE loss:0.00047253, KL loss:0.00182024\n",
      "Pretrain epoch [11/259], ZINB loss:0.3873, NB loss:4.6703, latent MSE loss:0.00034654, KL loss:0.00190901\n",
      "Pretrain epoch [12/259], ZINB loss:0.3982, NB loss:4.5785, latent MSE loss:0.00042583, KL loss:0.00199470\n",
      "Pretrain epoch [13/259], ZINB loss:0.4066, NB loss:4.6067, latent MSE loss:0.00047953, KL loss:0.00158455\n",
      "Pretrain epoch [14/259], ZINB loss:0.4066, NB loss:4.6255, latent MSE loss:0.00085796, KL loss:0.00194150\n",
      "Pretrain epoch [15/259], ZINB loss:0.4019, NB loss:4.6061, latent MSE loss:0.00049613, KL loss:0.00146617\n",
      "Pretrain epoch [16/259], ZINB loss:0.3921, NB loss:4.6036, latent MSE loss:0.00039726, KL loss:0.00146915\n",
      "Pretrain epoch [17/259], ZINB loss:0.3753, NB loss:4.6060, latent MSE loss:0.00034042, KL loss:0.00146566\n",
      "Pretrain epoch [18/259], ZINB loss:0.3960, NB loss:4.5878, latent MSE loss:0.00049883, KL loss:0.00155693\n",
      "Pretrain epoch [19/259], ZINB loss:0.3937, NB loss:4.5842, latent MSE loss:0.00047589, KL loss:0.00137753\n",
      "Pretrain epoch [20/259], ZINB loss:0.3896, NB loss:4.6129, latent MSE loss:0.00044581, KL loss:0.00169172\n",
      "Pretrain epoch [21/259], ZINB loss:0.4171, NB loss:4.5858, latent MSE loss:0.00049563, KL loss:0.00154832\n",
      "Pretrain epoch [22/259], ZINB loss:0.3981, NB loss:4.6145, latent MSE loss:0.00046683, KL loss:0.00142099\n",
      "Pretrain epoch [23/259], ZINB loss:0.3883, NB loss:4.5374, latent MSE loss:0.00041301, KL loss:0.00165777\n",
      "Pretrain epoch [24/259], ZINB loss:0.3834, NB loss:4.5766, latent MSE loss:0.00038811, KL loss:0.00147979\n",
      "Pretrain epoch [25/259], ZINB loss:0.4010, NB loss:4.5401, latent MSE loss:0.00034000, KL loss:0.00139415\n",
      "Pretrain epoch [26/259], ZINB loss:0.3954, NB loss:4.5636, latent MSE loss:0.00036559, KL loss:0.00162363\n",
      "Pretrain epoch [27/259], ZINB loss:0.4416, NB loss:4.5928, latent MSE loss:0.00036594, KL loss:0.00001424\n",
      "Pretrain epoch [1/260], ZINB loss:0.3897, NB loss:4.5727, latent MSE loss:0.00060289, KL loss:0.00126232\n",
      "Pretrain epoch [2/260], ZINB loss:0.3956, NB loss:4.6282, latent MSE loss:0.00085377, KL loss:0.00156696\n",
      "Pretrain epoch [3/260], ZINB loss:0.3944, NB loss:4.5811, latent MSE loss:0.00077594, KL loss:0.00138893\n",
      "Pretrain epoch [4/260], ZINB loss:0.3940, NB loss:4.5618, latent MSE loss:0.00062649, KL loss:0.00148387\n",
      "Pretrain epoch [5/260], ZINB loss:0.3912, NB loss:4.6098, latent MSE loss:0.00063716, KL loss:0.00170432\n",
      "Pretrain epoch [6/260], ZINB loss:0.3930, NB loss:4.5782, latent MSE loss:0.00065402, KL loss:0.00188219\n",
      "Pretrain epoch [7/260], ZINB loss:0.4163, NB loss:4.5768, latent MSE loss:0.00066227, KL loss:0.00196295\n",
      "Pretrain epoch [8/260], ZINB loss:0.3940, NB loss:4.5588, latent MSE loss:0.00041615, KL loss:0.00140981\n",
      "Pretrain epoch [9/260], ZINB loss:0.4327, NB loss:4.6065, latent MSE loss:0.00061068, KL loss:0.00166859\n",
      "Pretrain epoch [10/260], ZINB loss:0.4114, NB loss:4.5936, latent MSE loss:0.00055607, KL loss:0.00187077\n",
      "Pretrain epoch [11/260], ZINB loss:0.3921, NB loss:4.5836, latent MSE loss:0.00052572, KL loss:0.00139722\n",
      "Pretrain epoch [12/260], ZINB loss:0.3868, NB loss:4.6301, latent MSE loss:0.00051640, KL loss:0.00165382\n",
      "Pretrain epoch [13/260], ZINB loss:0.3809, NB loss:4.6420, latent MSE loss:0.00041576, KL loss:0.00213108\n",
      "Pretrain epoch [14/260], ZINB loss:0.3952, NB loss:4.5714, latent MSE loss:0.00036247, KL loss:0.00133119\n",
      "Pretrain epoch [15/260], ZINB loss:0.3923, NB loss:4.5884, latent MSE loss:0.00037995, KL loss:0.00139274\n",
      "Pretrain epoch [16/260], ZINB loss:0.3978, NB loss:4.6027, latent MSE loss:0.00043610, KL loss:0.00140874\n",
      "Pretrain epoch [17/260], ZINB loss:0.3993, NB loss:4.6373, latent MSE loss:0.00046410, KL loss:0.00195258\n",
      "Pretrain epoch [18/260], ZINB loss:0.3842, NB loss:4.5965, latent MSE loss:0.00041145, KL loss:0.00160256\n",
      "Pretrain epoch [19/260], ZINB loss:0.4010, NB loss:4.6274, latent MSE loss:0.00051693, KL loss:0.00138420\n",
      "Pretrain epoch [20/260], ZINB loss:0.3960, NB loss:4.5787, latent MSE loss:0.00042308, KL loss:0.00150198\n",
      "Pretrain epoch [21/260], ZINB loss:0.3822, NB loss:4.6575, latent MSE loss:0.00038393, KL loss:0.00148318\n",
      "Pretrain epoch [22/260], ZINB loss:0.3993, NB loss:4.5390, latent MSE loss:0.00041065, KL loss:0.00150159\n",
      "Pretrain epoch [23/260], ZINB loss:0.3984, NB loss:4.5689, latent MSE loss:0.00035006, KL loss:0.00174490\n",
      "Pretrain epoch [24/260], ZINB loss:0.3882, NB loss:4.5891, latent MSE loss:0.00038898, KL loss:0.00147894\n",
      "Pretrain epoch [25/260], ZINB loss:0.4108, NB loss:4.5645, latent MSE loss:0.00042970, KL loss:0.00190041\n",
      "Pretrain epoch [26/260], ZINB loss:0.4033, NB loss:4.6455, latent MSE loss:0.00034687, KL loss:0.00166469\n",
      "Pretrain epoch [27/260], ZINB loss:0.4489, NB loss:4.4856, latent MSE loss:0.00261981, KL loss:0.00005227\n",
      "Pretrain epoch [1/261], ZINB loss:0.4027, NB loss:4.6457, latent MSE loss:0.00210391, KL loss:0.00178213\n",
      "Pretrain epoch [2/261], ZINB loss:0.4183, NB loss:4.6638, latent MSE loss:0.00274450, KL loss:0.00188952\n",
      "Pretrain epoch [3/261], ZINB loss:0.4036, NB loss:4.6522, latent MSE loss:0.00350722, KL loss:0.00169962\n",
      "Pretrain epoch [4/261], ZINB loss:0.3987, NB loss:4.5293, latent MSE loss:0.00310393, KL loss:0.00186702\n",
      "Pretrain epoch [5/261], ZINB loss:0.3991, NB loss:4.5392, latent MSE loss:0.00359470, KL loss:0.00138524\n",
      "Pretrain epoch [6/261], ZINB loss:0.4044, NB loss:4.5834, latent MSE loss:0.00294615, KL loss:0.00189268\n",
      "Pretrain epoch [7/261], ZINB loss:0.4119, NB loss:4.6309, latent MSE loss:0.00231430, KL loss:0.00159456\n",
      "Pretrain epoch [8/261], ZINB loss:0.4128, NB loss:4.5743, latent MSE loss:0.00303919, KL loss:0.00171379\n",
      "Pretrain epoch [9/261], ZINB loss:0.4019, NB loss:4.5876, latent MSE loss:0.00236342, KL loss:0.00134569\n",
      "Pretrain epoch [10/261], ZINB loss:0.3969, NB loss:4.6325, latent MSE loss:0.00312736, KL loss:0.00196942\n",
      "Pretrain epoch [11/261], ZINB loss:0.3866, NB loss:4.5991, latent MSE loss:0.00192816, KL loss:0.00180760\n",
      "Pretrain epoch [12/261], ZINB loss:0.4014, NB loss:4.5778, latent MSE loss:0.00175418, KL loss:0.00141712\n",
      "Pretrain epoch [13/261], ZINB loss:0.4126, NB loss:4.5628, latent MSE loss:0.00219657, KL loss:0.00198754\n",
      "Pretrain epoch [14/261], ZINB loss:0.4087, NB loss:4.5280, latent MSE loss:0.00140434, KL loss:0.00161794\n",
      "Pretrain epoch [15/261], ZINB loss:0.4022, NB loss:4.5704, latent MSE loss:0.00179622, KL loss:0.00196446\n",
      "Pretrain epoch [16/261], ZINB loss:0.4016, NB loss:4.6566, latent MSE loss:0.00159896, KL loss:0.00181201\n",
      "Pretrain epoch [17/261], ZINB loss:0.4116, NB loss:4.5753, latent MSE loss:0.00196932, KL loss:0.00202815\n",
      "Pretrain epoch [18/261], ZINB loss:0.3919, NB loss:4.5918, latent MSE loss:0.00166097, KL loss:0.00138207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [19/261], ZINB loss:0.3983, NB loss:4.5886, latent MSE loss:0.00174648, KL loss:0.00144288\n",
      "Pretrain epoch [20/261], ZINB loss:0.3935, NB loss:4.5205, latent MSE loss:0.00140221, KL loss:0.00142238\n",
      "Pretrain epoch [21/261], ZINB loss:0.3900, NB loss:4.5986, latent MSE loss:0.00182788, KL loss:0.00170480\n",
      "Pretrain epoch [22/261], ZINB loss:0.4169, NB loss:4.6466, latent MSE loss:0.00139730, KL loss:0.00179921\n",
      "Pretrain epoch [23/261], ZINB loss:0.4077, NB loss:4.6284, latent MSE loss:0.00131979, KL loss:0.00179163\n",
      "Pretrain epoch [24/261], ZINB loss:0.3881, NB loss:4.5366, latent MSE loss:0.00129544, KL loss:0.00148042\n",
      "Pretrain epoch [25/261], ZINB loss:0.3866, NB loss:4.5752, latent MSE loss:0.00114106, KL loss:0.00186048\n",
      "Pretrain epoch [26/261], ZINB loss:0.4043, NB loss:4.6358, latent MSE loss:0.00131847, KL loss:0.00184877\n",
      "Pretrain epoch [27/261], ZINB loss:0.3481, NB loss:4.3084, latent MSE loss:0.00068721, KL loss:0.00005474\n",
      "Pretrain epoch [1/262], ZINB loss:0.3960, NB loss:4.5511, latent MSE loss:0.00178560, KL loss:0.00163114\n",
      "Pretrain epoch [2/262], ZINB loss:0.3961, NB loss:4.5422, latent MSE loss:0.00142694, KL loss:0.00173497\n",
      "Pretrain epoch [3/262], ZINB loss:0.3992, NB loss:4.6022, latent MSE loss:0.00109470, KL loss:0.00179996\n",
      "Pretrain epoch [4/262], ZINB loss:0.4157, NB loss:4.6185, latent MSE loss:0.00181044, KL loss:0.00200456\n",
      "Pretrain epoch [5/262], ZINB loss:0.4054, NB loss:4.5611, latent MSE loss:0.00124915, KL loss:0.00149589\n",
      "Pretrain epoch [6/262], ZINB loss:0.3848, NB loss:4.5814, latent MSE loss:0.00097101, KL loss:0.00154678\n",
      "Pretrain epoch [7/262], ZINB loss:0.4047, NB loss:4.5843, latent MSE loss:0.00139790, KL loss:0.00151672\n",
      "Pretrain epoch [8/262], ZINB loss:0.4140, NB loss:4.5909, latent MSE loss:0.00097452, KL loss:0.00155570\n",
      "Pretrain epoch [9/262], ZINB loss:0.4084, NB loss:4.5941, latent MSE loss:0.00082729, KL loss:0.00147733\n",
      "Pretrain epoch [10/262], ZINB loss:0.4137, NB loss:4.5549, latent MSE loss:0.00127864, KL loss:0.00151333\n",
      "Pretrain epoch [11/262], ZINB loss:0.3972, NB loss:4.6443, latent MSE loss:0.00093556, KL loss:0.00174293\n",
      "Pretrain epoch [12/262], ZINB loss:0.3895, NB loss:4.6137, latent MSE loss:0.00095968, KL loss:0.00160880\n",
      "Pretrain epoch [13/262], ZINB loss:0.3882, NB loss:4.5609, latent MSE loss:0.00078795, KL loss:0.00164194\n",
      "Pretrain epoch [14/262], ZINB loss:0.3982, NB loss:4.6103, latent MSE loss:0.00066977, KL loss:0.00179246\n",
      "Pretrain epoch [15/262], ZINB loss:0.3958, NB loss:4.6526, latent MSE loss:0.00089739, KL loss:0.00140468\n",
      "Pretrain epoch [16/262], ZINB loss:0.3787, NB loss:4.5955, latent MSE loss:0.00059848, KL loss:0.00199344\n",
      "Pretrain epoch [17/262], ZINB loss:0.3810, NB loss:4.5511, latent MSE loss:0.00069435, KL loss:0.00190803\n",
      "Pretrain epoch [18/262], ZINB loss:0.3809, NB loss:4.6017, latent MSE loss:0.00062582, KL loss:0.00149956\n",
      "Pretrain epoch [19/262], ZINB loss:0.4022, NB loss:4.6458, latent MSE loss:0.00048684, KL loss:0.00145935\n",
      "Pretrain epoch [20/262], ZINB loss:0.3973, NB loss:4.6269, latent MSE loss:0.00062709, KL loss:0.00150050\n",
      "Pretrain epoch [21/262], ZINB loss:0.3904, NB loss:4.5828, latent MSE loss:0.00051737, KL loss:0.00154640\n",
      "Pretrain epoch [22/262], ZINB loss:0.4050, NB loss:4.5756, latent MSE loss:0.00074121, KL loss:0.00150645\n",
      "Pretrain epoch [23/262], ZINB loss:0.4086, NB loss:4.5582, latent MSE loss:0.00057954, KL loss:0.00162493\n",
      "Pretrain epoch [24/262], ZINB loss:0.3902, NB loss:4.5807, latent MSE loss:0.00065126, KL loss:0.00156049\n",
      "Pretrain epoch [25/262], ZINB loss:0.4034, NB loss:4.6120, latent MSE loss:0.00058209, KL loss:0.00211128\n",
      "Pretrain epoch [26/262], ZINB loss:0.4012, NB loss:4.5876, latent MSE loss:0.00043892, KL loss:0.00181764\n",
      "Pretrain epoch [27/262], ZINB loss:0.4530, NB loss:5.0521, latent MSE loss:0.00040890, KL loss:0.00000207\n",
      "Pretrain epoch [1/263], ZINB loss:0.4057, NB loss:4.5963, latent MSE loss:0.00144730, KL loss:0.00186948\n",
      "Pretrain epoch [2/263], ZINB loss:0.3962, NB loss:4.5402, latent MSE loss:0.00101979, KL loss:0.00141980\n",
      "Pretrain epoch [3/263], ZINB loss:0.3887, NB loss:4.5995, latent MSE loss:0.00094800, KL loss:0.00147728\n",
      "Pretrain epoch [4/263], ZINB loss:0.4144, NB loss:4.6063, latent MSE loss:0.00084198, KL loss:0.00164027\n",
      "Pretrain epoch [5/263], ZINB loss:0.4073, NB loss:4.6014, latent MSE loss:0.00068532, KL loss:0.00136162\n",
      "Pretrain epoch [6/263], ZINB loss:0.4056, NB loss:4.6566, latent MSE loss:0.00084840, KL loss:0.00175345\n",
      "Pretrain epoch [7/263], ZINB loss:0.4015, NB loss:4.5809, latent MSE loss:0.00093532, KL loss:0.00212654\n",
      "Pretrain epoch [8/263], ZINB loss:0.3855, NB loss:4.5559, latent MSE loss:0.00081638, KL loss:0.00133965\n",
      "Pretrain epoch [9/263], ZINB loss:0.4044, NB loss:4.5995, latent MSE loss:0.00068998, KL loss:0.00155140\n",
      "Pretrain epoch [10/263], ZINB loss:0.3920, NB loss:4.6178, latent MSE loss:0.00067294, KL loss:0.00144148\n",
      "Pretrain epoch [11/263], ZINB loss:0.3900, NB loss:4.5543, latent MSE loss:0.00065510, KL loss:0.00173231\n",
      "Pretrain epoch [12/263], ZINB loss:0.3860, NB loss:4.7011, latent MSE loss:0.00053001, KL loss:0.00180088\n",
      "Pretrain epoch [13/263], ZINB loss:0.3864, NB loss:4.6312, latent MSE loss:0.00068500, KL loss:0.00158477\n",
      "Pretrain epoch [14/263], ZINB loss:0.3946, NB loss:4.5618, latent MSE loss:0.00051011, KL loss:0.00206921\n",
      "Pretrain epoch [15/263], ZINB loss:0.3877, NB loss:4.5840, latent MSE loss:0.00046721, KL loss:0.00144844\n",
      "Pretrain epoch [16/263], ZINB loss:0.4058, NB loss:4.6192, latent MSE loss:0.00071895, KL loss:0.00160948\n",
      "Pretrain epoch [17/263], ZINB loss:0.3950, NB loss:4.5530, latent MSE loss:0.00053466, KL loss:0.00133405\n",
      "Pretrain epoch [18/263], ZINB loss:0.3910, NB loss:4.6232, latent MSE loss:0.00041675, KL loss:0.00129564\n",
      "Pretrain epoch [19/263], ZINB loss:0.4080, NB loss:4.6346, latent MSE loss:0.00075723, KL loss:0.00186815\n",
      "Pretrain epoch [20/263], ZINB loss:0.4092, NB loss:4.6277, latent MSE loss:0.00053981, KL loss:0.00163383\n",
      "Pretrain epoch [21/263], ZINB loss:0.3895, NB loss:4.6148, latent MSE loss:0.00054914, KL loss:0.00131434\n",
      "Pretrain epoch [22/263], ZINB loss:0.3889, NB loss:4.6196, latent MSE loss:0.00045306, KL loss:0.00191066\n",
      "Pretrain epoch [23/263], ZINB loss:0.3960, NB loss:4.5595, latent MSE loss:0.00048755, KL loss:0.00146270\n",
      "Pretrain epoch [24/263], ZINB loss:0.4085, NB loss:4.5761, latent MSE loss:0.00050150, KL loss:0.00155229\n",
      "Pretrain epoch [25/263], ZINB loss:0.3882, NB loss:4.6093, latent MSE loss:0.00047698, KL loss:0.00170795\n",
      "Pretrain epoch [26/263], ZINB loss:0.4084, NB loss:4.5454, latent MSE loss:0.00052206, KL loss:0.00167305\n",
      "Pretrain epoch [27/263], ZINB loss:0.4751, NB loss:4.4663, latent MSE loss:0.00035256, KL loss:0.00000854\n",
      "Pretrain epoch [1/264], ZINB loss:0.3968, NB loss:4.5783, latent MSE loss:0.00085341, KL loss:0.00158328\n",
      "Pretrain epoch [2/264], ZINB loss:0.4048, NB loss:4.5937, latent MSE loss:0.00094314, KL loss:0.00177310\n",
      "Pretrain epoch [3/264], ZINB loss:0.4251, NB loss:4.5599, latent MSE loss:0.00073965, KL loss:0.00187345\n",
      "Pretrain epoch [4/264], ZINB loss:0.4025, NB loss:4.5336, latent MSE loss:0.00112503, KL loss:0.00190693\n",
      "Pretrain epoch [5/264], ZINB loss:0.3901, NB loss:4.5443, latent MSE loss:0.00080832, KL loss:0.00140499\n",
      "Pretrain epoch [6/264], ZINB loss:0.4145, NB loss:4.5516, latent MSE loss:0.00079069, KL loss:0.00185648\n",
      "Pretrain epoch [7/264], ZINB loss:0.4011, NB loss:4.6454, latent MSE loss:0.00066433, KL loss:0.00163350\n",
      "Pretrain epoch [8/264], ZINB loss:0.4055, NB loss:4.5047, latent MSE loss:0.00064080, KL loss:0.00128613\n",
      "Pretrain epoch [9/264], ZINB loss:0.4158, NB loss:4.5857, latent MSE loss:0.00083430, KL loss:0.00149084\n",
      "Pretrain epoch [10/264], ZINB loss:0.4232, NB loss:4.6357, latent MSE loss:0.00061794, KL loss:0.00179437\n",
      "Pretrain epoch [11/264], ZINB loss:0.3862, NB loss:4.6566, latent MSE loss:0.00070750, KL loss:0.00207364\n",
      "Pretrain epoch [12/264], ZINB loss:0.3955, NB loss:4.5723, latent MSE loss:0.00061151, KL loss:0.00128871\n",
      "Pretrain epoch [13/264], ZINB loss:0.4022, NB loss:4.5983, latent MSE loss:0.00059616, KL loss:0.00167390\n",
      "Pretrain epoch [14/264], ZINB loss:0.3883, NB loss:4.6442, latent MSE loss:0.00061931, KL loss:0.00145220\n",
      "Pretrain epoch [15/264], ZINB loss:0.3935, NB loss:4.6174, latent MSE loss:0.00060255, KL loss:0.00139739\n",
      "Pretrain epoch [16/264], ZINB loss:0.3801, NB loss:4.6604, latent MSE loss:0.00041917, KL loss:0.00132422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [17/264], ZINB loss:0.3741, NB loss:4.5417, latent MSE loss:0.00043075, KL loss:0.00142538\n",
      "Pretrain epoch [18/264], ZINB loss:0.4006, NB loss:4.5865, latent MSE loss:0.00056627, KL loss:0.00179010\n",
      "Pretrain epoch [19/264], ZINB loss:0.3840, NB loss:4.5471, latent MSE loss:0.00042838, KL loss:0.00138214\n",
      "Pretrain epoch [20/264], ZINB loss:0.3995, NB loss:4.5326, latent MSE loss:0.00056683, KL loss:0.00140621\n",
      "Pretrain epoch [21/264], ZINB loss:0.3948, NB loss:4.6100, latent MSE loss:0.00034873, KL loss:0.00149653\n",
      "Pretrain epoch [22/264], ZINB loss:0.3853, NB loss:4.6168, latent MSE loss:0.00035339, KL loss:0.00138974\n",
      "Pretrain epoch [23/264], ZINB loss:0.3880, NB loss:4.6037, latent MSE loss:0.00036844, KL loss:0.00158219\n",
      "Pretrain epoch [24/264], ZINB loss:0.3927, NB loss:4.5855, latent MSE loss:0.00055675, KL loss:0.00153148\n",
      "Pretrain epoch [25/264], ZINB loss:0.4092, NB loss:4.6342, latent MSE loss:0.00041247, KL loss:0.00175626\n",
      "Pretrain epoch [26/264], ZINB loss:0.3892, NB loss:4.5891, latent MSE loss:0.00039108, KL loss:0.00170251\n",
      "Pretrain epoch [27/264], ZINB loss:0.3553, NB loss:4.6577, latent MSE loss:0.00020044, KL loss:0.00005287\n",
      "Pretrain epoch [1/265], ZINB loss:0.3990, NB loss:4.6106, latent MSE loss:0.00047929, KL loss:0.00151265\n",
      "Pretrain epoch [2/265], ZINB loss:0.3867, NB loss:4.6038, latent MSE loss:0.00043956, KL loss:0.00162528\n",
      "Pretrain epoch [3/265], ZINB loss:0.4039, NB loss:4.5732, latent MSE loss:0.00068209, KL loss:0.00159361\n",
      "Pretrain epoch [4/265], ZINB loss:0.3919, NB loss:4.5984, latent MSE loss:0.00056604, KL loss:0.00136609\n",
      "Pretrain epoch [5/265], ZINB loss:0.3917, NB loss:4.6160, latent MSE loss:0.00041945, KL loss:0.00151315\n",
      "Pretrain epoch [6/265], ZINB loss:0.4232, NB loss:4.5953, latent MSE loss:0.00061218, KL loss:0.00159292\n",
      "Pretrain epoch [7/265], ZINB loss:0.3967, NB loss:4.5652, latent MSE loss:0.00045126, KL loss:0.00140229\n",
      "Pretrain epoch [8/265], ZINB loss:0.3976, NB loss:4.6286, latent MSE loss:0.00047822, KL loss:0.00144683\n",
      "Pretrain epoch [9/265], ZINB loss:0.3981, NB loss:4.6432, latent MSE loss:0.00042376, KL loss:0.00202306\n",
      "Pretrain epoch [10/265], ZINB loss:0.3903, NB loss:4.5467, latent MSE loss:0.00046275, KL loss:0.00129183\n",
      "Pretrain epoch [11/265], ZINB loss:0.4018, NB loss:4.6110, latent MSE loss:0.00046721, KL loss:0.00163179\n",
      "Pretrain epoch [12/265], ZINB loss:0.3890, NB loss:4.6048, latent MSE loss:0.00040499, KL loss:0.00197755\n",
      "Pretrain epoch [13/265], ZINB loss:0.4063, NB loss:4.5601, latent MSE loss:0.00037570, KL loss:0.00143926\n",
      "Pretrain epoch [14/265], ZINB loss:0.4148, NB loss:4.6181, latent MSE loss:0.00043631, KL loss:0.00175017\n",
      "Pretrain epoch [15/265], ZINB loss:0.4063, NB loss:4.5842, latent MSE loss:0.00038744, KL loss:0.00163546\n",
      "Pretrain epoch [16/265], ZINB loss:0.3894, NB loss:4.5543, latent MSE loss:0.00039448, KL loss:0.00158887\n",
      "Pretrain epoch [17/265], ZINB loss:0.4040, NB loss:4.5848, latent MSE loss:0.00049316, KL loss:0.00160735\n",
      "Pretrain epoch [18/265], ZINB loss:0.3995, NB loss:4.6329, latent MSE loss:0.00053591, KL loss:0.00153028\n",
      "Pretrain epoch [19/265], ZINB loss:0.3902, NB loss:4.5603, latent MSE loss:0.00035663, KL loss:0.00147714\n",
      "Pretrain epoch [20/265], ZINB loss:0.4046, NB loss:4.5772, latent MSE loss:0.00042958, KL loss:0.00157265\n",
      "Pretrain epoch [21/265], ZINB loss:0.3727, NB loss:4.5411, latent MSE loss:0.00048476, KL loss:0.00145286\n",
      "Pretrain epoch [22/265], ZINB loss:0.3901, NB loss:4.5523, latent MSE loss:0.00048835, KL loss:0.00135745\n",
      "Pretrain epoch [23/265], ZINB loss:0.4094, NB loss:4.5380, latent MSE loss:0.00037586, KL loss:0.00145982\n",
      "Pretrain epoch [24/265], ZINB loss:0.3869, NB loss:4.6581, latent MSE loss:0.00037378, KL loss:0.00150989\n",
      "Pretrain epoch [25/265], ZINB loss:0.4000, NB loss:4.5151, latent MSE loss:0.00062803, KL loss:0.00134902\n",
      "Pretrain epoch [26/265], ZINB loss:0.3782, NB loss:4.5776, latent MSE loss:0.00044374, KL loss:0.00133757\n",
      "Pretrain epoch [27/265], ZINB loss:0.5114, NB loss:4.7353, latent MSE loss:0.00053309, KL loss:0.00007073\n",
      "Pretrain epoch [1/266], ZINB loss:0.3803, NB loss:4.6052, latent MSE loss:0.00160921, KL loss:0.00140375\n",
      "Pretrain epoch [2/266], ZINB loss:0.3851, NB loss:4.5046, latent MSE loss:0.00129245, KL loss:0.00132385\n",
      "Pretrain epoch [3/266], ZINB loss:0.3978, NB loss:4.5716, latent MSE loss:0.00182586, KL loss:0.00145405\n",
      "Pretrain epoch [4/266], ZINB loss:0.3976, NB loss:4.6026, latent MSE loss:0.00211934, KL loss:0.00171304\n",
      "Pretrain epoch [5/266], ZINB loss:0.3985, NB loss:4.5542, latent MSE loss:0.00155996, KL loss:0.00140129\n",
      "Pretrain epoch [6/266], ZINB loss:0.4170, NB loss:4.5775, latent MSE loss:0.00077488, KL loss:0.00156521\n",
      "Pretrain epoch [7/266], ZINB loss:0.3982, NB loss:4.5777, latent MSE loss:0.00082092, KL loss:0.00153856\n",
      "Pretrain epoch [8/266], ZINB loss:0.4088, NB loss:4.6305, latent MSE loss:0.00151832, KL loss:0.00197894\n",
      "Pretrain epoch [9/266], ZINB loss:0.3870, NB loss:4.5307, latent MSE loss:0.00129388, KL loss:0.00133341\n",
      "Pretrain epoch [10/266], ZINB loss:0.3741, NB loss:4.5517, latent MSE loss:0.00074734, KL loss:0.00124886\n",
      "Pretrain epoch [11/266], ZINB loss:0.4033, NB loss:4.6090, latent MSE loss:0.00059201, KL loss:0.00135630\n",
      "Pretrain epoch [12/266], ZINB loss:0.3863, NB loss:4.5885, latent MSE loss:0.00085074, KL loss:0.00141790\n",
      "Pretrain epoch [13/266], ZINB loss:0.3768, NB loss:4.5911, latent MSE loss:0.00073092, KL loss:0.00144725\n",
      "Pretrain epoch [14/266], ZINB loss:0.3913, NB loss:4.6097, latent MSE loss:0.00063682, KL loss:0.00155800\n",
      "Pretrain epoch [15/266], ZINB loss:0.3996, NB loss:4.6387, latent MSE loss:0.00078716, KL loss:0.00143525\n",
      "Pretrain epoch [16/266], ZINB loss:0.4039, NB loss:4.6014, latent MSE loss:0.00055820, KL loss:0.00189706\n",
      "Pretrain epoch [17/266], ZINB loss:0.4058, NB loss:4.5610, latent MSE loss:0.00039006, KL loss:0.00140176\n",
      "Pretrain epoch [18/266], ZINB loss:0.3968, NB loss:4.6400, latent MSE loss:0.00048072, KL loss:0.00129465\n",
      "Pretrain epoch [19/266], ZINB loss:0.3938, NB loss:4.5647, latent MSE loss:0.00047939, KL loss:0.00131188\n",
      "Pretrain epoch [20/266], ZINB loss:0.4061, NB loss:4.6697, latent MSE loss:0.00057001, KL loss:0.00192040\n",
      "Pretrain epoch [21/266], ZINB loss:0.4085, NB loss:4.5943, latent MSE loss:0.00046723, KL loss:0.00178396\n",
      "Pretrain epoch [22/266], ZINB loss:0.4128, NB loss:4.5530, latent MSE loss:0.00040348, KL loss:0.00142690\n",
      "Pretrain epoch [23/266], ZINB loss:0.4014, NB loss:4.5562, latent MSE loss:0.00028626, KL loss:0.00146610\n",
      "Pretrain epoch [24/266], ZINB loss:0.4111, NB loss:4.5543, latent MSE loss:0.00039948, KL loss:0.00153059\n",
      "Pretrain epoch [25/266], ZINB loss:0.4058, NB loss:4.6107, latent MSE loss:0.00049022, KL loss:0.00195468\n",
      "Pretrain epoch [26/266], ZINB loss:0.3784, NB loss:4.5635, latent MSE loss:0.00035004, KL loss:0.00152078\n",
      "Pretrain epoch [27/266], ZINB loss:0.3155, NB loss:4.3846, latent MSE loss:0.00027289, KL loss:0.00007005\n",
      "Pretrain epoch [1/267], ZINB loss:0.3995, NB loss:4.5551, latent MSE loss:0.00038389, KL loss:0.00161985\n",
      "Pretrain epoch [2/267], ZINB loss:0.3997, NB loss:4.5831, latent MSE loss:0.00034384, KL loss:0.00134695\n",
      "Pretrain epoch [3/267], ZINB loss:0.4151, NB loss:4.6354, latent MSE loss:0.00046857, KL loss:0.00176907\n",
      "Pretrain epoch [4/267], ZINB loss:0.3995, NB loss:4.5920, latent MSE loss:0.00037368, KL loss:0.00150056\n",
      "Pretrain epoch [5/267], ZINB loss:0.3847, NB loss:4.5385, latent MSE loss:0.00028423, KL loss:0.00148820\n",
      "Pretrain epoch [6/267], ZINB loss:0.4060, NB loss:4.5440, latent MSE loss:0.00040565, KL loss:0.00136856\n",
      "Pretrain epoch [7/267], ZINB loss:0.4020, NB loss:4.5952, latent MSE loss:0.00045198, KL loss:0.00152427\n",
      "Pretrain epoch [8/267], ZINB loss:0.3970, NB loss:4.5565, latent MSE loss:0.00031063, KL loss:0.00138649\n",
      "Pretrain epoch [9/267], ZINB loss:0.3855, NB loss:4.6688, latent MSE loss:0.00037198, KL loss:0.00135298\n",
      "Pretrain epoch [10/267], ZINB loss:0.4033, NB loss:4.5583, latent MSE loss:0.00038370, KL loss:0.00121877\n",
      "Pretrain epoch [11/267], ZINB loss:0.3940, NB loss:4.5991, latent MSE loss:0.00030891, KL loss:0.00122251\n",
      "Pretrain epoch [12/267], ZINB loss:0.3906, NB loss:4.6468, latent MSE loss:0.00033708, KL loss:0.00196235\n",
      "Pretrain epoch [13/267], ZINB loss:0.3805, NB loss:4.5299, latent MSE loss:0.00031174, KL loss:0.00130509\n",
      "Pretrain epoch [14/267], ZINB loss:0.4024, NB loss:4.5931, latent MSE loss:0.00028905, KL loss:0.00136674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [15/267], ZINB loss:0.3968, NB loss:4.5456, latent MSE loss:0.00028410, KL loss:0.00141977\n",
      "Pretrain epoch [16/267], ZINB loss:0.3998, NB loss:4.5799, latent MSE loss:0.00030030, KL loss:0.00131187\n",
      "Pretrain epoch [17/267], ZINB loss:0.3787, NB loss:4.5353, latent MSE loss:0.00033248, KL loss:0.00143627\n",
      "Pretrain epoch [18/267], ZINB loss:0.3903, NB loss:4.5674, latent MSE loss:0.00023077, KL loss:0.00132763\n",
      "Pretrain epoch [19/267], ZINB loss:0.4081, NB loss:4.6173, latent MSE loss:0.00027097, KL loss:0.00160087\n",
      "Pretrain epoch [20/267], ZINB loss:0.4086, NB loss:4.6491, latent MSE loss:0.00040320, KL loss:0.00164528\n",
      "Pretrain epoch [21/267], ZINB loss:0.4015, NB loss:4.5698, latent MSE loss:0.00024716, KL loss:0.00142796\n",
      "Pretrain epoch [22/267], ZINB loss:0.3924, NB loss:4.5521, latent MSE loss:0.00020988, KL loss:0.00129185\n",
      "Pretrain epoch [23/267], ZINB loss:0.3895, NB loss:4.5104, latent MSE loss:0.00021754, KL loss:0.00135413\n",
      "Pretrain epoch [24/267], ZINB loss:0.4034, NB loss:4.5935, latent MSE loss:0.00026741, KL loss:0.00135472\n",
      "Pretrain epoch [25/267], ZINB loss:0.3888, NB loss:4.6251, latent MSE loss:0.00022770, KL loss:0.00145674\n",
      "Pretrain epoch [26/267], ZINB loss:0.3981, NB loss:4.6080, latent MSE loss:0.00025337, KL loss:0.00153472\n",
      "Pretrain epoch [27/267], ZINB loss:0.4200, NB loss:4.5513, latent MSE loss:0.00041555, KL loss:0.00004542\n",
      "Pretrain epoch [1/268], ZINB loss:0.4070, NB loss:4.6235, latent MSE loss:0.00050879, KL loss:0.00153842\n",
      "Pretrain epoch [2/268], ZINB loss:0.3984, NB loss:4.5605, latent MSE loss:0.00029615, KL loss:0.00126506\n",
      "Pretrain epoch [3/268], ZINB loss:0.3984, NB loss:4.6027, latent MSE loss:0.00036518, KL loss:0.00137144\n",
      "Pretrain epoch [4/268], ZINB loss:0.3966, NB loss:4.5812, latent MSE loss:0.00035324, KL loss:0.00113722\n",
      "Pretrain epoch [5/268], ZINB loss:0.4064, NB loss:4.5837, latent MSE loss:0.00037166, KL loss:0.00195430\n",
      "Pretrain epoch [6/268], ZINB loss:0.4006, NB loss:4.4955, latent MSE loss:0.00032327, KL loss:0.00115208\n",
      "Pretrain epoch [7/268], ZINB loss:0.3970, NB loss:4.5560, latent MSE loss:0.00030504, KL loss:0.00129567\n",
      "Pretrain epoch [8/268], ZINB loss:0.4131, NB loss:4.5567, latent MSE loss:0.00052648, KL loss:0.00132397\n",
      "Pretrain epoch [9/268], ZINB loss:0.3852, NB loss:4.6054, latent MSE loss:0.00031946, KL loss:0.00144970\n",
      "Pretrain epoch [10/268], ZINB loss:0.4036, NB loss:4.6014, latent MSE loss:0.00047021, KL loss:0.00162999\n",
      "Pretrain epoch [11/268], ZINB loss:0.3987, NB loss:4.6125, latent MSE loss:0.00029928, KL loss:0.00150751\n",
      "Pretrain epoch [12/268], ZINB loss:0.4157, NB loss:4.5809, latent MSE loss:0.00041516, KL loss:0.00164473\n",
      "Pretrain epoch [13/268], ZINB loss:0.3864, NB loss:4.5901, latent MSE loss:0.00030478, KL loss:0.00117299\n",
      "Pretrain epoch [14/268], ZINB loss:0.3801, NB loss:4.5929, latent MSE loss:0.00042868, KL loss:0.00132735\n",
      "Pretrain epoch [15/268], ZINB loss:0.4018, NB loss:4.5474, latent MSE loss:0.00033091, KL loss:0.00131611\n",
      "Pretrain epoch [16/268], ZINB loss:0.3818, NB loss:4.5373, latent MSE loss:0.00038138, KL loss:0.00136639\n",
      "Pretrain epoch [17/268], ZINB loss:0.3940, NB loss:4.5216, latent MSE loss:0.00031054, KL loss:0.00126201\n",
      "Pretrain epoch [18/268], ZINB loss:0.3971, NB loss:4.5329, latent MSE loss:0.00028704, KL loss:0.00134195\n",
      "Pretrain epoch [19/268], ZINB loss:0.3731, NB loss:4.5689, latent MSE loss:0.00032632, KL loss:0.00115172\n",
      "Pretrain epoch [20/268], ZINB loss:0.3942, NB loss:4.6591, latent MSE loss:0.00035075, KL loss:0.00190118\n",
      "Pretrain epoch [21/268], ZINB loss:0.3895, NB loss:4.5838, latent MSE loss:0.00026907, KL loss:0.00146442\n",
      "Pretrain epoch [22/268], ZINB loss:0.3935, NB loss:4.6834, latent MSE loss:0.00026638, KL loss:0.00162419\n",
      "Pretrain epoch [23/268], ZINB loss:0.4093, NB loss:4.5229, latent MSE loss:0.00035287, KL loss:0.00170444\n",
      "Pretrain epoch [24/268], ZINB loss:0.3996, NB loss:4.5805, latent MSE loss:0.00030241, KL loss:0.00184145\n",
      "Pretrain epoch [25/268], ZINB loss:0.3951, NB loss:4.5870, latent MSE loss:0.00025582, KL loss:0.00143431\n",
      "Pretrain epoch [26/268], ZINB loss:0.3972, NB loss:4.6350, latent MSE loss:0.00027950, KL loss:0.00163233\n",
      "Pretrain epoch [27/268], ZINB loss:0.4576, NB loss:4.6193, latent MSE loss:0.00056750, KL loss:0.00005956\n",
      "Pretrain epoch [1/269], ZINB loss:0.4020, NB loss:4.5204, latent MSE loss:0.00067443, KL loss:0.00126633\n",
      "Pretrain epoch [2/269], ZINB loss:0.3910, NB loss:4.5842, latent MSE loss:0.00093222, KL loss:0.00141499\n",
      "Pretrain epoch [3/269], ZINB loss:0.3758, NB loss:4.5891, latent MSE loss:0.00110878, KL loss:0.00171655\n",
      "Pretrain epoch [4/269], ZINB loss:0.3759, NB loss:4.5747, latent MSE loss:0.00103083, KL loss:0.00111897\n",
      "Pretrain epoch [5/269], ZINB loss:0.4024, NB loss:4.6077, latent MSE loss:0.00077865, KL loss:0.00154698\n",
      "Pretrain epoch [6/269], ZINB loss:0.3887, NB loss:4.5134, latent MSE loss:0.00057300, KL loss:0.00135920\n",
      "Pretrain epoch [7/269], ZINB loss:0.4172, NB loss:4.6140, latent MSE loss:0.00096784, KL loss:0.00216396\n",
      "Pretrain epoch [8/269], ZINB loss:0.3942, NB loss:4.5488, latent MSE loss:0.00118354, KL loss:0.00128852\n",
      "Pretrain epoch [9/269], ZINB loss:0.4023, NB loss:4.6157, latent MSE loss:0.00110367, KL loss:0.00157819\n",
      "Pretrain epoch [10/269], ZINB loss:0.3931, NB loss:4.6152, latent MSE loss:0.00054228, KL loss:0.00155948\n",
      "Pretrain epoch [11/269], ZINB loss:0.3872, NB loss:4.5830, latent MSE loss:0.00094909, KL loss:0.00126385\n",
      "Pretrain epoch [12/269], ZINB loss:0.3961, NB loss:4.6238, latent MSE loss:0.00147306, KL loss:0.00143158\n",
      "Pretrain epoch [13/269], ZINB loss:0.3842, NB loss:4.5983, latent MSE loss:0.00077589, KL loss:0.00116689\n",
      "Pretrain epoch [14/269], ZINB loss:0.4044, NB loss:4.5507, latent MSE loss:0.00047681, KL loss:0.00138802\n",
      "Pretrain epoch [15/269], ZINB loss:0.3969, NB loss:4.5079, latent MSE loss:0.00073904, KL loss:0.00126810\n",
      "Pretrain epoch [16/269], ZINB loss:0.3983, NB loss:4.6746, latent MSE loss:0.00059246, KL loss:0.00160392\n",
      "Pretrain epoch [17/269], ZINB loss:0.4187, NB loss:4.5996, latent MSE loss:0.00042104, KL loss:0.00178643\n",
      "Pretrain epoch [18/269], ZINB loss:0.3830, NB loss:4.5566, latent MSE loss:0.00051851, KL loss:0.00140425\n",
      "Pretrain epoch [19/269], ZINB loss:0.3892, NB loss:4.5920, latent MSE loss:0.00069776, KL loss:0.00155087\n",
      "Pretrain epoch [20/269], ZINB loss:0.3931, NB loss:4.5861, latent MSE loss:0.00033226, KL loss:0.00128832\n",
      "Pretrain epoch [21/269], ZINB loss:0.3934, NB loss:4.6090, latent MSE loss:0.00050367, KL loss:0.00144201\n",
      "Pretrain epoch [22/269], ZINB loss:0.4002, NB loss:4.5536, latent MSE loss:0.00050530, KL loss:0.00114738\n",
      "Pretrain epoch [23/269], ZINB loss:0.4250, NB loss:4.5638, latent MSE loss:0.00049683, KL loss:0.00165518\n",
      "Pretrain epoch [24/269], ZINB loss:0.4089, NB loss:4.5586, latent MSE loss:0.00039163, KL loss:0.00165317\n",
      "Pretrain epoch [25/269], ZINB loss:0.4000, NB loss:4.5912, latent MSE loss:0.00047745, KL loss:0.00160963\n",
      "Pretrain epoch [26/269], ZINB loss:0.3994, NB loss:4.5333, latent MSE loss:0.00027646, KL loss:0.00136754\n",
      "Pretrain epoch [27/269], ZINB loss:0.3433, NB loss:4.6372, latent MSE loss:0.00020650, KL loss:0.00007024\n",
      "Pretrain epoch [1/270], ZINB loss:0.4011, NB loss:4.6368, latent MSE loss:0.00099110, KL loss:0.00133119\n",
      "Pretrain epoch [2/270], ZINB loss:0.3836, NB loss:4.5711, latent MSE loss:0.00042193, KL loss:0.00126223\n",
      "Pretrain epoch [3/270], ZINB loss:0.3971, NB loss:4.6079, latent MSE loss:0.00074159, KL loss:0.00127687\n",
      "Pretrain epoch [4/270], ZINB loss:0.3983, NB loss:4.6427, latent MSE loss:0.00040397, KL loss:0.00142786\n",
      "Pretrain epoch [5/270], ZINB loss:0.4029, NB loss:4.5668, latent MSE loss:0.00061234, KL loss:0.00141527\n",
      "Pretrain epoch [6/270], ZINB loss:0.3897, NB loss:4.5682, latent MSE loss:0.00041952, KL loss:0.00161809\n",
      "Pretrain epoch [7/270], ZINB loss:0.3916, NB loss:4.5421, latent MSE loss:0.00057971, KL loss:0.00121761\n",
      "Pretrain epoch [8/270], ZINB loss:0.3856, NB loss:4.6496, latent MSE loss:0.00035899, KL loss:0.00162643\n",
      "Pretrain epoch [9/270], ZINB loss:0.3997, NB loss:4.6456, latent MSE loss:0.00053848, KL loss:0.00155374\n",
      "Pretrain epoch [10/270], ZINB loss:0.3990, NB loss:4.5069, latent MSE loss:0.00042519, KL loss:0.00124553\n",
      "Pretrain epoch [11/270], ZINB loss:0.4027, NB loss:4.5213, latent MSE loss:0.00037853, KL loss:0.00135714\n",
      "Pretrain epoch [12/270], ZINB loss:0.3883, NB loss:4.5879, latent MSE loss:0.00037288, KL loss:0.00126451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [13/270], ZINB loss:0.3962, NB loss:4.5728, latent MSE loss:0.00035405, KL loss:0.00143530\n",
      "Pretrain epoch [14/270], ZINB loss:0.3894, NB loss:4.6126, latent MSE loss:0.00043026, KL loss:0.00129498\n",
      "Pretrain epoch [15/270], ZINB loss:0.3954, NB loss:4.6059, latent MSE loss:0.00035906, KL loss:0.00138098\n",
      "Pretrain epoch [16/270], ZINB loss:0.3919, NB loss:4.5534, latent MSE loss:0.00032927, KL loss:0.00126658\n",
      "Pretrain epoch [17/270], ZINB loss:0.3849, NB loss:4.5578, latent MSE loss:0.00026165, KL loss:0.00166583\n",
      "Pretrain epoch [18/270], ZINB loss:0.4083, NB loss:4.6171, latent MSE loss:0.00042926, KL loss:0.00201169\n",
      "Pretrain epoch [19/270], ZINB loss:0.4116, NB loss:4.5557, latent MSE loss:0.00047619, KL loss:0.00198816\n",
      "Pretrain epoch [20/270], ZINB loss:0.4090, NB loss:4.5338, latent MSE loss:0.00025422, KL loss:0.00155108\n",
      "Pretrain epoch [21/270], ZINB loss:0.3955, NB loss:4.6099, latent MSE loss:0.00030634, KL loss:0.00144380\n",
      "Pretrain epoch [22/270], ZINB loss:0.4051, NB loss:4.5593, latent MSE loss:0.00028077, KL loss:0.00191033\n",
      "Pretrain epoch [23/270], ZINB loss:0.3832, NB loss:4.5774, latent MSE loss:0.00026734, KL loss:0.00120936\n",
      "Pretrain epoch [24/270], ZINB loss:0.4016, NB loss:4.5838, latent MSE loss:0.00036229, KL loss:0.00122292\n",
      "Pretrain epoch [25/270], ZINB loss:0.3899, NB loss:4.4978, latent MSE loss:0.00027389, KL loss:0.00119459\n",
      "Pretrain epoch [26/270], ZINB loss:0.4042, NB loss:4.5397, latent MSE loss:0.00021217, KL loss:0.00120709\n",
      "Pretrain epoch [27/270], ZINB loss:0.5550, NB loss:4.2225, latent MSE loss:0.00022458, KL loss:0.00000267\n",
      "Pretrain epoch [1/271], ZINB loss:0.3860, NB loss:4.6033, latent MSE loss:0.00070841, KL loss:0.00127795\n",
      "Pretrain epoch [2/271], ZINB loss:0.3823, NB loss:4.5747, latent MSE loss:0.00060220, KL loss:0.00123107\n",
      "Pretrain epoch [3/271], ZINB loss:0.3917, NB loss:4.5713, latent MSE loss:0.00067571, KL loss:0.00119805\n",
      "Pretrain epoch [4/271], ZINB loss:0.4018, NB loss:4.5187, latent MSE loss:0.00054830, KL loss:0.00124429\n",
      "Pretrain epoch [5/271], ZINB loss:0.4071, NB loss:4.5876, latent MSE loss:0.00049529, KL loss:0.00134314\n",
      "Pretrain epoch [6/271], ZINB loss:0.4058, NB loss:4.5982, latent MSE loss:0.00049762, KL loss:0.00163654\n",
      "Pretrain epoch [7/271], ZINB loss:0.3864, NB loss:4.6190, latent MSE loss:0.00047721, KL loss:0.00168842\n",
      "Pretrain epoch [8/271], ZINB loss:0.3849, NB loss:4.5771, latent MSE loss:0.00058972, KL loss:0.00184316\n",
      "Pretrain epoch [9/271], ZINB loss:0.3993, NB loss:4.5895, latent MSE loss:0.00047962, KL loss:0.00113165\n",
      "Pretrain epoch [10/271], ZINB loss:0.4134, NB loss:4.5458, latent MSE loss:0.00061855, KL loss:0.00146257\n",
      "Pretrain epoch [11/271], ZINB loss:0.4079, NB loss:4.5483, latent MSE loss:0.00039422, KL loss:0.00116206\n",
      "Pretrain epoch [12/271], ZINB loss:0.4082, NB loss:4.5886, latent MSE loss:0.00045263, KL loss:0.00143604\n",
      "Pretrain epoch [13/271], ZINB loss:0.3981, NB loss:4.5903, latent MSE loss:0.00039418, KL loss:0.00127021\n",
      "Pretrain epoch [14/271], ZINB loss:0.3927, NB loss:4.5528, latent MSE loss:0.00051760, KL loss:0.00122084\n",
      "Pretrain epoch [15/271], ZINB loss:0.3975, NB loss:4.5519, latent MSE loss:0.00036035, KL loss:0.00138132\n",
      "Pretrain epoch [16/271], ZINB loss:0.3932, NB loss:4.6010, latent MSE loss:0.00043593, KL loss:0.00151839\n",
      "Pretrain epoch [17/271], ZINB loss:0.3833, NB loss:4.5561, latent MSE loss:0.00035818, KL loss:0.00117786\n",
      "Pretrain epoch [18/271], ZINB loss:0.3811, NB loss:4.6254, latent MSE loss:0.00039932, KL loss:0.00140723\n",
      "Pretrain epoch [19/271], ZINB loss:0.3889, NB loss:4.6021, latent MSE loss:0.00032066, KL loss:0.00140952\n",
      "Pretrain epoch [20/271], ZINB loss:0.3995, NB loss:4.5732, latent MSE loss:0.00035756, KL loss:0.00132814\n",
      "Pretrain epoch [21/271], ZINB loss:0.4173, NB loss:4.6093, latent MSE loss:0.00055291, KL loss:0.00158700\n",
      "Pretrain epoch [22/271], ZINB loss:0.3969, NB loss:4.5380, latent MSE loss:0.00031458, KL loss:0.00127903\n",
      "Pretrain epoch [23/271], ZINB loss:0.3949, NB loss:4.5442, latent MSE loss:0.00030780, KL loss:0.00161319\n",
      "Pretrain epoch [24/271], ZINB loss:0.3988, NB loss:4.6316, latent MSE loss:0.00036880, KL loss:0.00148937\n",
      "Pretrain epoch [25/271], ZINB loss:0.3925, NB loss:4.5235, latent MSE loss:0.00025133, KL loss:0.00125367\n",
      "Pretrain epoch [26/271], ZINB loss:0.4065, NB loss:4.5658, latent MSE loss:0.00028952, KL loss:0.00138972\n",
      "Pretrain epoch [27/271], ZINB loss:0.3411, NB loss:4.3237, latent MSE loss:0.00021692, KL loss:0.00000694\n",
      "Pretrain epoch [1/272], ZINB loss:0.4008, NB loss:4.5600, latent MSE loss:0.00245750, KL loss:0.00116271\n",
      "Pretrain epoch [2/272], ZINB loss:0.4118, NB loss:4.5995, latent MSE loss:0.00084914, KL loss:0.00138000\n",
      "Pretrain epoch [3/272], ZINB loss:0.3989, NB loss:4.5539, latent MSE loss:0.00171138, KL loss:0.00116407\n",
      "Pretrain epoch [4/272], ZINB loss:0.3828, NB loss:4.5286, latent MSE loss:0.00127219, KL loss:0.00117831\n",
      "Pretrain epoch [5/272], ZINB loss:0.3832, NB loss:4.6745, latent MSE loss:0.00092510, KL loss:0.00170804\n",
      "Pretrain epoch [6/272], ZINB loss:0.4069, NB loss:4.6418, latent MSE loss:0.00085772, KL loss:0.00145289\n",
      "Pretrain epoch [7/272], ZINB loss:0.3898, NB loss:4.5631, latent MSE loss:0.00082814, KL loss:0.00131675\n",
      "Pretrain epoch [8/272], ZINB loss:0.3986, NB loss:4.5476, latent MSE loss:0.00086916, KL loss:0.00127576\n",
      "Pretrain epoch [9/272], ZINB loss:0.4021, NB loss:4.4971, latent MSE loss:0.00075940, KL loss:0.00132704\n",
      "Pretrain epoch [10/272], ZINB loss:0.3968, NB loss:4.6151, latent MSE loss:0.00062539, KL loss:0.00126616\n",
      "Pretrain epoch [11/272], ZINB loss:0.3830, NB loss:4.5623, latent MSE loss:0.00083684, KL loss:0.00119720\n",
      "Pretrain epoch [12/272], ZINB loss:0.4142, NB loss:4.5255, latent MSE loss:0.00093944, KL loss:0.00144213\n",
      "Pretrain epoch [13/272], ZINB loss:0.4040, NB loss:4.5753, latent MSE loss:0.00076998, KL loss:0.00128243\n",
      "Pretrain epoch [14/272], ZINB loss:0.3847, NB loss:4.5285, latent MSE loss:0.00079056, KL loss:0.00144315\n",
      "Pretrain epoch [15/272], ZINB loss:0.3915, NB loss:4.6505, latent MSE loss:0.00068650, KL loss:0.00129316\n",
      "Pretrain epoch [16/272], ZINB loss:0.3873, NB loss:4.5598, latent MSE loss:0.00065818, KL loss:0.00127242\n",
      "Pretrain epoch [17/272], ZINB loss:0.4093, NB loss:4.5780, latent MSE loss:0.00054623, KL loss:0.00153524\n",
      "Pretrain epoch [18/272], ZINB loss:0.4061, NB loss:4.6208, latent MSE loss:0.00068794, KL loss:0.00159514\n",
      "Pretrain epoch [19/272], ZINB loss:0.3938, NB loss:4.6100, latent MSE loss:0.00048933, KL loss:0.00126450\n",
      "Pretrain epoch [20/272], ZINB loss:0.4060, NB loss:4.5571, latent MSE loss:0.00071429, KL loss:0.00134643\n",
      "Pretrain epoch [21/272], ZINB loss:0.4002, NB loss:4.5884, latent MSE loss:0.00042608, KL loss:0.00133030\n",
      "Pretrain epoch [22/272], ZINB loss:0.3858, NB loss:4.5581, latent MSE loss:0.00049408, KL loss:0.00165875\n",
      "Pretrain epoch [23/272], ZINB loss:0.4045, NB loss:4.5501, latent MSE loss:0.00049362, KL loss:0.00119531\n",
      "Pretrain epoch [24/272], ZINB loss:0.3908, NB loss:4.5354, latent MSE loss:0.00043790, KL loss:0.00158503\n",
      "Pretrain epoch [25/272], ZINB loss:0.4023, NB loss:4.5810, latent MSE loss:0.00043756, KL loss:0.00142864\n",
      "Pretrain epoch [26/272], ZINB loss:0.3805, NB loss:4.5759, latent MSE loss:0.00040318, KL loss:0.00126781\n",
      "Pretrain epoch [27/272], ZINB loss:0.4123, NB loss:4.8893, latent MSE loss:0.00029021, KL loss:0.00001046\n",
      "Pretrain epoch [1/273], ZINB loss:0.3993, NB loss:4.6170, latent MSE loss:0.00059408, KL loss:0.00133915\n",
      "Pretrain epoch [2/273], ZINB loss:0.3932, NB loss:4.5731, latent MSE loss:0.00056883, KL loss:0.00136498\n",
      "Pretrain epoch [3/273], ZINB loss:0.3968, NB loss:4.6658, latent MSE loss:0.00053242, KL loss:0.00176515\n",
      "Pretrain epoch [4/273], ZINB loss:0.3978, NB loss:4.5956, latent MSE loss:0.00048137, KL loss:0.00149921\n",
      "Pretrain epoch [5/273], ZINB loss:0.3861, NB loss:4.6328, latent MSE loss:0.00045830, KL loss:0.00194465\n",
      "Pretrain epoch [6/273], ZINB loss:0.4112, NB loss:4.5586, latent MSE loss:0.00063046, KL loss:0.00135898\n",
      "Pretrain epoch [7/273], ZINB loss:0.3925, NB loss:4.5911, latent MSE loss:0.00051306, KL loss:0.00132700\n",
      "Pretrain epoch [8/273], ZINB loss:0.3912, NB loss:4.5587, latent MSE loss:0.00041449, KL loss:0.00141918\n",
      "Pretrain epoch [9/273], ZINB loss:0.3861, NB loss:4.5969, latent MSE loss:0.00046419, KL loss:0.00168420\n",
      "Pretrain epoch [10/273], ZINB loss:0.4065, NB loss:4.5527, latent MSE loss:0.00044059, KL loss:0.00117837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [11/273], ZINB loss:0.4034, NB loss:4.5485, latent MSE loss:0.00048553, KL loss:0.00179672\n",
      "Pretrain epoch [12/273], ZINB loss:0.4000, NB loss:4.5243, latent MSE loss:0.00040985, KL loss:0.00148213\n",
      "Pretrain epoch [13/273], ZINB loss:0.3927, NB loss:4.6179, latent MSE loss:0.00042626, KL loss:0.00136428\n",
      "Pretrain epoch [14/273], ZINB loss:0.4041, NB loss:4.5063, latent MSE loss:0.00037806, KL loss:0.00108065\n",
      "Pretrain epoch [15/273], ZINB loss:0.3727, NB loss:4.6303, latent MSE loss:0.00033322, KL loss:0.00152365\n",
      "Pretrain epoch [16/273], ZINB loss:0.3912, NB loss:4.6057, latent MSE loss:0.00039414, KL loss:0.00154065\n",
      "Pretrain epoch [17/273], ZINB loss:0.4141, NB loss:4.5134, latent MSE loss:0.00042635, KL loss:0.00141753\n",
      "Pretrain epoch [18/273], ZINB loss:0.4097, NB loss:4.5777, latent MSE loss:0.00037102, KL loss:0.00135731\n",
      "Pretrain epoch [19/273], ZINB loss:0.3750, NB loss:4.5794, latent MSE loss:0.00033826, KL loss:0.00126971\n",
      "Pretrain epoch [20/273], ZINB loss:0.4047, NB loss:4.5393, latent MSE loss:0.00028737, KL loss:0.00125610\n",
      "Pretrain epoch [21/273], ZINB loss:0.3801, NB loss:4.5819, latent MSE loss:0.00032665, KL loss:0.00125123\n",
      "Pretrain epoch [22/273], ZINB loss:0.4163, NB loss:4.4986, latent MSE loss:0.00031867, KL loss:0.00126764\n",
      "Pretrain epoch [23/273], ZINB loss:0.3927, NB loss:4.5794, latent MSE loss:0.00033503, KL loss:0.00124440\n",
      "Pretrain epoch [24/273], ZINB loss:0.3973, NB loss:4.5168, latent MSE loss:0.00022473, KL loss:0.00110967\n",
      "Pretrain epoch [25/273], ZINB loss:0.4060, NB loss:4.5894, latent MSE loss:0.00037842, KL loss:0.00140643\n",
      "Pretrain epoch [26/273], ZINB loss:0.3866, NB loss:4.5466, latent MSE loss:0.00024129, KL loss:0.00132270\n",
      "Pretrain epoch [27/273], ZINB loss:0.3277, NB loss:4.7911, latent MSE loss:0.00021595, KL loss:0.00005045\n",
      "Pretrain epoch [1/274], ZINB loss:0.3982, NB loss:4.5786, latent MSE loss:0.00056677, KL loss:0.00125002\n",
      "Pretrain epoch [2/274], ZINB loss:0.4148, NB loss:4.5723, latent MSE loss:0.00049717, KL loss:0.00124912\n",
      "Pretrain epoch [3/274], ZINB loss:0.4044, NB loss:4.5536, latent MSE loss:0.00042259, KL loss:0.00115371\n",
      "Pretrain epoch [4/274], ZINB loss:0.4034, NB loss:4.6064, latent MSE loss:0.00049504, KL loss:0.00130796\n",
      "Pretrain epoch [5/274], ZINB loss:0.4149, NB loss:4.5465, latent MSE loss:0.00043629, KL loss:0.00164102\n",
      "Pretrain epoch [6/274], ZINB loss:0.3779, NB loss:4.6238, latent MSE loss:0.00042834, KL loss:0.00124941\n",
      "Pretrain epoch [7/274], ZINB loss:0.3882, NB loss:4.5377, latent MSE loss:0.00036932, KL loss:0.00150507\n",
      "Pretrain epoch [8/274], ZINB loss:0.4033, NB loss:4.5403, latent MSE loss:0.00045135, KL loss:0.00143657\n",
      "Pretrain epoch [9/274], ZINB loss:0.4066, NB loss:4.5898, latent MSE loss:0.00033298, KL loss:0.00135084\n",
      "Pretrain epoch [10/274], ZINB loss:0.3803, NB loss:4.5628, latent MSE loss:0.00033006, KL loss:0.00116671\n",
      "Pretrain epoch [11/274], ZINB loss:0.4009, NB loss:4.5588, latent MSE loss:0.00030916, KL loss:0.00127324\n",
      "Pretrain epoch [12/274], ZINB loss:0.3906, NB loss:4.5448, latent MSE loss:0.00035394, KL loss:0.00115765\n",
      "Pretrain epoch [13/274], ZINB loss:0.4050, NB loss:4.6364, latent MSE loss:0.00033253, KL loss:0.00139849\n",
      "Pretrain epoch [14/274], ZINB loss:0.4144, NB loss:4.5353, latent MSE loss:0.00043601, KL loss:0.00160091\n",
      "Pretrain epoch [15/274], ZINB loss:0.3712, NB loss:4.5330, latent MSE loss:0.00023427, KL loss:0.00111539\n",
      "Pretrain epoch [16/274], ZINB loss:0.4122, NB loss:4.6323, latent MSE loss:0.00037140, KL loss:0.00129979\n",
      "Pretrain epoch [17/274], ZINB loss:0.3912, NB loss:4.5775, latent MSE loss:0.00034952, KL loss:0.00121973\n",
      "Pretrain epoch [18/274], ZINB loss:0.3840, NB loss:4.5744, latent MSE loss:0.00026993, KL loss:0.00141118\n",
      "Pretrain epoch [19/274], ZINB loss:0.4003, NB loss:4.5036, latent MSE loss:0.00029105, KL loss:0.00141168\n",
      "Pretrain epoch [20/274], ZINB loss:0.4005, NB loss:4.6354, latent MSE loss:0.00031151, KL loss:0.00125245\n",
      "Pretrain epoch [21/274], ZINB loss:0.3959, NB loss:4.5796, latent MSE loss:0.00026951, KL loss:0.00116278\n",
      "Pretrain epoch [22/274], ZINB loss:0.3910, NB loss:4.5791, latent MSE loss:0.00024618, KL loss:0.00134030\n",
      "Pretrain epoch [23/274], ZINB loss:0.4086, NB loss:4.6083, latent MSE loss:0.00026270, KL loss:0.00118874\n",
      "Pretrain epoch [24/274], ZINB loss:0.3906, NB loss:4.5852, latent MSE loss:0.00033116, KL loss:0.00186179\n",
      "Pretrain epoch [25/274], ZINB loss:0.3897, NB loss:4.5273, latent MSE loss:0.00023864, KL loss:0.00130643\n",
      "Pretrain epoch [26/274], ZINB loss:0.3684, NB loss:4.5414, latent MSE loss:0.00020258, KL loss:0.00102491\n",
      "Pretrain epoch [27/274], ZINB loss:0.3950, NB loss:4.2107, latent MSE loss:0.00026511, KL loss:0.00004428\n",
      "Pretrain epoch [1/275], ZINB loss:0.3919, NB loss:4.5851, latent MSE loss:0.00040081, KL loss:0.00145502\n",
      "Pretrain epoch [2/275], ZINB loss:0.3996, NB loss:4.5303, latent MSE loss:0.00041537, KL loss:0.00116002\n",
      "Pretrain epoch [3/275], ZINB loss:0.4080, NB loss:4.5384, latent MSE loss:0.00038787, KL loss:0.00127438\n",
      "Pretrain epoch [4/275], ZINB loss:0.3969, NB loss:4.5619, latent MSE loss:0.00038282, KL loss:0.00133824\n",
      "Pretrain epoch [5/275], ZINB loss:0.3925, NB loss:4.5212, latent MSE loss:0.00043419, KL loss:0.00137299\n",
      "Pretrain epoch [6/275], ZINB loss:0.4174, NB loss:4.5117, latent MSE loss:0.00055026, KL loss:0.00159180\n",
      "Pretrain epoch [7/275], ZINB loss:0.3953, NB loss:4.6172, latent MSE loss:0.00048258, KL loss:0.00189794\n",
      "Pretrain epoch [8/275], ZINB loss:0.4171, NB loss:4.5307, latent MSE loss:0.00056476, KL loss:0.00187078\n",
      "Pretrain epoch [9/275], ZINB loss:0.3842, NB loss:4.5532, latent MSE loss:0.00041920, KL loss:0.00109640\n",
      "Pretrain epoch [10/275], ZINB loss:0.3907, NB loss:4.5791, latent MSE loss:0.00052140, KL loss:0.00128823\n",
      "Pretrain epoch [11/275], ZINB loss:0.3918, NB loss:4.5334, latent MSE loss:0.00044935, KL loss:0.00106283\n",
      "Pretrain epoch [12/275], ZINB loss:0.3908, NB loss:4.5491, latent MSE loss:0.00042595, KL loss:0.00102036\n",
      "Pretrain epoch [13/275], ZINB loss:0.3865, NB loss:4.6032, latent MSE loss:0.00052113, KL loss:0.00134655\n",
      "Pretrain epoch [14/275], ZINB loss:0.4039, NB loss:4.6641, latent MSE loss:0.00045861, KL loss:0.00149293\n",
      "Pretrain epoch [15/275], ZINB loss:0.3926, NB loss:4.5663, latent MSE loss:0.00047880, KL loss:0.00168140\n",
      "Pretrain epoch [16/275], ZINB loss:0.3958, NB loss:4.5643, latent MSE loss:0.00051471, KL loss:0.00157600\n",
      "Pretrain epoch [17/275], ZINB loss:0.3846, NB loss:4.5393, latent MSE loss:0.00037254, KL loss:0.00113976\n",
      "Pretrain epoch [18/275], ZINB loss:0.4051, NB loss:4.5872, latent MSE loss:0.00042569, KL loss:0.00126494\n",
      "Pretrain epoch [19/275], ZINB loss:0.3963, NB loss:4.6245, latent MSE loss:0.00034173, KL loss:0.00116900\n",
      "Pretrain epoch [20/275], ZINB loss:0.4168, NB loss:4.6000, latent MSE loss:0.00042527, KL loss:0.00169374\n",
      "Pretrain epoch [21/275], ZINB loss:0.3973, NB loss:4.5678, latent MSE loss:0.00038529, KL loss:0.00177833\n",
      "Pretrain epoch [22/275], ZINB loss:0.3822, NB loss:4.5800, latent MSE loss:0.00036692, KL loss:0.00161307\n",
      "Pretrain epoch [23/275], ZINB loss:0.3938, NB loss:4.5598, latent MSE loss:0.00035646, KL loss:0.00116326\n",
      "Pretrain epoch [24/275], ZINB loss:0.4054, NB loss:4.6408, latent MSE loss:0.00037822, KL loss:0.00140120\n",
      "Pretrain epoch [25/275], ZINB loss:0.4007, NB loss:4.5598, latent MSE loss:0.00029967, KL loss:0.00114247\n",
      "Pretrain epoch [26/275], ZINB loss:0.3952, NB loss:4.5459, latent MSE loss:0.00036345, KL loss:0.00118064\n",
      "Pretrain epoch [27/275], ZINB loss:0.3211, NB loss:4.7803, latent MSE loss:0.00027438, KL loss:0.00000111\n",
      "Pretrain epoch [1/276], ZINB loss:0.4047, NB loss:4.5184, latent MSE loss:0.00062145, KL loss:0.00104982\n",
      "Pretrain epoch [2/276], ZINB loss:0.3758, NB loss:4.5425, latent MSE loss:0.00049381, KL loss:0.00104163\n",
      "Pretrain epoch [3/276], ZINB loss:0.4099, NB loss:4.6000, latent MSE loss:0.00056472, KL loss:0.00133737\n",
      "Pretrain epoch [4/276], ZINB loss:0.4063, NB loss:4.5571, latent MSE loss:0.00040293, KL loss:0.00144338\n",
      "Pretrain epoch [5/276], ZINB loss:0.3806, NB loss:4.6683, latent MSE loss:0.00042745, KL loss:0.00126479\n",
      "Pretrain epoch [6/276], ZINB loss:0.4169, NB loss:4.6078, latent MSE loss:0.00051346, KL loss:0.00144294\n",
      "Pretrain epoch [7/276], ZINB loss:0.4018, NB loss:4.6331, latent MSE loss:0.00069396, KL loss:0.00140466\n",
      "Pretrain epoch [8/276], ZINB loss:0.4131, NB loss:4.5736, latent MSE loss:0.00055336, KL loss:0.00155054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [9/276], ZINB loss:0.3974, NB loss:4.6080, latent MSE loss:0.00049254, KL loss:0.00192223\n",
      "Pretrain epoch [10/276], ZINB loss:0.3970, NB loss:4.5203, latent MSE loss:0.00034547, KL loss:0.00130645\n",
      "Pretrain epoch [11/276], ZINB loss:0.3963, NB loss:4.5076, latent MSE loss:0.00039046, KL loss:0.00115334\n",
      "Pretrain epoch [12/276], ZINB loss:0.3953, NB loss:4.5737, latent MSE loss:0.00039040, KL loss:0.00133701\n",
      "Pretrain epoch [13/276], ZINB loss:0.3858, NB loss:4.5433, latent MSE loss:0.00042751, KL loss:0.00161566\n",
      "Pretrain epoch [14/276], ZINB loss:0.4003, NB loss:4.5202, latent MSE loss:0.00039574, KL loss:0.00120846\n",
      "Pretrain epoch [15/276], ZINB loss:0.3917, NB loss:4.6364, latent MSE loss:0.00036985, KL loss:0.00131460\n",
      "Pretrain epoch [16/276], ZINB loss:0.3837, NB loss:4.5450, latent MSE loss:0.00032208, KL loss:0.00109698\n",
      "Pretrain epoch [17/276], ZINB loss:0.3935, NB loss:4.5308, latent MSE loss:0.00036407, KL loss:0.00141744\n",
      "Pretrain epoch [18/276], ZINB loss:0.3915, NB loss:4.5019, latent MSE loss:0.00033568, KL loss:0.00151927\n",
      "Pretrain epoch [19/276], ZINB loss:0.3929, NB loss:4.5476, latent MSE loss:0.00033116, KL loss:0.00110471\n",
      "Pretrain epoch [20/276], ZINB loss:0.4039, NB loss:4.5449, latent MSE loss:0.00038855, KL loss:0.00126898\n",
      "Pretrain epoch [21/276], ZINB loss:0.3941, NB loss:4.6254, latent MSE loss:0.00035495, KL loss:0.00150540\n",
      "Pretrain epoch [22/276], ZINB loss:0.3980, NB loss:4.6166, latent MSE loss:0.00035997, KL loss:0.00128672\n",
      "Pretrain epoch [23/276], ZINB loss:0.3881, NB loss:4.5406, latent MSE loss:0.00035526, KL loss:0.00117598\n",
      "Pretrain epoch [24/276], ZINB loss:0.3899, NB loss:4.5750, latent MSE loss:0.00037873, KL loss:0.00121706\n",
      "Pretrain epoch [25/276], ZINB loss:0.4188, NB loss:4.5739, latent MSE loss:0.00046785, KL loss:0.00128975\n",
      "Pretrain epoch [26/276], ZINB loss:0.3880, NB loss:4.5382, latent MSE loss:0.00032789, KL loss:0.00124177\n",
      "Pretrain epoch [27/276], ZINB loss:0.3402, NB loss:4.8825, latent MSE loss:0.00011528, KL loss:0.00006982\n",
      "Pretrain epoch [1/277], ZINB loss:0.4042, NB loss:4.5994, latent MSE loss:0.00044549, KL loss:0.00151903\n",
      "Pretrain epoch [2/277], ZINB loss:0.3927, NB loss:4.6040, latent MSE loss:0.00031935, KL loss:0.00121315\n",
      "Pretrain epoch [3/277], ZINB loss:0.3938, NB loss:4.5393, latent MSE loss:0.00036685, KL loss:0.00150535\n",
      "Pretrain epoch [4/277], ZINB loss:0.3921, NB loss:4.6067, latent MSE loss:0.00030931, KL loss:0.00113645\n",
      "Pretrain epoch [5/277], ZINB loss:0.3978, NB loss:4.5317, latent MSE loss:0.00037475, KL loss:0.00102998\n",
      "Pretrain epoch [6/277], ZINB loss:0.3872, NB loss:4.6007, latent MSE loss:0.00036312, KL loss:0.00114938\n",
      "Pretrain epoch [7/277], ZINB loss:0.3806, NB loss:4.5319, latent MSE loss:0.00035021, KL loss:0.00137191\n",
      "Pretrain epoch [8/277], ZINB loss:0.4011, NB loss:4.5701, latent MSE loss:0.00042932, KL loss:0.00140952\n",
      "Pretrain epoch [9/277], ZINB loss:0.4114, NB loss:4.6506, latent MSE loss:0.00033238, KL loss:0.00137128\n",
      "Pretrain epoch [10/277], ZINB loss:0.3767, NB loss:4.6040, latent MSE loss:0.00034196, KL loss:0.00118936\n",
      "Pretrain epoch [11/277], ZINB loss:0.3961, NB loss:4.5659, latent MSE loss:0.00029953, KL loss:0.00131417\n",
      "Pretrain epoch [12/277], ZINB loss:0.3982, NB loss:4.5543, latent MSE loss:0.00035906, KL loss:0.00138037\n",
      "Pretrain epoch [13/277], ZINB loss:0.3967, NB loss:4.5000, latent MSE loss:0.00044486, KL loss:0.00131582\n",
      "Pretrain epoch [14/277], ZINB loss:0.4148, NB loss:4.6518, latent MSE loss:0.00044172, KL loss:0.00124078\n",
      "Pretrain epoch [15/277], ZINB loss:0.4104, NB loss:4.5563, latent MSE loss:0.00043489, KL loss:0.00159936\n",
      "Pretrain epoch [16/277], ZINB loss:0.3914, NB loss:4.5826, latent MSE loss:0.00024359, KL loss:0.00153188\n",
      "Pretrain epoch [17/277], ZINB loss:0.3790, NB loss:4.6067, latent MSE loss:0.00026483, KL loss:0.00138236\n",
      "Pretrain epoch [18/277], ZINB loss:0.3697, NB loss:4.5415, latent MSE loss:0.00033137, KL loss:0.00123104\n",
      "Pretrain epoch [19/277], ZINB loss:0.4008, NB loss:4.5056, latent MSE loss:0.00037874, KL loss:0.00161406\n",
      "Pretrain epoch [20/277], ZINB loss:0.4060, NB loss:4.5947, latent MSE loss:0.00040445, KL loss:0.00134369\n",
      "Pretrain epoch [21/277], ZINB loss:0.4007, NB loss:4.5652, latent MSE loss:0.00030773, KL loss:0.00113926\n",
      "Pretrain epoch [22/277], ZINB loss:0.3903, NB loss:4.4953, latent MSE loss:0.00031547, KL loss:0.00133326\n",
      "Pretrain epoch [23/277], ZINB loss:0.4038, NB loss:4.5519, latent MSE loss:0.00032662, KL loss:0.00131708\n",
      "Pretrain epoch [24/277], ZINB loss:0.3931, NB loss:4.5425, latent MSE loss:0.00033139, KL loss:0.00110267\n",
      "Pretrain epoch [25/277], ZINB loss:0.4061, NB loss:4.5475, latent MSE loss:0.00039026, KL loss:0.00156125\n",
      "Pretrain epoch [26/277], ZINB loss:0.4089, NB loss:4.5290, latent MSE loss:0.00046792, KL loss:0.00122916\n",
      "Pretrain epoch [27/277], ZINB loss:0.5319, NB loss:4.4378, latent MSE loss:0.00026103, KL loss:0.00007262\n",
      "Pretrain epoch [1/278], ZINB loss:0.3926, NB loss:4.5753, latent MSE loss:0.00115906, KL loss:0.00130569\n",
      "Pretrain epoch [2/278], ZINB loss:0.3797, NB loss:4.5357, latent MSE loss:0.00106107, KL loss:0.00144316\n",
      "Pretrain epoch [3/278], ZINB loss:0.4120, NB loss:4.4506, latent MSE loss:0.00118327, KL loss:0.00106838\n",
      "Pretrain epoch [4/278], ZINB loss:0.3988, NB loss:4.5209, latent MSE loss:0.00137585, KL loss:0.00104606\n",
      "Pretrain epoch [5/278], ZINB loss:0.4012, NB loss:4.6137, latent MSE loss:0.00146343, KL loss:0.00137369\n",
      "Pretrain epoch [6/278], ZINB loss:0.3793, NB loss:4.5970, latent MSE loss:0.00081002, KL loss:0.00128105\n",
      "Pretrain epoch [7/278], ZINB loss:0.4070, NB loss:4.5759, latent MSE loss:0.00094358, KL loss:0.00119814\n",
      "Pretrain epoch [8/278], ZINB loss:0.4029, NB loss:4.5643, latent MSE loss:0.00152723, KL loss:0.00115864\n",
      "Pretrain epoch [9/278], ZINB loss:0.4218, NB loss:4.5845, latent MSE loss:0.00140174, KL loss:0.00125145\n",
      "Pretrain epoch [10/278], ZINB loss:0.4026, NB loss:4.5879, latent MSE loss:0.00057343, KL loss:0.00121356\n",
      "Pretrain epoch [11/278], ZINB loss:0.3961, NB loss:4.4722, latent MSE loss:0.00077456, KL loss:0.00122706\n",
      "Pretrain epoch [12/278], ZINB loss:0.3953, NB loss:4.5472, latent MSE loss:0.00092902, KL loss:0.00115657\n",
      "Pretrain epoch [13/278], ZINB loss:0.4083, NB loss:4.6432, latent MSE loss:0.00046697, KL loss:0.00183818\n",
      "Pretrain epoch [14/278], ZINB loss:0.3918, NB loss:4.5753, latent MSE loss:0.00069527, KL loss:0.00157042\n",
      "Pretrain epoch [15/278], ZINB loss:0.3984, NB loss:4.4896, latent MSE loss:0.00078157, KL loss:0.00120800\n",
      "Pretrain epoch [16/278], ZINB loss:0.3942, NB loss:4.5755, latent MSE loss:0.00049468, KL loss:0.00149794\n",
      "Pretrain epoch [17/278], ZINB loss:0.3911, NB loss:4.5232, latent MSE loss:0.00063833, KL loss:0.00113298\n",
      "Pretrain epoch [18/278], ZINB loss:0.3890, NB loss:4.6373, latent MSE loss:0.00069514, KL loss:0.00140890\n",
      "Pretrain epoch [19/278], ZINB loss:0.3931, NB loss:4.5379, latent MSE loss:0.00041632, KL loss:0.00122081\n",
      "Pretrain epoch [20/278], ZINB loss:0.3831, NB loss:4.6119, latent MSE loss:0.00051705, KL loss:0.00104615\n",
      "Pretrain epoch [21/278], ZINB loss:0.3958, NB loss:4.5718, latent MSE loss:0.00057039, KL loss:0.00139229\n",
      "Pretrain epoch [22/278], ZINB loss:0.3921, NB loss:4.6278, latent MSE loss:0.00041463, KL loss:0.00127258\n",
      "Pretrain epoch [23/278], ZINB loss:0.3780, NB loss:4.5990, latent MSE loss:0.00053847, KL loss:0.00107379\n",
      "Pretrain epoch [24/278], ZINB loss:0.4086, NB loss:4.5239, latent MSE loss:0.00051318, KL loss:0.00120704\n",
      "Pretrain epoch [25/278], ZINB loss:0.3799, NB loss:4.5314, latent MSE loss:0.00040737, KL loss:0.00122128\n",
      "Pretrain epoch [26/278], ZINB loss:0.4105, NB loss:4.6106, latent MSE loss:0.00056729, KL loss:0.00159266\n",
      "Pretrain epoch [27/278], ZINB loss:0.3867, NB loss:4.6845, latent MSE loss:0.00025470, KL loss:0.00006939\n",
      "Pretrain epoch [1/279], ZINB loss:0.4133, NB loss:4.6282, latent MSE loss:0.00068946, KL loss:0.00111565\n",
      "Pretrain epoch [2/279], ZINB loss:0.4030, NB loss:4.5447, latent MSE loss:0.00077937, KL loss:0.00122921\n",
      "Pretrain epoch [3/279], ZINB loss:0.3988, NB loss:4.5993, latent MSE loss:0.00056045, KL loss:0.00139681\n",
      "Pretrain epoch [4/279], ZINB loss:0.3997, NB loss:4.5420, latent MSE loss:0.00061484, KL loss:0.00121205\n",
      "Pretrain epoch [5/279], ZINB loss:0.3856, NB loss:4.5331, latent MSE loss:0.00067853, KL loss:0.00143681\n",
      "Pretrain epoch [6/279], ZINB loss:0.3943, NB loss:4.5367, latent MSE loss:0.00037604, KL loss:0.00120552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [7/279], ZINB loss:0.4060, NB loss:4.4657, latent MSE loss:0.00065796, KL loss:0.00123735\n",
      "Pretrain epoch [8/279], ZINB loss:0.4088, NB loss:4.5975, latent MSE loss:0.00046110, KL loss:0.00117946\n",
      "Pretrain epoch [9/279], ZINB loss:0.3857, NB loss:4.5660, latent MSE loss:0.00048388, KL loss:0.00127404\n",
      "Pretrain epoch [10/279], ZINB loss:0.3924, NB loss:4.5633, latent MSE loss:0.00055756, KL loss:0.00141339\n",
      "Pretrain epoch [11/279], ZINB loss:0.3905, NB loss:4.5601, latent MSE loss:0.00035004, KL loss:0.00107961\n",
      "Pretrain epoch [12/279], ZINB loss:0.3951, NB loss:4.5641, latent MSE loss:0.00050955, KL loss:0.00118753\n",
      "Pretrain epoch [13/279], ZINB loss:0.4032, NB loss:4.5463, latent MSE loss:0.00045108, KL loss:0.00120840\n",
      "Pretrain epoch [14/279], ZINB loss:0.4026, NB loss:4.5456, latent MSE loss:0.00036935, KL loss:0.00113435\n",
      "Pretrain epoch [15/279], ZINB loss:0.3846, NB loss:4.5722, latent MSE loss:0.00043194, KL loss:0.00130564\n",
      "Pretrain epoch [16/279], ZINB loss:0.3848, NB loss:4.5732, latent MSE loss:0.00036210, KL loss:0.00126609\n",
      "Pretrain epoch [17/279], ZINB loss:0.3822, NB loss:4.5621, latent MSE loss:0.00029231, KL loss:0.00110382\n",
      "Pretrain epoch [18/279], ZINB loss:0.3959, NB loss:4.5403, latent MSE loss:0.00049912, KL loss:0.00131977\n",
      "Pretrain epoch [19/279], ZINB loss:0.3748, NB loss:4.5540, latent MSE loss:0.00033847, KL loss:0.00098684\n",
      "Pretrain epoch [20/279], ZINB loss:0.3929, NB loss:4.5563, latent MSE loss:0.00056908, KL loss:0.00114935\n",
      "Pretrain epoch [21/279], ZINB loss:0.4042, NB loss:4.6052, latent MSE loss:0.00041282, KL loss:0.00138890\n",
      "Pretrain epoch [22/279], ZINB loss:0.4091, NB loss:4.5825, latent MSE loss:0.00045887, KL loss:0.00156480\n",
      "Pretrain epoch [23/279], ZINB loss:0.3822, NB loss:4.5973, latent MSE loss:0.00053613, KL loss:0.00104906\n",
      "Pretrain epoch [24/279], ZINB loss:0.4147, NB loss:4.5648, latent MSE loss:0.00029519, KL loss:0.00123754\n",
      "Pretrain epoch [25/279], ZINB loss:0.3946, NB loss:4.5756, latent MSE loss:0.00038388, KL loss:0.00143716\n",
      "Pretrain epoch [26/279], ZINB loss:0.4051, NB loss:4.5496, latent MSE loss:0.00036261, KL loss:0.00152195\n",
      "Pretrain epoch [27/279], ZINB loss:0.3874, NB loss:5.0393, latent MSE loss:0.00040508, KL loss:0.00000863\n",
      "Pretrain epoch [1/280], ZINB loss:0.4028, NB loss:4.5964, latent MSE loss:0.00105943, KL loss:0.00131332\n",
      "Pretrain epoch [2/280], ZINB loss:0.3911, NB loss:4.5677, latent MSE loss:0.00161562, KL loss:0.00127742\n",
      "Pretrain epoch [3/280], ZINB loss:0.3963, NB loss:4.5242, latent MSE loss:0.00136362, KL loss:0.00145815\n",
      "Pretrain epoch [4/280], ZINB loss:0.3947, NB loss:4.6011, latent MSE loss:0.00100287, KL loss:0.00149170\n",
      "Pretrain epoch [5/280], ZINB loss:0.3996, NB loss:4.5854, latent MSE loss:0.00048578, KL loss:0.00126248\n",
      "Pretrain epoch [6/280], ZINB loss:0.4008, NB loss:4.5119, latent MSE loss:0.00072991, KL loss:0.00121084\n",
      "Pretrain epoch [7/280], ZINB loss:0.4075, NB loss:4.5614, latent MSE loss:0.00113187, KL loss:0.00129438\n",
      "Pretrain epoch [8/280], ZINB loss:0.3946, NB loss:4.5625, latent MSE loss:0.00084653, KL loss:0.00124640\n",
      "Pretrain epoch [9/280], ZINB loss:0.4005, NB loss:4.5290, latent MSE loss:0.00062934, KL loss:0.00118988\n",
      "Pretrain epoch [10/280], ZINB loss:0.3864, NB loss:4.5726, latent MSE loss:0.00082312, KL loss:0.00127999\n",
      "Pretrain epoch [11/280], ZINB loss:0.4012, NB loss:4.5866, latent MSE loss:0.00092839, KL loss:0.00133408\n",
      "Pretrain epoch [12/280], ZINB loss:0.4111, NB loss:4.5991, latent MSE loss:0.00120048, KL loss:0.00130076\n",
      "Pretrain epoch [13/280], ZINB loss:0.4105, NB loss:4.5808, latent MSE loss:0.00085641, KL loss:0.00127100\n",
      "Pretrain epoch [14/280], ZINB loss:0.3878, NB loss:4.5603, latent MSE loss:0.00043863, KL loss:0.00121670\n",
      "Pretrain epoch [15/280], ZINB loss:0.3938, NB loss:4.5909, latent MSE loss:0.00076620, KL loss:0.00113604\n",
      "Pretrain epoch [16/280], ZINB loss:0.4027, NB loss:4.5211, latent MSE loss:0.00093910, KL loss:0.00104285\n",
      "Pretrain epoch [17/280], ZINB loss:0.3922, NB loss:4.5409, latent MSE loss:0.00070597, KL loss:0.00116389\n",
      "Pretrain epoch [18/280], ZINB loss:0.3874, NB loss:4.5767, latent MSE loss:0.00044216, KL loss:0.00115760\n",
      "Pretrain epoch [19/280], ZINB loss:0.3990, NB loss:4.5184, latent MSE loss:0.00056566, KL loss:0.00132126\n",
      "Pretrain epoch [20/280], ZINB loss:0.3863, NB loss:4.5237, latent MSE loss:0.00070809, KL loss:0.00130376\n",
      "Pretrain epoch [21/280], ZINB loss:0.4003, NB loss:4.5763, latent MSE loss:0.00047533, KL loss:0.00110200\n",
      "Pretrain epoch [22/280], ZINB loss:0.3930, NB loss:4.5503, latent MSE loss:0.00035972, KL loss:0.00136704\n",
      "Pretrain epoch [23/280], ZINB loss:0.4033, NB loss:4.5456, latent MSE loss:0.00058987, KL loss:0.00149842\n",
      "Pretrain epoch [24/280], ZINB loss:0.3875, NB loss:4.6367, latent MSE loss:0.00055029, KL loss:0.00129422\n",
      "Pretrain epoch [25/280], ZINB loss:0.3984, NB loss:4.5168, latent MSE loss:0.00047388, KL loss:0.00124605\n",
      "Pretrain epoch [26/280], ZINB loss:0.3779, NB loss:4.5912, latent MSE loss:0.00033819, KL loss:0.00104453\n",
      "Pretrain epoch [27/280], ZINB loss:0.3750, NB loss:4.6758, latent MSE loss:0.00042410, KL loss:0.00004850\n",
      "Pretrain epoch [1/281], ZINB loss:0.4037, NB loss:4.5328, latent MSE loss:0.00064242, KL loss:0.00104991\n",
      "Pretrain epoch [2/281], ZINB loss:0.3890, NB loss:4.5623, latent MSE loss:0.00038925, KL loss:0.00121016\n",
      "Pretrain epoch [3/281], ZINB loss:0.4020, NB loss:4.5457, latent MSE loss:0.00056933, KL loss:0.00119447\n",
      "Pretrain epoch [4/281], ZINB loss:0.3888, NB loss:4.5116, latent MSE loss:0.00043583, KL loss:0.00129070\n",
      "Pretrain epoch [5/281], ZINB loss:0.3887, NB loss:4.5385, latent MSE loss:0.00042066, KL loss:0.00122537\n",
      "Pretrain epoch [6/281], ZINB loss:0.3921, NB loss:4.5553, latent MSE loss:0.00043288, KL loss:0.00133240\n",
      "Pretrain epoch [7/281], ZINB loss:0.4137, NB loss:4.5342, latent MSE loss:0.00053717, KL loss:0.00118928\n",
      "Pretrain epoch [8/281], ZINB loss:0.4057, NB loss:4.5910, latent MSE loss:0.00051652, KL loss:0.00171580\n",
      "Pretrain epoch [9/281], ZINB loss:0.3927, NB loss:4.5545, latent MSE loss:0.00037411, KL loss:0.00111688\n",
      "Pretrain epoch [10/281], ZINB loss:0.4313, NB loss:4.5810, latent MSE loss:0.00034239, KL loss:0.00201645\n",
      "Pretrain epoch [11/281], ZINB loss:0.3917, NB loss:4.5882, latent MSE loss:0.00036128, KL loss:0.00117255\n",
      "Pretrain epoch [12/281], ZINB loss:0.3874, NB loss:4.5455, latent MSE loss:0.00035085, KL loss:0.00127053\n",
      "Pretrain epoch [13/281], ZINB loss:0.3877, NB loss:4.5702, latent MSE loss:0.00035331, KL loss:0.00116012\n",
      "Pretrain epoch [14/281], ZINB loss:0.3876, NB loss:4.5784, latent MSE loss:0.00030405, KL loss:0.00118195\n",
      "Pretrain epoch [15/281], ZINB loss:0.4199, NB loss:4.5755, latent MSE loss:0.00034390, KL loss:0.00109143\n",
      "Pretrain epoch [16/281], ZINB loss:0.3945, NB loss:4.5447, latent MSE loss:0.00027905, KL loss:0.00108036\n",
      "Pretrain epoch [17/281], ZINB loss:0.3893, NB loss:4.5887, latent MSE loss:0.00044409, KL loss:0.00128927\n",
      "Pretrain epoch [18/281], ZINB loss:0.4034, NB loss:4.5546, latent MSE loss:0.00028584, KL loss:0.00138544\n",
      "Pretrain epoch [19/281], ZINB loss:0.3811, NB loss:4.5433, latent MSE loss:0.00026859, KL loss:0.00100162\n",
      "Pretrain epoch [20/281], ZINB loss:0.3787, NB loss:4.6115, latent MSE loss:0.00021642, KL loss:0.00111924\n",
      "Pretrain epoch [21/281], ZINB loss:0.4109, NB loss:4.5203, latent MSE loss:0.00034508, KL loss:0.00114801\n",
      "Pretrain epoch [22/281], ZINB loss:0.4014, NB loss:4.5281, latent MSE loss:0.00033285, KL loss:0.00118322\n",
      "Pretrain epoch [23/281], ZINB loss:0.3904, NB loss:4.5596, latent MSE loss:0.00027397, KL loss:0.00135782\n",
      "Pretrain epoch [24/281], ZINB loss:0.3742, NB loss:4.5915, latent MSE loss:0.00028552, KL loss:0.00124004\n",
      "Pretrain epoch [25/281], ZINB loss:0.3852, NB loss:4.5904, latent MSE loss:0.00028145, KL loss:0.00127713\n",
      "Pretrain epoch [26/281], ZINB loss:0.4102, NB loss:4.5718, latent MSE loss:0.00038733, KL loss:0.00147969\n",
      "Pretrain epoch [27/281], ZINB loss:0.3590, NB loss:4.8918, latent MSE loss:0.00036974, KL loss:0.00005942\n",
      "Pretrain epoch [1/282], ZINB loss:0.3991, NB loss:4.5774, latent MSE loss:0.00046892, KL loss:0.00112543\n",
      "Pretrain epoch [2/282], ZINB loss:0.3830, NB loss:4.5347, latent MSE loss:0.00043388, KL loss:0.00098929\n",
      "Pretrain epoch [3/282], ZINB loss:0.4032, NB loss:4.5577, latent MSE loss:0.00042587, KL loss:0.00135647\n",
      "Pretrain epoch [4/282], ZINB loss:0.3951, NB loss:4.5611, latent MSE loss:0.00046020, KL loss:0.00126364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [5/282], ZINB loss:0.3970, NB loss:4.5127, latent MSE loss:0.00048039, KL loss:0.00132316\n",
      "Pretrain epoch [6/282], ZINB loss:0.3845, NB loss:4.5352, latent MSE loss:0.00047726, KL loss:0.00118912\n",
      "Pretrain epoch [7/282], ZINB loss:0.3969, NB loss:4.5176, latent MSE loss:0.00045847, KL loss:0.00099004\n",
      "Pretrain epoch [8/282], ZINB loss:0.4000, NB loss:4.5814, latent MSE loss:0.00048019, KL loss:0.00134706\n",
      "Pretrain epoch [9/282], ZINB loss:0.4141, NB loss:4.5594, latent MSE loss:0.00037721, KL loss:0.00183609\n",
      "Pretrain epoch [10/282], ZINB loss:0.4000, NB loss:4.5899, latent MSE loss:0.00045217, KL loss:0.00117310\n",
      "Pretrain epoch [11/282], ZINB loss:0.4190, NB loss:4.5530, latent MSE loss:0.00036287, KL loss:0.00107222\n",
      "Pretrain epoch [12/282], ZINB loss:0.4019, NB loss:4.5032, latent MSE loss:0.00037452, KL loss:0.00139698\n",
      "Pretrain epoch [13/282], ZINB loss:0.3744, NB loss:4.5274, latent MSE loss:0.00035256, KL loss:0.00113643\n",
      "Pretrain epoch [14/282], ZINB loss:0.3814, NB loss:4.5871, latent MSE loss:0.00031598, KL loss:0.00106523\n",
      "Pretrain epoch [15/282], ZINB loss:0.4043, NB loss:4.5082, latent MSE loss:0.00037514, KL loss:0.00110548\n",
      "Pretrain epoch [16/282], ZINB loss:0.4030, NB loss:4.5689, latent MSE loss:0.00038161, KL loss:0.00151479\n",
      "Pretrain epoch [17/282], ZINB loss:0.3916, NB loss:4.5750, latent MSE loss:0.00030948, KL loss:0.00119420\n",
      "Pretrain epoch [18/282], ZINB loss:0.3963, NB loss:4.6198, latent MSE loss:0.00040402, KL loss:0.00150873\n",
      "Pretrain epoch [19/282], ZINB loss:0.3865, NB loss:4.6052, latent MSE loss:0.00034076, KL loss:0.00111298\n",
      "Pretrain epoch [20/282], ZINB loss:0.3838, NB loss:4.5457, latent MSE loss:0.00030628, KL loss:0.00118305\n",
      "Pretrain epoch [21/282], ZINB loss:0.4003, NB loss:4.5363, latent MSE loss:0.00026252, KL loss:0.00101720\n",
      "Pretrain epoch [22/282], ZINB loss:0.3830, NB loss:4.5750, latent MSE loss:0.00026542, KL loss:0.00130568\n",
      "Pretrain epoch [23/282], ZINB loss:0.4026, NB loss:4.6232, latent MSE loss:0.00038024, KL loss:0.00131904\n",
      "Pretrain epoch [24/282], ZINB loss:0.3808, NB loss:4.5757, latent MSE loss:0.00030188, KL loss:0.00140693\n",
      "Pretrain epoch [25/282], ZINB loss:0.4095, NB loss:4.5909, latent MSE loss:0.00033100, KL loss:0.00169052\n",
      "Pretrain epoch [26/282], ZINB loss:0.4082, NB loss:4.5114, latent MSE loss:0.00027800, KL loss:0.00113749\n",
      "Pretrain epoch [27/282], ZINB loss:0.3158, NB loss:4.3093, latent MSE loss:0.00098483, KL loss:0.00004260\n",
      "Pretrain epoch [1/283], ZINB loss:0.3957, NB loss:4.5854, latent MSE loss:0.00099719, KL loss:0.00144080\n",
      "Pretrain epoch [2/283], ZINB loss:0.3913, NB loss:4.5865, latent MSE loss:0.00084572, KL loss:0.00144253\n",
      "Pretrain epoch [3/283], ZINB loss:0.3860, NB loss:4.5806, latent MSE loss:0.00142346, KL loss:0.00117362\n",
      "Pretrain epoch [4/283], ZINB loss:0.3888, NB loss:4.5699, latent MSE loss:0.00086903, KL loss:0.00109594\n",
      "Pretrain epoch [5/283], ZINB loss:0.4041, NB loss:4.5318, latent MSE loss:0.00085133, KL loss:0.00125838\n",
      "Pretrain epoch [6/283], ZINB loss:0.4261, NB loss:4.5528, latent MSE loss:0.00094465, KL loss:0.00155101\n",
      "Pretrain epoch [7/283], ZINB loss:0.3749, NB loss:4.4925, latent MSE loss:0.00072091, KL loss:0.00116096\n",
      "Pretrain epoch [8/283], ZINB loss:0.4053, NB loss:4.5623, latent MSE loss:0.00079200, KL loss:0.00126276\n",
      "Pretrain epoch [9/283], ZINB loss:0.3777, NB loss:4.5679, latent MSE loss:0.00055436, KL loss:0.00115391\n",
      "Pretrain epoch [10/283], ZINB loss:0.3907, NB loss:4.5820, latent MSE loss:0.00067098, KL loss:0.00191436\n",
      "Pretrain epoch [11/283], ZINB loss:0.3842, NB loss:4.5207, latent MSE loss:0.00050965, KL loss:0.00109637\n",
      "Pretrain epoch [12/283], ZINB loss:0.3924, NB loss:4.5680, latent MSE loss:0.00065496, KL loss:0.00112906\n",
      "Pretrain epoch [13/283], ZINB loss:0.3975, NB loss:4.5783, latent MSE loss:0.00056621, KL loss:0.00137866\n",
      "Pretrain epoch [14/283], ZINB loss:0.4005, NB loss:4.5860, latent MSE loss:0.00053521, KL loss:0.00126102\n",
      "Pretrain epoch [15/283], ZINB loss:0.4004, NB loss:4.4841, latent MSE loss:0.00049117, KL loss:0.00101808\n",
      "Pretrain epoch [16/283], ZINB loss:0.4071, NB loss:4.5551, latent MSE loss:0.00044139, KL loss:0.00109915\n",
      "Pretrain epoch [17/283], ZINB loss:0.4079, NB loss:4.4578, latent MSE loss:0.00043424, KL loss:0.00100425\n",
      "Pretrain epoch [18/283], ZINB loss:0.4071, NB loss:4.6017, latent MSE loss:0.00048587, KL loss:0.00190599\n",
      "Pretrain epoch [19/283], ZINB loss:0.3978, NB loss:4.6362, latent MSE loss:0.00032739, KL loss:0.00157978\n",
      "Pretrain epoch [20/283], ZINB loss:0.4003, NB loss:4.5418, latent MSE loss:0.00041635, KL loss:0.00146187\n",
      "Pretrain epoch [21/283], ZINB loss:0.3926, NB loss:4.5612, latent MSE loss:0.00039916, KL loss:0.00115427\n",
      "Pretrain epoch [22/283], ZINB loss:0.3844, NB loss:4.5798, latent MSE loss:0.00041360, KL loss:0.00105176\n",
      "Pretrain epoch [23/283], ZINB loss:0.4006, NB loss:4.5517, latent MSE loss:0.00036546, KL loss:0.00112333\n",
      "Pretrain epoch [24/283], ZINB loss:0.3981, NB loss:4.5094, latent MSE loss:0.00037572, KL loss:0.00119443\n",
      "Pretrain epoch [25/283], ZINB loss:0.3946, NB loss:4.5700, latent MSE loss:0.00032887, KL loss:0.00107856\n",
      "Pretrain epoch [26/283], ZINB loss:0.3995, NB loss:4.5817, latent MSE loss:0.00033832, KL loss:0.00105079\n",
      "Pretrain epoch [27/283], ZINB loss:0.2979, NB loss:4.9041, latent MSE loss:0.00023132, KL loss:0.00007009\n",
      "Pretrain epoch [1/284], ZINB loss:0.3984, NB loss:4.5861, latent MSE loss:0.00054172, KL loss:0.00120453\n",
      "Pretrain epoch [2/284], ZINB loss:0.3903, NB loss:4.5375, latent MSE loss:0.00063846, KL loss:0.00099317\n",
      "Pretrain epoch [3/284], ZINB loss:0.3842, NB loss:4.5727, latent MSE loss:0.00061321, KL loss:0.00112124\n",
      "Pretrain epoch [4/284], ZINB loss:0.4064, NB loss:4.5426, latent MSE loss:0.00049730, KL loss:0.00124342\n",
      "Pretrain epoch [5/284], ZINB loss:0.4092, NB loss:4.5317, latent MSE loss:0.00044933, KL loss:0.00116733\n",
      "Pretrain epoch [6/284], ZINB loss:0.3895, NB loss:4.5205, latent MSE loss:0.00041277, KL loss:0.00120757\n",
      "Pretrain epoch [7/284], ZINB loss:0.3939, NB loss:4.6088, latent MSE loss:0.00032683, KL loss:0.00116872\n",
      "Pretrain epoch [8/284], ZINB loss:0.3842, NB loss:4.5785, latent MSE loss:0.00042714, KL loss:0.00112507\n",
      "Pretrain epoch [9/284], ZINB loss:0.3945, NB loss:4.5363, latent MSE loss:0.00049140, KL loss:0.00108715\n",
      "Pretrain epoch [10/284], ZINB loss:0.4120, NB loss:4.5505, latent MSE loss:0.00041104, KL loss:0.00128989\n",
      "Pretrain epoch [11/284], ZINB loss:0.4035, NB loss:4.5419, latent MSE loss:0.00034187, KL loss:0.00114327\n",
      "Pretrain epoch [12/284], ZINB loss:0.3973, NB loss:4.5961, latent MSE loss:0.00032878, KL loss:0.00146785\n",
      "Pretrain epoch [13/284], ZINB loss:0.3757, NB loss:4.6015, latent MSE loss:0.00030418, KL loss:0.00113047\n",
      "Pretrain epoch [14/284], ZINB loss:0.4138, NB loss:4.5398, latent MSE loss:0.00034996, KL loss:0.00111567\n",
      "Pretrain epoch [15/284], ZINB loss:0.3838, NB loss:4.5231, latent MSE loss:0.00042354, KL loss:0.00110479\n",
      "Pretrain epoch [16/284], ZINB loss:0.3949, NB loss:4.5624, latent MSE loss:0.00029889, KL loss:0.00106732\n",
      "Pretrain epoch [17/284], ZINB loss:0.4229, NB loss:4.5858, latent MSE loss:0.00021333, KL loss:0.00133625\n",
      "Pretrain epoch [18/284], ZINB loss:0.3777, NB loss:4.5298, latent MSE loss:0.00037715, KL loss:0.00104608\n",
      "Pretrain epoch [19/284], ZINB loss:0.3904, NB loss:4.5869, latent MSE loss:0.00039356, KL loss:0.00111104\n",
      "Pretrain epoch [20/284], ZINB loss:0.3913, NB loss:4.5350, latent MSE loss:0.00037755, KL loss:0.00120540\n",
      "Pretrain epoch [21/284], ZINB loss:0.3978, NB loss:4.5534, latent MSE loss:0.00030421, KL loss:0.00155433\n",
      "Pretrain epoch [22/284], ZINB loss:0.4079, NB loss:4.5091, latent MSE loss:0.00025237, KL loss:0.00139080\n",
      "Pretrain epoch [23/284], ZINB loss:0.3829, NB loss:4.5483, latent MSE loss:0.00029451, KL loss:0.00133606\n",
      "Pretrain epoch [24/284], ZINB loss:0.3893, NB loss:4.5418, latent MSE loss:0.00030833, KL loss:0.00117979\n",
      "Pretrain epoch [25/284], ZINB loss:0.3928, NB loss:4.5001, latent MSE loss:0.00039866, KL loss:0.00100550\n",
      "Pretrain epoch [26/284], ZINB loss:0.4022, NB loss:4.6234, latent MSE loss:0.00039240, KL loss:0.00167939\n",
      "Pretrain epoch [27/284], ZINB loss:0.4707, NB loss:5.2380, latent MSE loss:0.00021466, KL loss:0.00000750\n",
      "Pretrain epoch [1/285], ZINB loss:0.4029, NB loss:4.5493, latent MSE loss:0.00043300, KL loss:0.00108488\n",
      "Pretrain epoch [2/285], ZINB loss:0.3874, NB loss:4.5390, latent MSE loss:0.00058019, KL loss:0.00122831\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [3/285], ZINB loss:0.3960, NB loss:4.5965, latent MSE loss:0.00055541, KL loss:0.00134847\n",
      "Pretrain epoch [4/285], ZINB loss:0.3934, NB loss:4.5685, latent MSE loss:0.00052568, KL loss:0.00130217\n",
      "Pretrain epoch [5/285], ZINB loss:0.4087, NB loss:4.5332, latent MSE loss:0.00052097, KL loss:0.00109178\n",
      "Pretrain epoch [6/285], ZINB loss:0.3853, NB loss:4.6154, latent MSE loss:0.00035265, KL loss:0.00139110\n",
      "Pretrain epoch [7/285], ZINB loss:0.3834, NB loss:4.5287, latent MSE loss:0.00039518, KL loss:0.00120175\n",
      "Pretrain epoch [8/285], ZINB loss:0.4093, NB loss:4.5683, latent MSE loss:0.00055253, KL loss:0.00179231\n",
      "Pretrain epoch [9/285], ZINB loss:0.3957, NB loss:4.5367, latent MSE loss:0.00040339, KL loss:0.00097659\n",
      "Pretrain epoch [10/285], ZINB loss:0.4051, NB loss:4.6164, latent MSE loss:0.00045794, KL loss:0.00160531\n",
      "Pretrain epoch [11/285], ZINB loss:0.3885, NB loss:4.5986, latent MSE loss:0.00029748, KL loss:0.00112054\n",
      "Pretrain epoch [12/285], ZINB loss:0.3867, NB loss:4.5370, latent MSE loss:0.00029288, KL loss:0.00125405\n",
      "Pretrain epoch [13/285], ZINB loss:0.4110, NB loss:4.5709, latent MSE loss:0.00038273, KL loss:0.00116618\n",
      "Pretrain epoch [14/285], ZINB loss:0.3807, NB loss:4.5769, latent MSE loss:0.00038906, KL loss:0.00101384\n",
      "Pretrain epoch [15/285], ZINB loss:0.3927, NB loss:4.4987, latent MSE loss:0.00037423, KL loss:0.00090199\n",
      "Pretrain epoch [16/285], ZINB loss:0.4094, NB loss:4.5738, latent MSE loss:0.00038043, KL loss:0.00113685\n",
      "Pretrain epoch [17/285], ZINB loss:0.3882, NB loss:4.5135, latent MSE loss:0.00027275, KL loss:0.00152726\n",
      "Pretrain epoch [18/285], ZINB loss:0.3938, NB loss:4.5129, latent MSE loss:0.00032706, KL loss:0.00098929\n",
      "Pretrain epoch [19/285], ZINB loss:0.3837, NB loss:4.5811, latent MSE loss:0.00028921, KL loss:0.00097643\n",
      "Pretrain epoch [20/285], ZINB loss:0.3951, NB loss:4.5049, latent MSE loss:0.00048417, KL loss:0.00123315\n",
      "Pretrain epoch [21/285], ZINB loss:0.3927, NB loss:4.5101, latent MSE loss:0.00038253, KL loss:0.00133938\n",
      "Pretrain epoch [22/285], ZINB loss:0.4157, NB loss:4.6391, latent MSE loss:0.00031566, KL loss:0.00127899\n",
      "Pretrain epoch [23/285], ZINB loss:0.4185, NB loss:4.5378, latent MSE loss:0.00031831, KL loss:0.00106411\n",
      "Pretrain epoch [24/285], ZINB loss:0.3883, NB loss:4.5624, latent MSE loss:0.00041188, KL loss:0.00112478\n",
      "Pretrain epoch [25/285], ZINB loss:0.3985, NB loss:4.5346, latent MSE loss:0.00047980, KL loss:0.00135737\n",
      "Pretrain epoch [26/285], ZINB loss:0.4001, NB loss:4.5350, latent MSE loss:0.00025732, KL loss:0.00132126\n",
      "Pretrain epoch [27/285], ZINB loss:0.3459, NB loss:4.3995, latent MSE loss:0.00050375, KL loss:0.00006307\n",
      "Pretrain epoch [1/286], ZINB loss:0.4008, NB loss:4.5669, latent MSE loss:0.00263502, KL loss:0.00138597\n",
      "Pretrain epoch [2/286], ZINB loss:0.4474, NB loss:4.5134, latent MSE loss:0.00457766, KL loss:0.00142953\n",
      "Pretrain epoch [3/286], ZINB loss:0.4154, NB loss:4.5032, latent MSE loss:0.00603974, KL loss:0.00151036\n",
      "Pretrain epoch [4/286], ZINB loss:0.4206, NB loss:4.5658, latent MSE loss:0.00410496, KL loss:0.00154513\n",
      "Pretrain epoch [5/286], ZINB loss:0.4091, NB loss:4.5104, latent MSE loss:0.00679887, KL loss:0.00138811\n",
      "Pretrain epoch [6/286], ZINB loss:0.4072, NB loss:4.5722, latent MSE loss:0.00810550, KL loss:0.00153571\n",
      "Pretrain epoch [7/286], ZINB loss:0.3944, NB loss:4.5324, latent MSE loss:0.00471454, KL loss:0.00171763\n",
      "Pretrain epoch [8/286], ZINB loss:0.3928, NB loss:4.5742, latent MSE loss:0.00382986, KL loss:0.00191805\n",
      "Pretrain epoch [9/286], ZINB loss:0.3960, NB loss:4.5624, latent MSE loss:0.00540721, KL loss:0.00181470\n",
      "Pretrain epoch [10/286], ZINB loss:0.4004, NB loss:4.5188, latent MSE loss:0.00326110, KL loss:0.00140005\n",
      "Pretrain epoch [11/286], ZINB loss:0.4112, NB loss:4.5838, latent MSE loss:0.00397131, KL loss:0.00175261\n",
      "Pretrain epoch [12/286], ZINB loss:0.4292, NB loss:4.5669, latent MSE loss:0.00434400, KL loss:0.00189431\n",
      "Pretrain epoch [13/286], ZINB loss:0.3961, NB loss:4.6147, latent MSE loss:0.00445889, KL loss:0.00200398\n",
      "Pretrain epoch [14/286], ZINB loss:0.3920, NB loss:4.5948, latent MSE loss:0.00340882, KL loss:0.00155433\n",
      "Pretrain epoch [15/286], ZINB loss:0.3969, NB loss:4.5954, latent MSE loss:0.00387591, KL loss:0.00235673\n",
      "Pretrain epoch [16/286], ZINB loss:0.3915, NB loss:4.5398, latent MSE loss:0.00264094, KL loss:0.00156163\n",
      "Pretrain epoch [17/286], ZINB loss:0.4007, NB loss:4.6013, latent MSE loss:0.00305239, KL loss:0.00203114\n",
      "Pretrain epoch [18/286], ZINB loss:0.3998, NB loss:4.4781, latent MSE loss:0.00260165, KL loss:0.00180632\n",
      "Pretrain epoch [19/286], ZINB loss:0.4120, NB loss:4.5263, latent MSE loss:0.00258870, KL loss:0.00160157\n",
      "Pretrain epoch [20/286], ZINB loss:0.3945, NB loss:4.5522, latent MSE loss:0.00269841, KL loss:0.00165361\n",
      "Pretrain epoch [21/286], ZINB loss:0.4102, NB loss:4.5770, latent MSE loss:0.00275849, KL loss:0.00183837\n",
      "Pretrain epoch [22/286], ZINB loss:0.4054, NB loss:4.5018, latent MSE loss:0.00211877, KL loss:0.00152250\n",
      "Pretrain epoch [23/286], ZINB loss:0.4100, NB loss:4.5691, latent MSE loss:0.00237042, KL loss:0.00165023\n",
      "Pretrain epoch [24/286], ZINB loss:0.3955, NB loss:4.5593, latent MSE loss:0.00226137, KL loss:0.00140350\n",
      "Pretrain epoch [25/286], ZINB loss:0.4069, NB loss:4.4971, latent MSE loss:0.00237423, KL loss:0.00162006\n",
      "Pretrain epoch [26/286], ZINB loss:0.4016, NB loss:4.6141, latent MSE loss:0.00238337, KL loss:0.00187089\n",
      "Pretrain epoch [27/286], ZINB loss:0.3871, NB loss:4.4949, latent MSE loss:0.00137023, KL loss:0.00000831\n",
      "Pretrain epoch [1/287], ZINB loss:0.4037, NB loss:4.5254, latent MSE loss:0.00281828, KL loss:0.00173187\n",
      "Pretrain epoch [2/287], ZINB loss:0.3919, NB loss:4.5629, latent MSE loss:0.00183619, KL loss:0.00175779\n",
      "Pretrain epoch [3/287], ZINB loss:0.3823, NB loss:4.5775, latent MSE loss:0.00206466, KL loss:0.00182638\n",
      "Pretrain epoch [4/287], ZINB loss:0.4099, NB loss:4.5369, latent MSE loss:0.00155398, KL loss:0.00192957\n",
      "Pretrain epoch [5/287], ZINB loss:0.4216, NB loss:4.5403, latent MSE loss:0.00208057, KL loss:0.00175238\n",
      "Pretrain epoch [6/287], ZINB loss:0.4005, NB loss:4.5654, latent MSE loss:0.00135507, KL loss:0.00166461\n",
      "Pretrain epoch [7/287], ZINB loss:0.3991, NB loss:4.5871, latent MSE loss:0.00171472, KL loss:0.00173500\n",
      "Pretrain epoch [8/287], ZINB loss:0.3927, NB loss:4.5445, latent MSE loss:0.00159351, KL loss:0.00144416\n",
      "Pretrain epoch [9/287], ZINB loss:0.3934, NB loss:4.5981, latent MSE loss:0.00158784, KL loss:0.00148088\n",
      "Pretrain epoch [10/287], ZINB loss:0.3990, NB loss:4.5358, latent MSE loss:0.00132439, KL loss:0.00137549\n",
      "Pretrain epoch [11/287], ZINB loss:0.3827, NB loss:4.5623, latent MSE loss:0.00097409, KL loss:0.00132566\n",
      "Pretrain epoch [12/287], ZINB loss:0.3892, NB loss:4.5072, latent MSE loss:0.00128333, KL loss:0.00156196\n",
      "Pretrain epoch [13/287], ZINB loss:0.4017, NB loss:4.6119, latent MSE loss:0.00087756, KL loss:0.00134069\n",
      "Pretrain epoch [14/287], ZINB loss:0.4189, NB loss:4.5508, latent MSE loss:0.00164272, KL loss:0.00161278\n",
      "Pretrain epoch [15/287], ZINB loss:0.3945, NB loss:4.5678, latent MSE loss:0.00096778, KL loss:0.00145769\n",
      "Pretrain epoch [16/287], ZINB loss:0.4130, NB loss:4.5764, latent MSE loss:0.00149170, KL loss:0.00184723\n",
      "Pretrain epoch [17/287], ZINB loss:0.3842, NB loss:4.5919, latent MSE loss:0.00067454, KL loss:0.00132343\n",
      "Pretrain epoch [18/287], ZINB loss:0.4138, NB loss:4.5688, latent MSE loss:0.00116648, KL loss:0.00158513\n",
      "Pretrain epoch [19/287], ZINB loss:0.3877, NB loss:4.5210, latent MSE loss:0.00052098, KL loss:0.00142949\n",
      "Pretrain epoch [20/287], ZINB loss:0.3936, NB loss:4.5920, latent MSE loss:0.00085976, KL loss:0.00141573\n",
      "Pretrain epoch [21/287], ZINB loss:0.3899, NB loss:4.5581, latent MSE loss:0.00068941, KL loss:0.00142703\n",
      "Pretrain epoch [22/287], ZINB loss:0.3914, NB loss:4.4765, latent MSE loss:0.00080902, KL loss:0.00150527\n",
      "Pretrain epoch [23/287], ZINB loss:0.3936, NB loss:4.4992, latent MSE loss:0.00058559, KL loss:0.00124104\n",
      "Pretrain epoch [24/287], ZINB loss:0.3824, NB loss:4.4947, latent MSE loss:0.00053212, KL loss:0.00163447\n",
      "Pretrain epoch [25/287], ZINB loss:0.4140, NB loss:4.5147, latent MSE loss:0.00062316, KL loss:0.00161677\n",
      "Pretrain epoch [26/287], ZINB loss:0.3976, NB loss:4.5987, latent MSE loss:0.00060776, KL loss:0.00159330\n",
      "Pretrain epoch [27/287], ZINB loss:0.3976, NB loss:4.1525, latent MSE loss:0.00056019, KL loss:0.00004994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [1/288], ZINB loss:0.3972, NB loss:4.5347, latent MSE loss:0.00092874, KL loss:0.00127252\n",
      "Pretrain epoch [2/288], ZINB loss:0.3779, NB loss:4.5282, latent MSE loss:0.00071027, KL loss:0.00130858\n",
      "Pretrain epoch [3/288], ZINB loss:0.3927, NB loss:4.5136, latent MSE loss:0.00055859, KL loss:0.00119630\n",
      "Pretrain epoch [4/288], ZINB loss:0.3869, NB loss:4.5634, latent MSE loss:0.00067718, KL loss:0.00123849\n",
      "Pretrain epoch [5/288], ZINB loss:0.4101, NB loss:4.5803, latent MSE loss:0.00090601, KL loss:0.00190386\n",
      "Pretrain epoch [6/288], ZINB loss:0.3942, NB loss:4.5185, latent MSE loss:0.00054236, KL loss:0.00110201\n",
      "Pretrain epoch [7/288], ZINB loss:0.4000, NB loss:4.5851, latent MSE loss:0.00058563, KL loss:0.00169845\n",
      "Pretrain epoch [8/288], ZINB loss:0.3988, NB loss:4.5096, latent MSE loss:0.00052182, KL loss:0.00145682\n",
      "Pretrain epoch [9/288], ZINB loss:0.4102, NB loss:4.5299, latent MSE loss:0.00061276, KL loss:0.00150102\n",
      "Pretrain epoch [10/288], ZINB loss:0.4014, NB loss:4.5496, latent MSE loss:0.00043261, KL loss:0.00128403\n",
      "Pretrain epoch [11/288], ZINB loss:0.3976, NB loss:4.5637, latent MSE loss:0.00049561, KL loss:0.00130616\n",
      "Pretrain epoch [12/288], ZINB loss:0.3904, NB loss:4.5625, latent MSE loss:0.00044850, KL loss:0.00123679\n",
      "Pretrain epoch [13/288], ZINB loss:0.3922, NB loss:4.5883, latent MSE loss:0.00049105, KL loss:0.00135520\n",
      "Pretrain epoch [14/288], ZINB loss:0.4184, NB loss:4.5998, latent MSE loss:0.00052646, KL loss:0.00170228\n",
      "Pretrain epoch [15/288], ZINB loss:0.3957, NB loss:4.5419, latent MSE loss:0.00039987, KL loss:0.00128622\n",
      "Pretrain epoch [16/288], ZINB loss:0.3992, NB loss:4.5210, latent MSE loss:0.00038744, KL loss:0.00136451\n",
      "Pretrain epoch [17/288], ZINB loss:0.3804, NB loss:4.6157, latent MSE loss:0.00041923, KL loss:0.00147812\n",
      "Pretrain epoch [18/288], ZINB loss:0.4141, NB loss:4.5012, latent MSE loss:0.00037208, KL loss:0.00128784\n",
      "Pretrain epoch [19/288], ZINB loss:0.3936, NB loss:4.5829, latent MSE loss:0.00045921, KL loss:0.00134472\n",
      "Pretrain epoch [20/288], ZINB loss:0.4080, NB loss:4.5425, latent MSE loss:0.00043687, KL loss:0.00134382\n",
      "Pretrain epoch [21/288], ZINB loss:0.3954, NB loss:4.5776, latent MSE loss:0.00033523, KL loss:0.00133184\n",
      "Pretrain epoch [22/288], ZINB loss:0.3946, NB loss:4.5794, latent MSE loss:0.00028046, KL loss:0.00122983\n",
      "Pretrain epoch [23/288], ZINB loss:0.3937, NB loss:4.4798, latent MSE loss:0.00032555, KL loss:0.00114814\n",
      "Pretrain epoch [24/288], ZINB loss:0.3790, NB loss:4.5583, latent MSE loss:0.00029903, KL loss:0.00126503\n",
      "Pretrain epoch [25/288], ZINB loss:0.4110, NB loss:4.5350, latent MSE loss:0.00033566, KL loss:0.00133869\n",
      "Pretrain epoch [26/288], ZINB loss:0.3905, NB loss:4.5686, latent MSE loss:0.00034152, KL loss:0.00125725\n",
      "Pretrain epoch [27/288], ZINB loss:0.3153, NB loss:4.4630, latent MSE loss:0.00013680, KL loss:0.00006374\n",
      "Pretrain epoch [1/289], ZINB loss:0.4127, NB loss:4.6174, latent MSE loss:0.00038284, KL loss:0.00155778\n",
      "Pretrain epoch [2/289], ZINB loss:0.3940, NB loss:4.5527, latent MSE loss:0.00039609, KL loss:0.00135293\n",
      "Pretrain epoch [3/289], ZINB loss:0.3961, NB loss:4.5243, latent MSE loss:0.00037239, KL loss:0.00127678\n",
      "Pretrain epoch [4/289], ZINB loss:0.3976, NB loss:4.5679, latent MSE loss:0.00049359, KL loss:0.00117214\n",
      "Pretrain epoch [5/289], ZINB loss:0.3984, NB loss:4.6011, latent MSE loss:0.00039317, KL loss:0.00139891\n",
      "Pretrain epoch [6/289], ZINB loss:0.4009, NB loss:4.5598, latent MSE loss:0.00033742, KL loss:0.00150672\n",
      "Pretrain epoch [7/289], ZINB loss:0.3974, NB loss:4.5019, latent MSE loss:0.00030328, KL loss:0.00126744\n",
      "Pretrain epoch [8/289], ZINB loss:0.4015, NB loss:4.4854, latent MSE loss:0.00041686, KL loss:0.00140161\n",
      "Pretrain epoch [9/289], ZINB loss:0.3954, NB loss:4.4853, latent MSE loss:0.00030093, KL loss:0.00123474\n",
      "Pretrain epoch [10/289], ZINB loss:0.3880, NB loss:4.5228, latent MSE loss:0.00033550, KL loss:0.00158760\n",
      "Pretrain epoch [11/289], ZINB loss:0.3920, NB loss:4.5368, latent MSE loss:0.00031790, KL loss:0.00123147\n",
      "Pretrain epoch [12/289], ZINB loss:0.4155, NB loss:4.5592, latent MSE loss:0.00030732, KL loss:0.00124744\n",
      "Pretrain epoch [13/289], ZINB loss:0.3979, NB loss:4.5486, latent MSE loss:0.00026458, KL loss:0.00108807\n",
      "Pretrain epoch [14/289], ZINB loss:0.3926, NB loss:4.5881, latent MSE loss:0.00031987, KL loss:0.00127750\n",
      "Pretrain epoch [15/289], ZINB loss:0.4004, NB loss:4.5367, latent MSE loss:0.00048765, KL loss:0.00149213\n",
      "Pretrain epoch [16/289], ZINB loss:0.3952, NB loss:4.5455, latent MSE loss:0.00035372, KL loss:0.00132738\n",
      "Pretrain epoch [17/289], ZINB loss:0.4045, NB loss:4.5297, latent MSE loss:0.00030312, KL loss:0.00131446\n",
      "Pretrain epoch [18/289], ZINB loss:0.4055, NB loss:4.5704, latent MSE loss:0.00026090, KL loss:0.00128289\n",
      "Pretrain epoch [19/289], ZINB loss:0.4026, NB loss:4.5605, latent MSE loss:0.00035633, KL loss:0.00129166\n",
      "Pretrain epoch [20/289], ZINB loss:0.3837, NB loss:4.5450, latent MSE loss:0.00030228, KL loss:0.00121003\n",
      "Pretrain epoch [21/289], ZINB loss:0.4065, NB loss:4.5185, latent MSE loss:0.00038633, KL loss:0.00109727\n",
      "Pretrain epoch [22/289], ZINB loss:0.3818, NB loss:4.5894, latent MSE loss:0.00025360, KL loss:0.00122267\n",
      "Pretrain epoch [23/289], ZINB loss:0.4072, NB loss:4.5809, latent MSE loss:0.00036408, KL loss:0.00121058\n",
      "Pretrain epoch [24/289], ZINB loss:0.3839, NB loss:4.6066, latent MSE loss:0.00025510, KL loss:0.00112983\n",
      "Pretrain epoch [25/289], ZINB loss:0.3774, NB loss:4.5541, latent MSE loss:0.00027772, KL loss:0.00109179\n",
      "Pretrain epoch [26/289], ZINB loss:0.3767, NB loss:4.5043, latent MSE loss:0.00028475, KL loss:0.00098413\n",
      "Pretrain epoch [27/289], ZINB loss:0.4589, NB loss:4.2622, latent MSE loss:0.00027487, KL loss:0.00007139\n",
      "Pretrain epoch [1/290], ZINB loss:0.3974, NB loss:4.5794, latent MSE loss:0.00038760, KL loss:0.00112145\n",
      "Pretrain epoch [2/290], ZINB loss:0.4057, NB loss:4.5663, latent MSE loss:0.00032949, KL loss:0.00118893\n",
      "Pretrain epoch [3/290], ZINB loss:0.4056, NB loss:4.5837, latent MSE loss:0.00034713, KL loss:0.00114485\n",
      "Pretrain epoch [4/290], ZINB loss:0.3844, NB loss:4.5225, latent MSE loss:0.00028267, KL loss:0.00126087\n",
      "Pretrain epoch [5/290], ZINB loss:0.3768, NB loss:4.5201, latent MSE loss:0.00037329, KL loss:0.00137180\n",
      "Pretrain epoch [6/290], ZINB loss:0.3862, NB loss:4.5773, latent MSE loss:0.00034775, KL loss:0.00121280\n",
      "Pretrain epoch [7/290], ZINB loss:0.3903, NB loss:4.5421, latent MSE loss:0.00030518, KL loss:0.00112527\n",
      "Pretrain epoch [8/290], ZINB loss:0.3821, NB loss:4.5579, latent MSE loss:0.00032856, KL loss:0.00120253\n",
      "Pretrain epoch [9/290], ZINB loss:0.4081, NB loss:4.5529, latent MSE loss:0.00035925, KL loss:0.00178177\n",
      "Pretrain epoch [10/290], ZINB loss:0.4040, NB loss:4.5199, latent MSE loss:0.00030315, KL loss:0.00151360\n",
      "Pretrain epoch [11/290], ZINB loss:0.3904, NB loss:4.5136, latent MSE loss:0.00030061, KL loss:0.00123239\n",
      "Pretrain epoch [12/290], ZINB loss:0.3935, NB loss:4.4972, latent MSE loss:0.00024720, KL loss:0.00116901\n",
      "Pretrain epoch [13/290], ZINB loss:0.3886, NB loss:4.5616, latent MSE loss:0.00029206, KL loss:0.00121597\n",
      "Pretrain epoch [14/290], ZINB loss:0.3900, NB loss:4.5633, latent MSE loss:0.00023539, KL loss:0.00136350\n",
      "Pretrain epoch [15/290], ZINB loss:0.4005, NB loss:4.5302, latent MSE loss:0.00026896, KL loss:0.00113292\n",
      "Pretrain epoch [16/290], ZINB loss:0.3789, NB loss:4.5384, latent MSE loss:0.00023355, KL loss:0.00141714\n",
      "Pretrain epoch [17/290], ZINB loss:0.4023, NB loss:4.5854, latent MSE loss:0.00022160, KL loss:0.00124719\n",
      "Pretrain epoch [18/290], ZINB loss:0.4089, NB loss:4.5848, latent MSE loss:0.00027597, KL loss:0.00126477\n",
      "Pretrain epoch [19/290], ZINB loss:0.3945, NB loss:4.5730, latent MSE loss:0.00028652, KL loss:0.00131762\n",
      "Pretrain epoch [20/290], ZINB loss:0.4001, NB loss:4.4839, latent MSE loss:0.00032527, KL loss:0.00105874\n",
      "Pretrain epoch [21/290], ZINB loss:0.4030, NB loss:4.5793, latent MSE loss:0.00027647, KL loss:0.00114105\n",
      "Pretrain epoch [22/290], ZINB loss:0.3818, NB loss:4.5388, latent MSE loss:0.00027071, KL loss:0.00112377\n",
      "Pretrain epoch [23/290], ZINB loss:0.4201, NB loss:4.5621, latent MSE loss:0.00030732, KL loss:0.00127087\n",
      "Pretrain epoch [24/290], ZINB loss:0.3963, NB loss:4.5517, latent MSE loss:0.00030872, KL loss:0.00169667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [25/290], ZINB loss:0.4142, NB loss:4.5797, latent MSE loss:0.00039823, KL loss:0.00112596\n",
      "Pretrain epoch [26/290], ZINB loss:0.3991, NB loss:4.4993, latent MSE loss:0.00035103, KL loss:0.00094534\n",
      "Pretrain epoch [27/290], ZINB loss:0.4673, NB loss:4.5366, latent MSE loss:0.00030094, KL loss:0.00007755\n",
      "Pretrain epoch [1/291], ZINB loss:0.4200, NB loss:4.6058, latent MSE loss:0.00082058, KL loss:0.00161802\n",
      "Pretrain epoch [2/291], ZINB loss:0.3796, NB loss:4.5457, latent MSE loss:0.00038066, KL loss:0.00106807\n",
      "Pretrain epoch [3/291], ZINB loss:0.3960, NB loss:4.5682, latent MSE loss:0.00050616, KL loss:0.00148294\n",
      "Pretrain epoch [4/291], ZINB loss:0.4005, NB loss:4.5662, latent MSE loss:0.00042779, KL loss:0.00115185\n",
      "Pretrain epoch [5/291], ZINB loss:0.4052, NB loss:4.5282, latent MSE loss:0.00042367, KL loss:0.00137960\n",
      "Pretrain epoch [6/291], ZINB loss:0.3979, NB loss:4.6447, latent MSE loss:0.00044371, KL loss:0.00111708\n",
      "Pretrain epoch [7/291], ZINB loss:0.4031, NB loss:4.5259, latent MSE loss:0.00038744, KL loss:0.00116798\n",
      "Pretrain epoch [8/291], ZINB loss:0.4075, NB loss:4.5442, latent MSE loss:0.00042326, KL loss:0.00129249\n",
      "Pretrain epoch [9/291], ZINB loss:0.4099, NB loss:4.5300, latent MSE loss:0.00040274, KL loss:0.00128546\n",
      "Pretrain epoch [10/291], ZINB loss:0.4043, NB loss:4.5683, latent MSE loss:0.00030473, KL loss:0.00128624\n",
      "Pretrain epoch [11/291], ZINB loss:0.3756, NB loss:4.5444, latent MSE loss:0.00041055, KL loss:0.00118555\n",
      "Pretrain epoch [12/291], ZINB loss:0.3874, NB loss:4.6054, latent MSE loss:0.00033031, KL loss:0.00116588\n",
      "Pretrain epoch [13/291], ZINB loss:0.3771, NB loss:4.4711, latent MSE loss:0.00039125, KL loss:0.00127095\n",
      "Pretrain epoch [14/291], ZINB loss:0.4094, NB loss:4.5632, latent MSE loss:0.00033591, KL loss:0.00138496\n",
      "Pretrain epoch [15/291], ZINB loss:0.4015, NB loss:4.5124, latent MSE loss:0.00040284, KL loss:0.00140284\n",
      "Pretrain epoch [16/291], ZINB loss:0.3867, NB loss:4.5376, latent MSE loss:0.00034422, KL loss:0.00097321\n",
      "Pretrain epoch [17/291], ZINB loss:0.3901, NB loss:4.4775, latent MSE loss:0.00024804, KL loss:0.00093927\n",
      "Pretrain epoch [18/291], ZINB loss:0.4006, NB loss:4.5456, latent MSE loss:0.00027367, KL loss:0.00125012\n",
      "Pretrain epoch [19/291], ZINB loss:0.3884, NB loss:4.5870, latent MSE loss:0.00027250, KL loss:0.00099023\n",
      "Pretrain epoch [20/291], ZINB loss:0.3883, NB loss:4.5299, latent MSE loss:0.00032221, KL loss:0.00096495\n",
      "Pretrain epoch [21/291], ZINB loss:0.4056, NB loss:4.4901, latent MSE loss:0.00038340, KL loss:0.00142728\n",
      "Pretrain epoch [22/291], ZINB loss:0.3933, NB loss:4.5856, latent MSE loss:0.00024384, KL loss:0.00143583\n",
      "Pretrain epoch [23/291], ZINB loss:0.4050, NB loss:4.5303, latent MSE loss:0.00033565, KL loss:0.00140685\n",
      "Pretrain epoch [24/291], ZINB loss:0.3945, NB loss:4.5831, latent MSE loss:0.00032440, KL loss:0.00148228\n",
      "Pretrain epoch [25/291], ZINB loss:0.3891, NB loss:4.5120, latent MSE loss:0.00025305, KL loss:0.00104153\n",
      "Pretrain epoch [26/291], ZINB loss:0.3848, NB loss:4.5212, latent MSE loss:0.00024343, KL loss:0.00094980\n",
      "Pretrain epoch [27/291], ZINB loss:0.5082, NB loss:4.1742, latent MSE loss:0.00054807, KL loss:0.00002887\n",
      "Pretrain epoch [1/292], ZINB loss:0.3981, NB loss:4.5870, latent MSE loss:0.00146360, KL loss:0.00142094\n",
      "Pretrain epoch [2/292], ZINB loss:0.3893, NB loss:4.5302, latent MSE loss:0.00062033, KL loss:0.00126569\n",
      "Pretrain epoch [3/292], ZINB loss:0.4045, NB loss:4.5098, latent MSE loss:0.00090052, KL loss:0.00119449\n",
      "Pretrain epoch [4/292], ZINB loss:0.3957, NB loss:4.5372, latent MSE loss:0.00065382, KL loss:0.00097002\n",
      "Pretrain epoch [5/292], ZINB loss:0.3951, NB loss:4.5192, latent MSE loss:0.00063810, KL loss:0.00136204\n",
      "Pretrain epoch [6/292], ZINB loss:0.3991, NB loss:4.5617, latent MSE loss:0.00095585, KL loss:0.00174879\n",
      "Pretrain epoch [7/292], ZINB loss:0.3911, NB loss:4.5273, latent MSE loss:0.00074650, KL loss:0.00127938\n",
      "Pretrain epoch [8/292], ZINB loss:0.3875, NB loss:4.5498, latent MSE loss:0.00072906, KL loss:0.00118995\n",
      "Pretrain epoch [9/292], ZINB loss:0.4075, NB loss:4.5258, latent MSE loss:0.00104895, KL loss:0.00154940\n",
      "Pretrain epoch [10/292], ZINB loss:0.4211, NB loss:4.6306, latent MSE loss:0.00085253, KL loss:0.00177887\n",
      "Pretrain epoch [11/292], ZINB loss:0.3879, NB loss:4.5234, latent MSE loss:0.00068478, KL loss:0.00132138\n",
      "Pretrain epoch [12/292], ZINB loss:0.3982, NB loss:4.6234, latent MSE loss:0.00072175, KL loss:0.00151293\n",
      "Pretrain epoch [13/292], ZINB loss:0.3960, NB loss:4.5662, latent MSE loss:0.00074604, KL loss:0.00155049\n",
      "Pretrain epoch [14/292], ZINB loss:0.4050, NB loss:4.5383, latent MSE loss:0.00085827, KL loss:0.00113921\n",
      "Pretrain epoch [15/292], ZINB loss:0.3915, NB loss:4.5420, latent MSE loss:0.00055284, KL loss:0.00125005\n",
      "Pretrain epoch [16/292], ZINB loss:0.3904, NB loss:4.5650, latent MSE loss:0.00056584, KL loss:0.00117501\n",
      "Pretrain epoch [17/292], ZINB loss:0.3984, NB loss:4.5562, latent MSE loss:0.00058769, KL loss:0.00120027\n",
      "Pretrain epoch [18/292], ZINB loss:0.4031, NB loss:4.5021, latent MSE loss:0.00058417, KL loss:0.00113600\n",
      "Pretrain epoch [19/292], ZINB loss:0.3994, NB loss:4.5423, latent MSE loss:0.00055656, KL loss:0.00147143\n",
      "Pretrain epoch [20/292], ZINB loss:0.3861, NB loss:4.5356, latent MSE loss:0.00045721, KL loss:0.00102399\n",
      "Pretrain epoch [21/292], ZINB loss:0.4041, NB loss:4.5393, latent MSE loss:0.00045422, KL loss:0.00126973\n",
      "Pretrain epoch [22/292], ZINB loss:0.3727, NB loss:4.5670, latent MSE loss:0.00045718, KL loss:0.00104926\n",
      "Pretrain epoch [23/292], ZINB loss:0.3951, NB loss:4.5623, latent MSE loss:0.00047604, KL loss:0.00144266\n",
      "Pretrain epoch [24/292], ZINB loss:0.3927, NB loss:4.4876, latent MSE loss:0.00049082, KL loss:0.00100113\n",
      "Pretrain epoch [25/292], ZINB loss:0.4012, NB loss:4.5350, latent MSE loss:0.00039045, KL loss:0.00120120\n",
      "Pretrain epoch [26/292], ZINB loss:0.4016, NB loss:4.5236, latent MSE loss:0.00049410, KL loss:0.00132634\n",
      "Pretrain epoch [27/292], ZINB loss:0.3716, NB loss:4.4663, latent MSE loss:0.00043803, KL loss:0.00005508\n",
      "Pretrain epoch [1/293], ZINB loss:0.3911, NB loss:4.5093, latent MSE loss:0.00058483, KL loss:0.00110514\n",
      "Pretrain epoch [2/293], ZINB loss:0.3930, NB loss:4.5560, latent MSE loss:0.00060188, KL loss:0.00153826\n",
      "Pretrain epoch [3/293], ZINB loss:0.3934, NB loss:4.4871, latent MSE loss:0.00062720, KL loss:0.00103671\n",
      "Pretrain epoch [4/293], ZINB loss:0.3963, NB loss:4.5626, latent MSE loss:0.00054732, KL loss:0.00113289\n",
      "Pretrain epoch [5/293], ZINB loss:0.3985, NB loss:4.6032, latent MSE loss:0.00061729, KL loss:0.00112257\n",
      "Pretrain epoch [6/293], ZINB loss:0.3936, NB loss:4.5864, latent MSE loss:0.00039891, KL loss:0.00129532\n",
      "Pretrain epoch [7/293], ZINB loss:0.3741, NB loss:4.5926, latent MSE loss:0.00051509, KL loss:0.00100950\n",
      "Pretrain epoch [8/293], ZINB loss:0.4092, NB loss:4.5744, latent MSE loss:0.00056917, KL loss:0.00131245\n",
      "Pretrain epoch [9/293], ZINB loss:0.3852, NB loss:4.5642, latent MSE loss:0.00049095, KL loss:0.00127386\n",
      "Pretrain epoch [10/293], ZINB loss:0.4013, NB loss:4.5340, latent MSE loss:0.00055523, KL loss:0.00112292\n",
      "Pretrain epoch [11/293], ZINB loss:0.3839, NB loss:4.5481, latent MSE loss:0.00040276, KL loss:0.00130762\n",
      "Pretrain epoch [12/293], ZINB loss:0.3930, NB loss:4.5014, latent MSE loss:0.00060106, KL loss:0.00108068\n",
      "Pretrain epoch [13/293], ZINB loss:0.3946, NB loss:4.5201, latent MSE loss:0.00054053, KL loss:0.00096876\n",
      "Pretrain epoch [14/293], ZINB loss:0.4091, NB loss:4.5361, latent MSE loss:0.00065572, KL loss:0.00125026\n",
      "Pretrain epoch [15/293], ZINB loss:0.3864, NB loss:4.4993, latent MSE loss:0.00056562, KL loss:0.00149135\n",
      "Pretrain epoch [16/293], ZINB loss:0.3967, NB loss:4.5985, latent MSE loss:0.00052582, KL loss:0.00167773\n",
      "Pretrain epoch [17/293], ZINB loss:0.4019, NB loss:4.5758, latent MSE loss:0.00039738, KL loss:0.00124155\n",
      "Pretrain epoch [18/293], ZINB loss:0.3870, NB loss:4.4689, latent MSE loss:0.00045394, KL loss:0.00109205\n",
      "Pretrain epoch [19/293], ZINB loss:0.4039, NB loss:4.5389, latent MSE loss:0.00043559, KL loss:0.00095621\n",
      "Pretrain epoch [20/293], ZINB loss:0.4050, NB loss:4.5078, latent MSE loss:0.00043931, KL loss:0.00102029\n",
      "Pretrain epoch [21/293], ZINB loss:0.3920, NB loss:4.5164, latent MSE loss:0.00041365, KL loss:0.00101780\n",
      "Pretrain epoch [22/293], ZINB loss:0.4193, NB loss:4.5619, latent MSE loss:0.00045518, KL loss:0.00122148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [23/293], ZINB loss:0.3925, NB loss:4.5120, latent MSE loss:0.00047736, KL loss:0.00104497\n",
      "Pretrain epoch [24/293], ZINB loss:0.3866, NB loss:4.5584, latent MSE loss:0.00038356, KL loss:0.00101505\n",
      "Pretrain epoch [25/293], ZINB loss:0.4035, NB loss:4.5986, latent MSE loss:0.00037674, KL loss:0.00128969\n",
      "Pretrain epoch [26/293], ZINB loss:0.4161, NB loss:4.5498, latent MSE loss:0.00036813, KL loss:0.00139832\n",
      "Pretrain epoch [27/293], ZINB loss:0.3581, NB loss:4.7458, latent MSE loss:0.00007571, KL loss:0.00000788\n",
      "Pretrain epoch [1/294], ZINB loss:0.3735, NB loss:4.5415, latent MSE loss:0.00065478, KL loss:0.00096945\n",
      "Pretrain epoch [2/294], ZINB loss:0.3870, NB loss:4.5120, latent MSE loss:0.00092024, KL loss:0.00101783\n",
      "Pretrain epoch [3/294], ZINB loss:0.3914, NB loss:4.5284, latent MSE loss:0.00086166, KL loss:0.00102951\n",
      "Pretrain epoch [4/294], ZINB loss:0.3941, NB loss:4.5231, latent MSE loss:0.00048597, KL loss:0.00110284\n",
      "Pretrain epoch [5/294], ZINB loss:0.4105, NB loss:4.5219, latent MSE loss:0.00031549, KL loss:0.00110479\n",
      "Pretrain epoch [6/294], ZINB loss:0.3784, NB loss:4.5729, latent MSE loss:0.00063610, KL loss:0.00144404\n",
      "Pretrain epoch [7/294], ZINB loss:0.4007, NB loss:4.6135, latent MSE loss:0.00098347, KL loss:0.00145160\n",
      "Pretrain epoch [8/294], ZINB loss:0.3953, NB loss:4.6055, latent MSE loss:0.00086398, KL loss:0.00121708\n",
      "Pretrain epoch [9/294], ZINB loss:0.4034, NB loss:4.4896, latent MSE loss:0.00063605, KL loss:0.00121653\n",
      "Pretrain epoch [10/294], ZINB loss:0.3818, NB loss:4.4939, latent MSE loss:0.00027241, KL loss:0.00106348\n",
      "Pretrain epoch [11/294], ZINB loss:0.3925, NB loss:4.5084, latent MSE loss:0.00046457, KL loss:0.00115275\n",
      "Pretrain epoch [12/294], ZINB loss:0.3941, NB loss:4.5405, latent MSE loss:0.00075370, KL loss:0.00119056\n",
      "Pretrain epoch [13/294], ZINB loss:0.3891, NB loss:4.5329, latent MSE loss:0.00057682, KL loss:0.00130828\n",
      "Pretrain epoch [14/294], ZINB loss:0.3894, NB loss:4.6268, latent MSE loss:0.00035158, KL loss:0.00164674\n",
      "Pretrain epoch [15/294], ZINB loss:0.4075, NB loss:4.4942, latent MSE loss:0.00029605, KL loss:0.00128068\n",
      "Pretrain epoch [16/294], ZINB loss:0.4111, NB loss:4.5849, latent MSE loss:0.00058382, KL loss:0.00119683\n",
      "Pretrain epoch [17/294], ZINB loss:0.4173, NB loss:4.5886, latent MSE loss:0.00060144, KL loss:0.00134001\n",
      "Pretrain epoch [18/294], ZINB loss:0.3981, NB loss:4.5269, latent MSE loss:0.00037420, KL loss:0.00116642\n",
      "Pretrain epoch [19/294], ZINB loss:0.4005, NB loss:4.5239, latent MSE loss:0.00028950, KL loss:0.00107901\n",
      "Pretrain epoch [20/294], ZINB loss:0.4007, NB loss:4.5543, latent MSE loss:0.00045442, KL loss:0.00103815\n",
      "Pretrain epoch [21/294], ZINB loss:0.3972, NB loss:4.5479, latent MSE loss:0.00045948, KL loss:0.00111210\n",
      "Pretrain epoch [22/294], ZINB loss:0.4007, NB loss:4.5142, latent MSE loss:0.00022566, KL loss:0.00102112\n",
      "Pretrain epoch [23/294], ZINB loss:0.3964, NB loss:4.5393, latent MSE loss:0.00038821, KL loss:0.00118243\n",
      "Pretrain epoch [24/294], ZINB loss:0.3931, NB loss:4.5198, latent MSE loss:0.00038585, KL loss:0.00115083\n",
      "Pretrain epoch [25/294], ZINB loss:0.4111, NB loss:4.5538, latent MSE loss:0.00029646, KL loss:0.00145375\n",
      "Pretrain epoch [26/294], ZINB loss:0.3904, NB loss:4.5790, latent MSE loss:0.00029037, KL loss:0.00108414\n",
      "Pretrain epoch [27/294], ZINB loss:0.3721, NB loss:4.7747, latent MSE loss:0.00023239, KL loss:0.00000838\n",
      "Pretrain epoch [1/295], ZINB loss:0.3982, NB loss:4.6438, latent MSE loss:0.00094800, KL loss:0.00121306\n",
      "Pretrain epoch [2/295], ZINB loss:0.3990, NB loss:4.6045, latent MSE loss:0.00077157, KL loss:0.00107394\n",
      "Pretrain epoch [3/295], ZINB loss:0.4005, NB loss:4.5178, latent MSE loss:0.00060654, KL loss:0.00131444\n",
      "Pretrain epoch [4/295], ZINB loss:0.3963, NB loss:4.5557, latent MSE loss:0.00059651, KL loss:0.00109596\n",
      "Pretrain epoch [5/295], ZINB loss:0.3896, NB loss:4.5017, latent MSE loss:0.00067628, KL loss:0.00105890\n",
      "Pretrain epoch [6/295], ZINB loss:0.4022, NB loss:4.5171, latent MSE loss:0.00073462, KL loss:0.00099102\n",
      "Pretrain epoch [7/295], ZINB loss:0.3845, NB loss:4.6002, latent MSE loss:0.00039417, KL loss:0.00145458\n",
      "Pretrain epoch [8/295], ZINB loss:0.3910, NB loss:4.5421, latent MSE loss:0.00064240, KL loss:0.00099616\n",
      "Pretrain epoch [9/295], ZINB loss:0.3909, NB loss:4.5377, latent MSE loss:0.00066611, KL loss:0.00121021\n",
      "Pretrain epoch [10/295], ZINB loss:0.4091, NB loss:4.4885, latent MSE loss:0.00049817, KL loss:0.00113987\n",
      "Pretrain epoch [11/295], ZINB loss:0.3880, NB loss:4.5562, latent MSE loss:0.00042551, KL loss:0.00104471\n",
      "Pretrain epoch [12/295], ZINB loss:0.4110, NB loss:4.4998, latent MSE loss:0.00041520, KL loss:0.00139681\n",
      "Pretrain epoch [13/295], ZINB loss:0.3844, NB loss:4.5262, latent MSE loss:0.00043971, KL loss:0.00149940\n",
      "Pretrain epoch [14/295], ZINB loss:0.3791, NB loss:4.5209, latent MSE loss:0.00031476, KL loss:0.00100084\n",
      "Pretrain epoch [15/295], ZINB loss:0.4034, NB loss:4.5192, latent MSE loss:0.00032549, KL loss:0.00143481\n",
      "Pretrain epoch [16/295], ZINB loss:0.4168, NB loss:4.6210, latent MSE loss:0.00039711, KL loss:0.00117858\n",
      "Pretrain epoch [17/295], ZINB loss:0.4000, NB loss:4.4731, latent MSE loss:0.00040742, KL loss:0.00101823\n",
      "Pretrain epoch [18/295], ZINB loss:0.3791, NB loss:4.5676, latent MSE loss:0.00030108, KL loss:0.00127516\n",
      "Pretrain epoch [19/295], ZINB loss:0.4030, NB loss:4.5205, latent MSE loss:0.00043670, KL loss:0.00120726\n",
      "Pretrain epoch [20/295], ZINB loss:0.3944, NB loss:4.5442, latent MSE loss:0.00043451, KL loss:0.00159763\n",
      "Pretrain epoch [21/295], ZINB loss:0.4013, NB loss:4.5440, latent MSE loss:0.00038871, KL loss:0.00121063\n",
      "Pretrain epoch [22/295], ZINB loss:0.3975, NB loss:4.5418, latent MSE loss:0.00027847, KL loss:0.00093734\n",
      "Pretrain epoch [23/295], ZINB loss:0.4130, NB loss:4.6026, latent MSE loss:0.00035060, KL loss:0.00107403\n",
      "Pretrain epoch [24/295], ZINB loss:0.3873, NB loss:4.5002, latent MSE loss:0.00035882, KL loss:0.00125378\n",
      "Pretrain epoch [25/295], ZINB loss:0.3897, NB loss:4.5651, latent MSE loss:0.00021942, KL loss:0.00121261\n",
      "Pretrain epoch [26/295], ZINB loss:0.3906, NB loss:4.4887, latent MSE loss:0.00027280, KL loss:0.00096191\n",
      "Pretrain epoch [27/295], ZINB loss:0.3439, NB loss:4.3223, latent MSE loss:0.00022873, KL loss:0.00000908\n",
      "Pretrain epoch [1/296], ZINB loss:0.4111, NB loss:4.5001, latent MSE loss:0.00080170, KL loss:0.00115461\n",
      "Pretrain epoch [2/296], ZINB loss:0.4155, NB loss:4.5036, latent MSE loss:0.00059595, KL loss:0.00110607\n",
      "Pretrain epoch [3/296], ZINB loss:0.3874, NB loss:4.5473, latent MSE loss:0.00044452, KL loss:0.00101317\n",
      "Pretrain epoch [4/296], ZINB loss:0.3927, NB loss:4.5093, latent MSE loss:0.00071111, KL loss:0.00115072\n",
      "Pretrain epoch [5/296], ZINB loss:0.3897, NB loss:4.6028, latent MSE loss:0.00047399, KL loss:0.00102686\n",
      "Pretrain epoch [6/296], ZINB loss:0.3921, NB loss:4.5291, latent MSE loss:0.00048033, KL loss:0.00096965\n",
      "Pretrain epoch [7/296], ZINB loss:0.3763, NB loss:4.5273, latent MSE loss:0.00049744, KL loss:0.00095155\n",
      "Pretrain epoch [8/296], ZINB loss:0.3813, NB loss:4.5322, latent MSE loss:0.00053283, KL loss:0.00105071\n",
      "Pretrain epoch [9/296], ZINB loss:0.4074, NB loss:4.5325, latent MSE loss:0.00047973, KL loss:0.00098632\n",
      "Pretrain epoch [10/296], ZINB loss:0.3898, NB loss:4.5566, latent MSE loss:0.00037081, KL loss:0.00136669\n",
      "Pretrain epoch [11/296], ZINB loss:0.3850, NB loss:4.5538, latent MSE loss:0.00058942, KL loss:0.00107395\n",
      "Pretrain epoch [12/296], ZINB loss:0.3790, NB loss:4.4867, latent MSE loss:0.00055087, KL loss:0.00141613\n",
      "Pretrain epoch [13/296], ZINB loss:0.4232, NB loss:4.5782, latent MSE loss:0.00043592, KL loss:0.00172236\n",
      "Pretrain epoch [14/296], ZINB loss:0.4158, NB loss:4.5454, latent MSE loss:0.00042140, KL loss:0.00122472\n",
      "Pretrain epoch [15/296], ZINB loss:0.4084, NB loss:4.4835, latent MSE loss:0.00048867, KL loss:0.00111390\n",
      "Pretrain epoch [16/296], ZINB loss:0.3950, NB loss:4.5450, latent MSE loss:0.00032404, KL loss:0.00090409\n",
      "Pretrain epoch [17/296], ZINB loss:0.3879, NB loss:4.5320, latent MSE loss:0.00029645, KL loss:0.00106915\n",
      "Pretrain epoch [18/296], ZINB loss:0.4010, NB loss:4.5577, latent MSE loss:0.00052705, KL loss:0.00120923\n",
      "Pretrain epoch [19/296], ZINB loss:0.3888, NB loss:4.5538, latent MSE loss:0.00043548, KL loss:0.00113135\n",
      "Pretrain epoch [20/296], ZINB loss:0.3872, NB loss:4.5765, latent MSE loss:0.00033501, KL loss:0.00131857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [21/296], ZINB loss:0.4010, NB loss:4.5157, latent MSE loss:0.00049974, KL loss:0.00131781\n",
      "Pretrain epoch [22/296], ZINB loss:0.3834, NB loss:4.5427, latent MSE loss:0.00045757, KL loss:0.00118162\n",
      "Pretrain epoch [23/296], ZINB loss:0.4108, NB loss:4.5339, latent MSE loss:0.00038990, KL loss:0.00105775\n",
      "Pretrain epoch [24/296], ZINB loss:0.3855, NB loss:4.6032, latent MSE loss:0.00036858, KL loss:0.00126661\n",
      "Pretrain epoch [25/296], ZINB loss:0.4123, NB loss:4.5444, latent MSE loss:0.00057825, KL loss:0.00141081\n",
      "Pretrain epoch [26/296], ZINB loss:0.3943, NB loss:4.5506, latent MSE loss:0.00046273, KL loss:0.00134253\n",
      "Pretrain epoch [27/296], ZINB loss:0.4564, NB loss:5.5024, latent MSE loss:0.00038367, KL loss:0.00001220\n",
      "Pretrain epoch [1/297], ZINB loss:0.4020, NB loss:4.5668, latent MSE loss:0.00090115, KL loss:0.00162277\n",
      "Pretrain epoch [2/297], ZINB loss:0.3940, NB loss:4.5598, latent MSE loss:0.00094762, KL loss:0.00111294\n",
      "Pretrain epoch [3/297], ZINB loss:0.3990, NB loss:4.4988, latent MSE loss:0.00059872, KL loss:0.00109852\n",
      "Pretrain epoch [4/297], ZINB loss:0.3984, NB loss:4.5547, latent MSE loss:0.00074958, KL loss:0.00117888\n",
      "Pretrain epoch [5/297], ZINB loss:0.3906, NB loss:4.5116, latent MSE loss:0.00099775, KL loss:0.00105862\n",
      "Pretrain epoch [6/297], ZINB loss:0.4161, NB loss:4.5860, latent MSE loss:0.00057368, KL loss:0.00174905\n",
      "Pretrain epoch [7/297], ZINB loss:0.3963, NB loss:4.5872, latent MSE loss:0.00065971, KL loss:0.00118274\n",
      "Pretrain epoch [8/297], ZINB loss:0.3952, NB loss:4.5170, latent MSE loss:0.00089894, KL loss:0.00131409\n",
      "Pretrain epoch [9/297], ZINB loss:0.3863, NB loss:4.5037, latent MSE loss:0.00061880, KL loss:0.00102709\n",
      "Pretrain epoch [10/297], ZINB loss:0.3929, NB loss:4.5417, latent MSE loss:0.00059734, KL loss:0.00110513\n",
      "Pretrain epoch [11/297], ZINB loss:0.3917, NB loss:4.5231, latent MSE loss:0.00075077, KL loss:0.00113407\n",
      "Pretrain epoch [12/297], ZINB loss:0.3981, NB loss:4.5388, latent MSE loss:0.00050497, KL loss:0.00119548\n",
      "Pretrain epoch [13/297], ZINB loss:0.3959, NB loss:4.4997, latent MSE loss:0.00060483, KL loss:0.00107383\n",
      "Pretrain epoch [14/297], ZINB loss:0.3762, NB loss:4.5137, latent MSE loss:0.00088438, KL loss:0.00102122\n",
      "Pretrain epoch [15/297], ZINB loss:0.4021, NB loss:4.5074, latent MSE loss:0.00085008, KL loss:0.00123599\n",
      "Pretrain epoch [16/297], ZINB loss:0.4041, NB loss:4.5014, latent MSE loss:0.00049923, KL loss:0.00113242\n",
      "Pretrain epoch [17/297], ZINB loss:0.3909, NB loss:4.5650, latent MSE loss:0.00068026, KL loss:0.00099513\n",
      "Pretrain epoch [18/297], ZINB loss:0.3942, NB loss:4.5829, latent MSE loss:0.00063310, KL loss:0.00099601\n",
      "Pretrain epoch [19/297], ZINB loss:0.3791, NB loss:4.5171, latent MSE loss:0.00053212, KL loss:0.00107703\n",
      "Pretrain epoch [20/297], ZINB loss:0.3984, NB loss:4.5422, latent MSE loss:0.00044508, KL loss:0.00152320\n",
      "Pretrain epoch [21/297], ZINB loss:0.3890, NB loss:4.5643, latent MSE loss:0.00055828, KL loss:0.00121372\n",
      "Pretrain epoch [22/297], ZINB loss:0.4020, NB loss:4.5809, latent MSE loss:0.00060871, KL loss:0.00110718\n",
      "Pretrain epoch [23/297], ZINB loss:0.4071, NB loss:4.5785, latent MSE loss:0.00035311, KL loss:0.00157181\n",
      "Pretrain epoch [24/297], ZINB loss:0.3995, NB loss:4.5566, latent MSE loss:0.00050478, KL loss:0.00103101\n",
      "Pretrain epoch [25/297], ZINB loss:0.4071, NB loss:4.5646, latent MSE loss:0.00043564, KL loss:0.00118864\n",
      "Pretrain epoch [26/297], ZINB loss:0.4030, NB loss:4.4904, latent MSE loss:0.00032686, KL loss:0.00095231\n",
      "Pretrain epoch [27/297], ZINB loss:0.4215, NB loss:4.9203, latent MSE loss:0.00033396, KL loss:0.00005116\n",
      "Pretrain epoch [1/298], ZINB loss:0.4014, NB loss:4.5173, latent MSE loss:0.00055953, KL loss:0.00102085\n",
      "Pretrain epoch [2/298], ZINB loss:0.4137, NB loss:4.5840, latent MSE loss:0.00055500, KL loss:0.00108207\n",
      "Pretrain epoch [3/298], ZINB loss:0.4009, NB loss:4.5656, latent MSE loss:0.00048031, KL loss:0.00100619\n",
      "Pretrain epoch [4/298], ZINB loss:0.3873, NB loss:4.5155, latent MSE loss:0.00065930, KL loss:0.00111398\n",
      "Pretrain epoch [5/298], ZINB loss:0.3801, NB loss:4.5794, latent MSE loss:0.00046817, KL loss:0.00110175\n",
      "Pretrain epoch [6/298], ZINB loss:0.4092, NB loss:4.5853, latent MSE loss:0.00068303, KL loss:0.00104838\n",
      "Pretrain epoch [7/298], ZINB loss:0.3905, NB loss:4.4899, latent MSE loss:0.00046369, KL loss:0.00125496\n",
      "Pretrain epoch [8/298], ZINB loss:0.3836, NB loss:4.4854, latent MSE loss:0.00055763, KL loss:0.00108000\n",
      "Pretrain epoch [9/298], ZINB loss:0.3969, NB loss:4.5021, latent MSE loss:0.00050420, KL loss:0.00121488\n",
      "Pretrain epoch [10/298], ZINB loss:0.3965, NB loss:4.5968, latent MSE loss:0.00058666, KL loss:0.00159117\n",
      "Pretrain epoch [11/298], ZINB loss:0.4065, NB loss:4.5432, latent MSE loss:0.00049740, KL loss:0.00129710\n",
      "Pretrain epoch [12/298], ZINB loss:0.3846, NB loss:4.5056, latent MSE loss:0.00035350, KL loss:0.00104318\n",
      "Pretrain epoch [13/298], ZINB loss:0.3962, NB loss:4.5103, latent MSE loss:0.00055559, KL loss:0.00116555\n",
      "Pretrain epoch [14/298], ZINB loss:0.4021, NB loss:4.5181, latent MSE loss:0.00040659, KL loss:0.00101494\n",
      "Pretrain epoch [15/298], ZINB loss:0.3861, NB loss:4.4965, latent MSE loss:0.00040973, KL loss:0.00106671\n",
      "Pretrain epoch [16/298], ZINB loss:0.4001, NB loss:4.5373, latent MSE loss:0.00046009, KL loss:0.00098427\n",
      "Pretrain epoch [17/298], ZINB loss:0.3905, NB loss:4.5436, latent MSE loss:0.00043930, KL loss:0.00104457\n",
      "Pretrain epoch [18/298], ZINB loss:0.4055, NB loss:4.5476, latent MSE loss:0.00035903, KL loss:0.00117858\n",
      "Pretrain epoch [19/298], ZINB loss:0.3990, NB loss:4.5342, latent MSE loss:0.00041617, KL loss:0.00093951\n",
      "Pretrain epoch [20/298], ZINB loss:0.4194, NB loss:4.5888, latent MSE loss:0.00047286, KL loss:0.00129880\n",
      "Pretrain epoch [21/298], ZINB loss:0.3912, NB loss:4.5729, latent MSE loss:0.00043289, KL loss:0.00099028\n",
      "Pretrain epoch [22/298], ZINB loss:0.3999, NB loss:4.5118, latent MSE loss:0.00052598, KL loss:0.00098606\n",
      "Pretrain epoch [23/298], ZINB loss:0.3794, NB loss:4.5769, latent MSE loss:0.00054698, KL loss:0.00122689\n",
      "Pretrain epoch [24/298], ZINB loss:0.4033, NB loss:4.5477, latent MSE loss:0.00040242, KL loss:0.00099877\n",
      "Pretrain epoch [25/298], ZINB loss:0.3888, NB loss:4.5313, latent MSE loss:0.00044799, KL loss:0.00150359\n",
      "Pretrain epoch [26/298], ZINB loss:0.3944, NB loss:4.5419, latent MSE loss:0.00034737, KL loss:0.00128223\n",
      "Pretrain epoch [27/298], ZINB loss:0.3833, NB loss:4.8913, latent MSE loss:0.00037397, KL loss:0.00004977\n",
      "Pretrain epoch [1/299], ZINB loss:0.3965, NB loss:4.5286, latent MSE loss:0.00042882, KL loss:0.00101050\n",
      "Pretrain epoch [2/299], ZINB loss:0.4058, NB loss:4.5113, latent MSE loss:0.00053766, KL loss:0.00113556\n",
      "Pretrain epoch [3/299], ZINB loss:0.3988, NB loss:4.5359, latent MSE loss:0.00032046, KL loss:0.00095753\n",
      "Pretrain epoch [4/299], ZINB loss:0.3956, NB loss:4.5832, latent MSE loss:0.00041236, KL loss:0.00123953\n",
      "Pretrain epoch [5/299], ZINB loss:0.3943, NB loss:4.5495, latent MSE loss:0.00041768, KL loss:0.00122485\n",
      "Pretrain epoch [6/299], ZINB loss:0.3951, NB loss:4.5771, latent MSE loss:0.00038167, KL loss:0.00134894\n",
      "Pretrain epoch [7/299], ZINB loss:0.4132, NB loss:4.5418, latent MSE loss:0.00039523, KL loss:0.00121856\n",
      "Pretrain epoch [8/299], ZINB loss:0.4110, NB loss:4.4874, latent MSE loss:0.00038352, KL loss:0.00120824\n",
      "Pretrain epoch [9/299], ZINB loss:0.3933, NB loss:4.6184, latent MSE loss:0.00024664, KL loss:0.00100393\n",
      "Pretrain epoch [10/299], ZINB loss:0.3879, NB loss:4.4739, latent MSE loss:0.00026846, KL loss:0.00093442\n",
      "Pretrain epoch [11/299], ZINB loss:0.3813, NB loss:4.5768, latent MSE loss:0.00025903, KL loss:0.00107643\n",
      "Pretrain epoch [12/299], ZINB loss:0.4085, NB loss:4.5313, latent MSE loss:0.00031647, KL loss:0.00144797\n",
      "Pretrain epoch [13/299], ZINB loss:0.4108, NB loss:4.5786, latent MSE loss:0.00037864, KL loss:0.00130934\n",
      "Pretrain epoch [14/299], ZINB loss:0.3886, NB loss:4.5374, latent MSE loss:0.00024975, KL loss:0.00098614\n",
      "Pretrain epoch [15/299], ZINB loss:0.3839, NB loss:4.5581, latent MSE loss:0.00019364, KL loss:0.00116891\n",
      "Pretrain epoch [16/299], ZINB loss:0.3893, NB loss:4.5166, latent MSE loss:0.00030543, KL loss:0.00105149\n",
      "Pretrain epoch [17/299], ZINB loss:0.3965, NB loss:4.4928, latent MSE loss:0.00025853, KL loss:0.00099788\n",
      "Pretrain epoch [18/299], ZINB loss:0.4012, NB loss:4.5379, latent MSE loss:0.00028095, KL loss:0.00121018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [19/299], ZINB loss:0.3962, NB loss:4.5633, latent MSE loss:0.00030737, KL loss:0.00136131\n",
      "Pretrain epoch [20/299], ZINB loss:0.3882, NB loss:4.5446, latent MSE loss:0.00021591, KL loss:0.00101679\n",
      "Pretrain epoch [21/299], ZINB loss:0.4027, NB loss:4.5158, latent MSE loss:0.00024393, KL loss:0.00134281\n",
      "Pretrain epoch [22/299], ZINB loss:0.3913, NB loss:4.4713, latent MSE loss:0.00021196, KL loss:0.00089775\n",
      "Pretrain epoch [23/299], ZINB loss:0.3954, NB loss:4.5376, latent MSE loss:0.00025201, KL loss:0.00103029\n",
      "Pretrain epoch [24/299], ZINB loss:0.3780, NB loss:4.5436, latent MSE loss:0.00016548, KL loss:0.00094234\n",
      "Pretrain epoch [25/299], ZINB loss:0.3877, NB loss:4.5350, latent MSE loss:0.00020374, KL loss:0.00093783\n",
      "Pretrain epoch [26/299], ZINB loss:0.4059, NB loss:4.5647, latent MSE loss:0.00024915, KL loss:0.00107751\n",
      "Pretrain epoch [27/299], ZINB loss:0.3521, NB loss:4.3884, latent MSE loss:0.00012399, KL loss:0.00007073\n",
      "Pretrain epoch [1/300], ZINB loss:0.3935, NB loss:4.5084, latent MSE loss:0.00024208, KL loss:0.00096942\n",
      "Pretrain epoch [2/300], ZINB loss:0.3998, NB loss:4.5209, latent MSE loss:0.00019581, KL loss:0.00088098\n",
      "Pretrain epoch [3/300], ZINB loss:0.4074, NB loss:4.5624, latent MSE loss:0.00028789, KL loss:0.00127676\n",
      "Pretrain epoch [4/300], ZINB loss:0.3944, NB loss:4.5055, latent MSE loss:0.00027378, KL loss:0.00104531\n",
      "Pretrain epoch [5/300], ZINB loss:0.3848, NB loss:4.5672, latent MSE loss:0.00021446, KL loss:0.00127671\n",
      "Pretrain epoch [6/300], ZINB loss:0.3865, NB loss:4.5348, latent MSE loss:0.00024866, KL loss:0.00104510\n",
      "Pretrain epoch [7/300], ZINB loss:0.3928, NB loss:4.5229, latent MSE loss:0.00025592, KL loss:0.00110525\n",
      "Pretrain epoch [8/300], ZINB loss:0.3945, NB loss:4.5557, latent MSE loss:0.00023361, KL loss:0.00103282\n",
      "Pretrain epoch [9/300], ZINB loss:0.3930, NB loss:4.5692, latent MSE loss:0.00023958, KL loss:0.00099958\n",
      "Pretrain epoch [10/300], ZINB loss:0.3977, NB loss:4.5257, latent MSE loss:0.00026453, KL loss:0.00096276\n",
      "Pretrain epoch [11/300], ZINB loss:0.4129, NB loss:4.6240, latent MSE loss:0.00033428, KL loss:0.00105797\n",
      "Pretrain epoch [12/300], ZINB loss:0.3893, NB loss:4.5693, latent MSE loss:0.00022710, KL loss:0.00089476\n",
      "Pretrain epoch [13/300], ZINB loss:0.4132, NB loss:4.4712, latent MSE loss:0.00031365, KL loss:0.00094404\n",
      "Pretrain epoch [14/300], ZINB loss:0.3850, NB loss:4.5207, latent MSE loss:0.00028636, KL loss:0.00122071\n",
      "Pretrain epoch [15/300], ZINB loss:0.3992, NB loss:4.5842, latent MSE loss:0.00028003, KL loss:0.00111387\n",
      "Pretrain epoch [16/300], ZINB loss:0.4149, NB loss:4.5399, latent MSE loss:0.00027685, KL loss:0.00120604\n",
      "Pretrain epoch [17/300], ZINB loss:0.3814, NB loss:4.5981, latent MSE loss:0.00030264, KL loss:0.00114724\n",
      "Pretrain epoch [18/300], ZINB loss:0.4029, NB loss:4.5739, latent MSE loss:0.00031469, KL loss:0.00141065\n",
      "Pretrain epoch [19/300], ZINB loss:0.3775, NB loss:4.5046, latent MSE loss:0.00026635, KL loss:0.00099981\n",
      "Pretrain epoch [20/300], ZINB loss:0.3861, NB loss:4.5096, latent MSE loss:0.00029358, KL loss:0.00085937\n",
      "Pretrain epoch [21/300], ZINB loss:0.4070, NB loss:4.4615, latent MSE loss:0.00027753, KL loss:0.00124846\n",
      "Pretrain epoch [22/300], ZINB loss:0.3856, NB loss:4.4840, latent MSE loss:0.00023746, KL loss:0.00089570\n",
      "Pretrain epoch [23/300], ZINB loss:0.3950, NB loss:4.5455, latent MSE loss:0.00032020, KL loss:0.00109248\n",
      "Pretrain epoch [24/300], ZINB loss:0.3925, NB loss:4.5819, latent MSE loss:0.00028176, KL loss:0.00107841\n",
      "Pretrain epoch [25/300], ZINB loss:0.3994, NB loss:4.4583, latent MSE loss:0.00026553, KL loss:0.00101240\n",
      "Pretrain epoch [26/300], ZINB loss:0.4028, NB loss:4.5527, latent MSE loss:0.00026201, KL loss:0.00120595\n",
      "Pretrain epoch [27/300], ZINB loss:0.3448, NB loss:4.6308, latent MSE loss:0.00011935, KL loss:0.00000114\n",
      "Pretrain epoch [1/301], ZINB loss:0.3995, NB loss:4.5460, latent MSE loss:0.00049464, KL loss:0.00116850\n",
      "Pretrain epoch [2/301], ZINB loss:0.3949, NB loss:4.5377, latent MSE loss:0.00064005, KL loss:0.00106681\n",
      "Pretrain epoch [3/301], ZINB loss:0.3990, NB loss:4.5572, latent MSE loss:0.00070531, KL loss:0.00112253\n",
      "Pretrain epoch [4/301], ZINB loss:0.3942, NB loss:4.5636, latent MSE loss:0.00044194, KL loss:0.00146021\n",
      "Pretrain epoch [5/301], ZINB loss:0.4130, NB loss:4.5926, latent MSE loss:0.00029993, KL loss:0.00104312\n",
      "Pretrain epoch [6/301], ZINB loss:0.3932, NB loss:4.6029, latent MSE loss:0.00031112, KL loss:0.00092601\n",
      "Pretrain epoch [7/301], ZINB loss:0.4008, NB loss:4.5581, latent MSE loss:0.00045976, KL loss:0.00132937\n",
      "Pretrain epoch [8/301], ZINB loss:0.4030, NB loss:4.5757, latent MSE loss:0.00040940, KL loss:0.00110139\n",
      "Pretrain epoch [9/301], ZINB loss:0.3985, NB loss:4.5868, latent MSE loss:0.00028185, KL loss:0.00134062\n",
      "Pretrain epoch [10/301], ZINB loss:0.3846, NB loss:4.5666, latent MSE loss:0.00021977, KL loss:0.00130092\n",
      "Pretrain epoch [11/301], ZINB loss:0.3947, NB loss:4.4419, latent MSE loss:0.00028853, KL loss:0.00088949\n",
      "Pretrain epoch [12/301], ZINB loss:0.3876, NB loss:4.4906, latent MSE loss:0.00030842, KL loss:0.00095374\n",
      "Pretrain epoch [13/301], ZINB loss:0.4156, NB loss:4.5685, latent MSE loss:0.00034457, KL loss:0.00107618\n",
      "Pretrain epoch [14/301], ZINB loss:0.3889, NB loss:4.5065, latent MSE loss:0.00026270, KL loss:0.00100410\n",
      "Pretrain epoch [15/301], ZINB loss:0.3882, NB loss:4.5324, latent MSE loss:0.00027074, KL loss:0.00088755\n",
      "Pretrain epoch [16/301], ZINB loss:0.3927, NB loss:4.5513, latent MSE loss:0.00030430, KL loss:0.00093622\n",
      "Pretrain epoch [17/301], ZINB loss:0.3971, NB loss:4.5407, latent MSE loss:0.00035757, KL loss:0.00107985\n",
      "Pretrain epoch [18/301], ZINB loss:0.4137, NB loss:4.4320, latent MSE loss:0.00042886, KL loss:0.00091418\n",
      "Pretrain epoch [19/301], ZINB loss:0.3763, NB loss:4.5265, latent MSE loss:0.00030173, KL loss:0.00105088\n",
      "Pretrain epoch [20/301], ZINB loss:0.3749, NB loss:4.5038, latent MSE loss:0.00027784, KL loss:0.00088734\n",
      "Pretrain epoch [21/301], ZINB loss:0.3741, NB loss:4.5700, latent MSE loss:0.00043354, KL loss:0.00102866\n",
      "Pretrain epoch [22/301], ZINB loss:0.4018, NB loss:4.5044, latent MSE loss:0.00033516, KL loss:0.00097903\n",
      "Pretrain epoch [23/301], ZINB loss:0.3982, NB loss:4.5317, latent MSE loss:0.00034823, KL loss:0.00088865\n",
      "Pretrain epoch [24/301], ZINB loss:0.4178, NB loss:4.5422, latent MSE loss:0.00034043, KL loss:0.00129658\n",
      "Pretrain epoch [25/301], ZINB loss:0.3888, NB loss:4.5420, latent MSE loss:0.00025867, KL loss:0.00126378\n",
      "Pretrain epoch [26/301], ZINB loss:0.3925, NB loss:4.4923, latent MSE loss:0.00026303, KL loss:0.00085251\n",
      "Pretrain epoch [27/301], ZINB loss:0.4850, NB loss:4.2975, latent MSE loss:0.00123844, KL loss:0.00005737\n",
      "Pretrain epoch [1/302], ZINB loss:0.4054, NB loss:4.5151, latent MSE loss:0.00202369, KL loss:0.00109044\n",
      "Pretrain epoch [2/302], ZINB loss:0.3929, NB loss:4.5474, latent MSE loss:0.00140148, KL loss:0.00122888\n",
      "Pretrain epoch [3/302], ZINB loss:0.3890, NB loss:4.5706, latent MSE loss:0.00257611, KL loss:0.00175242\n",
      "Pretrain epoch [4/302], ZINB loss:0.4126, NB loss:4.4906, latent MSE loss:0.00140058, KL loss:0.00122092\n",
      "Pretrain epoch [5/302], ZINB loss:0.3996, NB loss:4.5767, latent MSE loss:0.00238158, KL loss:0.00119913\n",
      "Pretrain epoch [6/302], ZINB loss:0.4069, NB loss:4.5585, latent MSE loss:0.00423735, KL loss:0.00158904\n",
      "Pretrain epoch [7/302], ZINB loss:0.3905, NB loss:4.5254, latent MSE loss:0.00212476, KL loss:0.00108375\n",
      "Pretrain epoch [8/302], ZINB loss:0.3932, NB loss:4.5184, latent MSE loss:0.00145731, KL loss:0.00151705\n",
      "Pretrain epoch [9/302], ZINB loss:0.3991, NB loss:4.5486, latent MSE loss:0.00115386, KL loss:0.00147336\n",
      "Pretrain epoch [10/302], ZINB loss:0.4011, NB loss:4.6103, latent MSE loss:0.00129720, KL loss:0.00143766\n",
      "Pretrain epoch [11/302], ZINB loss:0.4060, NB loss:4.4926, latent MSE loss:0.00159520, KL loss:0.00106724\n",
      "Pretrain epoch [12/302], ZINB loss:0.3814, NB loss:4.4372, latent MSE loss:0.00177948, KL loss:0.00164718\n",
      "Pretrain epoch [13/302], ZINB loss:0.3833, NB loss:4.5277, latent MSE loss:0.00104035, KL loss:0.00132509\n",
      "Pretrain epoch [14/302], ZINB loss:0.4160, NB loss:4.5456, latent MSE loss:0.00125944, KL loss:0.00122030\n",
      "Pretrain epoch [15/302], ZINB loss:0.3961, NB loss:4.5106, latent MSE loss:0.00137092, KL loss:0.00101224\n",
      "Pretrain epoch [16/302], ZINB loss:0.3998, NB loss:4.5362, latent MSE loss:0.00130000, KL loss:0.00121592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [17/302], ZINB loss:0.4113, NB loss:4.4964, latent MSE loss:0.00166315, KL loss:0.00146727\n",
      "Pretrain epoch [18/302], ZINB loss:0.4152, NB loss:4.5194, latent MSE loss:0.00121647, KL loss:0.00154628\n",
      "Pretrain epoch [19/302], ZINB loss:0.4032, NB loss:4.5386, latent MSE loss:0.00116407, KL loss:0.00150378\n",
      "Pretrain epoch [20/302], ZINB loss:0.3874, NB loss:4.5299, latent MSE loss:0.00107263, KL loss:0.00121788\n",
      "Pretrain epoch [21/302], ZINB loss:0.3978, NB loss:4.5153, latent MSE loss:0.00132046, KL loss:0.00131222\n",
      "Pretrain epoch [22/302], ZINB loss:0.3910, NB loss:4.5691, latent MSE loss:0.00143164, KL loss:0.00125869\n",
      "Pretrain epoch [23/302], ZINB loss:0.3955, NB loss:4.5957, latent MSE loss:0.00081117, KL loss:0.00135192\n",
      "Pretrain epoch [24/302], ZINB loss:0.3861, NB loss:4.5960, latent MSE loss:0.00080625, KL loss:0.00111710\n",
      "Pretrain epoch [25/302], ZINB loss:0.3974, NB loss:4.5259, latent MSE loss:0.00068826, KL loss:0.00112698\n",
      "Pretrain epoch [26/302], ZINB loss:0.3923, NB loss:4.4996, latent MSE loss:0.00061210, KL loss:0.00102719\n",
      "Pretrain epoch [27/302], ZINB loss:0.2831, NB loss:4.3994, latent MSE loss:0.00058487, KL loss:0.00006119\n",
      "Pretrain epoch [1/303], ZINB loss:0.3986, NB loss:4.5442, latent MSE loss:0.00095853, KL loss:0.00131313\n",
      "Pretrain epoch [2/303], ZINB loss:0.3995, NB loss:4.5427, latent MSE loss:0.00078747, KL loss:0.00120952\n",
      "Pretrain epoch [3/303], ZINB loss:0.4055, NB loss:4.6022, latent MSE loss:0.00077260, KL loss:0.00116133\n",
      "Pretrain epoch [4/303], ZINB loss:0.4104, NB loss:4.5200, latent MSE loss:0.00067274, KL loss:0.00153321\n",
      "Pretrain epoch [5/303], ZINB loss:0.4006, NB loss:4.5103, latent MSE loss:0.00079633, KL loss:0.00138520\n",
      "Pretrain epoch [6/303], ZINB loss:0.3981, NB loss:4.5224, latent MSE loss:0.00049552, KL loss:0.00106403\n",
      "Pretrain epoch [7/303], ZINB loss:0.4094, NB loss:4.5367, latent MSE loss:0.00078872, KL loss:0.00135642\n",
      "Pretrain epoch [8/303], ZINB loss:0.4164, NB loss:4.5194, latent MSE loss:0.00048091, KL loss:0.00118455\n",
      "Pretrain epoch [9/303], ZINB loss:0.4060, NB loss:4.5322, latent MSE loss:0.00053055, KL loss:0.00128374\n",
      "Pretrain epoch [10/303], ZINB loss:0.4029, NB loss:4.5320, latent MSE loss:0.00062222, KL loss:0.00196438\n",
      "Pretrain epoch [11/303], ZINB loss:0.3791, NB loss:4.5260, latent MSE loss:0.00044302, KL loss:0.00096671\n",
      "Pretrain epoch [12/303], ZINB loss:0.3917, NB loss:4.5274, latent MSE loss:0.00037812, KL loss:0.00132567\n",
      "Pretrain epoch [13/303], ZINB loss:0.3920, NB loss:4.5329, latent MSE loss:0.00041664, KL loss:0.00122350\n",
      "Pretrain epoch [14/303], ZINB loss:0.4004, NB loss:4.5563, latent MSE loss:0.00039400, KL loss:0.00107538\n",
      "Pretrain epoch [15/303], ZINB loss:0.3897, NB loss:4.4973, latent MSE loss:0.00044387, KL loss:0.00116713\n",
      "Pretrain epoch [16/303], ZINB loss:0.3993, NB loss:4.5457, latent MSE loss:0.00037358, KL loss:0.00123641\n",
      "Pretrain epoch [17/303], ZINB loss:0.3963, NB loss:4.5707, latent MSE loss:0.00038247, KL loss:0.00096846\n",
      "Pretrain epoch [18/303], ZINB loss:0.3844, NB loss:4.5339, latent MSE loss:0.00043366, KL loss:0.00124254\n",
      "Pretrain epoch [19/303], ZINB loss:0.3853, NB loss:4.5677, latent MSE loss:0.00038952, KL loss:0.00128436\n",
      "Pretrain epoch [20/303], ZINB loss:0.3794, NB loss:4.4895, latent MSE loss:0.00026554, KL loss:0.00095273\n",
      "Pretrain epoch [21/303], ZINB loss:0.3806, NB loss:4.5553, latent MSE loss:0.00044024, KL loss:0.00096185\n",
      "Pretrain epoch [22/303], ZINB loss:0.3998, NB loss:4.5571, latent MSE loss:0.00033934, KL loss:0.00120778\n",
      "Pretrain epoch [23/303], ZINB loss:0.3913, NB loss:4.4838, latent MSE loss:0.00029881, KL loss:0.00113895\n",
      "Pretrain epoch [24/303], ZINB loss:0.3813, NB loss:4.5125, latent MSE loss:0.00028387, KL loss:0.00104476\n",
      "Pretrain epoch [25/303], ZINB loss:0.4103, NB loss:4.5126, latent MSE loss:0.00026388, KL loss:0.00104147\n",
      "Pretrain epoch [26/303], ZINB loss:0.4052, NB loss:4.5345, latent MSE loss:0.00037035, KL loss:0.00129713\n",
      "Pretrain epoch [27/303], ZINB loss:0.2887, NB loss:4.5559, latent MSE loss:0.00018759, KL loss:0.00006715\n",
      "Pretrain epoch [1/304], ZINB loss:0.4052, NB loss:4.5316, latent MSE loss:0.00049373, KL loss:0.00096600\n",
      "Pretrain epoch [2/304], ZINB loss:0.4063, NB loss:4.5681, latent MSE loss:0.00043108, KL loss:0.00115780\n",
      "Pretrain epoch [3/304], ZINB loss:0.3875, NB loss:4.5439, latent MSE loss:0.00041209, KL loss:0.00104966\n",
      "Pretrain epoch [4/304], ZINB loss:0.4120, NB loss:4.5351, latent MSE loss:0.00040256, KL loss:0.00111304\n",
      "Pretrain epoch [5/304], ZINB loss:0.4039, NB loss:4.5466, latent MSE loss:0.00036632, KL loss:0.00107965\n",
      "Pretrain epoch [6/304], ZINB loss:0.4153, NB loss:4.5362, latent MSE loss:0.00043947, KL loss:0.00122820\n",
      "Pretrain epoch [7/304], ZINB loss:0.4033, NB loss:4.5423, latent MSE loss:0.00037381, KL loss:0.00100394\n",
      "Pretrain epoch [8/304], ZINB loss:0.3792, NB loss:4.5595, latent MSE loss:0.00046495, KL loss:0.00136289\n",
      "Pretrain epoch [9/304], ZINB loss:0.4018, NB loss:4.5744, latent MSE loss:0.00042563, KL loss:0.00126923\n",
      "Pretrain epoch [10/304], ZINB loss:0.3910, NB loss:4.5125, latent MSE loss:0.00041212, KL loss:0.00098995\n",
      "Pretrain epoch [11/304], ZINB loss:0.3817, NB loss:4.4372, latent MSE loss:0.00030518, KL loss:0.00092260\n",
      "Pretrain epoch [12/304], ZINB loss:0.3764, NB loss:4.5299, latent MSE loss:0.00034731, KL loss:0.00094786\n",
      "Pretrain epoch [13/304], ZINB loss:0.4117, NB loss:4.5918, latent MSE loss:0.00038501, KL loss:0.00098777\n",
      "Pretrain epoch [14/304], ZINB loss:0.3903, NB loss:4.5516, latent MSE loss:0.00050298, KL loss:0.00120419\n",
      "Pretrain epoch [15/304], ZINB loss:0.3940, NB loss:4.5418, latent MSE loss:0.00042270, KL loss:0.00118640\n",
      "Pretrain epoch [16/304], ZINB loss:0.4210, NB loss:4.5286, latent MSE loss:0.00042069, KL loss:0.00104563\n",
      "Pretrain epoch [17/304], ZINB loss:0.3795, NB loss:4.5038, latent MSE loss:0.00032462, KL loss:0.00097458\n",
      "Pretrain epoch [18/304], ZINB loss:0.3952, NB loss:4.5097, latent MSE loss:0.00039830, KL loss:0.00090643\n",
      "Pretrain epoch [19/304], ZINB loss:0.3982, NB loss:4.5229, latent MSE loss:0.00028049, KL loss:0.00099176\n",
      "Pretrain epoch [20/304], ZINB loss:0.4069, NB loss:4.5284, latent MSE loss:0.00034997, KL loss:0.00119992\n",
      "Pretrain epoch [21/304], ZINB loss:0.3951, NB loss:4.5113, latent MSE loss:0.00030115, KL loss:0.00089886\n",
      "Pretrain epoch [22/304], ZINB loss:0.3863, NB loss:4.5347, latent MSE loss:0.00027389, KL loss:0.00093740\n",
      "Pretrain epoch [23/304], ZINB loss:0.3875, NB loss:4.5637, latent MSE loss:0.00035506, KL loss:0.00113252\n",
      "Pretrain epoch [24/304], ZINB loss:0.3878, NB loss:4.5042, latent MSE loss:0.00031132, KL loss:0.00097722\n",
      "Pretrain epoch [25/304], ZINB loss:0.3838, NB loss:4.5059, latent MSE loss:0.00033553, KL loss:0.00132104\n",
      "Pretrain epoch [26/304], ZINB loss:0.3941, NB loss:4.5309, latent MSE loss:0.00025379, KL loss:0.00090201\n",
      "Pretrain epoch [27/304], ZINB loss:0.3828, NB loss:4.3515, latent MSE loss:0.00023671, KL loss:0.00006207\n",
      "Pretrain epoch [1/305], ZINB loss:0.4017, NB loss:4.4987, latent MSE loss:0.00065804, KL loss:0.00092272\n",
      "Pretrain epoch [2/305], ZINB loss:0.3969, NB loss:4.5490, latent MSE loss:0.00039312, KL loss:0.00143759\n",
      "Pretrain epoch [3/305], ZINB loss:0.3947, NB loss:4.4975, latent MSE loss:0.00047531, KL loss:0.00089138\n",
      "Pretrain epoch [4/305], ZINB loss:0.3881, NB loss:4.5246, latent MSE loss:0.00045154, KL loss:0.00083663\n",
      "Pretrain epoch [5/305], ZINB loss:0.4013, NB loss:4.5220, latent MSE loss:0.00048084, KL loss:0.00141675\n",
      "Pretrain epoch [6/305], ZINB loss:0.4086, NB loss:4.5680, latent MSE loss:0.00040254, KL loss:0.00097097\n",
      "Pretrain epoch [7/305], ZINB loss:0.3857, NB loss:4.5129, latent MSE loss:0.00045611, KL loss:0.00122512\n",
      "Pretrain epoch [8/305], ZINB loss:0.3964, NB loss:4.4871, latent MSE loss:0.00065061, KL loss:0.00114535\n",
      "Pretrain epoch [9/305], ZINB loss:0.4040, NB loss:4.5566, latent MSE loss:0.00043869, KL loss:0.00111141\n",
      "Pretrain epoch [10/305], ZINB loss:0.4038, NB loss:4.5871, latent MSE loss:0.00063547, KL loss:0.00150427\n",
      "Pretrain epoch [11/305], ZINB loss:0.4152, NB loss:4.4765, latent MSE loss:0.00052106, KL loss:0.00116038\n",
      "Pretrain epoch [12/305], ZINB loss:0.4032, NB loss:4.5530, latent MSE loss:0.00052800, KL loss:0.00122682\n",
      "Pretrain epoch [13/305], ZINB loss:0.3845, NB loss:4.5107, latent MSE loss:0.00048468, KL loss:0.00101705\n",
      "Pretrain epoch [14/305], ZINB loss:0.3967, NB loss:4.5674, latent MSE loss:0.00038933, KL loss:0.00096516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [15/305], ZINB loss:0.3961, NB loss:4.5991, latent MSE loss:0.00033119, KL loss:0.00120300\n",
      "Pretrain epoch [16/305], ZINB loss:0.3966, NB loss:4.5398, latent MSE loss:0.00039484, KL loss:0.00099871\n",
      "Pretrain epoch [17/305], ZINB loss:0.3968, NB loss:4.4865, latent MSE loss:0.00056528, KL loss:0.00115088\n",
      "Pretrain epoch [18/305], ZINB loss:0.3917, NB loss:4.5527, latent MSE loss:0.00060871, KL loss:0.00110853\n",
      "Pretrain epoch [19/305], ZINB loss:0.4001, NB loss:4.4744, latent MSE loss:0.00039287, KL loss:0.00089116\n",
      "Pretrain epoch [20/305], ZINB loss:0.3825, NB loss:4.5729, latent MSE loss:0.00039287, KL loss:0.00099705\n",
      "Pretrain epoch [21/305], ZINB loss:0.3898, NB loss:4.5074, latent MSE loss:0.00037812, KL loss:0.00104586\n",
      "Pretrain epoch [22/305], ZINB loss:0.3891, NB loss:4.5111, latent MSE loss:0.00043256, KL loss:0.00095681\n",
      "Pretrain epoch [23/305], ZINB loss:0.3867, NB loss:4.5398, latent MSE loss:0.00044276, KL loss:0.00101433\n",
      "Pretrain epoch [24/305], ZINB loss:0.3998, NB loss:4.4980, latent MSE loss:0.00046951, KL loss:0.00095006\n",
      "Pretrain epoch [25/305], ZINB loss:0.4086, NB loss:4.6011, latent MSE loss:0.00041349, KL loss:0.00111828\n",
      "Pretrain epoch [26/305], ZINB loss:0.3904, NB loss:4.5045, latent MSE loss:0.00038184, KL loss:0.00111222\n",
      "Pretrain epoch [27/305], ZINB loss:0.4758, NB loss:5.2305, latent MSE loss:0.00033016, KL loss:0.00007056\n",
      "Pretrain epoch [1/306], ZINB loss:0.3789, NB loss:4.5255, latent MSE loss:0.00076203, KL loss:0.00093497\n",
      "Pretrain epoch [2/306], ZINB loss:0.3919, NB loss:4.5317, latent MSE loss:0.00075103, KL loss:0.00090098\n",
      "Pretrain epoch [3/306], ZINB loss:0.3837, NB loss:4.5308, latent MSE loss:0.00072229, KL loss:0.00092845\n",
      "Pretrain epoch [4/306], ZINB loss:0.3868, NB loss:4.5675, latent MSE loss:0.00052609, KL loss:0.00118641\n",
      "Pretrain epoch [5/306], ZINB loss:0.3873, NB loss:4.5597, latent MSE loss:0.00040228, KL loss:0.00100939\n",
      "Pretrain epoch [6/306], ZINB loss:0.3997, NB loss:4.5318, latent MSE loss:0.00045331, KL loss:0.00123810\n",
      "Pretrain epoch [7/306], ZINB loss:0.4010, NB loss:4.5274, latent MSE loss:0.00066857, KL loss:0.00126933\n",
      "Pretrain epoch [8/306], ZINB loss:0.4110, NB loss:4.4709, latent MSE loss:0.00051146, KL loss:0.00115708\n",
      "Pretrain epoch [9/306], ZINB loss:0.3907, NB loss:4.6095, latent MSE loss:0.00038435, KL loss:0.00111279\n",
      "Pretrain epoch [10/306], ZINB loss:0.4201, NB loss:4.4754, latent MSE loss:0.00050953, KL loss:0.00113601\n",
      "Pretrain epoch [11/306], ZINB loss:0.4010, NB loss:4.4538, latent MSE loss:0.00055527, KL loss:0.00104115\n",
      "Pretrain epoch [12/306], ZINB loss:0.4114, NB loss:4.5237, latent MSE loss:0.00043660, KL loss:0.00121027\n",
      "Pretrain epoch [13/306], ZINB loss:0.4118, NB loss:4.4887, latent MSE loss:0.00032788, KL loss:0.00095148\n",
      "Pretrain epoch [14/306], ZINB loss:0.3977, NB loss:4.5154, latent MSE loss:0.00043352, KL loss:0.00135341\n",
      "Pretrain epoch [15/306], ZINB loss:0.3988, NB loss:4.5291, latent MSE loss:0.00054365, KL loss:0.00100930\n",
      "Pretrain epoch [16/306], ZINB loss:0.3863, NB loss:4.5335, latent MSE loss:0.00036843, KL loss:0.00095570\n",
      "Pretrain epoch [17/306], ZINB loss:0.3931, NB loss:4.5264, latent MSE loss:0.00032258, KL loss:0.00100021\n",
      "Pretrain epoch [18/306], ZINB loss:0.4102, NB loss:4.5219, latent MSE loss:0.00040383, KL loss:0.00114241\n",
      "Pretrain epoch [19/306], ZINB loss:0.3920, NB loss:4.5783, latent MSE loss:0.00026588, KL loss:0.00089031\n",
      "Pretrain epoch [20/306], ZINB loss:0.3913, NB loss:4.5046, latent MSE loss:0.00040146, KL loss:0.00091049\n",
      "Pretrain epoch [21/306], ZINB loss:0.3956, NB loss:4.5719, latent MSE loss:0.00037491, KL loss:0.00097657\n",
      "Pretrain epoch [22/306], ZINB loss:0.3919, NB loss:4.5545, latent MSE loss:0.00032493, KL loss:0.00101063\n",
      "Pretrain epoch [23/306], ZINB loss:0.3919, NB loss:4.5388, latent MSE loss:0.00029311, KL loss:0.00126426\n",
      "Pretrain epoch [24/306], ZINB loss:0.3949, NB loss:4.5207, latent MSE loss:0.00033690, KL loss:0.00088291\n",
      "Pretrain epoch [25/306], ZINB loss:0.3996, NB loss:4.5298, latent MSE loss:0.00037625, KL loss:0.00102778\n",
      "Pretrain epoch [26/306], ZINB loss:0.3831, NB loss:4.5664, latent MSE loss:0.00030728, KL loss:0.00096340\n",
      "Pretrain epoch [27/306], ZINB loss:0.3595, NB loss:4.5425, latent MSE loss:0.00014470, KL loss:0.00007042\n",
      "Pretrain epoch [1/307], ZINB loss:0.3936, NB loss:4.5100, latent MSE loss:0.00062035, KL loss:0.00142249\n",
      "Pretrain epoch [2/307], ZINB loss:0.3875, NB loss:4.4791, latent MSE loss:0.00042183, KL loss:0.00089013\n",
      "Pretrain epoch [3/307], ZINB loss:0.4012, NB loss:4.5658, latent MSE loss:0.00046483, KL loss:0.00097114\n",
      "Pretrain epoch [4/307], ZINB loss:0.3656, NB loss:4.5144, latent MSE loss:0.00031189, KL loss:0.00085828\n",
      "Pretrain epoch [5/307], ZINB loss:0.3983, NB loss:4.5604, latent MSE loss:0.00049773, KL loss:0.00141411\n",
      "Pretrain epoch [6/307], ZINB loss:0.3839, NB loss:4.5692, latent MSE loss:0.00033265, KL loss:0.00113065\n",
      "Pretrain epoch [7/307], ZINB loss:0.4160, NB loss:4.5315, latent MSE loss:0.00032781, KL loss:0.00104472\n",
      "Pretrain epoch [8/307], ZINB loss:0.3751, NB loss:4.4849, latent MSE loss:0.00034257, KL loss:0.00119951\n",
      "Pretrain epoch [9/307], ZINB loss:0.4005, NB loss:4.5135, latent MSE loss:0.00030300, KL loss:0.00091250\n",
      "Pretrain epoch [10/307], ZINB loss:0.4109, NB loss:4.4932, latent MSE loss:0.00038452, KL loss:0.00099226\n",
      "Pretrain epoch [11/307], ZINB loss:0.3883, NB loss:4.5716, latent MSE loss:0.00029745, KL loss:0.00121340\n",
      "Pretrain epoch [12/307], ZINB loss:0.3769, NB loss:4.4780, latent MSE loss:0.00033091, KL loss:0.00087114\n",
      "Pretrain epoch [13/307], ZINB loss:0.4059, NB loss:4.5212, latent MSE loss:0.00035433, KL loss:0.00093331\n",
      "Pretrain epoch [14/307], ZINB loss:0.3967, NB loss:4.5158, latent MSE loss:0.00037874, KL loss:0.00143732\n",
      "Pretrain epoch [15/307], ZINB loss:0.4070, NB loss:4.5265, latent MSE loss:0.00033645, KL loss:0.00087783\n",
      "Pretrain epoch [16/307], ZINB loss:0.4007, NB loss:4.5905, latent MSE loss:0.00023072, KL loss:0.00090037\n",
      "Pretrain epoch [17/307], ZINB loss:0.4077, NB loss:4.5086, latent MSE loss:0.00033673, KL loss:0.00098784\n",
      "Pretrain epoch [18/307], ZINB loss:0.4007, NB loss:4.5104, latent MSE loss:0.00030251, KL loss:0.00092994\n",
      "Pretrain epoch [19/307], ZINB loss:0.3844, NB loss:4.5201, latent MSE loss:0.00041456, KL loss:0.00154315\n",
      "Pretrain epoch [20/307], ZINB loss:0.3838, NB loss:4.5350, latent MSE loss:0.00037309, KL loss:0.00103235\n",
      "Pretrain epoch [21/307], ZINB loss:0.3777, NB loss:4.5636, latent MSE loss:0.00031045, KL loss:0.00088115\n",
      "Pretrain epoch [22/307], ZINB loss:0.4088, NB loss:4.5392, latent MSE loss:0.00034726, KL loss:0.00118171\n",
      "Pretrain epoch [23/307], ZINB loss:0.4077, NB loss:4.5255, latent MSE loss:0.00030842, KL loss:0.00097875\n",
      "Pretrain epoch [24/307], ZINB loss:0.4030, NB loss:4.5422, latent MSE loss:0.00034273, KL loss:0.00104196\n",
      "Pretrain epoch [25/307], ZINB loss:0.4221, NB loss:4.5344, latent MSE loss:0.00036105, KL loss:0.00105153\n",
      "Pretrain epoch [26/307], ZINB loss:0.3999, NB loss:4.5569, latent MSE loss:0.00039240, KL loss:0.00119158\n",
      "Pretrain epoch [27/307], ZINB loss:0.3390, NB loss:4.6223, latent MSE loss:0.00023764, KL loss:0.00006688\n",
      "Pretrain epoch [1/308], ZINB loss:0.3719, NB loss:4.5210, latent MSE loss:0.00044046, KL loss:0.00110206\n",
      "Pretrain epoch [2/308], ZINB loss:0.4004, NB loss:4.5021, latent MSE loss:0.00038240, KL loss:0.00099227\n",
      "Pretrain epoch [3/308], ZINB loss:0.4114, NB loss:4.4718, latent MSE loss:0.00037684, KL loss:0.00096525\n",
      "Pretrain epoch [4/308], ZINB loss:0.4012, NB loss:4.5964, latent MSE loss:0.00043598, KL loss:0.00097625\n",
      "Pretrain epoch [5/308], ZINB loss:0.3936, NB loss:4.5421, latent MSE loss:0.00040611, KL loss:0.00107613\n",
      "Pretrain epoch [6/308], ZINB loss:0.4022, NB loss:4.4857, latent MSE loss:0.00044840, KL loss:0.00112830\n",
      "Pretrain epoch [7/308], ZINB loss:0.4056, NB loss:4.5662, latent MSE loss:0.00038461, KL loss:0.00108053\n",
      "Pretrain epoch [8/308], ZINB loss:0.3765, NB loss:4.5451, latent MSE loss:0.00031724, KL loss:0.00096183\n",
      "Pretrain epoch [9/308], ZINB loss:0.3983, NB loss:4.5771, latent MSE loss:0.00040061, KL loss:0.00113417\n",
      "Pretrain epoch [10/308], ZINB loss:0.4113, NB loss:4.4862, latent MSE loss:0.00042293, KL loss:0.00105320\n",
      "Pretrain epoch [11/308], ZINB loss:0.4044, NB loss:4.5243, latent MSE loss:0.00037997, KL loss:0.00109597\n",
      "Pretrain epoch [12/308], ZINB loss:0.3766, NB loss:4.5209, latent MSE loss:0.00029283, KL loss:0.00092559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [13/308], ZINB loss:0.3998, NB loss:4.4649, latent MSE loss:0.00041375, KL loss:0.00101743\n",
      "Pretrain epoch [14/308], ZINB loss:0.3930, NB loss:4.5672, latent MSE loss:0.00035326, KL loss:0.00120820\n",
      "Pretrain epoch [15/308], ZINB loss:0.4041, NB loss:4.5606, latent MSE loss:0.00038848, KL loss:0.00170455\n",
      "Pretrain epoch [16/308], ZINB loss:0.3932, NB loss:4.5124, latent MSE loss:0.00033671, KL loss:0.00105814\n",
      "Pretrain epoch [17/308], ZINB loss:0.3800, NB loss:4.5146, latent MSE loss:0.00029430, KL loss:0.00092041\n",
      "Pretrain epoch [18/308], ZINB loss:0.3965, NB loss:4.5300, latent MSE loss:0.00030260, KL loss:0.00081406\n",
      "Pretrain epoch [19/308], ZINB loss:0.4049, NB loss:4.5572, latent MSE loss:0.00027371, KL loss:0.00105157\n",
      "Pretrain epoch [20/308], ZINB loss:0.4111, NB loss:4.5491, latent MSE loss:0.00049693, KL loss:0.00123425\n",
      "Pretrain epoch [21/308], ZINB loss:0.3918, NB loss:4.4925, latent MSE loss:0.00043067, KL loss:0.00091722\n",
      "Pretrain epoch [22/308], ZINB loss:0.3888, NB loss:4.6002, latent MSE loss:0.00027793, KL loss:0.00093849\n",
      "Pretrain epoch [23/308], ZINB loss:0.4069, NB loss:4.5344, latent MSE loss:0.00031946, KL loss:0.00130130\n",
      "Pretrain epoch [24/308], ZINB loss:0.3878, NB loss:4.4811, latent MSE loss:0.00028549, KL loss:0.00085326\n",
      "Pretrain epoch [25/308], ZINB loss:0.4030, NB loss:4.5312, latent MSE loss:0.00031475, KL loss:0.00101739\n",
      "Pretrain epoch [26/308], ZINB loss:0.3861, NB loss:4.5105, latent MSE loss:0.00036037, KL loss:0.00103162\n",
      "Pretrain epoch [27/308], ZINB loss:0.3954, NB loss:4.3611, latent MSE loss:0.00029004, KL loss:0.00000599\n",
      "Pretrain epoch [1/309], ZINB loss:0.4044, NB loss:4.5234, latent MSE loss:0.00039655, KL loss:0.00090137\n",
      "Pretrain epoch [2/309], ZINB loss:0.3962, NB loss:4.5213, latent MSE loss:0.00038519, KL loss:0.00096038\n",
      "Pretrain epoch [3/309], ZINB loss:0.4042, NB loss:4.5333, latent MSE loss:0.00047249, KL loss:0.00163291\n",
      "Pretrain epoch [4/309], ZINB loss:0.3958, NB loss:4.5090, latent MSE loss:0.00046640, KL loss:0.00090062\n",
      "Pretrain epoch [5/309], ZINB loss:0.3860, NB loss:4.5451, latent MSE loss:0.00058946, KL loss:0.00097878\n",
      "Pretrain epoch [6/309], ZINB loss:0.3954, NB loss:4.5133, latent MSE loss:0.00065358, KL loss:0.00130432\n",
      "Pretrain epoch [7/309], ZINB loss:0.3939, NB loss:4.5740, latent MSE loss:0.00054789, KL loss:0.00123229\n",
      "Pretrain epoch [8/309], ZINB loss:0.3834, NB loss:4.5360, latent MSE loss:0.00063120, KL loss:0.00086706\n",
      "Pretrain epoch [9/309], ZINB loss:0.4091, NB loss:4.5219, latent MSE loss:0.00082795, KL loss:0.00107292\n",
      "Pretrain epoch [10/309], ZINB loss:0.3918, NB loss:4.5497, latent MSE loss:0.00076064, KL loss:0.00095998\n",
      "Pretrain epoch [11/309], ZINB loss:0.3998, NB loss:4.4733, latent MSE loss:0.00062054, KL loss:0.00118849\n",
      "Pretrain epoch [12/309], ZINB loss:0.4196, NB loss:4.5081, latent MSE loss:0.00039369, KL loss:0.00100169\n",
      "Pretrain epoch [13/309], ZINB loss:0.4123, NB loss:4.5107, latent MSE loss:0.00053967, KL loss:0.00091859\n",
      "Pretrain epoch [14/309], ZINB loss:0.4030, NB loss:4.5222, latent MSE loss:0.00059879, KL loss:0.00150439\n",
      "Pretrain epoch [15/309], ZINB loss:0.3911, NB loss:4.5268, latent MSE loss:0.00052529, KL loss:0.00088456\n",
      "Pretrain epoch [16/309], ZINB loss:0.3914, NB loss:4.5173, latent MSE loss:0.00052380, KL loss:0.00092867\n",
      "Pretrain epoch [17/309], ZINB loss:0.4060, NB loss:4.5090, latent MSE loss:0.00050530, KL loss:0.00098068\n",
      "Pretrain epoch [18/309], ZINB loss:0.4050, NB loss:4.4824, latent MSE loss:0.00048946, KL loss:0.00083630\n",
      "Pretrain epoch [19/309], ZINB loss:0.3785, NB loss:4.5738, latent MSE loss:0.00038604, KL loss:0.00105438\n",
      "Pretrain epoch [20/309], ZINB loss:0.3818, NB loss:4.5905, latent MSE loss:0.00030525, KL loss:0.00101150\n",
      "Pretrain epoch [21/309], ZINB loss:0.4025, NB loss:4.4888, latent MSE loss:0.00055573, KL loss:0.00115532\n",
      "Pretrain epoch [22/309], ZINB loss:0.3793, NB loss:4.5328, latent MSE loss:0.00056935, KL loss:0.00091338\n",
      "Pretrain epoch [23/309], ZINB loss:0.4046, NB loss:4.5242, latent MSE loss:0.00040699, KL loss:0.00123713\n",
      "Pretrain epoch [24/309], ZINB loss:0.3710, NB loss:4.5382, latent MSE loss:0.00028630, KL loss:0.00079828\n",
      "Pretrain epoch [25/309], ZINB loss:0.3982, NB loss:4.5939, latent MSE loss:0.00038606, KL loss:0.00086592\n",
      "Pretrain epoch [26/309], ZINB loss:0.3936, NB loss:4.4847, latent MSE loss:0.00054051, KL loss:0.00109365\n",
      "Pretrain epoch [27/309], ZINB loss:0.3988, NB loss:4.3867, latent MSE loss:0.00043177, KL loss:0.00000927\n",
      "Pretrain epoch [1/310], ZINB loss:0.3758, NB loss:4.5521, latent MSE loss:0.00159244, KL loss:0.00091002\n",
      "Pretrain epoch [2/310], ZINB loss:0.3832, NB loss:4.5458, latent MSE loss:0.00178304, KL loss:0.00090729\n",
      "Pretrain epoch [3/310], ZINB loss:0.3905, NB loss:4.5347, latent MSE loss:0.00109733, KL loss:0.00111533\n",
      "Pretrain epoch [4/310], ZINB loss:0.4018, NB loss:4.4555, latent MSE loss:0.00171639, KL loss:0.00119592\n",
      "Pretrain epoch [5/310], ZINB loss:0.4027, NB loss:4.5086, latent MSE loss:0.00209691, KL loss:0.00115110\n",
      "Pretrain epoch [6/310], ZINB loss:0.3992, NB loss:4.5562, latent MSE loss:0.00148419, KL loss:0.00120994\n",
      "Pretrain epoch [7/310], ZINB loss:0.3922, NB loss:4.5361, latent MSE loss:0.00170735, KL loss:0.00091113\n",
      "Pretrain epoch [8/310], ZINB loss:0.3866, NB loss:4.5207, latent MSE loss:0.00181199, KL loss:0.00107170\n",
      "Pretrain epoch [9/310], ZINB loss:0.3967, NB loss:4.5359, latent MSE loss:0.00088208, KL loss:0.00108457\n",
      "Pretrain epoch [10/310], ZINB loss:0.3906, NB loss:4.5040, latent MSE loss:0.00127526, KL loss:0.00090333\n",
      "Pretrain epoch [11/310], ZINB loss:0.3975, NB loss:4.5251, latent MSE loss:0.00107724, KL loss:0.00098304\n",
      "Pretrain epoch [12/310], ZINB loss:0.3876, NB loss:4.5756, latent MSE loss:0.00136909, KL loss:0.00136514\n",
      "Pretrain epoch [13/310], ZINB loss:0.3837, NB loss:4.5248, latent MSE loss:0.00131536, KL loss:0.00088678\n",
      "Pretrain epoch [14/310], ZINB loss:0.3913, NB loss:4.5212, latent MSE loss:0.00073289, KL loss:0.00103340\n",
      "Pretrain epoch [15/310], ZINB loss:0.3866, NB loss:4.5686, latent MSE loss:0.00077412, KL loss:0.00101674\n",
      "Pretrain epoch [16/310], ZINB loss:0.4084, NB loss:4.4412, latent MSE loss:0.00078556, KL loss:0.00091055\n",
      "Pretrain epoch [17/310], ZINB loss:0.3906, NB loss:4.5691, latent MSE loss:0.00073089, KL loss:0.00099369\n",
      "Pretrain epoch [18/310], ZINB loss:0.3804, NB loss:4.5269, latent MSE loss:0.00063310, KL loss:0.00093732\n",
      "Pretrain epoch [19/310], ZINB loss:0.4016, NB loss:4.5507, latent MSE loss:0.00084749, KL loss:0.00100381\n",
      "Pretrain epoch [20/310], ZINB loss:0.4240, NB loss:4.5078, latent MSE loss:0.00084891, KL loss:0.00092523\n",
      "Pretrain epoch [21/310], ZINB loss:0.3912, NB loss:4.5034, latent MSE loss:0.00052073, KL loss:0.00084508\n",
      "Pretrain epoch [22/310], ZINB loss:0.4101, NB loss:4.5186, latent MSE loss:0.00085144, KL loss:0.00102902\n",
      "Pretrain epoch [23/310], ZINB loss:0.4172, NB loss:4.5307, latent MSE loss:0.00074265, KL loss:0.00109780\n",
      "Pretrain epoch [24/310], ZINB loss:0.4005, NB loss:4.5477, latent MSE loss:0.00053363, KL loss:0.00084065\n",
      "Pretrain epoch [25/310], ZINB loss:0.4123, NB loss:4.5595, latent MSE loss:0.00057304, KL loss:0.00152816\n",
      "Pretrain epoch [26/310], ZINB loss:0.3901, NB loss:4.4414, latent MSE loss:0.00048970, KL loss:0.00082892\n",
      "Pretrain epoch [27/310], ZINB loss:0.3660, NB loss:5.0236, latent MSE loss:0.00021359, KL loss:0.00001503\n",
      "Pretrain epoch [1/311], ZINB loss:0.4079, NB loss:4.5421, latent MSE loss:0.00076060, KL loss:0.00083623\n",
      "Pretrain epoch [2/311], ZINB loss:0.3919, NB loss:4.5212, latent MSE loss:0.00083242, KL loss:0.00099025\n",
      "Pretrain epoch [3/311], ZINB loss:0.3827, NB loss:4.5446, latent MSE loss:0.00077660, KL loss:0.00102533\n",
      "Pretrain epoch [4/311], ZINB loss:0.3975, NB loss:4.4826, latent MSE loss:0.00046372, KL loss:0.00094138\n",
      "Pretrain epoch [5/311], ZINB loss:0.3953, NB loss:4.4360, latent MSE loss:0.00092417, KL loss:0.00101609\n",
      "Pretrain epoch [6/311], ZINB loss:0.3790, NB loss:4.5197, latent MSE loss:0.00048907, KL loss:0.00088856\n",
      "Pretrain epoch [7/311], ZINB loss:0.4058, NB loss:4.5035, latent MSE loss:0.00067013, KL loss:0.00103367\n",
      "Pretrain epoch [8/311], ZINB loss:0.4089, NB loss:4.5573, latent MSE loss:0.00087364, KL loss:0.00140985\n",
      "Pretrain epoch [9/311], ZINB loss:0.3866, NB loss:4.5032, latent MSE loss:0.00048919, KL loss:0.00098237\n",
      "Pretrain epoch [10/311], ZINB loss:0.4098, NB loss:4.4483, latent MSE loss:0.00079765, KL loss:0.00096006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [11/311], ZINB loss:0.3917, NB loss:4.5249, latent MSE loss:0.00070743, KL loss:0.00102416\n",
      "Pretrain epoch [12/311], ZINB loss:0.3928, NB loss:4.5485, latent MSE loss:0.00051185, KL loss:0.00132366\n",
      "Pretrain epoch [13/311], ZINB loss:0.3954, NB loss:4.5131, latent MSE loss:0.00065423, KL loss:0.00102935\n",
      "Pretrain epoch [14/311], ZINB loss:0.3919, NB loss:4.5368, latent MSE loss:0.00060676, KL loss:0.00113226\n",
      "Pretrain epoch [15/311], ZINB loss:0.4045, NB loss:4.5788, latent MSE loss:0.00040591, KL loss:0.00125831\n",
      "Pretrain epoch [16/311], ZINB loss:0.3932, NB loss:4.5580, latent MSE loss:0.00073282, KL loss:0.00096385\n",
      "Pretrain epoch [17/311], ZINB loss:0.3890, NB loss:4.5240, latent MSE loss:0.00033613, KL loss:0.00087651\n",
      "Pretrain epoch [18/311], ZINB loss:0.3917, NB loss:4.6020, latent MSE loss:0.00058593, KL loss:0.00132961\n",
      "Pretrain epoch [19/311], ZINB loss:0.3759, NB loss:4.5628, latent MSE loss:0.00040198, KL loss:0.00084327\n",
      "Pretrain epoch [20/311], ZINB loss:0.3965, NB loss:4.5347, latent MSE loss:0.00041783, KL loss:0.00119840\n",
      "Pretrain epoch [21/311], ZINB loss:0.3987, NB loss:4.5041, latent MSE loss:0.00051087, KL loss:0.00110530\n",
      "Pretrain epoch [22/311], ZINB loss:0.3914, NB loss:4.5068, latent MSE loss:0.00029315, KL loss:0.00096656\n",
      "Pretrain epoch [23/311], ZINB loss:0.3981, NB loss:4.5197, latent MSE loss:0.00042971, KL loss:0.00107806\n",
      "Pretrain epoch [24/311], ZINB loss:0.4062, NB loss:4.5295, latent MSE loss:0.00042648, KL loss:0.00119595\n",
      "Pretrain epoch [25/311], ZINB loss:0.4146, NB loss:4.5301, latent MSE loss:0.00032430, KL loss:0.00101864\n",
      "Pretrain epoch [26/311], ZINB loss:0.3986, NB loss:4.5294, latent MSE loss:0.00046134, KL loss:0.00095273\n",
      "Pretrain epoch [27/311], ZINB loss:0.2789, NB loss:4.1226, latent MSE loss:0.00050629, KL loss:0.00000669\n",
      "Pretrain epoch [1/312], ZINB loss:0.4183, NB loss:4.4618, latent MSE loss:0.00377147, KL loss:0.00111667\n",
      "Pretrain epoch [2/312], ZINB loss:0.3790, NB loss:4.4820, latent MSE loss:0.00106798, KL loss:0.00106875\n",
      "Pretrain epoch [3/312], ZINB loss:0.3901, NB loss:4.5209, latent MSE loss:0.00297690, KL loss:0.00094750\n",
      "Pretrain epoch [4/312], ZINB loss:0.3980, NB loss:4.5426, latent MSE loss:0.00149210, KL loss:0.00107151\n",
      "Pretrain epoch [5/312], ZINB loss:0.3797, NB loss:4.5374, latent MSE loss:0.00243034, KL loss:0.00105913\n",
      "Pretrain epoch [6/312], ZINB loss:0.3852, NB loss:4.5257, latent MSE loss:0.00106491, KL loss:0.00095721\n",
      "Pretrain epoch [7/312], ZINB loss:0.4064, NB loss:4.5575, latent MSE loss:0.00179808, KL loss:0.00110839\n",
      "Pretrain epoch [8/312], ZINB loss:0.3916, NB loss:4.5861, latent MSE loss:0.00137962, KL loss:0.00100231\n",
      "Pretrain epoch [9/312], ZINB loss:0.3898, NB loss:4.5374, latent MSE loss:0.00115519, KL loss:0.00124556\n",
      "Pretrain epoch [10/312], ZINB loss:0.3959, NB loss:4.5251, latent MSE loss:0.00133439, KL loss:0.00090363\n",
      "Pretrain epoch [11/312], ZINB loss:0.4122, NB loss:4.5129, latent MSE loss:0.00096502, KL loss:0.00140563\n",
      "Pretrain epoch [12/312], ZINB loss:0.4033, NB loss:4.5378, latent MSE loss:0.00088941, KL loss:0.00110914\n",
      "Pretrain epoch [13/312], ZINB loss:0.4040, NB loss:4.5522, latent MSE loss:0.00113495, KL loss:0.00113094\n",
      "Pretrain epoch [14/312], ZINB loss:0.3831, NB loss:4.4941, latent MSE loss:0.00066551, KL loss:0.00104296\n",
      "Pretrain epoch [15/312], ZINB loss:0.3997, NB loss:4.5052, latent MSE loss:0.00089858, KL loss:0.00118029\n",
      "Pretrain epoch [16/312], ZINB loss:0.4038, NB loss:4.5516, latent MSE loss:0.00090117, KL loss:0.00100364\n",
      "Pretrain epoch [17/312], ZINB loss:0.3934, NB loss:4.4360, latent MSE loss:0.00060767, KL loss:0.00094430\n",
      "Pretrain epoch [18/312], ZINB loss:0.3804, NB loss:4.5115, latent MSE loss:0.00070675, KL loss:0.00089227\n",
      "Pretrain epoch [19/312], ZINB loss:0.3868, NB loss:4.5022, latent MSE loss:0.00059565, KL loss:0.00092314\n",
      "Pretrain epoch [20/312], ZINB loss:0.4024, NB loss:4.5514, latent MSE loss:0.00057714, KL loss:0.00133291\n",
      "Pretrain epoch [21/312], ZINB loss:0.3989, NB loss:4.5256, latent MSE loss:0.00053052, KL loss:0.00100131\n",
      "Pretrain epoch [22/312], ZINB loss:0.3969, NB loss:4.5815, latent MSE loss:0.00056592, KL loss:0.00108191\n",
      "Pretrain epoch [23/312], ZINB loss:0.4031, NB loss:4.4474, latent MSE loss:0.00042567, KL loss:0.00117023\n",
      "Pretrain epoch [24/312], ZINB loss:0.3940, NB loss:4.5873, latent MSE loss:0.00043607, KL loss:0.00096708\n",
      "Pretrain epoch [25/312], ZINB loss:0.3963, NB loss:4.4899, latent MSE loss:0.00049543, KL loss:0.00096785\n",
      "Pretrain epoch [26/312], ZINB loss:0.4001, NB loss:4.5590, latent MSE loss:0.00037657, KL loss:0.00105372\n",
      "Pretrain epoch [27/312], ZINB loss:0.4563, NB loss:5.0134, latent MSE loss:0.00035865, KL loss:0.00000925\n",
      "Pretrain epoch [1/313], ZINB loss:0.3919, NB loss:4.4648, latent MSE loss:0.00090778, KL loss:0.00093414\n",
      "Pretrain epoch [2/313], ZINB loss:0.3812, NB loss:4.5641, latent MSE loss:0.00058177, KL loss:0.00128954\n",
      "Pretrain epoch [3/313], ZINB loss:0.4135, NB loss:4.5687, latent MSE loss:0.00084575, KL loss:0.00111038\n",
      "Pretrain epoch [4/313], ZINB loss:0.4001, NB loss:4.5479, latent MSE loss:0.00052068, KL loss:0.00091758\n",
      "Pretrain epoch [5/313], ZINB loss:0.3932, NB loss:4.5219, latent MSE loss:0.00041719, KL loss:0.00106662\n",
      "Pretrain epoch [6/313], ZINB loss:0.3989, NB loss:4.4659, latent MSE loss:0.00053508, KL loss:0.00130958\n",
      "Pretrain epoch [7/313], ZINB loss:0.4139, NB loss:4.5203, latent MSE loss:0.00065723, KL loss:0.00128551\n",
      "Pretrain epoch [8/313], ZINB loss:0.4048, NB loss:4.5577, latent MSE loss:0.00046686, KL loss:0.00111445\n",
      "Pretrain epoch [9/313], ZINB loss:0.4073, NB loss:4.5882, latent MSE loss:0.00060607, KL loss:0.00133497\n",
      "Pretrain epoch [10/313], ZINB loss:0.3964, NB loss:4.5900, latent MSE loss:0.00054941, KL loss:0.00119871\n",
      "Pretrain epoch [11/313], ZINB loss:0.4056, NB loss:4.5546, latent MSE loss:0.00045641, KL loss:0.00120894\n",
      "Pretrain epoch [12/313], ZINB loss:0.3871, NB loss:4.4564, latent MSE loss:0.00045255, KL loss:0.00097112\n",
      "Pretrain epoch [13/313], ZINB loss:0.3733, NB loss:4.5213, latent MSE loss:0.00033404, KL loss:0.00085248\n",
      "Pretrain epoch [14/313], ZINB loss:0.3865, NB loss:4.5443, latent MSE loss:0.00035754, KL loss:0.00090514\n",
      "Pretrain epoch [15/313], ZINB loss:0.4169, NB loss:4.4835, latent MSE loss:0.00043506, KL loss:0.00146340\n",
      "Pretrain epoch [16/313], ZINB loss:0.3819, NB loss:4.5445, latent MSE loss:0.00031556, KL loss:0.00098313\n",
      "Pretrain epoch [17/313], ZINB loss:0.3843, NB loss:4.4977, latent MSE loss:0.00029724, KL loss:0.00090404\n",
      "Pretrain epoch [18/313], ZINB loss:0.3894, NB loss:4.4969, latent MSE loss:0.00028857, KL loss:0.00127225\n",
      "Pretrain epoch [19/313], ZINB loss:0.3931, NB loss:4.4850, latent MSE loss:0.00030482, KL loss:0.00094320\n",
      "Pretrain epoch [20/313], ZINB loss:0.4041, NB loss:4.5688, latent MSE loss:0.00031448, KL loss:0.00097300\n",
      "Pretrain epoch [21/313], ZINB loss:0.3972, NB loss:4.4577, latent MSE loss:0.00024728, KL loss:0.00093529\n",
      "Pretrain epoch [22/313], ZINB loss:0.3830, NB loss:4.4870, latent MSE loss:0.00028386, KL loss:0.00097715\n",
      "Pretrain epoch [23/313], ZINB loss:0.3827, NB loss:4.4762, latent MSE loss:0.00026695, KL loss:0.00098715\n",
      "Pretrain epoch [24/313], ZINB loss:0.3820, NB loss:4.5430, latent MSE loss:0.00027677, KL loss:0.00102014\n",
      "Pretrain epoch [25/313], ZINB loss:0.4014, NB loss:4.5712, latent MSE loss:0.00032652, KL loss:0.00114705\n",
      "Pretrain epoch [26/313], ZINB loss:0.4222, NB loss:4.5161, latent MSE loss:0.00023849, KL loss:0.00120149\n",
      "Pretrain epoch [27/313], ZINB loss:0.4688, NB loss:4.8447, latent MSE loss:0.00016772, KL loss:0.00001282\n",
      "Pretrain epoch [1/314], ZINB loss:0.4185, NB loss:4.4863, latent MSE loss:0.00052597, KL loss:0.00094888\n",
      "Pretrain epoch [2/314], ZINB loss:0.4219, NB loss:4.5429, latent MSE loss:0.00054264, KL loss:0.00111805\n",
      "Pretrain epoch [3/314], ZINB loss:0.3866, NB loss:4.5025, latent MSE loss:0.00037438, KL loss:0.00098079\n",
      "Pretrain epoch [4/314], ZINB loss:0.3910, NB loss:4.5720, latent MSE loss:0.00045565, KL loss:0.00097804\n",
      "Pretrain epoch [5/314], ZINB loss:0.3914, NB loss:4.6222, latent MSE loss:0.00042001, KL loss:0.00112939\n",
      "Pretrain epoch [6/314], ZINB loss:0.4224, NB loss:4.5412, latent MSE loss:0.00049413, KL loss:0.00122930\n",
      "Pretrain epoch [7/314], ZINB loss:0.3818, NB loss:4.5577, latent MSE loss:0.00041330, KL loss:0.00126887\n",
      "Pretrain epoch [8/314], ZINB loss:0.3726, NB loss:4.5225, latent MSE loss:0.00059658, KL loss:0.00095978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [9/314], ZINB loss:0.4163, NB loss:4.5525, latent MSE loss:0.00050566, KL loss:0.00155273\n",
      "Pretrain epoch [10/314], ZINB loss:0.4048, NB loss:4.5278, latent MSE loss:0.00051825, KL loss:0.00132259\n",
      "Pretrain epoch [11/314], ZINB loss:0.3904, NB loss:4.4852, latent MSE loss:0.00062046, KL loss:0.00104349\n",
      "Pretrain epoch [12/314], ZINB loss:0.3940, NB loss:4.5122, latent MSE loss:0.00065070, KL loss:0.00109855\n",
      "Pretrain epoch [13/314], ZINB loss:0.3929, NB loss:4.5413, latent MSE loss:0.00056548, KL loss:0.00100831\n",
      "Pretrain epoch [14/314], ZINB loss:0.4038, NB loss:4.5500, latent MSE loss:0.00050791, KL loss:0.00122122\n",
      "Pretrain epoch [15/314], ZINB loss:0.3956, NB loss:4.4656, latent MSE loss:0.00040046, KL loss:0.00084559\n",
      "Pretrain epoch [16/314], ZINB loss:0.4092, NB loss:4.5230, latent MSE loss:0.00037515, KL loss:0.00085374\n",
      "Pretrain epoch [17/314], ZINB loss:0.3968, NB loss:4.5055, latent MSE loss:0.00046861, KL loss:0.00106661\n",
      "Pretrain epoch [18/314], ZINB loss:0.3849, NB loss:4.5343, latent MSE loss:0.00056126, KL loss:0.00104441\n",
      "Pretrain epoch [19/314], ZINB loss:0.4026, NB loss:4.4781, latent MSE loss:0.00060616, KL loss:0.00095381\n",
      "Pretrain epoch [20/314], ZINB loss:0.3817, NB loss:4.4917, latent MSE loss:0.00053085, KL loss:0.00082808\n",
      "Pretrain epoch [21/314], ZINB loss:0.3839, NB loss:4.5008, latent MSE loss:0.00048025, KL loss:0.00125815\n",
      "Pretrain epoch [22/314], ZINB loss:0.3969, NB loss:4.4947, latent MSE loss:0.00035131, KL loss:0.00143257\n",
      "Pretrain epoch [23/314], ZINB loss:0.3954, NB loss:4.5642, latent MSE loss:0.00030653, KL loss:0.00104075\n",
      "Pretrain epoch [24/314], ZINB loss:0.4021, NB loss:4.5030, latent MSE loss:0.00034414, KL loss:0.00118166\n",
      "Pretrain epoch [25/314], ZINB loss:0.3914, NB loss:4.4857, latent MSE loss:0.00039354, KL loss:0.00089103\n",
      "Pretrain epoch [26/314], ZINB loss:0.4008, NB loss:4.5206, latent MSE loss:0.00049703, KL loss:0.00108318\n",
      "Pretrain epoch [27/314], ZINB loss:0.2638, NB loss:4.2851, latent MSE loss:0.00053014, KL loss:0.00006121\n",
      "Pretrain epoch [1/315], ZINB loss:0.4146, NB loss:4.4726, latent MSE loss:0.00055635, KL loss:0.00121307\n",
      "Pretrain epoch [2/315], ZINB loss:0.3823, NB loss:4.5416, latent MSE loss:0.00043531, KL loss:0.00131403\n",
      "Pretrain epoch [3/315], ZINB loss:0.4038, NB loss:4.5941, latent MSE loss:0.00035436, KL loss:0.00121098\n",
      "Pretrain epoch [4/315], ZINB loss:0.4086, NB loss:4.5588, latent MSE loss:0.00046806, KL loss:0.00097529\n",
      "Pretrain epoch [5/315], ZINB loss:0.4021, NB loss:4.5245, latent MSE loss:0.00044939, KL loss:0.00096101\n",
      "Pretrain epoch [6/315], ZINB loss:0.4169, NB loss:4.4466, latent MSE loss:0.00039551, KL loss:0.00092451\n",
      "Pretrain epoch [7/315], ZINB loss:0.3841, NB loss:4.5574, latent MSE loss:0.00028182, KL loss:0.00098079\n",
      "Pretrain epoch [8/315], ZINB loss:0.4067, NB loss:4.6537, latent MSE loss:0.00031435, KL loss:0.00104951\n",
      "Pretrain epoch [9/315], ZINB loss:0.3765, NB loss:4.4720, latent MSE loss:0.00026854, KL loss:0.00079910\n",
      "Pretrain epoch [10/315], ZINB loss:0.4174, NB loss:4.4840, latent MSE loss:0.00033628, KL loss:0.00140011\n",
      "Pretrain epoch [11/315], ZINB loss:0.4045, NB loss:4.5209, latent MSE loss:0.00034813, KL loss:0.00091785\n",
      "Pretrain epoch [12/315], ZINB loss:0.3758, NB loss:4.5849, latent MSE loss:0.00024756, KL loss:0.00121215\n",
      "Pretrain epoch [13/315], ZINB loss:0.4060, NB loss:4.5027, latent MSE loss:0.00027812, KL loss:0.00090625\n",
      "Pretrain epoch [14/315], ZINB loss:0.3892, NB loss:4.4991, latent MSE loss:0.00035703, KL loss:0.00086157\n",
      "Pretrain epoch [15/315], ZINB loss:0.3930, NB loss:4.5297, latent MSE loss:0.00029069, KL loss:0.00100568\n",
      "Pretrain epoch [16/315], ZINB loss:0.3981, NB loss:4.5365, latent MSE loss:0.00021931, KL loss:0.00129109\n",
      "Pretrain epoch [17/315], ZINB loss:0.3917, NB loss:4.5349, latent MSE loss:0.00032010, KL loss:0.00108975\n",
      "Pretrain epoch [18/315], ZINB loss:0.4023, NB loss:4.5188, latent MSE loss:0.00020646, KL loss:0.00090676\n",
      "Pretrain epoch [19/315], ZINB loss:0.3759, NB loss:4.4561, latent MSE loss:0.00025512, KL loss:0.00126528\n",
      "Pretrain epoch [20/315], ZINB loss:0.4118, NB loss:4.4640, latent MSE loss:0.00028997, KL loss:0.00116538\n",
      "Pretrain epoch [21/315], ZINB loss:0.4203, NB loss:4.5136, latent MSE loss:0.00024655, KL loss:0.00082832\n",
      "Pretrain epoch [22/315], ZINB loss:0.3740, NB loss:4.5483, latent MSE loss:0.00026984, KL loss:0.00107218\n",
      "Pretrain epoch [23/315], ZINB loss:0.3785, NB loss:4.5099, latent MSE loss:0.00025101, KL loss:0.00088503\n",
      "Pretrain epoch [24/315], ZINB loss:0.3861, NB loss:4.5122, latent MSE loss:0.00024576, KL loss:0.00089639\n",
      "Pretrain epoch [25/315], ZINB loss:0.3776, NB loss:4.4988, latent MSE loss:0.00020190, KL loss:0.00081145\n",
      "Pretrain epoch [26/315], ZINB loss:0.4008, NB loss:4.5141, latent MSE loss:0.00022968, KL loss:0.00082095\n",
      "Pretrain epoch [27/315], ZINB loss:0.4240, NB loss:4.5099, latent MSE loss:0.00028707, KL loss:0.00000954\n",
      "Pretrain epoch [1/316], ZINB loss:0.4020, NB loss:4.5487, latent MSE loss:0.00052539, KL loss:0.00111554\n",
      "Pretrain epoch [2/316], ZINB loss:0.3784, NB loss:4.4746, latent MSE loss:0.00049265, KL loss:0.00082566\n",
      "Pretrain epoch [3/316], ZINB loss:0.4140, NB loss:4.5612, latent MSE loss:0.00075884, KL loss:0.00107837\n",
      "Pretrain epoch [4/316], ZINB loss:0.3993, NB loss:4.4842, latent MSE loss:0.00051684, KL loss:0.00132728\n",
      "Pretrain epoch [5/316], ZINB loss:0.4096, NB loss:4.4836, latent MSE loss:0.00037315, KL loss:0.00094388\n",
      "Pretrain epoch [6/316], ZINB loss:0.3959, NB loss:4.5355, latent MSE loss:0.00044096, KL loss:0.00119073\n",
      "Pretrain epoch [7/316], ZINB loss:0.3853, NB loss:4.5326, latent MSE loss:0.00043960, KL loss:0.00086877\n",
      "Pretrain epoch [8/316], ZINB loss:0.3766, NB loss:4.5963, latent MSE loss:0.00047180, KL loss:0.00089640\n",
      "Pretrain epoch [9/316], ZINB loss:0.3887, NB loss:4.4920, latent MSE loss:0.00044713, KL loss:0.00112191\n",
      "Pretrain epoch [10/316], ZINB loss:0.3815, NB loss:4.4831, latent MSE loss:0.00030183, KL loss:0.00091052\n",
      "Pretrain epoch [11/316], ZINB loss:0.3949, NB loss:4.5732, latent MSE loss:0.00033078, KL loss:0.00100591\n",
      "Pretrain epoch [12/316], ZINB loss:0.4038, NB loss:4.4761, latent MSE loss:0.00035530, KL loss:0.00096580\n",
      "Pretrain epoch [13/316], ZINB loss:0.3843, NB loss:4.5086, latent MSE loss:0.00037703, KL loss:0.00121029\n",
      "Pretrain epoch [14/316], ZINB loss:0.3949, NB loss:4.5755, latent MSE loss:0.00040497, KL loss:0.00093571\n",
      "Pretrain epoch [15/316], ZINB loss:0.4030, NB loss:4.4592, latent MSE loss:0.00028617, KL loss:0.00081219\n",
      "Pretrain epoch [16/316], ZINB loss:0.4099, NB loss:4.5214, latent MSE loss:0.00031201, KL loss:0.00108880\n",
      "Pretrain epoch [17/316], ZINB loss:0.3977, NB loss:4.5294, latent MSE loss:0.00036221, KL loss:0.00086626\n",
      "Pretrain epoch [18/316], ZINB loss:0.4020, NB loss:4.5882, latent MSE loss:0.00039128, KL loss:0.00113989\n",
      "Pretrain epoch [19/316], ZINB loss:0.4059, NB loss:4.5625, latent MSE loss:0.00037956, KL loss:0.00117355\n",
      "Pretrain epoch [20/316], ZINB loss:0.3921, NB loss:4.5341, latent MSE loss:0.00032693, KL loss:0.00089656\n",
      "Pretrain epoch [21/316], ZINB loss:0.3865, NB loss:4.4356, latent MSE loss:0.00031704, KL loss:0.00086149\n",
      "Pretrain epoch [22/316], ZINB loss:0.3964, NB loss:4.5013, latent MSE loss:0.00033536, KL loss:0.00113353\n",
      "Pretrain epoch [23/316], ZINB loss:0.3955, NB loss:4.5184, latent MSE loss:0.00033378, KL loss:0.00094147\n",
      "Pretrain epoch [24/316], ZINB loss:0.4144, NB loss:4.5200, latent MSE loss:0.00037309, KL loss:0.00104229\n",
      "Pretrain epoch [25/316], ZINB loss:0.4009, NB loss:4.5449, latent MSE loss:0.00027144, KL loss:0.00089045\n",
      "Pretrain epoch [26/316], ZINB loss:0.3817, NB loss:4.4914, latent MSE loss:0.00025540, KL loss:0.00112549\n",
      "Pretrain epoch [27/316], ZINB loss:0.4099, NB loss:4.2333, latent MSE loss:0.00016266, KL loss:0.00005230\n",
      "Pretrain epoch [1/317], ZINB loss:0.3959, NB loss:4.5603, latent MSE loss:0.00045829, KL loss:0.00087719\n",
      "Pretrain epoch [2/317], ZINB loss:0.3774, NB loss:4.5262, latent MSE loss:0.00048979, KL loss:0.00081533\n",
      "Pretrain epoch [3/317], ZINB loss:0.4077, NB loss:4.5027, latent MSE loss:0.00051641, KL loss:0.00101599\n",
      "Pretrain epoch [4/317], ZINB loss:0.3914, NB loss:4.5045, latent MSE loss:0.00052667, KL loss:0.00099753\n",
      "Pretrain epoch [5/317], ZINB loss:0.4002, NB loss:4.5806, latent MSE loss:0.00029724, KL loss:0.00124927\n",
      "Pretrain epoch [6/317], ZINB loss:0.3835, NB loss:4.4830, latent MSE loss:0.00036164, KL loss:0.00109939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [7/317], ZINB loss:0.3975, NB loss:4.5627, latent MSE loss:0.00068114, KL loss:0.00091250\n",
      "Pretrain epoch [8/317], ZINB loss:0.3783, NB loss:4.5716, latent MSE loss:0.00079391, KL loss:0.00102116\n",
      "Pretrain epoch [9/317], ZINB loss:0.4137, NB loss:4.4917, latent MSE loss:0.00065444, KL loss:0.00105995\n",
      "Pretrain epoch [10/317], ZINB loss:0.4149, NB loss:4.5478, latent MSE loss:0.00055811, KL loss:0.00085126\n",
      "Pretrain epoch [11/317], ZINB loss:0.4011, NB loss:4.5672, latent MSE loss:0.00034670, KL loss:0.00093827\n",
      "Pretrain epoch [12/317], ZINB loss:0.3886, NB loss:4.4994, latent MSE loss:0.00042558, KL loss:0.00103315\n",
      "Pretrain epoch [13/317], ZINB loss:0.4273, NB loss:4.4642, latent MSE loss:0.00057109, KL loss:0.00094126\n",
      "Pretrain epoch [14/317], ZINB loss:0.3763, NB loss:4.5040, latent MSE loss:0.00035014, KL loss:0.00093472\n",
      "Pretrain epoch [15/317], ZINB loss:0.4019, NB loss:4.4278, latent MSE loss:0.00028402, KL loss:0.00094338\n",
      "Pretrain epoch [16/317], ZINB loss:0.4104, NB loss:4.5337, latent MSE loss:0.00048105, KL loss:0.00090063\n",
      "Pretrain epoch [17/317], ZINB loss:0.3667, NB loss:4.5291, latent MSE loss:0.00041819, KL loss:0.00130688\n",
      "Pretrain epoch [18/317], ZINB loss:0.3905, NB loss:4.5429, latent MSE loss:0.00045829, KL loss:0.00104767\n",
      "Pretrain epoch [19/317], ZINB loss:0.3847, NB loss:4.5433, latent MSE loss:0.00043042, KL loss:0.00093352\n",
      "Pretrain epoch [20/317], ZINB loss:0.3976, NB loss:4.5438, latent MSE loss:0.00030970, KL loss:0.00090799\n",
      "Pretrain epoch [21/317], ZINB loss:0.4044, NB loss:4.4422, latent MSE loss:0.00036746, KL loss:0.00087275\n",
      "Pretrain epoch [22/317], ZINB loss:0.3964, NB loss:4.4913, latent MSE loss:0.00037363, KL loss:0.00088471\n",
      "Pretrain epoch [23/317], ZINB loss:0.3916, NB loss:4.4686, latent MSE loss:0.00030197, KL loss:0.00105408\n",
      "Pretrain epoch [24/317], ZINB loss:0.4005, NB loss:4.5567, latent MSE loss:0.00037984, KL loss:0.00088975\n",
      "Pretrain epoch [25/317], ZINB loss:0.3936, NB loss:4.5535, latent MSE loss:0.00033985, KL loss:0.00101705\n",
      "Pretrain epoch [26/317], ZINB loss:0.3960, NB loss:4.5066, latent MSE loss:0.00033831, KL loss:0.00100089\n",
      "Pretrain epoch [27/317], ZINB loss:0.5059, NB loss:4.6849, latent MSE loss:0.00122637, KL loss:0.00004878\n",
      "Pretrain epoch [1/318], ZINB loss:0.4041, NB loss:4.5040, latent MSE loss:0.00127867, KL loss:0.00123342\n",
      "Pretrain epoch [2/318], ZINB loss:0.3973, NB loss:4.4993, latent MSE loss:0.00181349, KL loss:0.00086948\n",
      "Pretrain epoch [3/318], ZINB loss:0.4063, NB loss:4.4867, latent MSE loss:0.00165204, KL loss:0.00093893\n",
      "Pretrain epoch [4/318], ZINB loss:0.4057, NB loss:4.4892, latent MSE loss:0.00122189, KL loss:0.00092636\n",
      "Pretrain epoch [5/318], ZINB loss:0.3975, NB loss:4.5279, latent MSE loss:0.00143911, KL loss:0.00092800\n",
      "Pretrain epoch [6/318], ZINB loss:0.3885, NB loss:4.5659, latent MSE loss:0.00126229, KL loss:0.00119006\n",
      "Pretrain epoch [7/318], ZINB loss:0.3839, NB loss:4.5031, latent MSE loss:0.00110753, KL loss:0.00118251\n",
      "Pretrain epoch [8/318], ZINB loss:0.3943, NB loss:4.5130, latent MSE loss:0.00088626, KL loss:0.00118321\n",
      "Pretrain epoch [9/318], ZINB loss:0.4208, NB loss:4.5633, latent MSE loss:0.00141831, KL loss:0.00102698\n",
      "Pretrain epoch [10/318], ZINB loss:0.3795, NB loss:4.5472, latent MSE loss:0.00130730, KL loss:0.00105168\n",
      "Pretrain epoch [11/318], ZINB loss:0.3913, NB loss:4.5105, latent MSE loss:0.00069599, KL loss:0.00094331\n",
      "Pretrain epoch [12/318], ZINB loss:0.3821, NB loss:4.5193, latent MSE loss:0.00103682, KL loss:0.00104888\n",
      "Pretrain epoch [13/318], ZINB loss:0.4012, NB loss:4.5135, latent MSE loss:0.00109554, KL loss:0.00105734\n",
      "Pretrain epoch [14/318], ZINB loss:0.3855, NB loss:4.5313, latent MSE loss:0.00058791, KL loss:0.00089001\n",
      "Pretrain epoch [15/318], ZINB loss:0.3914, NB loss:4.5347, latent MSE loss:0.00094170, KL loss:0.00119941\n",
      "Pretrain epoch [16/318], ZINB loss:0.4147, NB loss:4.5423, latent MSE loss:0.00072591, KL loss:0.00118069\n",
      "Pretrain epoch [17/318], ZINB loss:0.3866, NB loss:4.5255, latent MSE loss:0.00065226, KL loss:0.00107833\n",
      "Pretrain epoch [18/318], ZINB loss:0.3920, NB loss:4.4861, latent MSE loss:0.00061613, KL loss:0.00087545\n",
      "Pretrain epoch [19/318], ZINB loss:0.4147, NB loss:4.4765, latent MSE loss:0.00059864, KL loss:0.00091407\n",
      "Pretrain epoch [20/318], ZINB loss:0.3984, NB loss:4.5176, latent MSE loss:0.00036530, KL loss:0.00093274\n",
      "Pretrain epoch [21/318], ZINB loss:0.4178, NB loss:4.5073, latent MSE loss:0.00048910, KL loss:0.00114628\n",
      "Pretrain epoch [22/318], ZINB loss:0.3936, NB loss:4.5026, latent MSE loss:0.00041617, KL loss:0.00170851\n",
      "Pretrain epoch [23/318], ZINB loss:0.3873, NB loss:4.5526, latent MSE loss:0.00033675, KL loss:0.00106302\n",
      "Pretrain epoch [24/318], ZINB loss:0.3781, NB loss:4.5471, latent MSE loss:0.00035258, KL loss:0.00093154\n",
      "Pretrain epoch [25/318], ZINB loss:0.4000, NB loss:4.5299, latent MSE loss:0.00041432, KL loss:0.00096526\n",
      "Pretrain epoch [26/318], ZINB loss:0.3985, NB loss:4.4930, latent MSE loss:0.00031143, KL loss:0.00093063\n",
      "Pretrain epoch [27/318], ZINB loss:0.3714, NB loss:4.4087, latent MSE loss:0.00035495, KL loss:0.00001513\n",
      "Pretrain epoch [1/319], ZINB loss:0.4090, NB loss:4.4380, latent MSE loss:0.00099459, KL loss:0.00105742\n",
      "Pretrain epoch [2/319], ZINB loss:0.3902, NB loss:4.5451, latent MSE loss:0.00045520, KL loss:0.00131549\n",
      "Pretrain epoch [3/319], ZINB loss:0.3999, NB loss:4.5046, latent MSE loss:0.00082035, KL loss:0.00100919\n",
      "Pretrain epoch [4/319], ZINB loss:0.3885, NB loss:4.4988, latent MSE loss:0.00053126, KL loss:0.00085535\n",
      "Pretrain epoch [5/319], ZINB loss:0.3802, NB loss:4.6079, latent MSE loss:0.00066226, KL loss:0.00114478\n",
      "Pretrain epoch [6/319], ZINB loss:0.4090, NB loss:4.4664, latent MSE loss:0.00080753, KL loss:0.00129467\n",
      "Pretrain epoch [7/319], ZINB loss:0.4081, NB loss:4.4854, latent MSE loss:0.00064675, KL loss:0.00114590\n",
      "Pretrain epoch [8/319], ZINB loss:0.3807, NB loss:4.5292, latent MSE loss:0.00062222, KL loss:0.00109022\n",
      "Pretrain epoch [9/319], ZINB loss:0.4062, NB loss:4.6239, latent MSE loss:0.00058252, KL loss:0.00114802\n",
      "Pretrain epoch [10/319], ZINB loss:0.3960, NB loss:4.5069, latent MSE loss:0.00061803, KL loss:0.00090495\n",
      "Pretrain epoch [11/319], ZINB loss:0.3984, NB loss:4.5592, latent MSE loss:0.00044933, KL loss:0.00123004\n",
      "Pretrain epoch [12/319], ZINB loss:0.3886, NB loss:4.4870, latent MSE loss:0.00067992, KL loss:0.00103876\n",
      "Pretrain epoch [13/319], ZINB loss:0.3963, NB loss:4.5286, latent MSE loss:0.00041203, KL loss:0.00098610\n",
      "Pretrain epoch [14/319], ZINB loss:0.4185, NB loss:4.5356, latent MSE loss:0.00069629, KL loss:0.00099027\n",
      "Pretrain epoch [15/319], ZINB loss:0.3996, NB loss:4.4787, latent MSE loss:0.00042998, KL loss:0.00097985\n",
      "Pretrain epoch [16/319], ZINB loss:0.4079, NB loss:4.4857, latent MSE loss:0.00075232, KL loss:0.00110375\n",
      "Pretrain epoch [17/319], ZINB loss:0.4095, NB loss:4.5261, latent MSE loss:0.00048296, KL loss:0.00129699\n",
      "Pretrain epoch [18/319], ZINB loss:0.3809, NB loss:4.5409, latent MSE loss:0.00070526, KL loss:0.00115298\n",
      "Pretrain epoch [19/319], ZINB loss:0.4061, NB loss:4.5150, latent MSE loss:0.00042666, KL loss:0.00098494\n",
      "Pretrain epoch [20/319], ZINB loss:0.3967, NB loss:4.5292, latent MSE loss:0.00049916, KL loss:0.00122673\n",
      "Pretrain epoch [21/319], ZINB loss:0.3921, NB loss:4.4873, latent MSE loss:0.00053988, KL loss:0.00112010\n",
      "Pretrain epoch [22/319], ZINB loss:0.3941, NB loss:4.5607, latent MSE loss:0.00039915, KL loss:0.00120048\n",
      "Pretrain epoch [23/319], ZINB loss:0.3853, NB loss:4.5072, latent MSE loss:0.00055602, KL loss:0.00122412\n",
      "Pretrain epoch [24/319], ZINB loss:0.3948, NB loss:4.4531, latent MSE loss:0.00052963, KL loss:0.00100903\n",
      "Pretrain epoch [25/319], ZINB loss:0.3963, NB loss:4.5131, latent MSE loss:0.00057833, KL loss:0.00088613\n",
      "Pretrain epoch [26/319], ZINB loss:0.3758, NB loss:4.5547, latent MSE loss:0.00042839, KL loss:0.00095179\n",
      "Pretrain epoch [27/319], ZINB loss:0.3632, NB loss:4.4335, latent MSE loss:0.00070625, KL loss:0.00000200\n",
      "Pretrain epoch [1/320], ZINB loss:0.4035, NB loss:4.4538, latent MSE loss:0.00166971, KL loss:0.00091590\n",
      "Pretrain epoch [2/320], ZINB loss:0.3932, NB loss:4.5084, latent MSE loss:0.00078539, KL loss:0.00119592\n",
      "Pretrain epoch [3/320], ZINB loss:0.3849, NB loss:4.6078, latent MSE loss:0.00092957, KL loss:0.00111742\n",
      "Pretrain epoch [4/320], ZINB loss:0.4007, NB loss:4.4960, latent MSE loss:0.00106804, KL loss:0.00112581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [5/320], ZINB loss:0.3912, NB loss:4.5564, latent MSE loss:0.00096762, KL loss:0.00104742\n",
      "Pretrain epoch [6/320], ZINB loss:0.3888, NB loss:4.5350, latent MSE loss:0.00078608, KL loss:0.00085745\n",
      "Pretrain epoch [7/320], ZINB loss:0.4139, NB loss:4.5268, latent MSE loss:0.00082502, KL loss:0.00091393\n",
      "Pretrain epoch [8/320], ZINB loss:0.3939, NB loss:4.5067, latent MSE loss:0.00069201, KL loss:0.00110872\n",
      "Pretrain epoch [9/320], ZINB loss:0.3955, NB loss:4.5575, latent MSE loss:0.00091417, KL loss:0.00090498\n",
      "Pretrain epoch [10/320], ZINB loss:0.3854, NB loss:4.4825, latent MSE loss:0.00049089, KL loss:0.00092975\n",
      "Pretrain epoch [11/320], ZINB loss:0.3962, NB loss:4.5259, latent MSE loss:0.00071764, KL loss:0.00144661\n",
      "Pretrain epoch [12/320], ZINB loss:0.3910, NB loss:4.5079, latent MSE loss:0.00070861, KL loss:0.00102126\n",
      "Pretrain epoch [13/320], ZINB loss:0.3837, NB loss:4.5725, latent MSE loss:0.00071660, KL loss:0.00114025\n",
      "Pretrain epoch [14/320], ZINB loss:0.4135, NB loss:4.5168, latent MSE loss:0.00046159, KL loss:0.00096414\n",
      "Pretrain epoch [15/320], ZINB loss:0.3853, NB loss:4.5073, latent MSE loss:0.00066216, KL loss:0.00098137\n",
      "Pretrain epoch [16/320], ZINB loss:0.3961, NB loss:4.5702, latent MSE loss:0.00044900, KL loss:0.00087804\n",
      "Pretrain epoch [17/320], ZINB loss:0.3829, NB loss:4.4550, latent MSE loss:0.00068335, KL loss:0.00092698\n",
      "Pretrain epoch [18/320], ZINB loss:0.4008, NB loss:4.4428, latent MSE loss:0.00053680, KL loss:0.00128761\n",
      "Pretrain epoch [19/320], ZINB loss:0.4076, NB loss:4.5070, latent MSE loss:0.00059274, KL loss:0.00099848\n",
      "Pretrain epoch [20/320], ZINB loss:0.4133, NB loss:4.4445, latent MSE loss:0.00045489, KL loss:0.00094796\n",
      "Pretrain epoch [21/320], ZINB loss:0.4013, NB loss:4.5623, latent MSE loss:0.00057423, KL loss:0.00137289\n",
      "Pretrain epoch [22/320], ZINB loss:0.3843, NB loss:4.5250, latent MSE loss:0.00043623, KL loss:0.00092865\n",
      "Pretrain epoch [23/320], ZINB loss:0.3985, NB loss:4.4822, latent MSE loss:0.00038813, KL loss:0.00083076\n",
      "Pretrain epoch [24/320], ZINB loss:0.3779, NB loss:4.4696, latent MSE loss:0.00031835, KL loss:0.00090288\n",
      "Pretrain epoch [25/320], ZINB loss:0.4051, NB loss:4.5460, latent MSE loss:0.00036766, KL loss:0.00130147\n",
      "Pretrain epoch [26/320], ZINB loss:0.4138, NB loss:4.5738, latent MSE loss:0.00039311, KL loss:0.00097317\n",
      "Pretrain epoch [27/320], ZINB loss:0.4546, NB loss:4.1782, latent MSE loss:0.00039679, KL loss:0.00006192\n",
      "Pretrain epoch [1/321], ZINB loss:0.3976, NB loss:4.5315, latent MSE loss:0.00082530, KL loss:0.00089560\n",
      "Pretrain epoch [2/321], ZINB loss:0.3936, NB loss:4.5288, latent MSE loss:0.00070278, KL loss:0.00105297\n",
      "Pretrain epoch [3/321], ZINB loss:0.3773, NB loss:4.5301, latent MSE loss:0.00056425, KL loss:0.00089194\n",
      "Pretrain epoch [4/321], ZINB loss:0.3863, NB loss:4.5241, latent MSE loss:0.00075365, KL loss:0.00115261\n",
      "Pretrain epoch [5/321], ZINB loss:0.3949, NB loss:4.5578, latent MSE loss:0.00045615, KL loss:0.00092404\n",
      "Pretrain epoch [6/321], ZINB loss:0.4039, NB loss:4.5023, latent MSE loss:0.00065530, KL loss:0.00088942\n",
      "Pretrain epoch [7/321], ZINB loss:0.3841, NB loss:4.5148, latent MSE loss:0.00045895, KL loss:0.00090140\n",
      "Pretrain epoch [8/321], ZINB loss:0.4091, NB loss:4.5218, latent MSE loss:0.00050143, KL loss:0.00087347\n",
      "Pretrain epoch [9/321], ZINB loss:0.3876, NB loss:4.5277, latent MSE loss:0.00053994, KL loss:0.00114381\n",
      "Pretrain epoch [10/321], ZINB loss:0.4074, NB loss:4.4938, latent MSE loss:0.00047758, KL loss:0.00083986\n",
      "Pretrain epoch [11/321], ZINB loss:0.3912, NB loss:4.5321, latent MSE loss:0.00037770, KL loss:0.00089578\n",
      "Pretrain epoch [12/321], ZINB loss:0.4322, NB loss:4.5250, latent MSE loss:0.00069827, KL loss:0.00143301\n",
      "Pretrain epoch [13/321], ZINB loss:0.4087, NB loss:4.5488, latent MSE loss:0.00043413, KL loss:0.00113422\n",
      "Pretrain epoch [14/321], ZINB loss:0.3844, NB loss:4.4994, latent MSE loss:0.00062670, KL loss:0.00089329\n",
      "Pretrain epoch [15/321], ZINB loss:0.3874, NB loss:4.4396, latent MSE loss:0.00047586, KL loss:0.00087689\n",
      "Pretrain epoch [16/321], ZINB loss:0.3862, NB loss:4.5114, latent MSE loss:0.00047567, KL loss:0.00090652\n",
      "Pretrain epoch [17/321], ZINB loss:0.3957, NB loss:4.4822, latent MSE loss:0.00059625, KL loss:0.00183452\n",
      "Pretrain epoch [18/321], ZINB loss:0.3904, NB loss:4.4454, latent MSE loss:0.00045544, KL loss:0.00114258\n",
      "Pretrain epoch [19/321], ZINB loss:0.3961, NB loss:4.5402, latent MSE loss:0.00035977, KL loss:0.00097946\n",
      "Pretrain epoch [20/321], ZINB loss:0.4078, NB loss:4.5608, latent MSE loss:0.00041543, KL loss:0.00094320\n",
      "Pretrain epoch [21/321], ZINB loss:0.3978, NB loss:4.6104, latent MSE loss:0.00050184, KL loss:0.00139487\n",
      "Pretrain epoch [22/321], ZINB loss:0.3963, NB loss:4.4890, latent MSE loss:0.00038377, KL loss:0.00087962\n",
      "Pretrain epoch [23/321], ZINB loss:0.4102, NB loss:4.5307, latent MSE loss:0.00046490, KL loss:0.00089521\n",
      "Pretrain epoch [24/321], ZINB loss:0.4017, NB loss:4.5287, latent MSE loss:0.00040688, KL loss:0.00113506\n",
      "Pretrain epoch [25/321], ZINB loss:0.3881, NB loss:4.4710, latent MSE loss:0.00028917, KL loss:0.00093043\n",
      "Pretrain epoch [26/321], ZINB loss:0.3787, NB loss:4.4854, latent MSE loss:0.00025791, KL loss:0.00084419\n",
      "Pretrain epoch [27/321], ZINB loss:0.4642, NB loss:4.0543, latent MSE loss:0.00028139, KL loss:0.00006904\n",
      "Pretrain epoch [1/322], ZINB loss:0.4087, NB loss:4.4918, latent MSE loss:0.00062552, KL loss:0.00083037\n",
      "Pretrain epoch [2/322], ZINB loss:0.4075, NB loss:4.4963, latent MSE loss:0.00064477, KL loss:0.00104650\n",
      "Pretrain epoch [3/322], ZINB loss:0.3836, NB loss:4.5566, latent MSE loss:0.00036059, KL loss:0.00091158\n",
      "Pretrain epoch [4/322], ZINB loss:0.4053, NB loss:4.4344, latent MSE loss:0.00044085, KL loss:0.00079662\n",
      "Pretrain epoch [5/322], ZINB loss:0.3776, NB loss:4.4662, latent MSE loss:0.00056815, KL loss:0.00093736\n",
      "Pretrain epoch [6/322], ZINB loss:0.3854, NB loss:4.4910, latent MSE loss:0.00037351, KL loss:0.00090943\n",
      "Pretrain epoch [7/322], ZINB loss:0.3990, NB loss:4.5286, latent MSE loss:0.00066311, KL loss:0.00098210\n",
      "Pretrain epoch [8/322], ZINB loss:0.3851, NB loss:4.5352, latent MSE loss:0.00033648, KL loss:0.00085365\n",
      "Pretrain epoch [9/322], ZINB loss:0.4038, NB loss:4.4727, latent MSE loss:0.00059549, KL loss:0.00102313\n",
      "Pretrain epoch [10/322], ZINB loss:0.4024, NB loss:4.5141, latent MSE loss:0.00042143, KL loss:0.00105627\n",
      "Pretrain epoch [11/322], ZINB loss:0.3814, NB loss:4.4909, latent MSE loss:0.00034639, KL loss:0.00129425\n",
      "Pretrain epoch [12/322], ZINB loss:0.3956, NB loss:4.5365, latent MSE loss:0.00047856, KL loss:0.00099534\n",
      "Pretrain epoch [13/322], ZINB loss:0.3868, NB loss:4.5145, latent MSE loss:0.00029159, KL loss:0.00082515\n",
      "Pretrain epoch [14/322], ZINB loss:0.4117, NB loss:4.5541, latent MSE loss:0.00040029, KL loss:0.00104145\n",
      "Pretrain epoch [15/322], ZINB loss:0.3932, NB loss:4.5120, latent MSE loss:0.00029248, KL loss:0.00091270\n",
      "Pretrain epoch [16/322], ZINB loss:0.4013, NB loss:4.5195, latent MSE loss:0.00030297, KL loss:0.00100997\n",
      "Pretrain epoch [17/322], ZINB loss:0.3938, NB loss:4.5634, latent MSE loss:0.00030891, KL loss:0.00096523\n",
      "Pretrain epoch [18/322], ZINB loss:0.3868, NB loss:4.6184, latent MSE loss:0.00026842, KL loss:0.00104421\n",
      "Pretrain epoch [19/322], ZINB loss:0.3803, NB loss:4.5651, latent MSE loss:0.00032292, KL loss:0.00097980\n",
      "Pretrain epoch [20/322], ZINB loss:0.3931, NB loss:4.4739, latent MSE loss:0.00025598, KL loss:0.00087769\n",
      "Pretrain epoch [21/322], ZINB loss:0.4017, NB loss:4.4869, latent MSE loss:0.00024782, KL loss:0.00091067\n",
      "Pretrain epoch [22/322], ZINB loss:0.4125, NB loss:4.4703, latent MSE loss:0.00029229, KL loss:0.00096921\n",
      "Pretrain epoch [23/322], ZINB loss:0.4059, NB loss:4.5120, latent MSE loss:0.00032528, KL loss:0.00105586\n",
      "Pretrain epoch [24/322], ZINB loss:0.4011, NB loss:4.5389, latent MSE loss:0.00035215, KL loss:0.00161528\n",
      "Pretrain epoch [25/322], ZINB loss:0.3856, NB loss:4.5449, latent MSE loss:0.00028397, KL loss:0.00094745\n",
      "Pretrain epoch [26/322], ZINB loss:0.3983, NB loss:4.5030, latent MSE loss:0.00031601, KL loss:0.00089308\n",
      "Pretrain epoch [27/322], ZINB loss:0.3694, NB loss:4.5081, latent MSE loss:0.00029422, KL loss:0.00000561\n",
      "Pretrain epoch [1/323], ZINB loss:0.3939, NB loss:4.5149, latent MSE loss:0.00056875, KL loss:0.00109268\n",
      "Pretrain epoch [2/323], ZINB loss:0.3866, NB loss:4.5584, latent MSE loss:0.00032790, KL loss:0.00093237\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [3/323], ZINB loss:0.3941, NB loss:4.5382, latent MSE loss:0.00043255, KL loss:0.00085797\n",
      "Pretrain epoch [4/323], ZINB loss:0.3818, NB loss:4.5189, latent MSE loss:0.00038297, KL loss:0.00099726\n",
      "Pretrain epoch [5/323], ZINB loss:0.4085, NB loss:4.4617, latent MSE loss:0.00029376, KL loss:0.00086072\n",
      "Pretrain epoch [6/323], ZINB loss:0.3747, NB loss:4.5241, latent MSE loss:0.00044444, KL loss:0.00095699\n",
      "Pretrain epoch [7/323], ZINB loss:0.4081, NB loss:4.4603, latent MSE loss:0.00041727, KL loss:0.00120826\n",
      "Pretrain epoch [8/323], ZINB loss:0.3813, NB loss:4.5335, latent MSE loss:0.00045278, KL loss:0.00091713\n",
      "Pretrain epoch [9/323], ZINB loss:0.4036, NB loss:4.4499, latent MSE loss:0.00041816, KL loss:0.00101981\n",
      "Pretrain epoch [10/323], ZINB loss:0.3933, NB loss:4.5575, latent MSE loss:0.00032722, KL loss:0.00105048\n",
      "Pretrain epoch [11/323], ZINB loss:0.3901, NB loss:4.5621, latent MSE loss:0.00040857, KL loss:0.00096816\n",
      "Pretrain epoch [12/323], ZINB loss:0.3853, NB loss:4.5548, latent MSE loss:0.00030680, KL loss:0.00119618\n",
      "Pretrain epoch [13/323], ZINB loss:0.3819, NB loss:4.4829, latent MSE loss:0.00034698, KL loss:0.00077250\n",
      "Pretrain epoch [14/323], ZINB loss:0.4024, NB loss:4.5131, latent MSE loss:0.00038055, KL loss:0.00104094\n",
      "Pretrain epoch [15/323], ZINB loss:0.4002, NB loss:4.5301, latent MSE loss:0.00024584, KL loss:0.00087429\n",
      "Pretrain epoch [16/323], ZINB loss:0.4001, NB loss:4.4409, latent MSE loss:0.00031907, KL loss:0.00104508\n",
      "Pretrain epoch [17/323], ZINB loss:0.3981, NB loss:4.5511, latent MSE loss:0.00025375, KL loss:0.00108242\n",
      "Pretrain epoch [18/323], ZINB loss:0.4026, NB loss:4.5692, latent MSE loss:0.00027592, KL loss:0.00109882\n",
      "Pretrain epoch [19/323], ZINB loss:0.3748, NB loss:4.5461, latent MSE loss:0.00022500, KL loss:0.00100816\n",
      "Pretrain epoch [20/323], ZINB loss:0.4025, NB loss:4.4616, latent MSE loss:0.00028452, KL loss:0.00092425\n",
      "Pretrain epoch [21/323], ZINB loss:0.4241, NB loss:4.5862, latent MSE loss:0.00035894, KL loss:0.00114376\n",
      "Pretrain epoch [22/323], ZINB loss:0.3963, NB loss:4.4881, latent MSE loss:0.00020478, KL loss:0.00086265\n",
      "Pretrain epoch [23/323], ZINB loss:0.4104, NB loss:4.5184, latent MSE loss:0.00022781, KL loss:0.00089581\n",
      "Pretrain epoch [24/323], ZINB loss:0.4012, NB loss:4.4939, latent MSE loss:0.00037462, KL loss:0.00097423\n",
      "Pretrain epoch [25/323], ZINB loss:0.3912, NB loss:4.4531, latent MSE loss:0.00028505, KL loss:0.00082064\n",
      "Pretrain epoch [26/323], ZINB loss:0.3930, NB loss:4.4994, latent MSE loss:0.00032607, KL loss:0.00091720\n",
      "Pretrain epoch [27/323], ZINB loss:0.5443, NB loss:4.4079, latent MSE loss:0.00091032, KL loss:0.00004173\n",
      "Pretrain epoch [1/324], ZINB loss:0.4081, NB loss:4.5530, latent MSE loss:0.00630589, KL loss:0.00110093\n",
      "Pretrain epoch [2/324], ZINB loss:0.3929, NB loss:4.5162, latent MSE loss:0.00347677, KL loss:0.00142715\n",
      "Pretrain epoch [3/324], ZINB loss:0.4119, NB loss:4.4973, latent MSE loss:0.00331850, KL loss:0.00186706\n",
      "Pretrain epoch [4/324], ZINB loss:0.3943, NB loss:4.4713, latent MSE loss:0.00332729, KL loss:0.00122990\n",
      "Pretrain epoch [5/324], ZINB loss:0.4156, NB loss:4.5227, latent MSE loss:0.00323752, KL loss:0.00108795\n",
      "Pretrain epoch [6/324], ZINB loss:0.4107, NB loss:4.4798, latent MSE loss:0.00325048, KL loss:0.00162446\n",
      "Pretrain epoch [7/324], ZINB loss:0.4037, NB loss:4.4698, latent MSE loss:0.00370471, KL loss:0.00140513\n",
      "Pretrain epoch [8/324], ZINB loss:0.4235, NB loss:4.4297, latent MSE loss:0.00273633, KL loss:0.00121142\n",
      "Pretrain epoch [9/324], ZINB loss:0.3900, NB loss:4.5538, latent MSE loss:0.00248124, KL loss:0.00141313\n",
      "Pretrain epoch [10/324], ZINB loss:0.4061, NB loss:4.5392, latent MSE loss:0.00210349, KL loss:0.00132338\n",
      "Pretrain epoch [11/324], ZINB loss:0.3913, NB loss:4.5357, latent MSE loss:0.00235152, KL loss:0.00153274\n",
      "Pretrain epoch [12/324], ZINB loss:0.4041, NB loss:4.4625, latent MSE loss:0.00207858, KL loss:0.00127010\n",
      "Pretrain epoch [13/324], ZINB loss:0.3758, NB loss:4.5503, latent MSE loss:0.00149305, KL loss:0.00122047\n",
      "Pretrain epoch [14/324], ZINB loss:0.3898, NB loss:4.4744, latent MSE loss:0.00181282, KL loss:0.00131745\n",
      "Pretrain epoch [15/324], ZINB loss:0.3875, NB loss:4.5298, latent MSE loss:0.00134813, KL loss:0.00144865\n",
      "Pretrain epoch [16/324], ZINB loss:0.3802, NB loss:4.4869, latent MSE loss:0.00147039, KL loss:0.00091232\n",
      "Pretrain epoch [17/324], ZINB loss:0.3848, NB loss:4.5205, latent MSE loss:0.00126398, KL loss:0.00115803\n",
      "Pretrain epoch [18/324], ZINB loss:0.4133, NB loss:4.5362, latent MSE loss:0.00114691, KL loss:0.00106753\n",
      "Pretrain epoch [19/324], ZINB loss:0.3946, NB loss:4.5600, latent MSE loss:0.00080930, KL loss:0.00096101\n",
      "Pretrain epoch [20/324], ZINB loss:0.3924, NB loss:4.5348, latent MSE loss:0.00116772, KL loss:0.00108983\n",
      "Pretrain epoch [21/324], ZINB loss:0.4061, NB loss:4.4976, latent MSE loss:0.00114738, KL loss:0.00152302\n",
      "Pretrain epoch [22/324], ZINB loss:0.3862, NB loss:4.4856, latent MSE loss:0.00093438, KL loss:0.00114586\n",
      "Pretrain epoch [23/324], ZINB loss:0.3854, NB loss:4.5208, latent MSE loss:0.00100542, KL loss:0.00122636\n",
      "Pretrain epoch [24/324], ZINB loss:0.3660, NB loss:4.5440, latent MSE loss:0.00056141, KL loss:0.00105479\n",
      "Pretrain epoch [25/324], ZINB loss:0.4050, NB loss:4.4926, latent MSE loss:0.00081978, KL loss:0.00108004\n",
      "Pretrain epoch [26/324], ZINB loss:0.4044, NB loss:4.5685, latent MSE loss:0.00098812, KL loss:0.00105990\n",
      "Pretrain epoch [27/324], ZINB loss:0.6311, NB loss:4.7749, latent MSE loss:0.00276365, KL loss:0.00005496\n",
      "Pretrain epoch [1/325], ZINB loss:0.4041, NB loss:4.5694, latent MSE loss:0.00117660, KL loss:0.00158445\n",
      "Pretrain epoch [2/325], ZINB loss:0.3844, NB loss:4.4367, latent MSE loss:0.00102400, KL loss:0.00116667\n",
      "Pretrain epoch [3/325], ZINB loss:0.4158, NB loss:4.5191, latent MSE loss:0.00102771, KL loss:0.00156995\n",
      "Pretrain epoch [4/325], ZINB loss:0.4050, NB loss:4.5360, latent MSE loss:0.00118016, KL loss:0.00120220\n",
      "Pretrain epoch [5/325], ZINB loss:0.4066, NB loss:4.5308, latent MSE loss:0.00081736, KL loss:0.00126744\n",
      "Pretrain epoch [6/325], ZINB loss:0.4103, NB loss:4.5581, latent MSE loss:0.00093447, KL loss:0.00116205\n",
      "Pretrain epoch [7/325], ZINB loss:0.3817, NB loss:4.5105, latent MSE loss:0.00077278, KL loss:0.00119194\n",
      "Pretrain epoch [8/325], ZINB loss:0.4157, NB loss:4.5226, latent MSE loss:0.00072508, KL loss:0.00106100\n",
      "Pretrain epoch [9/325], ZINB loss:0.4039, NB loss:4.4637, latent MSE loss:0.00059301, KL loss:0.00103376\n",
      "Pretrain epoch [10/325], ZINB loss:0.3882, NB loss:4.4926, latent MSE loss:0.00054880, KL loss:0.00106356\n",
      "Pretrain epoch [11/325], ZINB loss:0.3867, NB loss:4.5307, latent MSE loss:0.00082782, KL loss:0.00106504\n",
      "Pretrain epoch [12/325], ZINB loss:0.4166, NB loss:4.5073, latent MSE loss:0.00064192, KL loss:0.00098109\n",
      "Pretrain epoch [13/325], ZINB loss:0.3837, NB loss:4.4839, latent MSE loss:0.00053848, KL loss:0.00112054\n",
      "Pretrain epoch [14/325], ZINB loss:0.3991, NB loss:4.5550, latent MSE loss:0.00058650, KL loss:0.00113100\n",
      "Pretrain epoch [15/325], ZINB loss:0.3981, NB loss:4.4952, latent MSE loss:0.00040010, KL loss:0.00107808\n",
      "Pretrain epoch [16/325], ZINB loss:0.3936, NB loss:4.5039, latent MSE loss:0.00053239, KL loss:0.00115939\n",
      "Pretrain epoch [17/325], ZINB loss:0.3996, NB loss:4.5682, latent MSE loss:0.00046119, KL loss:0.00138212\n",
      "Pretrain epoch [18/325], ZINB loss:0.4177, NB loss:4.5602, latent MSE loss:0.00048842, KL loss:0.00102716\n",
      "Pretrain epoch [19/325], ZINB loss:0.3780, NB loss:4.4725, latent MSE loss:0.00043491, KL loss:0.00123205\n",
      "Pretrain epoch [20/325], ZINB loss:0.3891, NB loss:4.5180, latent MSE loss:0.00047986, KL loss:0.00102412\n",
      "Pretrain epoch [21/325], ZINB loss:0.3896, NB loss:4.5268, latent MSE loss:0.00047022, KL loss:0.00100059\n",
      "Pretrain epoch [22/325], ZINB loss:0.4018, NB loss:4.4900, latent MSE loss:0.00061474, KL loss:0.00125916\n",
      "Pretrain epoch [23/325], ZINB loss:0.3857, NB loss:4.4726, latent MSE loss:0.00033920, KL loss:0.00096281\n",
      "Pretrain epoch [24/325], ZINB loss:0.3988, NB loss:4.5158, latent MSE loss:0.00035422, KL loss:0.00113656\n",
      "Pretrain epoch [25/325], ZINB loss:0.3951, NB loss:4.4448, latent MSE loss:0.00033220, KL loss:0.00097925\n",
      "Pretrain epoch [26/325], ZINB loss:0.3742, NB loss:4.5544, latent MSE loss:0.00041562, KL loss:0.00100154\n",
      "Pretrain epoch [27/325], ZINB loss:0.3793, NB loss:4.6359, latent MSE loss:0.00016105, KL loss:0.00007066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [1/326], ZINB loss:0.4125, NB loss:4.5261, latent MSE loss:0.00057679, KL loss:0.00092094\n",
      "Pretrain epoch [2/326], ZINB loss:0.3715, NB loss:4.5397, latent MSE loss:0.00052248, KL loss:0.00111971\n",
      "Pretrain epoch [3/326], ZINB loss:0.3874, NB loss:4.5171, latent MSE loss:0.00049852, KL loss:0.00098377\n",
      "Pretrain epoch [4/326], ZINB loss:0.3817, NB loss:4.5120, latent MSE loss:0.00028564, KL loss:0.00087194\n",
      "Pretrain epoch [5/326], ZINB loss:0.3680, NB loss:4.5377, latent MSE loss:0.00029917, KL loss:0.00096448\n",
      "Pretrain epoch [6/326], ZINB loss:0.4056, NB loss:4.5433, latent MSE loss:0.00039420, KL loss:0.00095228\n",
      "Pretrain epoch [7/326], ZINB loss:0.4051, NB loss:4.4880, latent MSE loss:0.00040767, KL loss:0.00109827\n",
      "Pretrain epoch [8/326], ZINB loss:0.3919, NB loss:4.5483, latent MSE loss:0.00036399, KL loss:0.00140060\n",
      "Pretrain epoch [9/326], ZINB loss:0.3996, NB loss:4.4862, latent MSE loss:0.00039154, KL loss:0.00115820\n",
      "Pretrain epoch [10/326], ZINB loss:0.4117, NB loss:4.5174, latent MSE loss:0.00039989, KL loss:0.00125072\n",
      "Pretrain epoch [11/326], ZINB loss:0.3993, NB loss:4.4626, latent MSE loss:0.00044457, KL loss:0.00096699\n",
      "Pretrain epoch [12/326], ZINB loss:0.3964, NB loss:4.5348, latent MSE loss:0.00032833, KL loss:0.00088315\n",
      "Pretrain epoch [13/326], ZINB loss:0.4059, NB loss:4.4803, latent MSE loss:0.00040132, KL loss:0.00104581\n",
      "Pretrain epoch [14/326], ZINB loss:0.4030, NB loss:4.5852, latent MSE loss:0.00029276, KL loss:0.00103293\n",
      "Pretrain epoch [15/326], ZINB loss:0.3955, NB loss:4.4781, latent MSE loss:0.00043776, KL loss:0.00082870\n",
      "Pretrain epoch [16/326], ZINB loss:0.3813, NB loss:4.5181, latent MSE loss:0.00031332, KL loss:0.00085118\n",
      "Pretrain epoch [17/326], ZINB loss:0.3859, NB loss:4.4658, latent MSE loss:0.00023838, KL loss:0.00098826\n",
      "Pretrain epoch [18/326], ZINB loss:0.3982, NB loss:4.5717, latent MSE loss:0.00018828, KL loss:0.00122354\n",
      "Pretrain epoch [19/326], ZINB loss:0.4258, NB loss:4.4608, latent MSE loss:0.00036417, KL loss:0.00153436\n",
      "Pretrain epoch [20/326], ZINB loss:0.3956, NB loss:4.4973, latent MSE loss:0.00029126, KL loss:0.00096920\n",
      "Pretrain epoch [21/326], ZINB loss:0.3864, NB loss:4.5121, latent MSE loss:0.00027287, KL loss:0.00103214\n",
      "Pretrain epoch [22/326], ZINB loss:0.4054, NB loss:4.5744, latent MSE loss:0.00028885, KL loss:0.00122328\n",
      "Pretrain epoch [23/326], ZINB loss:0.4074, NB loss:4.4831, latent MSE loss:0.00031918, KL loss:0.00104983\n",
      "Pretrain epoch [24/326], ZINB loss:0.3959, NB loss:4.4603, latent MSE loss:0.00019457, KL loss:0.00083755\n",
      "Pretrain epoch [25/326], ZINB loss:0.3897, NB loss:4.4893, latent MSE loss:0.00022419, KL loss:0.00089395\n",
      "Pretrain epoch [26/326], ZINB loss:0.3887, NB loss:4.5273, latent MSE loss:0.00033530, KL loss:0.00124943\n",
      "Pretrain epoch [27/326], ZINB loss:0.3295, NB loss:4.6287, latent MSE loss:0.00025985, KL loss:0.00001201\n",
      "Pretrain epoch [1/327], ZINB loss:0.3899, NB loss:4.5029, latent MSE loss:0.00031087, KL loss:0.00109651\n",
      "Pretrain epoch [2/327], ZINB loss:0.3917, NB loss:4.5216, latent MSE loss:0.00020495, KL loss:0.00096412\n",
      "Pretrain epoch [3/327], ZINB loss:0.3959, NB loss:4.5897, latent MSE loss:0.00033866, KL loss:0.00115118\n",
      "Pretrain epoch [4/327], ZINB loss:0.3960, NB loss:4.5320, latent MSE loss:0.00029634, KL loss:0.00091759\n",
      "Pretrain epoch [5/327], ZINB loss:0.4144, NB loss:4.5388, latent MSE loss:0.00033874, KL loss:0.00103757\n",
      "Pretrain epoch [6/327], ZINB loss:0.3949, NB loss:4.5201, latent MSE loss:0.00024238, KL loss:0.00097460\n",
      "Pretrain epoch [7/327], ZINB loss:0.3817, NB loss:4.5266, latent MSE loss:0.00028897, KL loss:0.00100247\n",
      "Pretrain epoch [8/327], ZINB loss:0.3939, NB loss:4.4918, latent MSE loss:0.00034338, KL loss:0.00085418\n",
      "Pretrain epoch [9/327], ZINB loss:0.4040, NB loss:4.4530, latent MSE loss:0.00026008, KL loss:0.00089162\n",
      "Pretrain epoch [10/327], ZINB loss:0.3984, NB loss:4.5614, latent MSE loss:0.00025137, KL loss:0.00129838\n",
      "Pretrain epoch [11/327], ZINB loss:0.4053, NB loss:4.5040, latent MSE loss:0.00030028, KL loss:0.00098480\n",
      "Pretrain epoch [12/327], ZINB loss:0.3788, NB loss:4.4715, latent MSE loss:0.00023945, KL loss:0.00089647\n",
      "Pretrain epoch [13/327], ZINB loss:0.3879, NB loss:4.5088, latent MSE loss:0.00023132, KL loss:0.00095272\n",
      "Pretrain epoch [14/327], ZINB loss:0.3919, NB loss:4.5202, latent MSE loss:0.00024668, KL loss:0.00092519\n",
      "Pretrain epoch [15/327], ZINB loss:0.4078, NB loss:4.5150, latent MSE loss:0.00023071, KL loss:0.00092134\n",
      "Pretrain epoch [16/327], ZINB loss:0.3826, NB loss:4.5077, latent MSE loss:0.00022595, KL loss:0.00089884\n",
      "Pretrain epoch [17/327], ZINB loss:0.3810, NB loss:4.4975, latent MSE loss:0.00021912, KL loss:0.00086887\n",
      "Pretrain epoch [18/327], ZINB loss:0.4127, NB loss:4.5521, latent MSE loss:0.00022433, KL loss:0.00099828\n",
      "Pretrain epoch [19/327], ZINB loss:0.3790, NB loss:4.4983, latent MSE loss:0.00020576, KL loss:0.00086714\n",
      "Pretrain epoch [20/327], ZINB loss:0.4022, NB loss:4.5332, latent MSE loss:0.00031136, KL loss:0.00101670\n",
      "Pretrain epoch [21/327], ZINB loss:0.3886, NB loss:4.5108, latent MSE loss:0.00024017, KL loss:0.00091077\n",
      "Pretrain epoch [22/327], ZINB loss:0.3964, NB loss:4.4988, latent MSE loss:0.00024470, KL loss:0.00088707\n",
      "Pretrain epoch [23/327], ZINB loss:0.4000, NB loss:4.4511, latent MSE loss:0.00017430, KL loss:0.00078700\n",
      "Pretrain epoch [24/327], ZINB loss:0.4146, NB loss:4.5305, latent MSE loss:0.00025988, KL loss:0.00092789\n",
      "Pretrain epoch [25/327], ZINB loss:0.3989, NB loss:4.4415, latent MSE loss:0.00030130, KL loss:0.00086797\n",
      "Pretrain epoch [26/327], ZINB loss:0.3971, NB loss:4.5012, latent MSE loss:0.00022950, KL loss:0.00085393\n",
      "Pretrain epoch [27/327], ZINB loss:0.3990, NB loss:4.2408, latent MSE loss:0.00018109, KL loss:0.00000609\n",
      "Pretrain epoch [1/328], ZINB loss:0.4087, NB loss:4.5533, latent MSE loss:0.00043961, KL loss:0.00112094\n",
      "Pretrain epoch [2/328], ZINB loss:0.3847, NB loss:4.5051, latent MSE loss:0.00029901, KL loss:0.00105690\n",
      "Pretrain epoch [3/328], ZINB loss:0.3917, NB loss:4.5101, latent MSE loss:0.00034741, KL loss:0.00084790\n",
      "Pretrain epoch [4/328], ZINB loss:0.3956, NB loss:4.4853, latent MSE loss:0.00024999, KL loss:0.00083791\n",
      "Pretrain epoch [5/328], ZINB loss:0.3966, NB loss:4.5415, latent MSE loss:0.00033110, KL loss:0.00100244\n",
      "Pretrain epoch [6/328], ZINB loss:0.4043, NB loss:4.5689, latent MSE loss:0.00035682, KL loss:0.00113459\n",
      "Pretrain epoch [7/328], ZINB loss:0.4092, NB loss:4.5112, latent MSE loss:0.00026209, KL loss:0.00090172\n",
      "Pretrain epoch [8/328], ZINB loss:0.3931, NB loss:4.5291, latent MSE loss:0.00027878, KL loss:0.00121498\n",
      "Pretrain epoch [9/328], ZINB loss:0.3894, NB loss:4.4712, latent MSE loss:0.00029338, KL loss:0.00079719\n",
      "Pretrain epoch [10/328], ZINB loss:0.4086, NB loss:4.4717, latent MSE loss:0.00040305, KL loss:0.00095554\n",
      "Pretrain epoch [11/328], ZINB loss:0.3980, NB loss:4.5844, latent MSE loss:0.00040425, KL loss:0.00092397\n",
      "Pretrain epoch [12/328], ZINB loss:0.4025, NB loss:4.4942, latent MSE loss:0.00042485, KL loss:0.00099706\n",
      "Pretrain epoch [13/328], ZINB loss:0.3885, NB loss:4.4636, latent MSE loss:0.00027045, KL loss:0.00086809\n",
      "Pretrain epoch [14/328], ZINB loss:0.4034, NB loss:4.5005, latent MSE loss:0.00039405, KL loss:0.00084005\n",
      "Pretrain epoch [15/328], ZINB loss:0.3937, NB loss:4.5710, latent MSE loss:0.00032349, KL loss:0.00110847\n",
      "Pretrain epoch [16/328], ZINB loss:0.4017, NB loss:4.4924, latent MSE loss:0.00031963, KL loss:0.00083655\n",
      "Pretrain epoch [17/328], ZINB loss:0.4157, NB loss:4.5379, latent MSE loss:0.00032686, KL loss:0.00133271\n",
      "Pretrain epoch [18/328], ZINB loss:0.3905, NB loss:4.4670, latent MSE loss:0.00034027, KL loss:0.00085907\n",
      "Pretrain epoch [19/328], ZINB loss:0.3906, NB loss:4.5470, latent MSE loss:0.00024254, KL loss:0.00086417\n",
      "Pretrain epoch [20/328], ZINB loss:0.3771, NB loss:4.4774, latent MSE loss:0.00035463, KL loss:0.00084323\n",
      "Pretrain epoch [21/328], ZINB loss:0.4014, NB loss:4.4998, latent MSE loss:0.00028767, KL loss:0.00093529\n",
      "Pretrain epoch [22/328], ZINB loss:0.3790, NB loss:4.5343, latent MSE loss:0.00023256, KL loss:0.00085000\n",
      "Pretrain epoch [23/328], ZINB loss:0.4125, NB loss:4.4421, latent MSE loss:0.00030883, KL loss:0.00124423\n",
      "Pretrain epoch [24/328], ZINB loss:0.3944, NB loss:4.5112, latent MSE loss:0.00036469, KL loss:0.00154306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [25/328], ZINB loss:0.3625, NB loss:4.4744, latent MSE loss:0.00024265, KL loss:0.00080261\n",
      "Pretrain epoch [26/328], ZINB loss:0.3981, NB loss:4.5181, latent MSE loss:0.00025596, KL loss:0.00133372\n",
      "Pretrain epoch [27/328], ZINB loss:0.4810, NB loss:4.7999, latent MSE loss:0.00022370, KL loss:0.00000703\n",
      "Pretrain epoch [1/329], ZINB loss:0.3941, NB loss:4.5141, latent MSE loss:0.00069583, KL loss:0.00121909\n",
      "Pretrain epoch [2/329], ZINB loss:0.3870, NB loss:4.5396, latent MSE loss:0.00050482, KL loss:0.00077836\n",
      "Pretrain epoch [3/329], ZINB loss:0.4116, NB loss:4.4716, latent MSE loss:0.00084100, KL loss:0.00091674\n",
      "Pretrain epoch [4/329], ZINB loss:0.4141, NB loss:4.5193, latent MSE loss:0.00067808, KL loss:0.00082559\n",
      "Pretrain epoch [5/329], ZINB loss:0.3851, NB loss:4.5970, latent MSE loss:0.00030594, KL loss:0.00096296\n",
      "Pretrain epoch [6/329], ZINB loss:0.4038, NB loss:4.5891, latent MSE loss:0.00061035, KL loss:0.00094847\n",
      "Pretrain epoch [7/329], ZINB loss:0.4040, NB loss:4.5070, latent MSE loss:0.00063292, KL loss:0.00088348\n",
      "Pretrain epoch [8/329], ZINB loss:0.3905, NB loss:4.4896, latent MSE loss:0.00081949, KL loss:0.00087928\n",
      "Pretrain epoch [9/329], ZINB loss:0.3795, NB loss:4.5212, latent MSE loss:0.00054773, KL loss:0.00105164\n",
      "Pretrain epoch [10/329], ZINB loss:0.3972, NB loss:4.5844, latent MSE loss:0.00046251, KL loss:0.00136876\n",
      "Pretrain epoch [11/329], ZINB loss:0.3764, NB loss:4.4850, latent MSE loss:0.00036145, KL loss:0.00077434\n",
      "Pretrain epoch [12/329], ZINB loss:0.3859, NB loss:4.4729, latent MSE loss:0.00059410, KL loss:0.00100844\n",
      "Pretrain epoch [13/329], ZINB loss:0.3869, NB loss:4.4890, latent MSE loss:0.00066675, KL loss:0.00129262\n",
      "Pretrain epoch [14/329], ZINB loss:0.3958, NB loss:4.5578, latent MSE loss:0.00046456, KL loss:0.00113862\n",
      "Pretrain epoch [15/329], ZINB loss:0.3878, NB loss:4.5299, latent MSE loss:0.00039193, KL loss:0.00076991\n",
      "Pretrain epoch [16/329], ZINB loss:0.4130, NB loss:4.5304, latent MSE loss:0.00031090, KL loss:0.00090690\n",
      "Pretrain epoch [17/329], ZINB loss:0.3992, NB loss:4.4480, latent MSE loss:0.00036041, KL loss:0.00109321\n",
      "Pretrain epoch [18/329], ZINB loss:0.4071, NB loss:4.4876, latent MSE loss:0.00041548, KL loss:0.00093614\n",
      "Pretrain epoch [19/329], ZINB loss:0.3877, NB loss:4.4828, latent MSE loss:0.00040075, KL loss:0.00077977\n",
      "Pretrain epoch [20/329], ZINB loss:0.3902, NB loss:4.4720, latent MSE loss:0.00028777, KL loss:0.00090645\n",
      "Pretrain epoch [21/329], ZINB loss:0.4152, NB loss:4.4635, latent MSE loss:0.00038534, KL loss:0.00112245\n",
      "Pretrain epoch [22/329], ZINB loss:0.3891, NB loss:4.4511, latent MSE loss:0.00034252, KL loss:0.00096644\n",
      "Pretrain epoch [23/329], ZINB loss:0.3751, NB loss:4.5093, latent MSE loss:0.00030854, KL loss:0.00080480\n",
      "Pretrain epoch [24/329], ZINB loss:0.3864, NB loss:4.4772, latent MSE loss:0.00034747, KL loss:0.00082921\n",
      "Pretrain epoch [25/329], ZINB loss:0.4330, NB loss:4.5623, latent MSE loss:0.00046732, KL loss:0.00102425\n",
      "Pretrain epoch [26/329], ZINB loss:0.3910, NB loss:4.5262, latent MSE loss:0.00034917, KL loss:0.00118080\n",
      "Pretrain epoch [27/329], ZINB loss:0.3599, NB loss:4.0440, latent MSE loss:0.00021687, KL loss:0.00000495\n",
      "Pretrain epoch [1/330], ZINB loss:0.3851, NB loss:4.5765, latent MSE loss:0.00051685, KL loss:0.00091902\n",
      "Pretrain epoch [2/330], ZINB loss:0.4017, NB loss:4.5349, latent MSE loss:0.00050688, KL loss:0.00147105\n",
      "Pretrain epoch [3/330], ZINB loss:0.3984, NB loss:4.5059, latent MSE loss:0.00038026, KL loss:0.00087619\n",
      "Pretrain epoch [4/330], ZINB loss:0.3870, NB loss:4.5060, latent MSE loss:0.00040138, KL loss:0.00100067\n",
      "Pretrain epoch [5/330], ZINB loss:0.3900, NB loss:4.4916, latent MSE loss:0.00043769, KL loss:0.00095119\n",
      "Pretrain epoch [6/330], ZINB loss:0.3960, NB loss:4.4304, latent MSE loss:0.00051532, KL loss:0.00119758\n",
      "Pretrain epoch [7/330], ZINB loss:0.3800, NB loss:4.5153, latent MSE loss:0.00030981, KL loss:0.00082263\n",
      "Pretrain epoch [8/330], ZINB loss:0.3983, NB loss:4.5660, latent MSE loss:0.00030894, KL loss:0.00102131\n",
      "Pretrain epoch [9/330], ZINB loss:0.3988, NB loss:4.5490, latent MSE loss:0.00037418, KL loss:0.00108690\n",
      "Pretrain epoch [10/330], ZINB loss:0.3974, NB loss:4.4365, latent MSE loss:0.00033743, KL loss:0.00103220\n",
      "Pretrain epoch [11/330], ZINB loss:0.4066, NB loss:4.4917, latent MSE loss:0.00042056, KL loss:0.00117380\n",
      "Pretrain epoch [12/330], ZINB loss:0.3899, NB loss:4.5030, latent MSE loss:0.00026541, KL loss:0.00080393\n",
      "Pretrain epoch [13/330], ZINB loss:0.3940, NB loss:4.5316, latent MSE loss:0.00027784, KL loss:0.00090031\n",
      "Pretrain epoch [14/330], ZINB loss:0.3813, NB loss:4.4800, latent MSE loss:0.00021997, KL loss:0.00085214\n",
      "Pretrain epoch [15/330], ZINB loss:0.4126, NB loss:4.4904, latent MSE loss:0.00029741, KL loss:0.00082931\n",
      "Pretrain epoch [16/330], ZINB loss:0.4125, NB loss:4.5129, latent MSE loss:0.00024911, KL loss:0.00080436\n",
      "Pretrain epoch [17/330], ZINB loss:0.4221, NB loss:4.5609, latent MSE loss:0.00039837, KL loss:0.00118551\n",
      "Pretrain epoch [18/330], ZINB loss:0.4024, NB loss:4.4556, latent MSE loss:0.00030835, KL loss:0.00083154\n",
      "Pretrain epoch [19/330], ZINB loss:0.3670, NB loss:4.4677, latent MSE loss:0.00020686, KL loss:0.00083278\n",
      "Pretrain epoch [20/330], ZINB loss:0.3901, NB loss:4.4863, latent MSE loss:0.00025510, KL loss:0.00102384\n",
      "Pretrain epoch [21/330], ZINB loss:0.3867, NB loss:4.4760, latent MSE loss:0.00025491, KL loss:0.00082496\n",
      "Pretrain epoch [22/330], ZINB loss:0.3904, NB loss:4.5504, latent MSE loss:0.00019198, KL loss:0.00086005\n",
      "Pretrain epoch [23/330], ZINB loss:0.4046, NB loss:4.4910, latent MSE loss:0.00031466, KL loss:0.00103958\n",
      "Pretrain epoch [24/330], ZINB loss:0.3836, NB loss:4.4795, latent MSE loss:0.00018844, KL loss:0.00092499\n",
      "Pretrain epoch [25/330], ZINB loss:0.3949, NB loss:4.5138, latent MSE loss:0.00025310, KL loss:0.00141146\n",
      "Pretrain epoch [26/330], ZINB loss:0.4069, NB loss:4.5912, latent MSE loss:0.00024098, KL loss:0.00086482\n",
      "Pretrain epoch [27/330], ZINB loss:0.5623, NB loss:5.2282, latent MSE loss:0.00051511, KL loss:0.00000512\n",
      "Pretrain epoch [1/331], ZINB loss:0.3916, NB loss:4.5146, latent MSE loss:0.00105173, KL loss:0.00103917\n",
      "Pretrain epoch [2/331], ZINB loss:0.3920, NB loss:4.5406, latent MSE loss:0.00133008, KL loss:0.00131013\n",
      "Pretrain epoch [3/331], ZINB loss:0.3752, NB loss:4.5426, latent MSE loss:0.00110774, KL loss:0.00099229\n",
      "Pretrain epoch [4/331], ZINB loss:0.3814, NB loss:4.4604, latent MSE loss:0.00057075, KL loss:0.00084963\n",
      "Pretrain epoch [5/331], ZINB loss:0.3867, NB loss:4.5052, latent MSE loss:0.00079865, KL loss:0.00098640\n",
      "Pretrain epoch [6/331], ZINB loss:0.3998, NB loss:4.5292, latent MSE loss:0.00160346, KL loss:0.00094584\n",
      "Pretrain epoch [7/331], ZINB loss:0.3803, NB loss:4.4860, latent MSE loss:0.00134039, KL loss:0.00091700\n",
      "Pretrain epoch [8/331], ZINB loss:0.4121, NB loss:4.4622, latent MSE loss:0.00064099, KL loss:0.00080192\n",
      "Pretrain epoch [9/331], ZINB loss:0.3828, NB loss:4.4539, latent MSE loss:0.00082285, KL loss:0.00084990\n",
      "Pretrain epoch [10/331], ZINB loss:0.3980, NB loss:4.5225, latent MSE loss:0.00106069, KL loss:0.00114366\n",
      "Pretrain epoch [11/331], ZINB loss:0.3875, NB loss:4.5176, latent MSE loss:0.00077020, KL loss:0.00120806\n",
      "Pretrain epoch [12/331], ZINB loss:0.4134, NB loss:4.4617, latent MSE loss:0.00064366, KL loss:0.00089253\n",
      "Pretrain epoch [13/331], ZINB loss:0.4012, NB loss:4.4940, latent MSE loss:0.00095898, KL loss:0.00103384\n",
      "Pretrain epoch [14/331], ZINB loss:0.3944, NB loss:4.4825, latent MSE loss:0.00053537, KL loss:0.00093980\n",
      "Pretrain epoch [15/331], ZINB loss:0.4031, NB loss:4.5250, latent MSE loss:0.00066801, KL loss:0.00092883\n",
      "Pretrain epoch [16/331], ZINB loss:0.3982, NB loss:4.5391, latent MSE loss:0.00063859, KL loss:0.00096830\n",
      "Pretrain epoch [17/331], ZINB loss:0.4027, NB loss:4.4801, latent MSE loss:0.00059262, KL loss:0.00089381\n",
      "Pretrain epoch [18/331], ZINB loss:0.4119, NB loss:4.5387, latent MSE loss:0.00052639, KL loss:0.00119144\n",
      "Pretrain epoch [19/331], ZINB loss:0.4204, NB loss:4.5528, latent MSE loss:0.00057662, KL loss:0.00106163\n",
      "Pretrain epoch [20/331], ZINB loss:0.3906, NB loss:4.5657, latent MSE loss:0.00045478, KL loss:0.00094711\n",
      "Pretrain epoch [21/331], ZINB loss:0.3959, NB loss:4.4526, latent MSE loss:0.00034725, KL loss:0.00081138\n",
      "Pretrain epoch [22/331], ZINB loss:0.3924, NB loss:4.5675, latent MSE loss:0.00049403, KL loss:0.00103091\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [23/331], ZINB loss:0.4031, NB loss:4.5276, latent MSE loss:0.00037756, KL loss:0.00079161\n",
      "Pretrain epoch [24/331], ZINB loss:0.3908, NB loss:4.4464, latent MSE loss:0.00028664, KL loss:0.00077040\n",
      "Pretrain epoch [25/331], ZINB loss:0.3845, NB loss:4.4905, latent MSE loss:0.00038747, KL loss:0.00080707\n",
      "Pretrain epoch [26/331], ZINB loss:0.4043, NB loss:4.5358, latent MSE loss:0.00032814, KL loss:0.00093940\n",
      "Pretrain epoch [27/331], ZINB loss:0.4127, NB loss:4.7182, latent MSE loss:0.00026464, KL loss:0.00007716\n",
      "Pretrain epoch [1/332], ZINB loss:0.3987, NB loss:4.5109, latent MSE loss:0.00115439, KL loss:0.00095615\n",
      "Pretrain epoch [2/332], ZINB loss:0.3830, NB loss:4.5452, latent MSE loss:0.00040152, KL loss:0.00099648\n",
      "Pretrain epoch [3/332], ZINB loss:0.3806, NB loss:4.4942, latent MSE loss:0.00079519, KL loss:0.00090173\n",
      "Pretrain epoch [4/332], ZINB loss:0.3964, NB loss:4.5056, latent MSE loss:0.00072473, KL loss:0.00108294\n",
      "Pretrain epoch [5/332], ZINB loss:0.3931, NB loss:4.5677, latent MSE loss:0.00054984, KL loss:0.00085428\n",
      "Pretrain epoch [6/332], ZINB loss:0.4009, NB loss:4.5221, latent MSE loss:0.00077515, KL loss:0.00108771\n",
      "Pretrain epoch [7/332], ZINB loss:0.3982, NB loss:4.5167, latent MSE loss:0.00051976, KL loss:0.00100765\n",
      "Pretrain epoch [8/332], ZINB loss:0.3752, NB loss:4.4374, latent MSE loss:0.00044645, KL loss:0.00084939\n",
      "Pretrain epoch [9/332], ZINB loss:0.4043, NB loss:4.5144, latent MSE loss:0.00064371, KL loss:0.00089878\n",
      "Pretrain epoch [10/332], ZINB loss:0.4048, NB loss:4.5616, latent MSE loss:0.00032441, KL loss:0.00083765\n",
      "Pretrain epoch [11/332], ZINB loss:0.3843, NB loss:4.4889, latent MSE loss:0.00052741, KL loss:0.00091484\n",
      "Pretrain epoch [12/332], ZINB loss:0.4194, NB loss:4.4354, latent MSE loss:0.00043473, KL loss:0.00073461\n",
      "Pretrain epoch [13/332], ZINB loss:0.3906, NB loss:4.5060, latent MSE loss:0.00043148, KL loss:0.00085450\n",
      "Pretrain epoch [14/332], ZINB loss:0.3921, NB loss:4.4681, latent MSE loss:0.00023495, KL loss:0.00079034\n",
      "Pretrain epoch [15/332], ZINB loss:0.4223, NB loss:4.5416, latent MSE loss:0.00042052, KL loss:0.00087108\n",
      "Pretrain epoch [16/332], ZINB loss:0.3968, NB loss:4.4991, latent MSE loss:0.00024442, KL loss:0.00080012\n",
      "Pretrain epoch [17/332], ZINB loss:0.3931, NB loss:4.5027, latent MSE loss:0.00041298, KL loss:0.00094478\n",
      "Pretrain epoch [18/332], ZINB loss:0.4141, NB loss:4.5323, latent MSE loss:0.00033228, KL loss:0.00094025\n",
      "Pretrain epoch [19/332], ZINB loss:0.3933, NB loss:4.4948, latent MSE loss:0.00031089, KL loss:0.00086405\n",
      "Pretrain epoch [20/332], ZINB loss:0.3939, NB loss:4.4813, latent MSE loss:0.00025501, KL loss:0.00082502\n",
      "Pretrain epoch [21/332], ZINB loss:0.3986, NB loss:4.4807, latent MSE loss:0.00032488, KL loss:0.00079416\n",
      "Pretrain epoch [22/332], ZINB loss:0.3921, NB loss:4.5455, latent MSE loss:0.00018974, KL loss:0.00077274\n",
      "Pretrain epoch [23/332], ZINB loss:0.3855, NB loss:4.4657, latent MSE loss:0.00033835, KL loss:0.00085382\n",
      "Pretrain epoch [24/332], ZINB loss:0.3740, NB loss:4.4950, latent MSE loss:0.00028523, KL loss:0.00085537\n",
      "Pretrain epoch [25/332], ZINB loss:0.4082, NB loss:4.4957, latent MSE loss:0.00035536, KL loss:0.00140429\n",
      "Pretrain epoch [26/332], ZINB loss:0.3897, NB loss:4.5602, latent MSE loss:0.00028099, KL loss:0.00108792\n",
      "Pretrain epoch [27/332], ZINB loss:0.4361, NB loss:4.7456, latent MSE loss:0.00031549, KL loss:0.00000686\n",
      "Pretrain epoch [1/333], ZINB loss:0.3678, NB loss:4.5134, latent MSE loss:0.00045779, KL loss:0.00087427\n",
      "Pretrain epoch [2/333], ZINB loss:0.3864, NB loss:4.5030, latent MSE loss:0.00047649, KL loss:0.00079153\n",
      "Pretrain epoch [3/333], ZINB loss:0.3622, NB loss:4.4916, latent MSE loss:0.00038942, KL loss:0.00090897\n",
      "Pretrain epoch [4/333], ZINB loss:0.3968, NB loss:4.5379, latent MSE loss:0.00047964, KL loss:0.00096160\n",
      "Pretrain epoch [5/333], ZINB loss:0.3970, NB loss:4.5255, latent MSE loss:0.00032555, KL loss:0.00085961\n",
      "Pretrain epoch [6/333], ZINB loss:0.4106, NB loss:4.5115, latent MSE loss:0.00040753, KL loss:0.00129987\n",
      "Pretrain epoch [7/333], ZINB loss:0.4028, NB loss:4.4710, latent MSE loss:0.00034663, KL loss:0.00094335\n",
      "Pretrain epoch [8/333], ZINB loss:0.4109, NB loss:4.5519, latent MSE loss:0.00037366, KL loss:0.00085433\n",
      "Pretrain epoch [9/333], ZINB loss:0.4024, NB loss:4.5206, latent MSE loss:0.00039891, KL loss:0.00102634\n",
      "Pretrain epoch [10/333], ZINB loss:0.4095, NB loss:4.5146, latent MSE loss:0.00035450, KL loss:0.00080076\n",
      "Pretrain epoch [11/333], ZINB loss:0.3827, NB loss:4.5050, latent MSE loss:0.00033955, KL loss:0.00097720\n",
      "Pretrain epoch [12/333], ZINB loss:0.4124, NB loss:4.4657, latent MSE loss:0.00026699, KL loss:0.00090521\n",
      "Pretrain epoch [13/333], ZINB loss:0.3639, NB loss:4.4327, latent MSE loss:0.00032456, KL loss:0.00075021\n",
      "Pretrain epoch [14/333], ZINB loss:0.3984, NB loss:4.5236, latent MSE loss:0.00039335, KL loss:0.00104908\n",
      "Pretrain epoch [15/333], ZINB loss:0.3942, NB loss:4.4618, latent MSE loss:0.00037225, KL loss:0.00075580\n",
      "Pretrain epoch [16/333], ZINB loss:0.3931, NB loss:4.4651, latent MSE loss:0.00031993, KL loss:0.00087532\n",
      "Pretrain epoch [17/333], ZINB loss:0.3826, NB loss:4.5065, latent MSE loss:0.00033557, KL loss:0.00086324\n",
      "Pretrain epoch [18/333], ZINB loss:0.3960, NB loss:4.5040, latent MSE loss:0.00034429, KL loss:0.00094550\n",
      "Pretrain epoch [19/333], ZINB loss:0.4260, NB loss:4.5419, latent MSE loss:0.00052219, KL loss:0.00139702\n",
      "Pretrain epoch [20/333], ZINB loss:0.4015, NB loss:4.5089, latent MSE loss:0.00024618, KL loss:0.00089315\n",
      "Pretrain epoch [21/333], ZINB loss:0.4002, NB loss:4.4730, latent MSE loss:0.00027182, KL loss:0.00089484\n",
      "Pretrain epoch [22/333], ZINB loss:0.4027, NB loss:4.5240, latent MSE loss:0.00028111, KL loss:0.00107700\n",
      "Pretrain epoch [23/333], ZINB loss:0.3977, NB loss:4.5000, latent MSE loss:0.00029643, KL loss:0.00110482\n",
      "Pretrain epoch [24/333], ZINB loss:0.3900, NB loss:4.5889, latent MSE loss:0.00025491, KL loss:0.00113918\n",
      "Pretrain epoch [25/333], ZINB loss:0.3907, NB loss:4.5303, latent MSE loss:0.00024267, KL loss:0.00083123\n",
      "Pretrain epoch [26/333], ZINB loss:0.4004, NB loss:4.4946, latent MSE loss:0.00041319, KL loss:0.00109974\n",
      "Pretrain epoch [27/333], ZINB loss:0.3894, NB loss:4.1058, latent MSE loss:0.00023013, KL loss:0.00000275\n",
      "Pretrain epoch [1/334], ZINB loss:0.3950, NB loss:4.5294, latent MSE loss:0.00087802, KL loss:0.00117401\n",
      "Pretrain epoch [2/334], ZINB loss:0.4256, NB loss:4.4674, latent MSE loss:0.00061432, KL loss:0.00092470\n",
      "Pretrain epoch [3/334], ZINB loss:0.3843, NB loss:4.4827, latent MSE loss:0.00099004, KL loss:0.00113818\n",
      "Pretrain epoch [4/334], ZINB loss:0.3809, NB loss:4.4879, latent MSE loss:0.00049286, KL loss:0.00085331\n",
      "Pretrain epoch [5/334], ZINB loss:0.3906, NB loss:4.5094, latent MSE loss:0.00064655, KL loss:0.00091173\n",
      "Pretrain epoch [6/334], ZINB loss:0.4003, NB loss:4.4676, latent MSE loss:0.00082136, KL loss:0.00075936\n",
      "Pretrain epoch [7/334], ZINB loss:0.3980, NB loss:4.4974, latent MSE loss:0.00061675, KL loss:0.00081647\n",
      "Pretrain epoch [8/334], ZINB loss:0.3879, NB loss:4.5153, latent MSE loss:0.00056200, KL loss:0.00078278\n",
      "Pretrain epoch [9/334], ZINB loss:0.3883, NB loss:4.4500, latent MSE loss:0.00054912, KL loss:0.00096062\n",
      "Pretrain epoch [10/334], ZINB loss:0.3811, NB loss:4.4903, latent MSE loss:0.00060088, KL loss:0.00083010\n",
      "Pretrain epoch [11/334], ZINB loss:0.4025, NB loss:4.5195, latent MSE loss:0.00048097, KL loss:0.00095167\n",
      "Pretrain epoch [12/334], ZINB loss:0.3963, NB loss:4.4260, latent MSE loss:0.00053445, KL loss:0.00090198\n",
      "Pretrain epoch [13/334], ZINB loss:0.3886, NB loss:4.5156, latent MSE loss:0.00035006, KL loss:0.00075562\n",
      "Pretrain epoch [14/334], ZINB loss:0.4114, NB loss:4.5764, latent MSE loss:0.00050333, KL loss:0.00095646\n",
      "Pretrain epoch [15/334], ZINB loss:0.4075, NB loss:4.5142, latent MSE loss:0.00037227, KL loss:0.00089340\n",
      "Pretrain epoch [16/334], ZINB loss:0.4068, NB loss:4.5489, latent MSE loss:0.00044653, KL loss:0.00099146\n",
      "Pretrain epoch [17/334], ZINB loss:0.3991, NB loss:4.5354, latent MSE loss:0.00037616, KL loss:0.00102421\n",
      "Pretrain epoch [18/334], ZINB loss:0.3850, NB loss:4.5941, latent MSE loss:0.00037320, KL loss:0.00101112\n",
      "Pretrain epoch [19/334], ZINB loss:0.3901, NB loss:4.4563, latent MSE loss:0.00032239, KL loss:0.00078224\n",
      "Pretrain epoch [20/334], ZINB loss:0.3941, NB loss:4.5364, latent MSE loss:0.00038427, KL loss:0.00086193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [21/334], ZINB loss:0.4139, NB loss:4.4868, latent MSE loss:0.00033753, KL loss:0.00081451\n",
      "Pretrain epoch [22/334], ZINB loss:0.4007, NB loss:4.4703, latent MSE loss:0.00041925, KL loss:0.00086980\n",
      "Pretrain epoch [23/334], ZINB loss:0.3698, NB loss:4.5451, latent MSE loss:0.00024882, KL loss:0.00081576\n",
      "Pretrain epoch [24/334], ZINB loss:0.3932, NB loss:4.4767, latent MSE loss:0.00034652, KL loss:0.00095128\n",
      "Pretrain epoch [25/334], ZINB loss:0.3923, NB loss:4.5191, latent MSE loss:0.00026999, KL loss:0.00074250\n",
      "Pretrain epoch [26/334], ZINB loss:0.4015, NB loss:4.5160, latent MSE loss:0.00031003, KL loss:0.00085593\n",
      "Pretrain epoch [27/334], ZINB loss:0.4008, NB loss:4.2040, latent MSE loss:0.00015736, KL loss:0.00007641\n",
      "Pretrain epoch [1/335], ZINB loss:0.3902, NB loss:4.4479, latent MSE loss:0.00037978, KL loss:0.00073262\n",
      "Pretrain epoch [2/335], ZINB loss:0.3995, NB loss:4.5137, latent MSE loss:0.00033445, KL loss:0.00086296\n",
      "Pretrain epoch [3/335], ZINB loss:0.3810, NB loss:4.5575, latent MSE loss:0.00034979, KL loss:0.00102864\n",
      "Pretrain epoch [4/335], ZINB loss:0.3725, NB loss:4.4933, latent MSE loss:0.00036777, KL loss:0.00094497\n",
      "Pretrain epoch [5/335], ZINB loss:0.3999, NB loss:4.4999, latent MSE loss:0.00030728, KL loss:0.00087576\n",
      "Pretrain epoch [6/335], ZINB loss:0.3981, NB loss:4.5134, latent MSE loss:0.00040890, KL loss:0.00115111\n",
      "Pretrain epoch [7/335], ZINB loss:0.4082, NB loss:4.5043, latent MSE loss:0.00038094, KL loss:0.00098499\n",
      "Pretrain epoch [8/335], ZINB loss:0.4143, NB loss:4.5546, latent MSE loss:0.00039307, KL loss:0.00133527\n",
      "Pretrain epoch [9/335], ZINB loss:0.3995, NB loss:4.4668, latent MSE loss:0.00030037, KL loss:0.00084048\n",
      "Pretrain epoch [10/335], ZINB loss:0.4015, NB loss:4.5069, latent MSE loss:0.00028547, KL loss:0.00081636\n",
      "Pretrain epoch [11/335], ZINB loss:0.4044, NB loss:4.5057, latent MSE loss:0.00039600, KL loss:0.00123339\n",
      "Pretrain epoch [12/335], ZINB loss:0.3748, NB loss:4.5207, latent MSE loss:0.00029455, KL loss:0.00083219\n",
      "Pretrain epoch [13/335], ZINB loss:0.3845, NB loss:4.5707, latent MSE loss:0.00024834, KL loss:0.00087338\n",
      "Pretrain epoch [14/335], ZINB loss:0.3959, NB loss:4.4716, latent MSE loss:0.00023711, KL loss:0.00076057\n",
      "Pretrain epoch [15/335], ZINB loss:0.4110, NB loss:4.5215, latent MSE loss:0.00045223, KL loss:0.00103776\n",
      "Pretrain epoch [16/335], ZINB loss:0.3973, NB loss:4.4176, latent MSE loss:0.00034292, KL loss:0.00096943\n",
      "Pretrain epoch [17/335], ZINB loss:0.4058, NB loss:4.4557, latent MSE loss:0.00034209, KL loss:0.00090559\n",
      "Pretrain epoch [18/335], ZINB loss:0.3975, NB loss:4.4839, latent MSE loss:0.00029543, KL loss:0.00111829\n",
      "Pretrain epoch [19/335], ZINB loss:0.3906, NB loss:4.5351, latent MSE loss:0.00023418, KL loss:0.00099592\n",
      "Pretrain epoch [20/335], ZINB loss:0.4121, NB loss:4.5430, latent MSE loss:0.00027317, KL loss:0.00078005\n",
      "Pretrain epoch [21/335], ZINB loss:0.4085, NB loss:4.5680, latent MSE loss:0.00023366, KL loss:0.00090530\n",
      "Pretrain epoch [22/335], ZINB loss:0.3859, NB loss:4.5235, latent MSE loss:0.00025752, KL loss:0.00080767\n",
      "Pretrain epoch [23/335], ZINB loss:0.3885, NB loss:4.4982, latent MSE loss:0.00025039, KL loss:0.00079615\n",
      "Pretrain epoch [24/335], ZINB loss:0.3818, NB loss:4.4559, latent MSE loss:0.00020621, KL loss:0.00078727\n",
      "Pretrain epoch [25/335], ZINB loss:0.4071, NB loss:4.4860, latent MSE loss:0.00027434, KL loss:0.00089116\n",
      "Pretrain epoch [26/335], ZINB loss:0.4050, NB loss:4.4811, latent MSE loss:0.00025446, KL loss:0.00077997\n",
      "Pretrain epoch [27/335], ZINB loss:0.3936, NB loss:4.5904, latent MSE loss:0.00026039, KL loss:0.00004011\n",
      "Pretrain epoch [1/336], ZINB loss:0.3873, NB loss:4.5352, latent MSE loss:0.00036512, KL loss:0.00092760\n",
      "Pretrain epoch [2/336], ZINB loss:0.3900, NB loss:4.4984, latent MSE loss:0.00033919, KL loss:0.00090688\n",
      "Pretrain epoch [3/336], ZINB loss:0.3814, NB loss:4.4351, latent MSE loss:0.00026914, KL loss:0.00072101\n",
      "Pretrain epoch [4/336], ZINB loss:0.3941, NB loss:4.5121, latent MSE loss:0.00030942, KL loss:0.00082671\n",
      "Pretrain epoch [5/336], ZINB loss:0.4102, NB loss:4.5061, latent MSE loss:0.00029300, KL loss:0.00098623\n",
      "Pretrain epoch [6/336], ZINB loss:0.3939, NB loss:4.5368, latent MSE loss:0.00035734, KL loss:0.00097750\n",
      "Pretrain epoch [7/336], ZINB loss:0.4129, NB loss:4.5943, latent MSE loss:0.00033088, KL loss:0.00130804\n",
      "Pretrain epoch [8/336], ZINB loss:0.4044, NB loss:4.5529, latent MSE loss:0.00032154, KL loss:0.00084146\n",
      "Pretrain epoch [9/336], ZINB loss:0.3926, NB loss:4.4963, latent MSE loss:0.00033784, KL loss:0.00074994\n",
      "Pretrain epoch [10/336], ZINB loss:0.3990, NB loss:4.4354, latent MSE loss:0.00041105, KL loss:0.00097539\n",
      "Pretrain epoch [11/336], ZINB loss:0.3932, NB loss:4.5165, latent MSE loss:0.00035839, KL loss:0.00125853\n",
      "Pretrain epoch [12/336], ZINB loss:0.4120, NB loss:4.4506, latent MSE loss:0.00025742, KL loss:0.00074789\n",
      "Pretrain epoch [13/336], ZINB loss:0.3868, NB loss:4.5353, latent MSE loss:0.00035947, KL loss:0.00114612\n",
      "Pretrain epoch [14/336], ZINB loss:0.4092, NB loss:4.4889, latent MSE loss:0.00041479, KL loss:0.00083658\n",
      "Pretrain epoch [15/336], ZINB loss:0.4107, NB loss:4.4546, latent MSE loss:0.00044935, KL loss:0.00114790\n",
      "Pretrain epoch [16/336], ZINB loss:0.3923, NB loss:4.4969, latent MSE loss:0.00025442, KL loss:0.00078758\n",
      "Pretrain epoch [17/336], ZINB loss:0.3744, NB loss:4.4649, latent MSE loss:0.00019939, KL loss:0.00074119\n",
      "Pretrain epoch [18/336], ZINB loss:0.3799, NB loss:4.5056, latent MSE loss:0.00029062, KL loss:0.00109363\n",
      "Pretrain epoch [19/336], ZINB loss:0.3897, NB loss:4.5191, latent MSE loss:0.00030002, KL loss:0.00078743\n",
      "Pretrain epoch [20/336], ZINB loss:0.3908, NB loss:4.4795, latent MSE loss:0.00038184, KL loss:0.00080188\n",
      "Pretrain epoch [21/336], ZINB loss:0.3924, NB loss:4.4821, latent MSE loss:0.00048439, KL loss:0.00095002\n",
      "Pretrain epoch [22/336], ZINB loss:0.3966, NB loss:4.4706, latent MSE loss:0.00032921, KL loss:0.00100627\n",
      "Pretrain epoch [23/336], ZINB loss:0.4044, NB loss:4.5807, latent MSE loss:0.00023456, KL loss:0.00089631\n",
      "Pretrain epoch [24/336], ZINB loss:0.4060, NB loss:4.5360, latent MSE loss:0.00025471, KL loss:0.00083475\n",
      "Pretrain epoch [25/336], ZINB loss:0.3983, NB loss:4.5256, latent MSE loss:0.00026904, KL loss:0.00115673\n",
      "Pretrain epoch [26/336], ZINB loss:0.3883, NB loss:4.4755, latent MSE loss:0.00031164, KL loss:0.00075487\n",
      "Pretrain epoch [27/336], ZINB loss:0.3097, NB loss:4.3586, latent MSE loss:0.00014398, KL loss:0.00007066\n",
      "Pretrain epoch [1/337], ZINB loss:0.3939, NB loss:4.5186, latent MSE loss:0.00029172, KL loss:0.00103115\n",
      "Pretrain epoch [2/337], ZINB loss:0.3993, NB loss:4.4581, latent MSE loss:0.00033309, KL loss:0.00079958\n",
      "Pretrain epoch [3/337], ZINB loss:0.3894, NB loss:4.5352, latent MSE loss:0.00034844, KL loss:0.00123768\n",
      "Pretrain epoch [4/337], ZINB loss:0.3885, NB loss:4.5133, latent MSE loss:0.00030727, KL loss:0.00103751\n",
      "Pretrain epoch [5/337], ZINB loss:0.3981, NB loss:4.5191, latent MSE loss:0.00030427, KL loss:0.00085468\n",
      "Pretrain epoch [6/337], ZINB loss:0.3936, NB loss:4.5252, latent MSE loss:0.00037273, KL loss:0.00086793\n",
      "Pretrain epoch [7/337], ZINB loss:0.3979, NB loss:4.4994, latent MSE loss:0.00026403, KL loss:0.00072207\n",
      "Pretrain epoch [8/337], ZINB loss:0.4037, NB loss:4.4614, latent MSE loss:0.00029283, KL loss:0.00080039\n",
      "Pretrain epoch [9/337], ZINB loss:0.3809, NB loss:4.5101, latent MSE loss:0.00028147, KL loss:0.00079902\n",
      "Pretrain epoch [10/337], ZINB loss:0.3869, NB loss:4.5329, latent MSE loss:0.00024828, KL loss:0.00081281\n",
      "Pretrain epoch [11/337], ZINB loss:0.4151, NB loss:4.5216, latent MSE loss:0.00029900, KL loss:0.00086837\n",
      "Pretrain epoch [12/337], ZINB loss:0.4052, NB loss:4.4804, latent MSE loss:0.00024243, KL loss:0.00076190\n",
      "Pretrain epoch [13/337], ZINB loss:0.3888, NB loss:4.5268, latent MSE loss:0.00027903, KL loss:0.00090387\n",
      "Pretrain epoch [14/337], ZINB loss:0.4123, NB loss:4.5614, latent MSE loss:0.00029961, KL loss:0.00086450\n",
      "Pretrain epoch [15/337], ZINB loss:0.3873, NB loss:4.5474, latent MSE loss:0.00032752, KL loss:0.00132580\n",
      "Pretrain epoch [16/337], ZINB loss:0.3836, NB loss:4.4872, latent MSE loss:0.00028470, KL loss:0.00087015\n",
      "Pretrain epoch [17/337], ZINB loss:0.3957, NB loss:4.4468, latent MSE loss:0.00026898, KL loss:0.00076254\n",
      "Pretrain epoch [18/337], ZINB loss:0.3821, NB loss:4.4634, latent MSE loss:0.00018333, KL loss:0.00070073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [19/337], ZINB loss:0.4059, NB loss:4.4412, latent MSE loss:0.00028020, KL loss:0.00089854\n",
      "Pretrain epoch [20/337], ZINB loss:0.3960, NB loss:4.4499, latent MSE loss:0.00028528, KL loss:0.00115483\n",
      "Pretrain epoch [21/337], ZINB loss:0.3986, NB loss:4.5516, latent MSE loss:0.00026256, KL loss:0.00091936\n",
      "Pretrain epoch [22/337], ZINB loss:0.4086, NB loss:4.5089, latent MSE loss:0.00030837, KL loss:0.00095851\n",
      "Pretrain epoch [23/337], ZINB loss:0.3691, NB loss:4.5803, latent MSE loss:0.00022635, KL loss:0.00082808\n",
      "Pretrain epoch [24/337], ZINB loss:0.3819, NB loss:4.4316, latent MSE loss:0.00021922, KL loss:0.00079780\n",
      "Pretrain epoch [25/337], ZINB loss:0.3909, NB loss:4.4788, latent MSE loss:0.00028798, KL loss:0.00079393\n",
      "Pretrain epoch [26/337], ZINB loss:0.4247, NB loss:4.5239, latent MSE loss:0.00031472, KL loss:0.00106570\n",
      "Pretrain epoch [27/337], ZINB loss:0.3308, NB loss:4.3116, latent MSE loss:0.00032661, KL loss:0.00006298\n",
      "Pretrain epoch [1/338], ZINB loss:0.3728, NB loss:4.5062, latent MSE loss:0.00105882, KL loss:0.00128865\n",
      "Pretrain epoch [2/338], ZINB loss:0.3986, NB loss:4.4471, latent MSE loss:0.00182245, KL loss:0.00087792\n",
      "Pretrain epoch [3/338], ZINB loss:0.4010, NB loss:4.4885, latent MSE loss:0.00206124, KL loss:0.00090300\n",
      "Pretrain epoch [4/338], ZINB loss:0.4032, NB loss:4.5191, latent MSE loss:0.00145771, KL loss:0.00085718\n",
      "Pretrain epoch [5/338], ZINB loss:0.4202, NB loss:4.5582, latent MSE loss:0.00095169, KL loss:0.00115714\n",
      "Pretrain epoch [6/338], ZINB loss:0.4070, NB loss:4.4878, latent MSE loss:0.00088687, KL loss:0.00085497\n",
      "Pretrain epoch [7/338], ZINB loss:0.3947, NB loss:4.4672, latent MSE loss:0.00102319, KL loss:0.00114043\n",
      "Pretrain epoch [8/338], ZINB loss:0.3909, NB loss:4.5219, latent MSE loss:0.00065410, KL loss:0.00076947\n",
      "Pretrain epoch [9/338], ZINB loss:0.3903, NB loss:4.5493, latent MSE loss:0.00102312, KL loss:0.00089480\n",
      "Pretrain epoch [10/338], ZINB loss:0.3975, NB loss:4.4910, latent MSE loss:0.00077062, KL loss:0.00094017\n",
      "Pretrain epoch [11/338], ZINB loss:0.4026, NB loss:4.4720, latent MSE loss:0.00062046, KL loss:0.00115612\n",
      "Pretrain epoch [12/338], ZINB loss:0.4082, NB loss:4.5038, latent MSE loss:0.00073284, KL loss:0.00104457\n",
      "Pretrain epoch [13/338], ZINB loss:0.3774, NB loss:4.5006, latent MSE loss:0.00074666, KL loss:0.00084526\n",
      "Pretrain epoch [14/338], ZINB loss:0.3806, NB loss:4.4865, latent MSE loss:0.00060088, KL loss:0.00092553\n",
      "Pretrain epoch [15/338], ZINB loss:0.3863, NB loss:4.5574, latent MSE loss:0.00048988, KL loss:0.00084844\n",
      "Pretrain epoch [16/338], ZINB loss:0.3956, NB loss:4.5792, latent MSE loss:0.00086785, KL loss:0.00109081\n",
      "Pretrain epoch [17/338], ZINB loss:0.4055, NB loss:4.4528, latent MSE loss:0.00066032, KL loss:0.00079030\n",
      "Pretrain epoch [18/338], ZINB loss:0.3993, NB loss:4.4562, latent MSE loss:0.00067263, KL loss:0.00091870\n",
      "Pretrain epoch [19/338], ZINB loss:0.3847, NB loss:4.5172, latent MSE loss:0.00051872, KL loss:0.00096309\n",
      "Pretrain epoch [20/338], ZINB loss:0.3792, NB loss:4.4996, latent MSE loss:0.00043056, KL loss:0.00081702\n",
      "Pretrain epoch [21/338], ZINB loss:0.3987, NB loss:4.4819, latent MSE loss:0.00045696, KL loss:0.00082416\n",
      "Pretrain epoch [22/338], ZINB loss:0.3964, NB loss:4.4975, latent MSE loss:0.00048115, KL loss:0.00107852\n",
      "Pretrain epoch [23/338], ZINB loss:0.3896, NB loss:4.5775, latent MSE loss:0.00040841, KL loss:0.00097909\n",
      "Pretrain epoch [24/338], ZINB loss:0.3971, NB loss:4.4809, latent MSE loss:0.00034476, KL loss:0.00108462\n",
      "Pretrain epoch [25/338], ZINB loss:0.4056, NB loss:4.4601, latent MSE loss:0.00037877, KL loss:0.00093215\n",
      "Pretrain epoch [26/338], ZINB loss:0.3982, NB loss:4.4767, latent MSE loss:0.00046010, KL loss:0.00094623\n",
      "Pretrain epoch [27/338], ZINB loss:0.4341, NB loss:4.8447, latent MSE loss:0.00025866, KL loss:0.00000886\n",
      "Pretrain epoch [1/339], ZINB loss:0.4074, NB loss:4.4499, latent MSE loss:0.00051567, KL loss:0.00082786\n",
      "Pretrain epoch [2/339], ZINB loss:0.4166, NB loss:4.5407, latent MSE loss:0.00048088, KL loss:0.00099147\n",
      "Pretrain epoch [3/339], ZINB loss:0.3776, NB loss:4.5227, latent MSE loss:0.00042328, KL loss:0.00090703\n",
      "Pretrain epoch [4/339], ZINB loss:0.3874, NB loss:4.5086, latent MSE loss:0.00044044, KL loss:0.00115219\n",
      "Pretrain epoch [5/339], ZINB loss:0.4076, NB loss:4.4869, latent MSE loss:0.00036872, KL loss:0.00091832\n",
      "Pretrain epoch [6/339], ZINB loss:0.3983, NB loss:4.5223, latent MSE loss:0.00036259, KL loss:0.00087417\n",
      "Pretrain epoch [7/339], ZINB loss:0.4090, NB loss:4.4539, latent MSE loss:0.00051498, KL loss:0.00110635\n",
      "Pretrain epoch [8/339], ZINB loss:0.4031, NB loss:4.4289, latent MSE loss:0.00042473, KL loss:0.00082449\n",
      "Pretrain epoch [9/339], ZINB loss:0.4019, NB loss:4.5005, latent MSE loss:0.00043710, KL loss:0.00091041\n",
      "Pretrain epoch [10/339], ZINB loss:0.3954, NB loss:4.5221, latent MSE loss:0.00037798, KL loss:0.00100908\n",
      "Pretrain epoch [11/339], ZINB loss:0.3830, NB loss:4.4973, latent MSE loss:0.00029439, KL loss:0.00084059\n",
      "Pretrain epoch [12/339], ZINB loss:0.3900, NB loss:4.4924, latent MSE loss:0.00028547, KL loss:0.00083838\n",
      "Pretrain epoch [13/339], ZINB loss:0.3819, NB loss:4.4863, latent MSE loss:0.00030811, KL loss:0.00073021\n",
      "Pretrain epoch [14/339], ZINB loss:0.4082, NB loss:4.5518, latent MSE loss:0.00036312, KL loss:0.00095255\n",
      "Pretrain epoch [15/339], ZINB loss:0.3729, NB loss:4.5565, latent MSE loss:0.00028378, KL loss:0.00099281\n",
      "Pretrain epoch [16/339], ZINB loss:0.4088, NB loss:4.5147, latent MSE loss:0.00038626, KL loss:0.00111884\n",
      "Pretrain epoch [17/339], ZINB loss:0.3866, NB loss:4.5263, latent MSE loss:0.00025938, KL loss:0.00080242\n",
      "Pretrain epoch [18/339], ZINB loss:0.4063, NB loss:4.4517, latent MSE loss:0.00034651, KL loss:0.00094339\n",
      "Pretrain epoch [19/339], ZINB loss:0.3768, NB loss:4.4297, latent MSE loss:0.00020581, KL loss:0.00098496\n",
      "Pretrain epoch [20/339], ZINB loss:0.4063, NB loss:4.5139, latent MSE loss:0.00029926, KL loss:0.00087645\n",
      "Pretrain epoch [21/339], ZINB loss:0.3868, NB loss:4.5036, latent MSE loss:0.00031721, KL loss:0.00105627\n",
      "Pretrain epoch [22/339], ZINB loss:0.3968, NB loss:4.5090, latent MSE loss:0.00022859, KL loss:0.00094590\n",
      "Pretrain epoch [23/339], ZINB loss:0.3866, NB loss:4.5446, latent MSE loss:0.00026104, KL loss:0.00090463\n",
      "Pretrain epoch [24/339], ZINB loss:0.4097, NB loss:4.4955, latent MSE loss:0.00019985, KL loss:0.00082346\n",
      "Pretrain epoch [25/339], ZINB loss:0.3876, NB loss:4.5248, latent MSE loss:0.00020932, KL loss:0.00091935\n",
      "Pretrain epoch [26/339], ZINB loss:0.3985, NB loss:4.4880, latent MSE loss:0.00019988, KL loss:0.00079013\n",
      "Pretrain epoch [27/339], ZINB loss:0.3084, NB loss:4.3681, latent MSE loss:0.00032671, KL loss:0.00004117\n",
      "Pretrain epoch [1/340], ZINB loss:0.3861, NB loss:4.4895, latent MSE loss:0.00035692, KL loss:0.00080269\n",
      "Pretrain epoch [2/340], ZINB loss:0.3954, NB loss:4.4259, latent MSE loss:0.00043760, KL loss:0.00101353\n",
      "Pretrain epoch [3/340], ZINB loss:0.3998, NB loss:4.5250, latent MSE loss:0.00032960, KL loss:0.00104520\n",
      "Pretrain epoch [4/340], ZINB loss:0.4041, NB loss:4.5299, latent MSE loss:0.00029819, KL loss:0.00109731\n",
      "Pretrain epoch [5/340], ZINB loss:0.3958, NB loss:4.5555, latent MSE loss:0.00030419, KL loss:0.00088708\n",
      "Pretrain epoch [6/340], ZINB loss:0.4063, NB loss:4.5372, latent MSE loss:0.00034321, KL loss:0.00101764\n",
      "Pretrain epoch [7/340], ZINB loss:0.3785, NB loss:4.5244, latent MSE loss:0.00029317, KL loss:0.00076069\n",
      "Pretrain epoch [8/340], ZINB loss:0.3829, NB loss:4.5216, latent MSE loss:0.00031383, KL loss:0.00091262\n",
      "Pretrain epoch [9/340], ZINB loss:0.4034, NB loss:4.4724, latent MSE loss:0.00040482, KL loss:0.00118605\n",
      "Pretrain epoch [10/340], ZINB loss:0.4058, NB loss:4.4925, latent MSE loss:0.00049553, KL loss:0.00107113\n",
      "Pretrain epoch [11/340], ZINB loss:0.3990, NB loss:4.5047, latent MSE loss:0.00045211, KL loss:0.00122623\n",
      "Pretrain epoch [12/340], ZINB loss:0.3873, NB loss:4.5079, latent MSE loss:0.00031158, KL loss:0.00079642\n",
      "Pretrain epoch [13/340], ZINB loss:0.3882, NB loss:4.5339, latent MSE loss:0.00035107, KL loss:0.00087454\n",
      "Pretrain epoch [14/340], ZINB loss:0.3815, NB loss:4.4902, latent MSE loss:0.00040650, KL loss:0.00101384\n",
      "Pretrain epoch [15/340], ZINB loss:0.3871, NB loss:4.4369, latent MSE loss:0.00044603, KL loss:0.00075999\n",
      "Pretrain epoch [16/340], ZINB loss:0.3917, NB loss:4.4732, latent MSE loss:0.00046188, KL loss:0.00124976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [17/340], ZINB loss:0.3910, NB loss:4.5645, latent MSE loss:0.00036766, KL loss:0.00093859\n",
      "Pretrain epoch [18/340], ZINB loss:0.4036, NB loss:4.5466, latent MSE loss:0.00034900, KL loss:0.00085446\n",
      "Pretrain epoch [19/340], ZINB loss:0.3978, NB loss:4.4162, latent MSE loss:0.00026877, KL loss:0.00100355\n",
      "Pretrain epoch [20/340], ZINB loss:0.4081, NB loss:4.4423, latent MSE loss:0.00033163, KL loss:0.00087338\n",
      "Pretrain epoch [21/340], ZINB loss:0.4164, NB loss:4.5119, latent MSE loss:0.00036922, KL loss:0.00098408\n",
      "Pretrain epoch [22/340], ZINB loss:0.3914, NB loss:4.4607, latent MSE loss:0.00036451, KL loss:0.00088749\n",
      "Pretrain epoch [23/340], ZINB loss:0.3998, NB loss:4.4801, latent MSE loss:0.00031260, KL loss:0.00080115\n",
      "Pretrain epoch [24/340], ZINB loss:0.3820, NB loss:4.5470, latent MSE loss:0.00026074, KL loss:0.00076213\n",
      "Pretrain epoch [25/340], ZINB loss:0.4016, NB loss:4.5202, latent MSE loss:0.00029430, KL loss:0.00091821\n",
      "Pretrain epoch [26/340], ZINB loss:0.4007, NB loss:4.5062, latent MSE loss:0.00034247, KL loss:0.00089646\n",
      "Pretrain epoch [27/340], ZINB loss:0.3708, NB loss:4.3017, latent MSE loss:0.00035734, KL loss:0.00006351\n",
      "Pretrain epoch [1/341], ZINB loss:0.4032, NB loss:4.4567, latent MSE loss:0.00048084, KL loss:0.00079614\n",
      "Pretrain epoch [2/341], ZINB loss:0.4064, NB loss:4.5346, latent MSE loss:0.00047660, KL loss:0.00093292\n",
      "Pretrain epoch [3/341], ZINB loss:0.3923, NB loss:4.5168, latent MSE loss:0.00042649, KL loss:0.00088879\n",
      "Pretrain epoch [4/341], ZINB loss:0.4116, NB loss:4.5016, latent MSE loss:0.00040055, KL loss:0.00093396\n",
      "Pretrain epoch [5/341], ZINB loss:0.3943, NB loss:4.5155, latent MSE loss:0.00048615, KL loss:0.00086631\n",
      "Pretrain epoch [6/341], ZINB loss:0.4040, NB loss:4.4334, latent MSE loss:0.00048093, KL loss:0.00116292\n",
      "Pretrain epoch [7/341], ZINB loss:0.3865, NB loss:4.5290, latent MSE loss:0.00047047, KL loss:0.00079996\n",
      "Pretrain epoch [8/341], ZINB loss:0.4053, NB loss:4.5200, latent MSE loss:0.00046835, KL loss:0.00088969\n",
      "Pretrain epoch [9/341], ZINB loss:0.3885, NB loss:4.5046, latent MSE loss:0.00038775, KL loss:0.00075281\n",
      "Pretrain epoch [10/341], ZINB loss:0.3931, NB loss:4.5478, latent MSE loss:0.00041689, KL loss:0.00109062\n",
      "Pretrain epoch [11/341], ZINB loss:0.3927, NB loss:4.4643, latent MSE loss:0.00039915, KL loss:0.00120670\n",
      "Pretrain epoch [12/341], ZINB loss:0.3873, NB loss:4.4373, latent MSE loss:0.00038069, KL loss:0.00086752\n",
      "Pretrain epoch [13/341], ZINB loss:0.3920, NB loss:4.5163, latent MSE loss:0.00043322, KL loss:0.00089639\n",
      "Pretrain epoch [14/341], ZINB loss:0.3919, NB loss:4.5047, latent MSE loss:0.00041293, KL loss:0.00084379\n",
      "Pretrain epoch [15/341], ZINB loss:0.3943, NB loss:4.5188, latent MSE loss:0.00039888, KL loss:0.00078804\n",
      "Pretrain epoch [16/341], ZINB loss:0.3942, NB loss:4.4305, latent MSE loss:0.00044505, KL loss:0.00092818\n",
      "Pretrain epoch [17/341], ZINB loss:0.3835, NB loss:4.4910, latent MSE loss:0.00035040, KL loss:0.00090278\n",
      "Pretrain epoch [18/341], ZINB loss:0.3959, NB loss:4.5022, latent MSE loss:0.00043757, KL loss:0.00095573\n",
      "Pretrain epoch [19/341], ZINB loss:0.3911, NB loss:4.4958, latent MSE loss:0.00034467, KL loss:0.00094020\n",
      "Pretrain epoch [20/341], ZINB loss:0.3894, NB loss:4.4916, latent MSE loss:0.00029460, KL loss:0.00080433\n",
      "Pretrain epoch [21/341], ZINB loss:0.3917, NB loss:4.5640, latent MSE loss:0.00027015, KL loss:0.00075828\n",
      "Pretrain epoch [22/341], ZINB loss:0.3864, NB loss:4.4958, latent MSE loss:0.00032826, KL loss:0.00082028\n",
      "Pretrain epoch [23/341], ZINB loss:0.3996, NB loss:4.4819, latent MSE loss:0.00037914, KL loss:0.00085200\n",
      "Pretrain epoch [24/341], ZINB loss:0.4125, NB loss:4.5154, latent MSE loss:0.00039066, KL loss:0.00088722\n",
      "Pretrain epoch [25/341], ZINB loss:0.4058, NB loss:4.5117, latent MSE loss:0.00033526, KL loss:0.00085514\n",
      "Pretrain epoch [26/341], ZINB loss:0.3868, NB loss:4.5009, latent MSE loss:0.00037696, KL loss:0.00079594\n",
      "Pretrain epoch [27/341], ZINB loss:0.4308, NB loss:4.4090, latent MSE loss:0.00019217, KL loss:0.00000506\n",
      "Pretrain epoch [1/342], ZINB loss:0.3948, NB loss:4.5172, latent MSE loss:0.00063237, KL loss:0.00124645\n",
      "Pretrain epoch [2/342], ZINB loss:0.3824, NB loss:4.4951, latent MSE loss:0.00042570, KL loss:0.00135256\n",
      "Pretrain epoch [3/342], ZINB loss:0.4098, NB loss:4.5619, latent MSE loss:0.00070871, KL loss:0.00083060\n",
      "Pretrain epoch [4/342], ZINB loss:0.3988, NB loss:4.5420, latent MSE loss:0.00049893, KL loss:0.00096948\n",
      "Pretrain epoch [5/342], ZINB loss:0.3849, NB loss:4.5410, latent MSE loss:0.00058169, KL loss:0.00093112\n",
      "Pretrain epoch [6/342], ZINB loss:0.3985, NB loss:4.5760, latent MSE loss:0.00035687, KL loss:0.00118298\n",
      "Pretrain epoch [7/342], ZINB loss:0.3892, NB loss:4.4728, latent MSE loss:0.00052233, KL loss:0.00078882\n",
      "Pretrain epoch [8/342], ZINB loss:0.4123, NB loss:4.5395, latent MSE loss:0.00052414, KL loss:0.00127313\n",
      "Pretrain epoch [9/342], ZINB loss:0.3975, NB loss:4.4494, latent MSE loss:0.00033458, KL loss:0.00076819\n",
      "Pretrain epoch [10/342], ZINB loss:0.3920, NB loss:4.4531, latent MSE loss:0.00034508, KL loss:0.00072886\n",
      "Pretrain epoch [11/342], ZINB loss:0.3986, NB loss:4.5085, latent MSE loss:0.00031254, KL loss:0.00084576\n",
      "Pretrain epoch [12/342], ZINB loss:0.3969, NB loss:4.4784, latent MSE loss:0.00052135, KL loss:0.00081067\n",
      "Pretrain epoch [13/342], ZINB loss:0.4149, NB loss:4.4449, latent MSE loss:0.00047426, KL loss:0.00084070\n",
      "Pretrain epoch [14/342], ZINB loss:0.3905, NB loss:4.5964, latent MSE loss:0.00032715, KL loss:0.00086171\n",
      "Pretrain epoch [15/342], ZINB loss:0.3932, NB loss:4.5004, latent MSE loss:0.00037020, KL loss:0.00087197\n",
      "Pretrain epoch [16/342], ZINB loss:0.4025, NB loss:4.4199, latent MSE loss:0.00031637, KL loss:0.00075396\n",
      "Pretrain epoch [17/342], ZINB loss:0.4025, NB loss:4.4957, latent MSE loss:0.00026526, KL loss:0.00081936\n",
      "Pretrain epoch [18/342], ZINB loss:0.3788, NB loss:4.3952, latent MSE loss:0.00042439, KL loss:0.00091599\n",
      "Pretrain epoch [19/342], ZINB loss:0.3850, NB loss:4.5370, latent MSE loss:0.00028165, KL loss:0.00117350\n",
      "Pretrain epoch [20/342], ZINB loss:0.3903, NB loss:4.5438, latent MSE loss:0.00035496, KL loss:0.00089628\n",
      "Pretrain epoch [21/342], ZINB loss:0.4062, NB loss:4.5150, latent MSE loss:0.00028050, KL loss:0.00119092\n",
      "Pretrain epoch [22/342], ZINB loss:0.3949, NB loss:4.5010, latent MSE loss:0.00042370, KL loss:0.00083580\n",
      "Pretrain epoch [23/342], ZINB loss:0.3904, NB loss:4.4877, latent MSE loss:0.00031047, KL loss:0.00082781\n",
      "Pretrain epoch [24/342], ZINB loss:0.3984, NB loss:4.4444, latent MSE loss:0.00028823, KL loss:0.00082782\n",
      "Pretrain epoch [25/342], ZINB loss:0.3891, NB loss:4.4926, latent MSE loss:0.00026576, KL loss:0.00097980\n",
      "Pretrain epoch [26/342], ZINB loss:0.3963, NB loss:4.5140, latent MSE loss:0.00020943, KL loss:0.00073606\n",
      "Pretrain epoch [27/342], ZINB loss:0.4626, NB loss:4.3086, latent MSE loss:0.00011035, KL loss:0.00000455\n",
      "Pretrain epoch [1/343], ZINB loss:0.3811, NB loss:4.4911, latent MSE loss:0.00029820, KL loss:0.00070963\n",
      "Pretrain epoch [2/343], ZINB loss:0.3878, NB loss:4.5046, latent MSE loss:0.00028489, KL loss:0.00070673\n",
      "Pretrain epoch [3/343], ZINB loss:0.4041, NB loss:4.4839, latent MSE loss:0.00035533, KL loss:0.00089333\n",
      "Pretrain epoch [4/343], ZINB loss:0.4000, NB loss:4.4625, latent MSE loss:0.00034419, KL loss:0.00091553\n",
      "Pretrain epoch [5/343], ZINB loss:0.4000, NB loss:4.5430, latent MSE loss:0.00029503, KL loss:0.00100578\n",
      "Pretrain epoch [6/343], ZINB loss:0.4063, NB loss:4.4382, latent MSE loss:0.00023070, KL loss:0.00083187\n",
      "Pretrain epoch [7/343], ZINB loss:0.3916, NB loss:4.4705, latent MSE loss:0.00024244, KL loss:0.00071363\n",
      "Pretrain epoch [8/343], ZINB loss:0.3940, NB loss:4.4510, latent MSE loss:0.00029777, KL loss:0.00071135\n",
      "Pretrain epoch [9/343], ZINB loss:0.3872, NB loss:4.5138, latent MSE loss:0.00026399, KL loss:0.00104828\n",
      "Pretrain epoch [10/343], ZINB loss:0.3906, NB loss:4.5203, latent MSE loss:0.00029881, KL loss:0.00134236\n",
      "Pretrain epoch [11/343], ZINB loss:0.3864, NB loss:4.5457, latent MSE loss:0.00023478, KL loss:0.00084827\n",
      "Pretrain epoch [12/343], ZINB loss:0.3882, NB loss:4.5496, latent MSE loss:0.00020928, KL loss:0.00113276\n",
      "Pretrain epoch [13/343], ZINB loss:0.3996, NB loss:4.5649, latent MSE loss:0.00035142, KL loss:0.00088965\n",
      "Pretrain epoch [14/343], ZINB loss:0.4004, NB loss:4.5409, latent MSE loss:0.00024271, KL loss:0.00075597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [15/343], ZINB loss:0.3966, NB loss:4.4775, latent MSE loss:0.00027339, KL loss:0.00091496\n",
      "Pretrain epoch [16/343], ZINB loss:0.3842, NB loss:4.5091, latent MSE loss:0.00027012, KL loss:0.00107444\n",
      "Pretrain epoch [17/343], ZINB loss:0.3993, NB loss:4.4746, latent MSE loss:0.00021220, KL loss:0.00088953\n",
      "Pretrain epoch [18/343], ZINB loss:0.3880, NB loss:4.4981, latent MSE loss:0.00027996, KL loss:0.00096313\n",
      "Pretrain epoch [19/343], ZINB loss:0.3915, NB loss:4.4439, latent MSE loss:0.00029893, KL loss:0.00097714\n",
      "Pretrain epoch [20/343], ZINB loss:0.4122, NB loss:4.4980, latent MSE loss:0.00028175, KL loss:0.00151298\n",
      "Pretrain epoch [21/343], ZINB loss:0.4110, NB loss:4.4769, latent MSE loss:0.00022227, KL loss:0.00081687\n",
      "Pretrain epoch [22/343], ZINB loss:0.3647, NB loss:4.5044, latent MSE loss:0.00024132, KL loss:0.00082689\n",
      "Pretrain epoch [23/343], ZINB loss:0.4328, NB loss:4.4668, latent MSE loss:0.00036630, KL loss:0.00130523\n",
      "Pretrain epoch [24/343], ZINB loss:0.3963, NB loss:4.5343, latent MSE loss:0.00023131, KL loss:0.00118313\n",
      "Pretrain epoch [25/343], ZINB loss:0.3951, NB loss:4.4925, latent MSE loss:0.00021104, KL loss:0.00082318\n",
      "Pretrain epoch [26/343], ZINB loss:0.3882, NB loss:4.5134, latent MSE loss:0.00015814, KL loss:0.00104135\n",
      "Pretrain epoch [27/343], ZINB loss:0.4054, NB loss:4.1381, latent MSE loss:0.00012232, KL loss:0.00000449\n",
      "Pretrain epoch [1/344], ZINB loss:0.3931, NB loss:4.4827, latent MSE loss:0.00030665, KL loss:0.00085162\n",
      "Pretrain epoch [2/344], ZINB loss:0.3897, NB loss:4.5071, latent MSE loss:0.00030336, KL loss:0.00072050\n",
      "Pretrain epoch [3/344], ZINB loss:0.3810, NB loss:4.4666, latent MSE loss:0.00032714, KL loss:0.00084022\n",
      "Pretrain epoch [4/344], ZINB loss:0.3870, NB loss:4.5124, latent MSE loss:0.00029569, KL loss:0.00096993\n",
      "Pretrain epoch [5/344], ZINB loss:0.3932, NB loss:4.4957, latent MSE loss:0.00032835, KL loss:0.00092315\n",
      "Pretrain epoch [6/344], ZINB loss:0.3854, NB loss:4.4699, latent MSE loss:0.00032101, KL loss:0.00074910\n",
      "Pretrain epoch [7/344], ZINB loss:0.4082, NB loss:4.5097, latent MSE loss:0.00035474, KL loss:0.00097821\n",
      "Pretrain epoch [8/344], ZINB loss:0.3825, NB loss:4.5412, latent MSE loss:0.00040961, KL loss:0.00104297\n",
      "Pretrain epoch [9/344], ZINB loss:0.3888, NB loss:4.4918, latent MSE loss:0.00030737, KL loss:0.00089691\n",
      "Pretrain epoch [10/344], ZINB loss:0.3978, NB loss:4.5067, latent MSE loss:0.00037181, KL loss:0.00119039\n",
      "Pretrain epoch [11/344], ZINB loss:0.4118, NB loss:4.4798, latent MSE loss:0.00040080, KL loss:0.00082942\n",
      "Pretrain epoch [12/344], ZINB loss:0.3858, NB loss:4.5207, latent MSE loss:0.00030713, KL loss:0.00086250\n",
      "Pretrain epoch [13/344], ZINB loss:0.4001, NB loss:4.4864, latent MSE loss:0.00033015, KL loss:0.00131760\n",
      "Pretrain epoch [14/344], ZINB loss:0.3962, NB loss:4.5065, latent MSE loss:0.00039356, KL loss:0.00081093\n",
      "Pretrain epoch [15/344], ZINB loss:0.4039, NB loss:4.5139, latent MSE loss:0.00047895, KL loss:0.00084068\n",
      "Pretrain epoch [16/344], ZINB loss:0.3766, NB loss:4.5002, latent MSE loss:0.00034631, KL loss:0.00089121\n",
      "Pretrain epoch [17/344], ZINB loss:0.4062, NB loss:4.5344, latent MSE loss:0.00032516, KL loss:0.00104022\n",
      "Pretrain epoch [18/344], ZINB loss:0.4027, NB loss:4.4584, latent MSE loss:0.00036018, KL loss:0.00081226\n",
      "Pretrain epoch [19/344], ZINB loss:0.4033, NB loss:4.5050, latent MSE loss:0.00049741, KL loss:0.00080193\n",
      "Pretrain epoch [20/344], ZINB loss:0.4052, NB loss:4.4628, latent MSE loss:0.00044735, KL loss:0.00098641\n",
      "Pretrain epoch [21/344], ZINB loss:0.4064, NB loss:4.5524, latent MSE loss:0.00029232, KL loss:0.00086045\n",
      "Pretrain epoch [22/344], ZINB loss:0.3960, NB loss:4.4587, latent MSE loss:0.00035618, KL loss:0.00119642\n",
      "Pretrain epoch [23/344], ZINB loss:0.3921, NB loss:4.4740, latent MSE loss:0.00049143, KL loss:0.00074138\n",
      "Pretrain epoch [24/344], ZINB loss:0.4005, NB loss:4.4923, latent MSE loss:0.00053669, KL loss:0.00081774\n",
      "Pretrain epoch [25/344], ZINB loss:0.3996, NB loss:4.5426, latent MSE loss:0.00054824, KL loss:0.00112938\n",
      "Pretrain epoch [26/344], ZINB loss:0.4046, NB loss:4.4743, latent MSE loss:0.00036175, KL loss:0.00123571\n",
      "Pretrain epoch [27/344], ZINB loss:0.2917, NB loss:4.6468, latent MSE loss:0.00084846, KL loss:0.00000021\n",
      "Pretrain epoch [1/345], ZINB loss:0.3841, NB loss:4.5183, latent MSE loss:0.00107306, KL loss:0.00074597\n",
      "Pretrain epoch [2/345], ZINB loss:0.3894, NB loss:4.5108, latent MSE loss:0.00154721, KL loss:0.00076396\n",
      "Pretrain epoch [3/345], ZINB loss:0.3887, NB loss:4.4617, latent MSE loss:0.00209157, KL loss:0.00080629\n",
      "Pretrain epoch [4/345], ZINB loss:0.4115, NB loss:4.4820, latent MSE loss:0.00229937, KL loss:0.00080469\n",
      "Pretrain epoch [5/345], ZINB loss:0.3684, NB loss:4.4361, latent MSE loss:0.00249328, KL loss:0.00069607\n",
      "Pretrain epoch [6/345], ZINB loss:0.3912, NB loss:4.5537, latent MSE loss:0.00212411, KL loss:0.00118107\n",
      "Pretrain epoch [7/345], ZINB loss:0.3865, NB loss:4.5162, latent MSE loss:0.00139262, KL loss:0.00088409\n",
      "Pretrain epoch [8/345], ZINB loss:0.4040, NB loss:4.4691, latent MSE loss:0.00101844, KL loss:0.00076127\n",
      "Pretrain epoch [9/345], ZINB loss:0.3772, NB loss:4.5173, latent MSE loss:0.00172040, KL loss:0.00084833\n",
      "Pretrain epoch [10/345], ZINB loss:0.3936, NB loss:4.4490, latent MSE loss:0.00137621, KL loss:0.00102575\n",
      "Pretrain epoch [11/345], ZINB loss:0.4177, NB loss:4.5096, latent MSE loss:0.00096945, KL loss:0.00117012\n",
      "Pretrain epoch [12/345], ZINB loss:0.4137, NB loss:4.4812, latent MSE loss:0.00154971, KL loss:0.00093840\n",
      "Pretrain epoch [13/345], ZINB loss:0.3887, NB loss:4.4031, latent MSE loss:0.00080263, KL loss:0.00086583\n",
      "Pretrain epoch [14/345], ZINB loss:0.3933, NB loss:4.4838, latent MSE loss:0.00123128, KL loss:0.00089935\n",
      "Pretrain epoch [15/345], ZINB loss:0.4043, NB loss:4.4964, latent MSE loss:0.00088115, KL loss:0.00072746\n",
      "Pretrain epoch [16/345], ZINB loss:0.4070, NB loss:4.4963, latent MSE loss:0.00102643, KL loss:0.00082146\n",
      "Pretrain epoch [17/345], ZINB loss:0.3921, NB loss:4.4873, latent MSE loss:0.00078573, KL loss:0.00081234\n",
      "Pretrain epoch [18/345], ZINB loss:0.4010, NB loss:4.4882, latent MSE loss:0.00120262, KL loss:0.00105666\n",
      "Pretrain epoch [19/345], ZINB loss:0.4014, NB loss:4.5206, latent MSE loss:0.00074635, KL loss:0.00104456\n",
      "Pretrain epoch [20/345], ZINB loss:0.4017, NB loss:4.5194, latent MSE loss:0.00073814, KL loss:0.00088004\n",
      "Pretrain epoch [21/345], ZINB loss:0.4081, NB loss:4.5231, latent MSE loss:0.00077923, KL loss:0.00097211\n",
      "Pretrain epoch [22/345], ZINB loss:0.3936, NB loss:4.5222, latent MSE loss:0.00055372, KL loss:0.00082048\n",
      "Pretrain epoch [23/345], ZINB loss:0.3928, NB loss:4.5826, latent MSE loss:0.00080643, KL loss:0.00134725\n",
      "Pretrain epoch [24/345], ZINB loss:0.4071, NB loss:4.5172, latent MSE loss:0.00062147, KL loss:0.00086215\n",
      "Pretrain epoch [25/345], ZINB loss:0.3871, NB loss:4.4306, latent MSE loss:0.00058126, KL loss:0.00084390\n",
      "Pretrain epoch [26/345], ZINB loss:0.3782, NB loss:4.5496, latent MSE loss:0.00058101, KL loss:0.00087577\n",
      "Pretrain epoch [27/345], ZINB loss:0.3356, NB loss:4.5326, latent MSE loss:0.00083382, KL loss:0.00006179\n",
      "Pretrain epoch [1/346], ZINB loss:0.3959, NB loss:4.5278, latent MSE loss:0.00295886, KL loss:0.00100668\n",
      "Pretrain epoch [2/346], ZINB loss:0.3976, NB loss:4.4819, latent MSE loss:0.00099734, KL loss:0.00091182\n",
      "Pretrain epoch [3/346], ZINB loss:0.3990, NB loss:4.5477, latent MSE loss:0.00141827, KL loss:0.00087854\n",
      "Pretrain epoch [4/346], ZINB loss:0.3941, NB loss:4.5068, latent MSE loss:0.00238366, KL loss:0.00085667\n",
      "Pretrain epoch [5/346], ZINB loss:0.3870, NB loss:4.4259, latent MSE loss:0.00089012, KL loss:0.00098384\n",
      "Pretrain epoch [6/346], ZINB loss:0.4056, NB loss:4.4326, latent MSE loss:0.00230362, KL loss:0.00095165\n",
      "Pretrain epoch [7/346], ZINB loss:0.3747, NB loss:4.4555, latent MSE loss:0.00098178, KL loss:0.00081755\n",
      "Pretrain epoch [8/346], ZINB loss:0.3962, NB loss:4.5573, latent MSE loss:0.00169843, KL loss:0.00087938\n",
      "Pretrain epoch [9/346], ZINB loss:0.3770, NB loss:4.4812, latent MSE loss:0.00102988, KL loss:0.00079767\n",
      "Pretrain epoch [10/346], ZINB loss:0.3916, NB loss:4.4779, latent MSE loss:0.00134985, KL loss:0.00093914\n",
      "Pretrain epoch [11/346], ZINB loss:0.3942, NB loss:4.5196, latent MSE loss:0.00087850, KL loss:0.00079153\n",
      "Pretrain epoch [12/346], ZINB loss:0.3974, NB loss:4.5266, latent MSE loss:0.00115301, KL loss:0.00088517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [13/346], ZINB loss:0.4066, NB loss:4.5095, latent MSE loss:0.00112027, KL loss:0.00095927\n",
      "Pretrain epoch [14/346], ZINB loss:0.4194, NB loss:4.5139, latent MSE loss:0.00085999, KL loss:0.00089476\n",
      "Pretrain epoch [15/346], ZINB loss:0.4003, NB loss:4.4668, latent MSE loss:0.00105454, KL loss:0.00079015\n",
      "Pretrain epoch [16/346], ZINB loss:0.3992, NB loss:4.4789, latent MSE loss:0.00073526, KL loss:0.00085623\n",
      "Pretrain epoch [17/346], ZINB loss:0.3947, NB loss:4.4764, latent MSE loss:0.00087552, KL loss:0.00082582\n",
      "Pretrain epoch [18/346], ZINB loss:0.3855, NB loss:4.4567, latent MSE loss:0.00074181, KL loss:0.00097424\n",
      "Pretrain epoch [19/346], ZINB loss:0.3965, NB loss:4.5334, latent MSE loss:0.00052344, KL loss:0.00094053\n",
      "Pretrain epoch [20/346], ZINB loss:0.4051, NB loss:4.5134, latent MSE loss:0.00077077, KL loss:0.00120883\n",
      "Pretrain epoch [21/346], ZINB loss:0.4003, NB loss:4.5592, latent MSE loss:0.00052834, KL loss:0.00094519\n",
      "Pretrain epoch [22/346], ZINB loss:0.3937, NB loss:4.4931, latent MSE loss:0.00057915, KL loss:0.00093074\n",
      "Pretrain epoch [23/346], ZINB loss:0.3984, NB loss:4.5141, latent MSE loss:0.00058657, KL loss:0.00093890\n",
      "Pretrain epoch [24/346], ZINB loss:0.3826, NB loss:4.4763, latent MSE loss:0.00041742, KL loss:0.00079155\n",
      "Pretrain epoch [25/346], ZINB loss:0.3947, NB loss:4.5610, latent MSE loss:0.00039646, KL loss:0.00087207\n",
      "Pretrain epoch [26/346], ZINB loss:0.3946, NB loss:4.3860, latent MSE loss:0.00038977, KL loss:0.00074520\n",
      "Pretrain epoch [27/346], ZINB loss:0.3807, NB loss:4.5227, latent MSE loss:0.00041594, KL loss:0.00004165\n",
      "Pretrain epoch [1/347], ZINB loss:0.3937, NB loss:4.4762, latent MSE loss:0.00042720, KL loss:0.00081503\n",
      "Pretrain epoch [2/347], ZINB loss:0.3868, NB loss:4.4764, latent MSE loss:0.00049245, KL loss:0.00085891\n",
      "Pretrain epoch [3/347], ZINB loss:0.4162, NB loss:4.5293, latent MSE loss:0.00033928, KL loss:0.00110815\n",
      "Pretrain epoch [4/347], ZINB loss:0.3831, NB loss:4.6155, latent MSE loss:0.00039460, KL loss:0.00127905\n",
      "Pretrain epoch [5/347], ZINB loss:0.4149, NB loss:4.5038, latent MSE loss:0.00050606, KL loss:0.00113607\n",
      "Pretrain epoch [6/347], ZINB loss:0.3796, NB loss:4.4781, latent MSE loss:0.00024615, KL loss:0.00077993\n",
      "Pretrain epoch [7/347], ZINB loss:0.3863, NB loss:4.5474, latent MSE loss:0.00040843, KL loss:0.00108892\n",
      "Pretrain epoch [8/347], ZINB loss:0.4005, NB loss:4.4458, latent MSE loss:0.00039642, KL loss:0.00082638\n",
      "Pretrain epoch [9/347], ZINB loss:0.3953, NB loss:4.5312, latent MSE loss:0.00042704, KL loss:0.00096294\n",
      "Pretrain epoch [10/347], ZINB loss:0.3926, NB loss:4.3948, latent MSE loss:0.00032170, KL loss:0.00081837\n",
      "Pretrain epoch [11/347], ZINB loss:0.4136, NB loss:4.4902, latent MSE loss:0.00031451, KL loss:0.00100936\n",
      "Pretrain epoch [12/347], ZINB loss:0.4005, NB loss:4.4988, latent MSE loss:0.00026265, KL loss:0.00103772\n",
      "Pretrain epoch [13/347], ZINB loss:0.3808, NB loss:4.5033, latent MSE loss:0.00036594, KL loss:0.00089854\n",
      "Pretrain epoch [14/347], ZINB loss:0.3915, NB loss:4.5113, latent MSE loss:0.00033662, KL loss:0.00092308\n",
      "Pretrain epoch [15/347], ZINB loss:0.3961, NB loss:4.4799, latent MSE loss:0.00029766, KL loss:0.00085299\n",
      "Pretrain epoch [16/347], ZINB loss:0.3879, NB loss:4.4621, latent MSE loss:0.00025631, KL loss:0.00077805\n",
      "Pretrain epoch [17/347], ZINB loss:0.4036, NB loss:4.5068, latent MSE loss:0.00022608, KL loss:0.00088680\n",
      "Pretrain epoch [18/347], ZINB loss:0.3949, NB loss:4.5055, latent MSE loss:0.00032961, KL loss:0.00096190\n",
      "Pretrain epoch [19/347], ZINB loss:0.3895, NB loss:4.6037, latent MSE loss:0.00025380, KL loss:0.00091749\n",
      "Pretrain epoch [20/347], ZINB loss:0.3885, NB loss:4.4583, latent MSE loss:0.00031814, KL loss:0.00096974\n",
      "Pretrain epoch [21/347], ZINB loss:0.4057, NB loss:4.4790, latent MSE loss:0.00030525, KL loss:0.00089255\n",
      "Pretrain epoch [22/347], ZINB loss:0.3959, NB loss:4.4597, latent MSE loss:0.00027315, KL loss:0.00091392\n",
      "Pretrain epoch [23/347], ZINB loss:0.3960, NB loss:4.4643, latent MSE loss:0.00025160, KL loss:0.00080198\n",
      "Pretrain epoch [24/347], ZINB loss:0.4009, NB loss:4.5183, latent MSE loss:0.00031595, KL loss:0.00117796\n",
      "Pretrain epoch [25/347], ZINB loss:0.3887, NB loss:4.4639, latent MSE loss:0.00021247, KL loss:0.00075218\n",
      "Pretrain epoch [26/347], ZINB loss:0.3958, NB loss:4.4681, latent MSE loss:0.00019646, KL loss:0.00082126\n",
      "Pretrain epoch [27/347], ZINB loss:0.3074, NB loss:4.6620, latent MSE loss:0.00012785, KL loss:0.00000729\n",
      "Pretrain epoch [1/348], ZINB loss:0.3938, NB loss:4.4873, latent MSE loss:0.00034744, KL loss:0.00090619\n",
      "Pretrain epoch [2/348], ZINB loss:0.3932, NB loss:4.4995, latent MSE loss:0.00028632, KL loss:0.00095039\n",
      "Pretrain epoch [3/348], ZINB loss:0.3943, NB loss:4.4788, latent MSE loss:0.00031075, KL loss:0.00088684\n",
      "Pretrain epoch [4/348], ZINB loss:0.4150, NB loss:4.4843, latent MSE loss:0.00025689, KL loss:0.00082865\n",
      "Pretrain epoch [5/348], ZINB loss:0.3926, NB loss:4.5388, latent MSE loss:0.00020453, KL loss:0.00081743\n",
      "Pretrain epoch [6/348], ZINB loss:0.3818, NB loss:4.5119, latent MSE loss:0.00021249, KL loss:0.00094424\n",
      "Pretrain epoch [7/348], ZINB loss:0.3768, NB loss:4.4285, latent MSE loss:0.00019543, KL loss:0.00079988\n",
      "Pretrain epoch [8/348], ZINB loss:0.4142, NB loss:4.5134, latent MSE loss:0.00022820, KL loss:0.00096328\n",
      "Pretrain epoch [9/348], ZINB loss:0.3892, NB loss:4.4201, latent MSE loss:0.00017367, KL loss:0.00073581\n",
      "Pretrain epoch [10/348], ZINB loss:0.4134, NB loss:4.5079, latent MSE loss:0.00021103, KL loss:0.00120138\n",
      "Pretrain epoch [11/348], ZINB loss:0.4004, NB loss:4.4936, latent MSE loss:0.00025085, KL loss:0.00125505\n",
      "Pretrain epoch [12/348], ZINB loss:0.4068, NB loss:4.5541, latent MSE loss:0.00026070, KL loss:0.00094014\n",
      "Pretrain epoch [13/348], ZINB loss:0.4041, NB loss:4.5206, latent MSE loss:0.00018650, KL loss:0.00085636\n",
      "Pretrain epoch [14/348], ZINB loss:0.3934, NB loss:4.5242, latent MSE loss:0.00023286, KL loss:0.00081444\n",
      "Pretrain epoch [15/348], ZINB loss:0.3930, NB loss:4.5191, latent MSE loss:0.00019252, KL loss:0.00116775\n",
      "Pretrain epoch [16/348], ZINB loss:0.3891, NB loss:4.4914, latent MSE loss:0.00017020, KL loss:0.00090548\n",
      "Pretrain epoch [17/348], ZINB loss:0.3689, NB loss:4.4700, latent MSE loss:0.00017291, KL loss:0.00081746\n",
      "Pretrain epoch [18/348], ZINB loss:0.3940, NB loss:4.4470, latent MSE loss:0.00016156, KL loss:0.00083063\n",
      "Pretrain epoch [19/348], ZINB loss:0.3976, NB loss:4.5166, latent MSE loss:0.00023466, KL loss:0.00079844\n",
      "Pretrain epoch [20/348], ZINB loss:0.3941, NB loss:4.5312, latent MSE loss:0.00018851, KL loss:0.00091833\n",
      "Pretrain epoch [21/348], ZINB loss:0.3977, NB loss:4.4915, latent MSE loss:0.00019908, KL loss:0.00084153\n",
      "Pretrain epoch [22/348], ZINB loss:0.3963, NB loss:4.5098, latent MSE loss:0.00025229, KL loss:0.00070384\n",
      "Pretrain epoch [23/348], ZINB loss:0.3969, NB loss:4.4323, latent MSE loss:0.00016199, KL loss:0.00077738\n",
      "Pretrain epoch [24/348], ZINB loss:0.3834, NB loss:4.5139, latent MSE loss:0.00020537, KL loss:0.00078311\n",
      "Pretrain epoch [25/348], ZINB loss:0.3928, NB loss:4.4995, latent MSE loss:0.00020406, KL loss:0.00079768\n",
      "Pretrain epoch [26/348], ZINB loss:0.3956, NB loss:4.4611, latent MSE loss:0.00016944, KL loss:0.00095303\n",
      "Pretrain epoch [27/348], ZINB loss:0.3433, NB loss:4.7381, latent MSE loss:0.00010749, KL loss:0.00000260\n",
      "Pretrain epoch [1/349], ZINB loss:0.4013, NB loss:4.4867, latent MSE loss:0.00018797, KL loss:0.00070189\n",
      "Pretrain epoch [2/349], ZINB loss:0.3935, NB loss:4.5104, latent MSE loss:0.00023414, KL loss:0.00077058\n",
      "Pretrain epoch [3/349], ZINB loss:0.3983, NB loss:4.5296, latent MSE loss:0.00023351, KL loss:0.00071205\n",
      "Pretrain epoch [4/349], ZINB loss:0.3768, NB loss:4.5056, latent MSE loss:0.00019649, KL loss:0.00075421\n",
      "Pretrain epoch [5/349], ZINB loss:0.3950, NB loss:4.4810, latent MSE loss:0.00020637, KL loss:0.00068990\n",
      "Pretrain epoch [6/349], ZINB loss:0.4153, NB loss:4.5040, latent MSE loss:0.00026132, KL loss:0.00076693\n",
      "Pretrain epoch [7/349], ZINB loss:0.3827, NB loss:4.5055, latent MSE loss:0.00023233, KL loss:0.00094396\n",
      "Pretrain epoch [8/349], ZINB loss:0.3893, NB loss:4.4731, latent MSE loss:0.00018967, KL loss:0.00079005\n",
      "Pretrain epoch [9/349], ZINB loss:0.3877, NB loss:4.4905, latent MSE loss:0.00023720, KL loss:0.00106981\n",
      "Pretrain epoch [10/349], ZINB loss:0.3771, NB loss:4.4433, latent MSE loss:0.00017318, KL loss:0.00070820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [11/349], ZINB loss:0.3845, NB loss:4.5408, latent MSE loss:0.00018493, KL loss:0.00082284\n",
      "Pretrain epoch [12/349], ZINB loss:0.4042, NB loss:4.5375, latent MSE loss:0.00015811, KL loss:0.00097539\n",
      "Pretrain epoch [13/349], ZINB loss:0.3716, NB loss:4.4262, latent MSE loss:0.00026652, KL loss:0.00096302\n",
      "Pretrain epoch [14/349], ZINB loss:0.3855, NB loss:4.5137, latent MSE loss:0.00019561, KL loss:0.00082288\n",
      "Pretrain epoch [15/349], ZINB loss:0.3942, NB loss:4.4583, latent MSE loss:0.00019702, KL loss:0.00112599\n",
      "Pretrain epoch [16/349], ZINB loss:0.3963, NB loss:4.4922, latent MSE loss:0.00016695, KL loss:0.00077158\n",
      "Pretrain epoch [17/349], ZINB loss:0.3892, NB loss:4.5169, latent MSE loss:0.00021920, KL loss:0.00083782\n",
      "Pretrain epoch [18/349], ZINB loss:0.4042, NB loss:4.5194, latent MSE loss:0.00033992, KL loss:0.00117949\n",
      "Pretrain epoch [19/349], ZINB loss:0.4048, NB loss:4.5202, latent MSE loss:0.00026005, KL loss:0.00098872\n",
      "Pretrain epoch [20/349], ZINB loss:0.3864, NB loss:4.4355, latent MSE loss:0.00025586, KL loss:0.00086024\n",
      "Pretrain epoch [21/349], ZINB loss:0.3813, NB loss:4.4537, latent MSE loss:0.00017593, KL loss:0.00075365\n",
      "Pretrain epoch [22/349], ZINB loss:0.4116, NB loss:4.4478, latent MSE loss:0.00019033, KL loss:0.00075598\n",
      "Pretrain epoch [23/349], ZINB loss:0.4086, NB loss:4.4789, latent MSE loss:0.00030889, KL loss:0.00114533\n",
      "Pretrain epoch [24/349], ZINB loss:0.4059, NB loss:4.5348, latent MSE loss:0.00029010, KL loss:0.00130920\n",
      "Pretrain epoch [25/349], ZINB loss:0.4186, NB loss:4.4367, latent MSE loss:0.00035099, KL loss:0.00096424\n",
      "Pretrain epoch [26/349], ZINB loss:0.4066, NB loss:4.5778, latent MSE loss:0.00027298, KL loss:0.00113533\n",
      "Pretrain epoch [27/349], ZINB loss:0.3765, NB loss:4.6237, latent MSE loss:0.00016998, KL loss:0.00000817\n",
      "Pretrain epoch [1/350], ZINB loss:0.3913, NB loss:4.4650, latent MSE loss:0.00032963, KL loss:0.00083975\n",
      "Pretrain epoch [2/350], ZINB loss:0.3877, NB loss:4.4668, latent MSE loss:0.00034075, KL loss:0.00103204\n",
      "Pretrain epoch [3/350], ZINB loss:0.3827, NB loss:4.4444, latent MSE loss:0.00042612, KL loss:0.00108737\n",
      "Pretrain epoch [4/350], ZINB loss:0.3963, NB loss:4.5241, latent MSE loss:0.00033001, KL loss:0.00088872\n",
      "Pretrain epoch [5/350], ZINB loss:0.3950, NB loss:4.5437, latent MSE loss:0.00034121, KL loss:0.00097040\n",
      "Pretrain epoch [6/350], ZINB loss:0.3937, NB loss:4.4637, latent MSE loss:0.00039659, KL loss:0.00103600\n",
      "Pretrain epoch [7/350], ZINB loss:0.3955, NB loss:4.5655, latent MSE loss:0.00038324, KL loss:0.00127788\n",
      "Pretrain epoch [8/350], ZINB loss:0.3762, NB loss:4.5060, latent MSE loss:0.00031515, KL loss:0.00077740\n",
      "Pretrain epoch [9/350], ZINB loss:0.3976, NB loss:4.4641, latent MSE loss:0.00033258, KL loss:0.00080681\n",
      "Pretrain epoch [10/350], ZINB loss:0.3989, NB loss:4.4536, latent MSE loss:0.00030976, KL loss:0.00083301\n",
      "Pretrain epoch [11/350], ZINB loss:0.4014, NB loss:4.5227, latent MSE loss:0.00040229, KL loss:0.00086450\n",
      "Pretrain epoch [12/350], ZINB loss:0.3741, NB loss:4.4655, latent MSE loss:0.00038762, KL loss:0.00087815\n",
      "Pretrain epoch [13/350], ZINB loss:0.3889, NB loss:4.5020, latent MSE loss:0.00030349, KL loss:0.00110591\n",
      "Pretrain epoch [14/350], ZINB loss:0.4047, NB loss:4.5292, latent MSE loss:0.00028790, KL loss:0.00088929\n",
      "Pretrain epoch [15/350], ZINB loss:0.3982, NB loss:4.4496, latent MSE loss:0.00031812, KL loss:0.00070200\n",
      "Pretrain epoch [16/350], ZINB loss:0.3931, NB loss:4.5239, latent MSE loss:0.00037108, KL loss:0.00118057\n",
      "Pretrain epoch [17/350], ZINB loss:0.4143, NB loss:4.4871, latent MSE loss:0.00025230, KL loss:0.00073934\n",
      "Pretrain epoch [18/350], ZINB loss:0.4089, NB loss:4.4482, latent MSE loss:0.00026066, KL loss:0.00074293\n",
      "Pretrain epoch [19/350], ZINB loss:0.4059, NB loss:4.4266, latent MSE loss:0.00031493, KL loss:0.00094059\n",
      "Pretrain epoch [20/350], ZINB loss:0.4076, NB loss:4.4897, latent MSE loss:0.00032851, KL loss:0.00085238\n",
      "Pretrain epoch [21/350], ZINB loss:0.3907, NB loss:4.5315, latent MSE loss:0.00026299, KL loss:0.00114232\n",
      "Pretrain epoch [22/350], ZINB loss:0.4131, NB loss:4.5741, latent MSE loss:0.00031659, KL loss:0.00087108\n",
      "Pretrain epoch [23/350], ZINB loss:0.3678, NB loss:4.4885, latent MSE loss:0.00027513, KL loss:0.00095177\n",
      "Pretrain epoch [24/350], ZINB loss:0.3925, NB loss:4.4654, latent MSE loss:0.00022441, KL loss:0.00094706\n",
      "Pretrain epoch [25/350], ZINB loss:0.3921, NB loss:4.4709, latent MSE loss:0.00028028, KL loss:0.00121100\n",
      "Pretrain epoch [26/350], ZINB loss:0.4196, NB loss:4.5383, latent MSE loss:0.00025832, KL loss:0.00087604\n",
      "Pretrain epoch [27/350], ZINB loss:0.3857, NB loss:4.5485, latent MSE loss:0.00016169, KL loss:0.00004199\n",
      "Pretrain epoch [1/351], ZINB loss:0.3891, NB loss:4.5284, latent MSE loss:0.00041527, KL loss:0.00079243\n",
      "Pretrain epoch [2/351], ZINB loss:0.4114, NB loss:4.4702, latent MSE loss:0.00045155, KL loss:0.00087890\n",
      "Pretrain epoch [3/351], ZINB loss:0.3778, NB loss:4.4763, latent MSE loss:0.00045105, KL loss:0.00088555\n",
      "Pretrain epoch [4/351], ZINB loss:0.3930, NB loss:4.5550, latent MSE loss:0.00033140, KL loss:0.00107043\n",
      "Pretrain epoch [5/351], ZINB loss:0.3777, NB loss:4.4480, latent MSE loss:0.00031351, KL loss:0.00083850\n",
      "Pretrain epoch [6/351], ZINB loss:0.4007, NB loss:4.5325, latent MSE loss:0.00038572, KL loss:0.00102208\n",
      "Pretrain epoch [7/351], ZINB loss:0.3849, NB loss:4.4397, latent MSE loss:0.00038558, KL loss:0.00073615\n",
      "Pretrain epoch [8/351], ZINB loss:0.4023, NB loss:4.5530, latent MSE loss:0.00036201, KL loss:0.00085319\n",
      "Pretrain epoch [9/351], ZINB loss:0.4033, NB loss:4.4313, latent MSE loss:0.00046370, KL loss:0.00109321\n",
      "Pretrain epoch [10/351], ZINB loss:0.4029, NB loss:4.4965, latent MSE loss:0.00046083, KL loss:0.00083391\n",
      "Pretrain epoch [11/351], ZINB loss:0.3859, NB loss:4.4298, latent MSE loss:0.00039754, KL loss:0.00104509\n",
      "Pretrain epoch [12/351], ZINB loss:0.3986, NB loss:4.5154, latent MSE loss:0.00052975, KL loss:0.00078542\n",
      "Pretrain epoch [13/351], ZINB loss:0.4199, NB loss:4.4904, latent MSE loss:0.00040164, KL loss:0.00095813\n",
      "Pretrain epoch [14/351], ZINB loss:0.3844, NB loss:4.5359, latent MSE loss:0.00034096, KL loss:0.00090111\n",
      "Pretrain epoch [15/351], ZINB loss:0.4087, NB loss:4.4963, latent MSE loss:0.00044577, KL loss:0.00080452\n",
      "Pretrain epoch [16/351], ZINB loss:0.4109, NB loss:4.4782, latent MSE loss:0.00047649, KL loss:0.00098908\n",
      "Pretrain epoch [17/351], ZINB loss:0.3962, NB loss:4.5392, latent MSE loss:0.00042918, KL loss:0.00081647\n",
      "Pretrain epoch [18/351], ZINB loss:0.3853, NB loss:4.4312, latent MSE loss:0.00037405, KL loss:0.00072927\n",
      "Pretrain epoch [19/351], ZINB loss:0.3940, NB loss:4.4957, latent MSE loss:0.00040795, KL loss:0.00074109\n",
      "Pretrain epoch [20/351], ZINB loss:0.3944, NB loss:4.5204, latent MSE loss:0.00049655, KL loss:0.00084144\n",
      "Pretrain epoch [21/351], ZINB loss:0.4019, NB loss:4.4695, latent MSE loss:0.00051848, KL loss:0.00074374\n",
      "Pretrain epoch [22/351], ZINB loss:0.3932, NB loss:4.5230, latent MSE loss:0.00036171, KL loss:0.00128218\n",
      "Pretrain epoch [23/351], ZINB loss:0.3989, NB loss:4.4932, latent MSE loss:0.00027598, KL loss:0.00123576\n",
      "Pretrain epoch [24/351], ZINB loss:0.3893, NB loss:4.4710, latent MSE loss:0.00034889, KL loss:0.00074772\n",
      "Pretrain epoch [25/351], ZINB loss:0.3933, NB loss:4.5355, latent MSE loss:0.00031062, KL loss:0.00080404\n",
      "Pretrain epoch [26/351], ZINB loss:0.3945, NB loss:4.4484, latent MSE loss:0.00033688, KL loss:0.00088965\n",
      "Pretrain epoch [27/351], ZINB loss:0.3271, NB loss:4.1403, latent MSE loss:0.00026192, KL loss:0.00000825\n",
      "Pretrain epoch [1/352], ZINB loss:0.3827, NB loss:4.4901, latent MSE loss:0.00089574, KL loss:0.00110540\n",
      "Pretrain epoch [2/352], ZINB loss:0.4005, NB loss:4.4422, latent MSE loss:0.00088144, KL loss:0.00074658\n",
      "Pretrain epoch [3/352], ZINB loss:0.3759, NB loss:4.4993, latent MSE loss:0.00078035, KL loss:0.00088538\n",
      "Pretrain epoch [4/352], ZINB loss:0.4113, NB loss:4.4679, latent MSE loss:0.00078131, KL loss:0.00113278\n",
      "Pretrain epoch [5/352], ZINB loss:0.3848, NB loss:4.5262, latent MSE loss:0.00065989, KL loss:0.00104260\n",
      "Pretrain epoch [6/352], ZINB loss:0.3934, NB loss:4.4313, latent MSE loss:0.00095442, KL loss:0.00074575\n",
      "Pretrain epoch [7/352], ZINB loss:0.4014, NB loss:4.5383, latent MSE loss:0.00086523, KL loss:0.00075992\n",
      "Pretrain epoch [8/352], ZINB loss:0.3995, NB loss:4.4637, latent MSE loss:0.00048464, KL loss:0.00082808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [9/352], ZINB loss:0.4064, NB loss:4.4476, latent MSE loss:0.00059976, KL loss:0.00081518\n",
      "Pretrain epoch [10/352], ZINB loss:0.4011, NB loss:4.4637, latent MSE loss:0.00063021, KL loss:0.00091082\n",
      "Pretrain epoch [11/352], ZINB loss:0.3780, NB loss:4.5326, latent MSE loss:0.00071163, KL loss:0.00075424\n",
      "Pretrain epoch [12/352], ZINB loss:0.4113, NB loss:4.4838, latent MSE loss:0.00064191, KL loss:0.00097682\n",
      "Pretrain epoch [13/352], ZINB loss:0.3834, NB loss:4.4299, latent MSE loss:0.00054872, KL loss:0.00084731\n",
      "Pretrain epoch [14/352], ZINB loss:0.3818, NB loss:4.5353, latent MSE loss:0.00054208, KL loss:0.00102469\n",
      "Pretrain epoch [15/352], ZINB loss:0.3837, NB loss:4.4817, latent MSE loss:0.00035887, KL loss:0.00084907\n",
      "Pretrain epoch [16/352], ZINB loss:0.4036, NB loss:4.4234, latent MSE loss:0.00059075, KL loss:0.00074252\n",
      "Pretrain epoch [17/352], ZINB loss:0.3983, NB loss:4.5231, latent MSE loss:0.00066592, KL loss:0.00084363\n",
      "Pretrain epoch [18/352], ZINB loss:0.3894, NB loss:4.4784, latent MSE loss:0.00030272, KL loss:0.00076593\n",
      "Pretrain epoch [19/352], ZINB loss:0.4064, NB loss:4.4705, latent MSE loss:0.00056261, KL loss:0.00099713\n",
      "Pretrain epoch [20/352], ZINB loss:0.3968, NB loss:4.5142, latent MSE loss:0.00058883, KL loss:0.00087099\n",
      "Pretrain epoch [21/352], ZINB loss:0.4097, NB loss:4.5212, latent MSE loss:0.00040277, KL loss:0.00084681\n",
      "Pretrain epoch [22/352], ZINB loss:0.4042, NB loss:4.5193, latent MSE loss:0.00048466, KL loss:0.00096367\n",
      "Pretrain epoch [23/352], ZINB loss:0.3950, NB loss:4.5076, latent MSE loss:0.00050240, KL loss:0.00078683\n",
      "Pretrain epoch [24/352], ZINB loss:0.3888, NB loss:4.5407, latent MSE loss:0.00037538, KL loss:0.00086305\n",
      "Pretrain epoch [25/352], ZINB loss:0.4005, NB loss:4.5574, latent MSE loss:0.00038963, KL loss:0.00092407\n",
      "Pretrain epoch [26/352], ZINB loss:0.3911, NB loss:4.4730, latent MSE loss:0.00030758, KL loss:0.00068299\n",
      "Pretrain epoch [27/352], ZINB loss:0.3169, NB loss:5.0265, latent MSE loss:0.00037631, KL loss:0.00005705\n",
      "Pretrain epoch [1/353], ZINB loss:0.4068, NB loss:4.5290, latent MSE loss:0.00067792, KL loss:0.00096584\n",
      "Pretrain epoch [2/353], ZINB loss:0.4083, NB loss:4.5277, latent MSE loss:0.00038442, KL loss:0.00100892\n",
      "Pretrain epoch [3/353], ZINB loss:0.3957, NB loss:4.5181, latent MSE loss:0.00060587, KL loss:0.00084819\n",
      "Pretrain epoch [4/353], ZINB loss:0.3946, NB loss:4.5415, latent MSE loss:0.00034884, KL loss:0.00085685\n",
      "Pretrain epoch [5/353], ZINB loss:0.3869, NB loss:4.4696, latent MSE loss:0.00044196, KL loss:0.00076527\n",
      "Pretrain epoch [6/353], ZINB loss:0.4053, NB loss:4.4819, latent MSE loss:0.00026845, KL loss:0.00080728\n",
      "Pretrain epoch [7/353], ZINB loss:0.3977, NB loss:4.4711, latent MSE loss:0.00042915, KL loss:0.00095007\n",
      "Pretrain epoch [8/353], ZINB loss:0.4049, NB loss:4.4658, latent MSE loss:0.00030439, KL loss:0.00092759\n",
      "Pretrain epoch [9/353], ZINB loss:0.3751, NB loss:4.4465, latent MSE loss:0.00031785, KL loss:0.00070875\n",
      "Pretrain epoch [10/353], ZINB loss:0.3787, NB loss:4.4876, latent MSE loss:0.00028386, KL loss:0.00073282\n",
      "Pretrain epoch [11/353], ZINB loss:0.4168, NB loss:4.5056, latent MSE loss:0.00028998, KL loss:0.00096565\n",
      "Pretrain epoch [12/353], ZINB loss:0.3966, NB loss:4.4847, latent MSE loss:0.00031193, KL loss:0.00076945\n",
      "Pretrain epoch [13/353], ZINB loss:0.3990, NB loss:4.4570, latent MSE loss:0.00035108, KL loss:0.00075698\n",
      "Pretrain epoch [14/353], ZINB loss:0.3851, NB loss:4.5077, latent MSE loss:0.00027654, KL loss:0.00091545\n",
      "Pretrain epoch [15/353], ZINB loss:0.3878, NB loss:4.4869, latent MSE loss:0.00033003, KL loss:0.00111367\n",
      "Pretrain epoch [16/353], ZINB loss:0.4008, NB loss:4.4793, latent MSE loss:0.00027059, KL loss:0.00075168\n",
      "Pretrain epoch [17/353], ZINB loss:0.3794, NB loss:4.4986, latent MSE loss:0.00020458, KL loss:0.00077584\n",
      "Pretrain epoch [18/353], ZINB loss:0.3911, NB loss:4.4640, latent MSE loss:0.00022594, KL loss:0.00078727\n",
      "Pretrain epoch [19/353], ZINB loss:0.3902, NB loss:4.4946, latent MSE loss:0.00019382, KL loss:0.00068418\n",
      "Pretrain epoch [20/353], ZINB loss:0.3809, NB loss:4.4713, latent MSE loss:0.00021710, KL loss:0.00070588\n",
      "Pretrain epoch [21/353], ZINB loss:0.3877, NB loss:4.5125, latent MSE loss:0.00035651, KL loss:0.00116433\n",
      "Pretrain epoch [22/353], ZINB loss:0.4223, NB loss:4.5192, latent MSE loss:0.00034033, KL loss:0.00103189\n",
      "Pretrain epoch [23/353], ZINB loss:0.4052, NB loss:4.5481, latent MSE loss:0.00025792, KL loss:0.00100714\n",
      "Pretrain epoch [24/353], ZINB loss:0.4049, NB loss:4.4685, latent MSE loss:0.00022715, KL loss:0.00075774\n",
      "Pretrain epoch [25/353], ZINB loss:0.3807, NB loss:4.4633, latent MSE loss:0.00017699, KL loss:0.00071797\n",
      "Pretrain epoch [26/353], ZINB loss:0.3845, NB loss:4.4888, latent MSE loss:0.00021443, KL loss:0.00080533\n",
      "Pretrain epoch [27/353], ZINB loss:0.5309, NB loss:4.8667, latent MSE loss:0.00090399, KL loss:0.00007808\n",
      "Pretrain epoch [1/354], ZINB loss:0.3894, NB loss:4.5153, latent MSE loss:0.00074032, KL loss:0.00081749\n",
      "Pretrain epoch [2/354], ZINB loss:0.3945, NB loss:4.4931, latent MSE loss:0.00067682, KL loss:0.00083352\n",
      "Pretrain epoch [3/354], ZINB loss:0.3861, NB loss:4.5023, latent MSE loss:0.00057036, KL loss:0.00078173\n",
      "Pretrain epoch [4/354], ZINB loss:0.3990, NB loss:4.5091, latent MSE loss:0.00062287, KL loss:0.00122566\n",
      "Pretrain epoch [5/354], ZINB loss:0.3956, NB loss:4.4546, latent MSE loss:0.00049713, KL loss:0.00077839\n",
      "Pretrain epoch [6/354], ZINB loss:0.3884, NB loss:4.4613, latent MSE loss:0.00090061, KL loss:0.00091824\n",
      "Pretrain epoch [7/354], ZINB loss:0.3995, NB loss:4.4647, latent MSE loss:0.00057140, KL loss:0.00079314\n",
      "Pretrain epoch [8/354], ZINB loss:0.3980, NB loss:4.4955, latent MSE loss:0.00051405, KL loss:0.00114353\n",
      "Pretrain epoch [9/354], ZINB loss:0.3863, NB loss:4.4657, latent MSE loss:0.00048564, KL loss:0.00085956\n",
      "Pretrain epoch [10/354], ZINB loss:0.3964, NB loss:4.5161, latent MSE loss:0.00058463, KL loss:0.00098828\n",
      "Pretrain epoch [11/354], ZINB loss:0.3971, NB loss:4.4149, latent MSE loss:0.00052259, KL loss:0.00070201\n",
      "Pretrain epoch [12/354], ZINB loss:0.3964, NB loss:4.4081, latent MSE loss:0.00049828, KL loss:0.00073511\n",
      "Pretrain epoch [13/354], ZINB loss:0.4169, NB loss:4.5102, latent MSE loss:0.00044805, KL loss:0.00081049\n",
      "Pretrain epoch [14/354], ZINB loss:0.3879, NB loss:4.5571, latent MSE loss:0.00062596, KL loss:0.00079187\n",
      "Pretrain epoch [15/354], ZINB loss:0.3790, NB loss:4.5018, latent MSE loss:0.00060104, KL loss:0.00120952\n",
      "Pretrain epoch [16/354], ZINB loss:0.3947, NB loss:4.4666, latent MSE loss:0.00050022, KL loss:0.00071431\n",
      "Pretrain epoch [17/354], ZINB loss:0.3869, NB loss:4.4572, latent MSE loss:0.00039938, KL loss:0.00090161\n",
      "Pretrain epoch [18/354], ZINB loss:0.4227, NB loss:4.4339, latent MSE loss:0.00060461, KL loss:0.00082762\n",
      "Pretrain epoch [19/354], ZINB loss:0.4027, NB loss:4.5088, latent MSE loss:0.00060581, KL loss:0.00076652\n",
      "Pretrain epoch [20/354], ZINB loss:0.3979, NB loss:4.5107, latent MSE loss:0.00051184, KL loss:0.00081042\n",
      "Pretrain epoch [21/354], ZINB loss:0.3944, NB loss:4.5030, latent MSE loss:0.00047794, KL loss:0.00112983\n",
      "Pretrain epoch [22/354], ZINB loss:0.3982, NB loss:4.5098, latent MSE loss:0.00039853, KL loss:0.00089941\n",
      "Pretrain epoch [23/354], ZINB loss:0.3966, NB loss:4.5453, latent MSE loss:0.00040213, KL loss:0.00080532\n",
      "Pretrain epoch [24/354], ZINB loss:0.3850, NB loss:4.5795, latent MSE loss:0.00037344, KL loss:0.00103879\n",
      "Pretrain epoch [25/354], ZINB loss:0.3995, NB loss:4.4579, latent MSE loss:0.00037621, KL loss:0.00072836\n",
      "Pretrain epoch [26/354], ZINB loss:0.3859, NB loss:4.5233, latent MSE loss:0.00043604, KL loss:0.00094276\n",
      "Pretrain epoch [27/354], ZINB loss:0.4074, NB loss:4.2877, latent MSE loss:0.00028122, KL loss:0.00004477\n",
      "Pretrain epoch [1/355], ZINB loss:0.4069, NB loss:4.5227, latent MSE loss:0.00079854, KL loss:0.00083182\n",
      "Pretrain epoch [2/355], ZINB loss:0.4086, NB loss:4.5144, latent MSE loss:0.00063699, KL loss:0.00076561\n",
      "Pretrain epoch [3/355], ZINB loss:0.3927, NB loss:4.4184, latent MSE loss:0.00066955, KL loss:0.00071058\n",
      "Pretrain epoch [4/355], ZINB loss:0.3877, NB loss:4.4510, latent MSE loss:0.00051156, KL loss:0.00071632\n",
      "Pretrain epoch [5/355], ZINB loss:0.3861, NB loss:4.5375, latent MSE loss:0.00061429, KL loss:0.00099530\n",
      "Pretrain epoch [6/355], ZINB loss:0.4089, NB loss:4.5131, latent MSE loss:0.00067145, KL loss:0.00118133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [7/355], ZINB loss:0.3909, NB loss:4.4400, latent MSE loss:0.00061167, KL loss:0.00076193\n",
      "Pretrain epoch [8/355], ZINB loss:0.3813, NB loss:4.4726, latent MSE loss:0.00048327, KL loss:0.00079421\n",
      "Pretrain epoch [9/355], ZINB loss:0.3965, NB loss:4.5410, latent MSE loss:0.00042121, KL loss:0.00098293\n",
      "Pretrain epoch [10/355], ZINB loss:0.3882, NB loss:4.4314, latent MSE loss:0.00051055, KL loss:0.00082161\n",
      "Pretrain epoch [11/355], ZINB loss:0.4038, NB loss:4.4980, latent MSE loss:0.00044464, KL loss:0.00114507\n",
      "Pretrain epoch [12/355], ZINB loss:0.4074, NB loss:4.4810, latent MSE loss:0.00051960, KL loss:0.00101869\n",
      "Pretrain epoch [13/355], ZINB loss:0.3648, NB loss:4.4761, latent MSE loss:0.00041891, KL loss:0.00067397\n",
      "Pretrain epoch [14/355], ZINB loss:0.3983, NB loss:4.5103, latent MSE loss:0.00031988, KL loss:0.00081520\n",
      "Pretrain epoch [15/355], ZINB loss:0.4087, NB loss:4.4318, latent MSE loss:0.00037105, KL loss:0.00076062\n",
      "Pretrain epoch [16/355], ZINB loss:0.4028, NB loss:4.5321, latent MSE loss:0.00041028, KL loss:0.00091296\n",
      "Pretrain epoch [17/355], ZINB loss:0.4121, NB loss:4.5182, latent MSE loss:0.00046923, KL loss:0.00114250\n",
      "Pretrain epoch [18/355], ZINB loss:0.3998, NB loss:4.4950, latent MSE loss:0.00029714, KL loss:0.00096060\n",
      "Pretrain epoch [19/355], ZINB loss:0.3906, NB loss:4.4722, latent MSE loss:0.00025135, KL loss:0.00077822\n",
      "Pretrain epoch [20/355], ZINB loss:0.3899, NB loss:4.4923, latent MSE loss:0.00034685, KL loss:0.00080226\n",
      "Pretrain epoch [21/355], ZINB loss:0.4018, NB loss:4.5228, latent MSE loss:0.00031129, KL loss:0.00085372\n",
      "Pretrain epoch [22/355], ZINB loss:0.3946, NB loss:4.4758, latent MSE loss:0.00034494, KL loss:0.00082941\n",
      "Pretrain epoch [23/355], ZINB loss:0.3940, NB loss:4.5059, latent MSE loss:0.00031851, KL loss:0.00076034\n",
      "Pretrain epoch [24/355], ZINB loss:0.3789, NB loss:4.5756, latent MSE loss:0.00035059, KL loss:0.00076504\n",
      "Pretrain epoch [25/355], ZINB loss:0.3990, NB loss:4.4837, latent MSE loss:0.00023728, KL loss:0.00074147\n",
      "Pretrain epoch [26/355], ZINB loss:0.3807, NB loss:4.4487, latent MSE loss:0.00030837, KL loss:0.00076306\n",
      "Pretrain epoch [27/355], ZINB loss:0.3379, NB loss:4.7452, latent MSE loss:0.00025129, KL loss:0.00007002\n",
      "Pretrain epoch [1/356], ZINB loss:0.3784, NB loss:4.5151, latent MSE loss:0.00051278, KL loss:0.00099843\n",
      "Pretrain epoch [2/356], ZINB loss:0.3914, NB loss:4.4533, latent MSE loss:0.00045094, KL loss:0.00102122\n",
      "Pretrain epoch [3/356], ZINB loss:0.3935, NB loss:4.4982, latent MSE loss:0.00040646, KL loss:0.00094257\n",
      "Pretrain epoch [4/356], ZINB loss:0.4038, NB loss:4.4301, latent MSE loss:0.00028076, KL loss:0.00072673\n",
      "Pretrain epoch [5/356], ZINB loss:0.3873, NB loss:4.4992, latent MSE loss:0.00036218, KL loss:0.00073911\n",
      "Pretrain epoch [6/356], ZINB loss:0.3841, NB loss:4.5166, latent MSE loss:0.00033379, KL loss:0.00074487\n",
      "Pretrain epoch [7/356], ZINB loss:0.3906, NB loss:4.4919, latent MSE loss:0.00026057, KL loss:0.00078817\n",
      "Pretrain epoch [8/356], ZINB loss:0.3858, NB loss:4.4998, latent MSE loss:0.00032188, KL loss:0.00070283\n",
      "Pretrain epoch [9/356], ZINB loss:0.4099, NB loss:4.5006, latent MSE loss:0.00040721, KL loss:0.00095928\n",
      "Pretrain epoch [10/356], ZINB loss:0.3884, NB loss:4.5291, latent MSE loss:0.00028329, KL loss:0.00092899\n",
      "Pretrain epoch [11/356], ZINB loss:0.3788, NB loss:4.4448, latent MSE loss:0.00022786, KL loss:0.00073156\n",
      "Pretrain epoch [12/356], ZINB loss:0.3935, NB loss:4.4715, latent MSE loss:0.00028720, KL loss:0.00086046\n",
      "Pretrain epoch [13/356], ZINB loss:0.3862, NB loss:4.5048, latent MSE loss:0.00031076, KL loss:0.00074042\n",
      "Pretrain epoch [14/356], ZINB loss:0.4183, NB loss:4.5228, latent MSE loss:0.00025292, KL loss:0.00080155\n",
      "Pretrain epoch [15/356], ZINB loss:0.3768, NB loss:4.4666, latent MSE loss:0.00026277, KL loss:0.00078909\n",
      "Pretrain epoch [16/356], ZINB loss:0.3933, NB loss:4.5162, latent MSE loss:0.00027645, KL loss:0.00086835\n",
      "Pretrain epoch [17/356], ZINB loss:0.3978, NB loss:4.4988, latent MSE loss:0.00016038, KL loss:0.00075380\n",
      "Pretrain epoch [18/356], ZINB loss:0.4072, NB loss:4.4953, latent MSE loss:0.00027199, KL loss:0.00121726\n",
      "Pretrain epoch [19/356], ZINB loss:0.4215, NB loss:4.4822, latent MSE loss:0.00023848, KL loss:0.00081505\n",
      "Pretrain epoch [20/356], ZINB loss:0.4074, NB loss:4.4516, latent MSE loss:0.00022701, KL loss:0.00083174\n",
      "Pretrain epoch [21/356], ZINB loss:0.3948, NB loss:4.5223, latent MSE loss:0.00026033, KL loss:0.00080809\n",
      "Pretrain epoch [22/356], ZINB loss:0.3935, NB loss:4.4725, latent MSE loss:0.00029381, KL loss:0.00087423\n",
      "Pretrain epoch [23/356], ZINB loss:0.3906, NB loss:4.4864, latent MSE loss:0.00024511, KL loss:0.00070002\n",
      "Pretrain epoch [24/356], ZINB loss:0.4044, NB loss:4.4902, latent MSE loss:0.00021071, KL loss:0.00075767\n",
      "Pretrain epoch [25/356], ZINB loss:0.3906, NB loss:4.4744, latent MSE loss:0.00029408, KL loss:0.00102234\n",
      "Pretrain epoch [26/356], ZINB loss:0.3922, NB loss:4.4699, latent MSE loss:0.00023776, KL loss:0.00090800\n",
      "Pretrain epoch [27/356], ZINB loss:0.4841, NB loss:4.5496, latent MSE loss:0.00016270, KL loss:0.00000642\n",
      "Pretrain epoch [1/357], ZINB loss:0.4242, NB loss:4.5018, latent MSE loss:0.00042850, KL loss:0.00102600\n",
      "Pretrain epoch [2/357], ZINB loss:0.3954, NB loss:4.4555, latent MSE loss:0.00036820, KL loss:0.00085643\n",
      "Pretrain epoch [3/357], ZINB loss:0.4097, NB loss:4.4795, latent MSE loss:0.00037188, KL loss:0.00156906\n",
      "Pretrain epoch [4/357], ZINB loss:0.3915, NB loss:4.4958, latent MSE loss:0.00034051, KL loss:0.00078629\n",
      "Pretrain epoch [5/357], ZINB loss:0.3975, NB loss:4.4390, latent MSE loss:0.00033397, KL loss:0.00072267\n",
      "Pretrain epoch [6/357], ZINB loss:0.3941, NB loss:4.4771, latent MSE loss:0.00026628, KL loss:0.00088367\n",
      "Pretrain epoch [7/357], ZINB loss:0.4030, NB loss:4.4712, latent MSE loss:0.00034417, KL loss:0.00092614\n",
      "Pretrain epoch [8/357], ZINB loss:0.3913, NB loss:4.4702, latent MSE loss:0.00030874, KL loss:0.00075094\n",
      "Pretrain epoch [9/357], ZINB loss:0.3884, NB loss:4.5128, latent MSE loss:0.00032141, KL loss:0.00071541\n",
      "Pretrain epoch [10/357], ZINB loss:0.3897, NB loss:4.5173, latent MSE loss:0.00036817, KL loss:0.00086906\n",
      "Pretrain epoch [11/357], ZINB loss:0.3918, NB loss:4.5011, latent MSE loss:0.00039426, KL loss:0.00091276\n",
      "Pretrain epoch [12/357], ZINB loss:0.4003, NB loss:4.4369, latent MSE loss:0.00034153, KL loss:0.00081789\n",
      "Pretrain epoch [13/357], ZINB loss:0.3873, NB loss:4.4765, latent MSE loss:0.00034891, KL loss:0.00092929\n",
      "Pretrain epoch [14/357], ZINB loss:0.3990, NB loss:4.4976, latent MSE loss:0.00042806, KL loss:0.00094585\n",
      "Pretrain epoch [15/357], ZINB loss:0.3894, NB loss:4.4655, latent MSE loss:0.00033217, KL loss:0.00076929\n",
      "Pretrain epoch [16/357], ZINB loss:0.4171, NB loss:4.5122, latent MSE loss:0.00035908, KL loss:0.00084269\n",
      "Pretrain epoch [17/357], ZINB loss:0.3851, NB loss:4.5257, latent MSE loss:0.00026874, KL loss:0.00093191\n",
      "Pretrain epoch [18/357], ZINB loss:0.4037, NB loss:4.5499, latent MSE loss:0.00031257, KL loss:0.00083457\n",
      "Pretrain epoch [19/357], ZINB loss:0.3915, NB loss:4.4191, latent MSE loss:0.00025259, KL loss:0.00076974\n",
      "Pretrain epoch [20/357], ZINB loss:0.3937, NB loss:4.4896, latent MSE loss:0.00024120, KL loss:0.00076176\n",
      "Pretrain epoch [21/357], ZINB loss:0.3737, NB loss:4.4893, latent MSE loss:0.00025597, KL loss:0.00088623\n",
      "Pretrain epoch [22/357], ZINB loss:0.4012, NB loss:4.5216, latent MSE loss:0.00028451, KL loss:0.00092150\n",
      "Pretrain epoch [23/357], ZINB loss:0.3974, NB loss:4.5342, latent MSE loss:0.00031632, KL loss:0.00098385\n",
      "Pretrain epoch [24/357], ZINB loss:0.3981, NB loss:4.4759, latent MSE loss:0.00021389, KL loss:0.00072205\n",
      "Pretrain epoch [25/357], ZINB loss:0.3756, NB loss:4.4716, latent MSE loss:0.00020080, KL loss:0.00077400\n",
      "Pretrain epoch [26/357], ZINB loss:0.3838, NB loss:4.4983, latent MSE loss:0.00022604, KL loss:0.00098081\n",
      "Pretrain epoch [27/357], ZINB loss:0.4990, NB loss:4.6376, latent MSE loss:0.00082822, KL loss:0.00001095\n",
      "Pretrain epoch [1/358], ZINB loss:0.4105, NB loss:4.4441, latent MSE loss:0.00046848, KL loss:0.00088090\n",
      "Pretrain epoch [2/358], ZINB loss:0.3936, NB loss:4.5417, latent MSE loss:0.00042549, KL loss:0.00112888\n",
      "Pretrain epoch [3/358], ZINB loss:0.3767, NB loss:4.5352, latent MSE loss:0.00052811, KL loss:0.00085797\n",
      "Pretrain epoch [4/358], ZINB loss:0.3795, NB loss:4.4793, latent MSE loss:0.00088764, KL loss:0.00109174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [5/358], ZINB loss:0.4000, NB loss:4.4799, latent MSE loss:0.00071641, KL loss:0.00080849\n",
      "Pretrain epoch [6/358], ZINB loss:0.4209, NB loss:4.5249, latent MSE loss:0.00186380, KL loss:0.00106978\n",
      "Pretrain epoch [7/358], ZINB loss:0.3958, NB loss:4.4834, latent MSE loss:0.00047380, KL loss:0.00081570\n",
      "Pretrain epoch [8/358], ZINB loss:0.3854, NB loss:4.4514, latent MSE loss:0.00106249, KL loss:0.00070403\n",
      "Pretrain epoch [9/358], ZINB loss:0.3766, NB loss:4.4895, latent MSE loss:0.00081979, KL loss:0.00073251\n",
      "Pretrain epoch [10/358], ZINB loss:0.4182, NB loss:4.5471, latent MSE loss:0.00111072, KL loss:0.00105344\n",
      "Pretrain epoch [11/358], ZINB loss:0.4118, NB loss:4.4499, latent MSE loss:0.00133540, KL loss:0.00136519\n",
      "Pretrain epoch [12/358], ZINB loss:0.3909, NB loss:4.5365, latent MSE loss:0.00039887, KL loss:0.00080211\n",
      "Pretrain epoch [13/358], ZINB loss:0.3901, NB loss:4.4680, latent MSE loss:0.00103645, KL loss:0.00088613\n",
      "Pretrain epoch [14/358], ZINB loss:0.3913, NB loss:4.4869, latent MSE loss:0.00091876, KL loss:0.00093303\n",
      "Pretrain epoch [15/358], ZINB loss:0.3841, NB loss:4.3873, latent MSE loss:0.00056443, KL loss:0.00076906\n",
      "Pretrain epoch [16/358], ZINB loss:0.3849, NB loss:4.4569, latent MSE loss:0.00048550, KL loss:0.00074653\n",
      "Pretrain epoch [17/358], ZINB loss:0.3996, NB loss:4.5052, latent MSE loss:0.00075613, KL loss:0.00075845\n",
      "Pretrain epoch [18/358], ZINB loss:0.3757, NB loss:4.4704, latent MSE loss:0.00065380, KL loss:0.00077465\n",
      "Pretrain epoch [19/358], ZINB loss:0.3922, NB loss:4.5334, latent MSE loss:0.00038393, KL loss:0.00114479\n",
      "Pretrain epoch [20/358], ZINB loss:0.4109, NB loss:4.5134, latent MSE loss:0.00063834, KL loss:0.00108081\n",
      "Pretrain epoch [21/358], ZINB loss:0.4171, NB loss:4.4749, latent MSE loss:0.00070379, KL loss:0.00088966\n",
      "Pretrain epoch [22/358], ZINB loss:0.4042, NB loss:4.4405, latent MSE loss:0.00060550, KL loss:0.00079729\n",
      "Pretrain epoch [23/358], ZINB loss:0.3678, NB loss:4.4707, latent MSE loss:0.00045749, KL loss:0.00085300\n",
      "Pretrain epoch [24/358], ZINB loss:0.4044, NB loss:4.4452, latent MSE loss:0.00062244, KL loss:0.00081625\n",
      "Pretrain epoch [25/358], ZINB loss:0.4102, NB loss:4.5095, latent MSE loss:0.00046918, KL loss:0.00085676\n",
      "Pretrain epoch [26/358], ZINB loss:0.3932, NB loss:4.5141, latent MSE loss:0.00045326, KL loss:0.00095934\n",
      "Pretrain epoch [27/358], ZINB loss:0.5067, NB loss:5.1935, latent MSE loss:0.00080489, KL loss:0.00001271\n",
      "Pretrain epoch [1/359], ZINB loss:0.4012, NB loss:4.5176, latent MSE loss:0.00169728, KL loss:0.00110733\n",
      "Pretrain epoch [2/359], ZINB loss:0.3960, NB loss:4.4969, latent MSE loss:0.00184235, KL loss:0.00095009\n",
      "Pretrain epoch [3/359], ZINB loss:0.4087, NB loss:4.4671, latent MSE loss:0.00181948, KL loss:0.00103599\n",
      "Pretrain epoch [4/359], ZINB loss:0.4119, NB loss:4.4865, latent MSE loss:0.00141566, KL loss:0.00090861\n",
      "Pretrain epoch [5/359], ZINB loss:0.3980, NB loss:4.5554, latent MSE loss:0.00174869, KL loss:0.00122780\n",
      "Pretrain epoch [6/359], ZINB loss:0.3915, NB loss:4.5169, latent MSE loss:0.00167927, KL loss:0.00125798\n",
      "Pretrain epoch [7/359], ZINB loss:0.3866, NB loss:4.4564, latent MSE loss:0.00182588, KL loss:0.00095215\n",
      "Pretrain epoch [8/359], ZINB loss:0.4049, NB loss:4.4592, latent MSE loss:0.00169969, KL loss:0.00105007\n",
      "Pretrain epoch [9/359], ZINB loss:0.3843, NB loss:4.4762, latent MSE loss:0.00122271, KL loss:0.00104075\n",
      "Pretrain epoch [10/359], ZINB loss:0.3976, NB loss:4.4678, latent MSE loss:0.00116135, KL loss:0.00084296\n",
      "Pretrain epoch [11/359], ZINB loss:0.4179, NB loss:4.4631, latent MSE loss:0.00131042, KL loss:0.00101086\n",
      "Pretrain epoch [12/359], ZINB loss:0.3995, NB loss:4.4397, latent MSE loss:0.00126723, KL loss:0.00087729\n",
      "Pretrain epoch [13/359], ZINB loss:0.4031, NB loss:4.4913, latent MSE loss:0.00133465, KL loss:0.00089640\n",
      "Pretrain epoch [14/359], ZINB loss:0.4123, NB loss:4.4844, latent MSE loss:0.00119291, KL loss:0.00107443\n",
      "Pretrain epoch [15/359], ZINB loss:0.3882, NB loss:4.4760, latent MSE loss:0.00107261, KL loss:0.00085017\n",
      "Pretrain epoch [16/359], ZINB loss:0.4009, NB loss:4.5272, latent MSE loss:0.00113337, KL loss:0.00115896\n",
      "Pretrain epoch [17/359], ZINB loss:0.3928, NB loss:4.4512, latent MSE loss:0.00085174, KL loss:0.00082814\n",
      "Pretrain epoch [18/359], ZINB loss:0.4006, NB loss:4.4561, latent MSE loss:0.00099194, KL loss:0.00111813\n",
      "Pretrain epoch [19/359], ZINB loss:0.3930, NB loss:4.4989, latent MSE loss:0.00083122, KL loss:0.00087969\n",
      "Pretrain epoch [20/359], ZINB loss:0.3812, NB loss:4.4914, latent MSE loss:0.00065505, KL loss:0.00075198\n",
      "Pretrain epoch [21/359], ZINB loss:0.3957, NB loss:4.4802, latent MSE loss:0.00081334, KL loss:0.00083726\n",
      "Pretrain epoch [22/359], ZINB loss:0.3827, NB loss:4.4827, latent MSE loss:0.00075077, KL loss:0.00083156\n",
      "Pretrain epoch [23/359], ZINB loss:0.3900, NB loss:4.4707, latent MSE loss:0.00066351, KL loss:0.00080719\n",
      "Pretrain epoch [24/359], ZINB loss:0.3969, NB loss:4.5066, latent MSE loss:0.00078730, KL loss:0.00098248\n",
      "Pretrain epoch [25/359], ZINB loss:0.3890, NB loss:4.5044, latent MSE loss:0.00048256, KL loss:0.00080548\n",
      "Pretrain epoch [26/359], ZINB loss:0.4113, NB loss:4.5376, latent MSE loss:0.00061282, KL loss:0.00111546\n",
      "Pretrain epoch [27/359], ZINB loss:0.3686, NB loss:4.2786, latent MSE loss:0.00048515, KL loss:0.00004371\n",
      "Pretrain epoch [1/360], ZINB loss:0.3974, NB loss:4.4614, latent MSE loss:0.00099073, KL loss:0.00076771\n",
      "Pretrain epoch [2/360], ZINB loss:0.3967, NB loss:4.5405, latent MSE loss:0.00061464, KL loss:0.00113229\n",
      "Pretrain epoch [3/360], ZINB loss:0.4002, NB loss:4.4742, latent MSE loss:0.00059551, KL loss:0.00094817\n",
      "Pretrain epoch [4/360], ZINB loss:0.4040, NB loss:4.4457, latent MSE loss:0.00055614, KL loss:0.00080701\n",
      "Pretrain epoch [5/360], ZINB loss:0.4036, NB loss:4.4513, latent MSE loss:0.00057295, KL loss:0.00078719\n",
      "Pretrain epoch [6/360], ZINB loss:0.4144, NB loss:4.4319, latent MSE loss:0.00073401, KL loss:0.00096696\n",
      "Pretrain epoch [7/360], ZINB loss:0.3929, NB loss:4.4961, latent MSE loss:0.00071322, KL loss:0.00073033\n",
      "Pretrain epoch [8/360], ZINB loss:0.4057, NB loss:4.5234, latent MSE loss:0.00070671, KL loss:0.00078069\n",
      "Pretrain epoch [9/360], ZINB loss:0.3922, NB loss:4.5127, latent MSE loss:0.00054112, KL loss:0.00090140\n",
      "Pretrain epoch [10/360], ZINB loss:0.3928, NB loss:4.4709, latent MSE loss:0.00040829, KL loss:0.00078221\n",
      "Pretrain epoch [11/360], ZINB loss:0.3870, NB loss:4.4859, latent MSE loss:0.00062289, KL loss:0.00092411\n",
      "Pretrain epoch [12/360], ZINB loss:0.3920, NB loss:4.5294, latent MSE loss:0.00049554, KL loss:0.00079010\n",
      "Pretrain epoch [13/360], ZINB loss:0.4099, NB loss:4.4724, latent MSE loss:0.00042263, KL loss:0.00086757\n",
      "Pretrain epoch [14/360], ZINB loss:0.3964, NB loss:4.4907, latent MSE loss:0.00058970, KL loss:0.00071327\n",
      "Pretrain epoch [15/360], ZINB loss:0.3820, NB loss:4.5413, latent MSE loss:0.00031541, KL loss:0.00087133\n",
      "Pretrain epoch [16/360], ZINB loss:0.3824, NB loss:4.4710, latent MSE loss:0.00045558, KL loss:0.00091141\n",
      "Pretrain epoch [17/360], ZINB loss:0.4000, NB loss:4.5583, latent MSE loss:0.00040035, KL loss:0.00083334\n",
      "Pretrain epoch [18/360], ZINB loss:0.3952, NB loss:4.4785, latent MSE loss:0.00032575, KL loss:0.00074473\n",
      "Pretrain epoch [19/360], ZINB loss:0.4249, NB loss:4.5939, latent MSE loss:0.00050480, KL loss:0.00101917\n",
      "Pretrain epoch [20/360], ZINB loss:0.4105, NB loss:4.4480, latent MSE loss:0.00037590, KL loss:0.00081578\n",
      "Pretrain epoch [21/360], ZINB loss:0.3849, NB loss:4.4430, latent MSE loss:0.00040235, KL loss:0.00075383\n",
      "Pretrain epoch [22/360], ZINB loss:0.3828, NB loss:4.4511, latent MSE loss:0.00034475, KL loss:0.00079985\n",
      "Pretrain epoch [23/360], ZINB loss:0.3911, NB loss:4.4653, latent MSE loss:0.00041221, KL loss:0.00085740\n",
      "Pretrain epoch [24/360], ZINB loss:0.4044, NB loss:4.5024, latent MSE loss:0.00051433, KL loss:0.00100604\n",
      "Pretrain epoch [25/360], ZINB loss:0.3937, NB loss:4.4506, latent MSE loss:0.00039324, KL loss:0.00091728\n",
      "Pretrain epoch [26/360], ZINB loss:0.3710, NB loss:4.4462, latent MSE loss:0.00035644, KL loss:0.00077704\n",
      "Pretrain epoch [27/360], ZINB loss:0.5616, NB loss:4.4078, latent MSE loss:0.00045694, KL loss:0.00001194\n",
      "Pretrain epoch [1/361], ZINB loss:0.4051, NB loss:4.4320, latent MSE loss:0.00147968, KL loss:0.00096479\n",
      "Pretrain epoch [2/361], ZINB loss:0.4034, NB loss:4.5418, latent MSE loss:0.00115972, KL loss:0.00091863\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [3/361], ZINB loss:0.3797, NB loss:4.4608, latent MSE loss:0.00093210, KL loss:0.00076268\n",
      "Pretrain epoch [4/361], ZINB loss:0.3885, NB loss:4.4640, latent MSE loss:0.00120361, KL loss:0.00069439\n",
      "Pretrain epoch [5/361], ZINB loss:0.3935, NB loss:4.4591, latent MSE loss:0.00068239, KL loss:0.00074160\n",
      "Pretrain epoch [6/361], ZINB loss:0.3864, NB loss:4.4599, latent MSE loss:0.00084284, KL loss:0.00068846\n",
      "Pretrain epoch [7/361], ZINB loss:0.3863, NB loss:4.5201, latent MSE loss:0.00089160, KL loss:0.00111059\n",
      "Pretrain epoch [8/361], ZINB loss:0.3770, NB loss:4.4527, latent MSE loss:0.00075219, KL loss:0.00098435\n",
      "Pretrain epoch [9/361], ZINB loss:0.4054, NB loss:4.5015, latent MSE loss:0.00088508, KL loss:0.00096788\n",
      "Pretrain epoch [10/361], ZINB loss:0.4064, NB loss:4.3864, latent MSE loss:0.00057472, KL loss:0.00078153\n",
      "Pretrain epoch [11/361], ZINB loss:0.4116, NB loss:4.4779, latent MSE loss:0.00060689, KL loss:0.00084751\n",
      "Pretrain epoch [12/361], ZINB loss:0.4012, NB loss:4.4573, latent MSE loss:0.00058759, KL loss:0.00138856\n",
      "Pretrain epoch [13/361], ZINB loss:0.3805, NB loss:4.5574, latent MSE loss:0.00064275, KL loss:0.00117831\n",
      "Pretrain epoch [14/361], ZINB loss:0.4085, NB loss:4.5145, latent MSE loss:0.00056818, KL loss:0.00114827\n",
      "Pretrain epoch [15/361], ZINB loss:0.3865, NB loss:4.5256, latent MSE loss:0.00057077, KL loss:0.00086158\n",
      "Pretrain epoch [16/361], ZINB loss:0.4124, NB loss:4.4406, latent MSE loss:0.00047225, KL loss:0.00081697\n",
      "Pretrain epoch [17/361], ZINB loss:0.4004, NB loss:4.4534, latent MSE loss:0.00044109, KL loss:0.00078704\n",
      "Pretrain epoch [18/361], ZINB loss:0.3959, NB loss:4.4469, latent MSE loss:0.00048853, KL loss:0.00091924\n",
      "Pretrain epoch [19/361], ZINB loss:0.3846, NB loss:4.4935, latent MSE loss:0.00034560, KL loss:0.00072396\n",
      "Pretrain epoch [20/361], ZINB loss:0.3893, NB loss:4.4744, latent MSE loss:0.00037325, KL loss:0.00078842\n",
      "Pretrain epoch [21/361], ZINB loss:0.4154, NB loss:4.5143, latent MSE loss:0.00041969, KL loss:0.00131460\n",
      "Pretrain epoch [22/361], ZINB loss:0.3998, NB loss:4.5806, latent MSE loss:0.00036423, KL loss:0.00096940\n",
      "Pretrain epoch [23/361], ZINB loss:0.3675, NB loss:4.5227, latent MSE loss:0.00022557, KL loss:0.00081036\n",
      "Pretrain epoch [24/361], ZINB loss:0.4085, NB loss:4.5273, latent MSE loss:0.00041752, KL loss:0.00077668\n",
      "Pretrain epoch [25/361], ZINB loss:0.4048, NB loss:4.4219, latent MSE loss:0.00033722, KL loss:0.00073064\n",
      "Pretrain epoch [26/361], ZINB loss:0.4014, NB loss:4.5181, latent MSE loss:0.00026824, KL loss:0.00119895\n",
      "Pretrain epoch [27/361], ZINB loss:0.5438, NB loss:4.6204, latent MSE loss:0.00057813, KL loss:0.00004978\n",
      "Pretrain epoch [1/362], ZINB loss:0.4129, NB loss:4.4763, latent MSE loss:0.00195531, KL loss:0.00111196\n",
      "Pretrain epoch [2/362], ZINB loss:0.4104, NB loss:4.4936, latent MSE loss:0.00216330, KL loss:0.00132035\n",
      "Pretrain epoch [3/362], ZINB loss:0.4249, NB loss:4.4767, latent MSE loss:0.00234919, KL loss:0.00195907\n",
      "Pretrain epoch [4/362], ZINB loss:0.4201, NB loss:4.5368, latent MSE loss:0.00433690, KL loss:0.00140772\n",
      "Pretrain epoch [5/362], ZINB loss:0.4008, NB loss:4.4040, latent MSE loss:0.00202240, KL loss:0.00092664\n",
      "Pretrain epoch [6/362], ZINB loss:0.4068, NB loss:4.4265, latent MSE loss:0.00209012, KL loss:0.00102316\n",
      "Pretrain epoch [7/362], ZINB loss:0.4267, NB loss:4.4905, latent MSE loss:0.00335745, KL loss:0.00182890\n",
      "Pretrain epoch [8/362], ZINB loss:0.4152, NB loss:4.4482, latent MSE loss:0.00145425, KL loss:0.00109738\n",
      "Pretrain epoch [9/362], ZINB loss:0.4033, NB loss:4.5261, latent MSE loss:0.00230625, KL loss:0.00136725\n",
      "Pretrain epoch [10/362], ZINB loss:0.4187, NB loss:4.4346, latent MSE loss:0.00428887, KL loss:0.00153888\n",
      "Pretrain epoch [11/362], ZINB loss:0.3978, NB loss:4.5527, latent MSE loss:0.00154773, KL loss:0.00093370\n",
      "Pretrain epoch [12/362], ZINB loss:0.4105, NB loss:4.5093, latent MSE loss:0.00172828, KL loss:0.00091438\n",
      "Pretrain epoch [13/362], ZINB loss:0.3977, NB loss:4.5418, latent MSE loss:0.00232568, KL loss:0.00103071\n",
      "Pretrain epoch [14/362], ZINB loss:0.3915, NB loss:4.4880, latent MSE loss:0.00143540, KL loss:0.00083881\n",
      "Pretrain epoch [15/362], ZINB loss:0.4161, NB loss:4.4773, latent MSE loss:0.00223816, KL loss:0.00131663\n",
      "Pretrain epoch [16/362], ZINB loss:0.4015, NB loss:4.4944, latent MSE loss:0.00139447, KL loss:0.00094871\n",
      "Pretrain epoch [17/362], ZINB loss:0.3930, NB loss:4.4469, latent MSE loss:0.00140586, KL loss:0.00085759\n",
      "Pretrain epoch [18/362], ZINB loss:0.3904, NB loss:4.4863, latent MSE loss:0.00161941, KL loss:0.00118079\n",
      "Pretrain epoch [19/362], ZINB loss:0.4110, NB loss:4.4507, latent MSE loss:0.00146946, KL loss:0.00099308\n",
      "Pretrain epoch [20/362], ZINB loss:0.4077, NB loss:4.4738, latent MSE loss:0.00178548, KL loss:0.00151515\n",
      "Pretrain epoch [21/362], ZINB loss:0.3895, NB loss:4.4325, latent MSE loss:0.00100473, KL loss:0.00075986\n",
      "Pretrain epoch [22/362], ZINB loss:0.3921, NB loss:4.4761, latent MSE loss:0.00094543, KL loss:0.00084175\n",
      "Pretrain epoch [23/362], ZINB loss:0.3788, NB loss:4.4797, latent MSE loss:0.00096400, KL loss:0.00100099\n",
      "Pretrain epoch [24/362], ZINB loss:0.4054, NB loss:4.4787, latent MSE loss:0.00072208, KL loss:0.00090282\n",
      "Pretrain epoch [25/362], ZINB loss:0.4049, NB loss:4.5396, latent MSE loss:0.00094177, KL loss:0.00124261\n",
      "Pretrain epoch [26/362], ZINB loss:0.3944, NB loss:4.5498, latent MSE loss:0.00083584, KL loss:0.00136073\n",
      "Pretrain epoch [27/362], ZINB loss:0.6264, NB loss:4.5633, latent MSE loss:0.00375446, KL loss:0.00005874\n",
      "Pretrain epoch [1/363], ZINB loss:0.3933, NB loss:4.4517, latent MSE loss:0.00953662, KL loss:0.00100180\n",
      "Pretrain epoch [2/363], ZINB loss:0.4003, NB loss:4.4343, latent MSE loss:0.00421518, KL loss:0.00120129\n",
      "Pretrain epoch [3/363], ZINB loss:0.4055, NB loss:4.4368, latent MSE loss:0.00666220, KL loss:0.00133674\n",
      "Pretrain epoch [4/363], ZINB loss:0.3991, NB loss:4.4824, latent MSE loss:0.00539166, KL loss:0.00120883\n",
      "Pretrain epoch [5/363], ZINB loss:0.3981, NB loss:4.4547, latent MSE loss:0.00505339, KL loss:0.00133889\n",
      "Pretrain epoch [6/363], ZINB loss:0.4235, NB loss:4.4549, latent MSE loss:0.00823934, KL loss:0.00163920\n",
      "Pretrain epoch [7/363], ZINB loss:0.4360, NB loss:4.4902, latent MSE loss:0.00599624, KL loss:0.00150137\n",
      "Pretrain epoch [8/363], ZINB loss:0.4139, NB loss:4.4466, latent MSE loss:0.00339155, KL loss:0.00134115\n",
      "Pretrain epoch [9/363], ZINB loss:0.3893, NB loss:4.5002, latent MSE loss:0.00428979, KL loss:0.00156476\n",
      "Pretrain epoch [10/363], ZINB loss:0.3938, NB loss:4.5207, latent MSE loss:0.00585238, KL loss:0.00204131\n",
      "Pretrain epoch [11/363], ZINB loss:0.4109, NB loss:4.5195, latent MSE loss:0.00389552, KL loss:0.00193116\n",
      "Pretrain epoch [12/363], ZINB loss:0.3910, NB loss:4.5007, latent MSE loss:0.00485404, KL loss:0.00175424\n",
      "Pretrain epoch [13/363], ZINB loss:0.4011, NB loss:4.4004, latent MSE loss:0.00321920, KL loss:0.00137889\n",
      "Pretrain epoch [14/363], ZINB loss:0.4111, NB loss:4.5700, latent MSE loss:0.00319375, KL loss:0.00151020\n",
      "Pretrain epoch [15/363], ZINB loss:0.4032, NB loss:4.5821, latent MSE loss:0.00350461, KL loss:0.00133539\n",
      "Pretrain epoch [16/363], ZINB loss:0.4011, NB loss:4.4773, latent MSE loss:0.00392252, KL loss:0.00146105\n",
      "Pretrain epoch [17/363], ZINB loss:0.4063, NB loss:4.4430, latent MSE loss:0.00349537, KL loss:0.00131178\n",
      "Pretrain epoch [18/363], ZINB loss:0.4179, NB loss:4.4997, latent MSE loss:0.00354496, KL loss:0.00134237\n",
      "Pretrain epoch [19/363], ZINB loss:0.4100, NB loss:4.4915, latent MSE loss:0.00330673, KL loss:0.00149998\n",
      "Pretrain epoch [20/363], ZINB loss:0.4174, NB loss:4.5770, latent MSE loss:0.00243073, KL loss:0.00135885\n",
      "Pretrain epoch [21/363], ZINB loss:0.4028, NB loss:4.4853, latent MSE loss:0.00307181, KL loss:0.00142877\n",
      "Pretrain epoch [22/363], ZINB loss:0.3999, NB loss:4.4937, latent MSE loss:0.00203689, KL loss:0.00122313\n",
      "Pretrain epoch [23/363], ZINB loss:0.4254, NB loss:4.4337, latent MSE loss:0.00209393, KL loss:0.00131528\n",
      "Pretrain epoch [24/363], ZINB loss:0.3890, NB loss:4.4911, latent MSE loss:0.00160958, KL loss:0.00129774\n",
      "Pretrain epoch [25/363], ZINB loss:0.3861, NB loss:4.4484, latent MSE loss:0.00183058, KL loss:0.00124218\n",
      "Pretrain epoch [26/363], ZINB loss:0.4172, NB loss:4.4878, latent MSE loss:0.00203225, KL loss:0.00142548\n",
      "Pretrain epoch [27/363], ZINB loss:0.4808, NB loss:4.1874, latent MSE loss:0.00125042, KL loss:0.00000752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [1/364], ZINB loss:0.3989, NB loss:4.4448, latent MSE loss:0.00394390, KL loss:0.00137570\n",
      "Pretrain epoch [2/364], ZINB loss:0.3966, NB loss:4.4741, latent MSE loss:0.00304985, KL loss:0.00122897\n",
      "Pretrain epoch [3/364], ZINB loss:0.4254, NB loss:4.4564, latent MSE loss:0.00238364, KL loss:0.00142992\n",
      "Pretrain epoch [4/364], ZINB loss:0.4174, NB loss:4.4694, latent MSE loss:0.00357809, KL loss:0.00126161\n",
      "Pretrain epoch [5/364], ZINB loss:0.4105, NB loss:4.4915, latent MSE loss:0.00203355, KL loss:0.00133774\n",
      "Pretrain epoch [6/364], ZINB loss:0.4038, NB loss:4.5241, latent MSE loss:0.00161381, KL loss:0.00126198\n",
      "Pretrain epoch [7/364], ZINB loss:0.3827, NB loss:4.5667, latent MSE loss:0.00181903, KL loss:0.00106923\n",
      "Pretrain epoch [8/364], ZINB loss:0.4007, NB loss:4.4595, latent MSE loss:0.00196110, KL loss:0.00117377\n",
      "Pretrain epoch [9/364], ZINB loss:0.4108, NB loss:4.4676, latent MSE loss:0.00198758, KL loss:0.00101782\n",
      "Pretrain epoch [10/364], ZINB loss:0.3994, NB loss:4.4968, latent MSE loss:0.00139631, KL loss:0.00135045\n",
      "Pretrain epoch [11/364], ZINB loss:0.3793, NB loss:4.4745, latent MSE loss:0.00138823, KL loss:0.00098623\n",
      "Pretrain epoch [12/364], ZINB loss:0.4052, NB loss:4.4631, latent MSE loss:0.00130149, KL loss:0.00137155\n",
      "Pretrain epoch [13/364], ZINB loss:0.4118, NB loss:4.4898, latent MSE loss:0.00135404, KL loss:0.00117192\n",
      "Pretrain epoch [14/364], ZINB loss:0.3821, NB loss:4.5245, latent MSE loss:0.00099005, KL loss:0.00098190\n",
      "Pretrain epoch [15/364], ZINB loss:0.3872, NB loss:4.4904, latent MSE loss:0.00120893, KL loss:0.00105643\n",
      "Pretrain epoch [16/364], ZINB loss:0.3844, NB loss:4.5437, latent MSE loss:0.00116960, KL loss:0.00132743\n",
      "Pretrain epoch [17/364], ZINB loss:0.3962, NB loss:4.4364, latent MSE loss:0.00116005, KL loss:0.00109562\n",
      "Pretrain epoch [18/364], ZINB loss:0.4043, NB loss:4.4285, latent MSE loss:0.00090109, KL loss:0.00124058\n",
      "Pretrain epoch [19/364], ZINB loss:0.4048, NB loss:4.5258, latent MSE loss:0.00092797, KL loss:0.00147740\n",
      "Pretrain epoch [20/364], ZINB loss:0.3848, NB loss:4.4658, latent MSE loss:0.00104352, KL loss:0.00110873\n",
      "Pretrain epoch [21/364], ZINB loss:0.3950, NB loss:4.4939, latent MSE loss:0.00090378, KL loss:0.00110594\n",
      "Pretrain epoch [22/364], ZINB loss:0.3990, NB loss:4.5622, latent MSE loss:0.00090450, KL loss:0.00115555\n",
      "Pretrain epoch [23/364], ZINB loss:0.3667, NB loss:4.4426, latent MSE loss:0.00060950, KL loss:0.00090812\n",
      "Pretrain epoch [24/364], ZINB loss:0.3933, NB loss:4.4310, latent MSE loss:0.00072373, KL loss:0.00104097\n",
      "Pretrain epoch [25/364], ZINB loss:0.4107, NB loss:4.4609, latent MSE loss:0.00074644, KL loss:0.00116904\n",
      "Pretrain epoch [26/364], ZINB loss:0.4084, NB loss:4.4668, latent MSE loss:0.00087743, KL loss:0.00133773\n",
      "Pretrain epoch [27/364], ZINB loss:0.4044, NB loss:4.6197, latent MSE loss:0.00044954, KL loss:0.00003990\n",
      "Pretrain epoch [1/365], ZINB loss:0.3943, NB loss:4.4741, latent MSE loss:0.00075299, KL loss:0.00131400\n",
      "Pretrain epoch [2/365], ZINB loss:0.3868, NB loss:4.3958, latent MSE loss:0.00069055, KL loss:0.00085153\n",
      "Pretrain epoch [3/365], ZINB loss:0.4120, NB loss:4.5278, latent MSE loss:0.00083707, KL loss:0.00120084\n",
      "Pretrain epoch [4/365], ZINB loss:0.3925, NB loss:4.4758, latent MSE loss:0.00061687, KL loss:0.00107094\n",
      "Pretrain epoch [5/365], ZINB loss:0.3968, NB loss:4.5112, latent MSE loss:0.00072579, KL loss:0.00122351\n",
      "Pretrain epoch [6/365], ZINB loss:0.4059, NB loss:4.4920, latent MSE loss:0.00070917, KL loss:0.00140862\n",
      "Pretrain epoch [7/365], ZINB loss:0.3997, NB loss:4.5038, latent MSE loss:0.00063075, KL loss:0.00087986\n",
      "Pretrain epoch [8/365], ZINB loss:0.4026, NB loss:4.5055, latent MSE loss:0.00065474, KL loss:0.00100233\n",
      "Pretrain epoch [9/365], ZINB loss:0.3912, NB loss:4.5357, latent MSE loss:0.00063109, KL loss:0.00112186\n",
      "Pretrain epoch [10/365], ZINB loss:0.3909, NB loss:4.5190, latent MSE loss:0.00055622, KL loss:0.00107359\n",
      "Pretrain epoch [11/365], ZINB loss:0.4079, NB loss:4.4537, latent MSE loss:0.00055864, KL loss:0.00120054\n",
      "Pretrain epoch [12/365], ZINB loss:0.3925, NB loss:4.4511, latent MSE loss:0.00041987, KL loss:0.00098613\n",
      "Pretrain epoch [13/365], ZINB loss:0.4047, NB loss:4.5233, latent MSE loss:0.00042051, KL loss:0.00095382\n",
      "Pretrain epoch [14/365], ZINB loss:0.3842, NB loss:4.4714, latent MSE loss:0.00036955, KL loss:0.00099761\n",
      "Pretrain epoch [15/365], ZINB loss:0.4084, NB loss:4.4553, latent MSE loss:0.00039352, KL loss:0.00087219\n",
      "Pretrain epoch [16/365], ZINB loss:0.4037, NB loss:4.4888, latent MSE loss:0.00035940, KL loss:0.00103439\n",
      "Pretrain epoch [17/365], ZINB loss:0.3971, NB loss:4.5216, latent MSE loss:0.00045127, KL loss:0.00087776\n",
      "Pretrain epoch [18/365], ZINB loss:0.3900, NB loss:4.4866, latent MSE loss:0.00035250, KL loss:0.00092550\n",
      "Pretrain epoch [19/365], ZINB loss:0.3977, NB loss:4.4736, latent MSE loss:0.00043142, KL loss:0.00104539\n",
      "Pretrain epoch [20/365], ZINB loss:0.3770, NB loss:4.4655, latent MSE loss:0.00029419, KL loss:0.00085012\n",
      "Pretrain epoch [21/365], ZINB loss:0.4100, NB loss:4.4752, latent MSE loss:0.00038691, KL loss:0.00095399\n",
      "Pretrain epoch [22/365], ZINB loss:0.3949, NB loss:4.4695, latent MSE loss:0.00032012, KL loss:0.00088741\n",
      "Pretrain epoch [23/365], ZINB loss:0.3908, NB loss:4.4485, latent MSE loss:0.00032285, KL loss:0.00118814\n",
      "Pretrain epoch [24/365], ZINB loss:0.3876, NB loss:4.5006, latent MSE loss:0.00029564, KL loss:0.00090162\n",
      "Pretrain epoch [25/365], ZINB loss:0.3883, NB loss:4.4708, latent MSE loss:0.00030676, KL loss:0.00099369\n",
      "Pretrain epoch [26/365], ZINB loss:0.4163, NB loss:4.4426, latent MSE loss:0.00035641, KL loss:0.00149500\n",
      "Pretrain epoch [27/365], ZINB loss:0.4497, NB loss:4.2618, latent MSE loss:0.00046916, KL loss:0.00000736\n",
      "Pretrain epoch [1/366], ZINB loss:0.4095, NB loss:4.5133, latent MSE loss:0.00087131, KL loss:0.00127913\n",
      "Pretrain epoch [2/366], ZINB loss:0.4095, NB loss:4.4481, latent MSE loss:0.00047628, KL loss:0.00094301\n",
      "Pretrain epoch [3/366], ZINB loss:0.4059, NB loss:4.4781, latent MSE loss:0.00059057, KL loss:0.00130654\n",
      "Pretrain epoch [4/366], ZINB loss:0.4118, NB loss:4.4606, latent MSE loss:0.00055409, KL loss:0.00109530\n",
      "Pretrain epoch [5/366], ZINB loss:0.4012, NB loss:4.4525, latent MSE loss:0.00058741, KL loss:0.00078046\n",
      "Pretrain epoch [6/366], ZINB loss:0.3840, NB loss:4.4874, latent MSE loss:0.00046506, KL loss:0.00115385\n",
      "Pretrain epoch [7/366], ZINB loss:0.3820, NB loss:4.4983, latent MSE loss:0.00046288, KL loss:0.00087419\n",
      "Pretrain epoch [8/366], ZINB loss:0.3837, NB loss:4.4984, latent MSE loss:0.00071347, KL loss:0.00082924\n",
      "Pretrain epoch [9/366], ZINB loss:0.3956, NB loss:4.4756, latent MSE loss:0.00042180, KL loss:0.00110621\n",
      "Pretrain epoch [10/366], ZINB loss:0.3834, NB loss:4.4593, latent MSE loss:0.00071580, KL loss:0.00086163\n",
      "Pretrain epoch [11/366], ZINB loss:0.3849, NB loss:4.5079, latent MSE loss:0.00046353, KL loss:0.00090679\n",
      "Pretrain epoch [12/366], ZINB loss:0.3835, NB loss:4.4891, latent MSE loss:0.00066350, KL loss:0.00080298\n",
      "Pretrain epoch [13/366], ZINB loss:0.3863, NB loss:4.4929, latent MSE loss:0.00039848, KL loss:0.00079908\n",
      "Pretrain epoch [14/366], ZINB loss:0.3916, NB loss:4.4901, latent MSE loss:0.00049233, KL loss:0.00114182\n",
      "Pretrain epoch [15/366], ZINB loss:0.4011, NB loss:4.5021, latent MSE loss:0.00048024, KL loss:0.00085549\n",
      "Pretrain epoch [16/366], ZINB loss:0.4058, NB loss:4.5535, latent MSE loss:0.00030562, KL loss:0.00080681\n",
      "Pretrain epoch [17/366], ZINB loss:0.3873, NB loss:4.4596, latent MSE loss:0.00051040, KL loss:0.00098284\n",
      "Pretrain epoch [18/366], ZINB loss:0.4099, NB loss:4.5155, latent MSE loss:0.00036250, KL loss:0.00093042\n",
      "Pretrain epoch [19/366], ZINB loss:0.4104, NB loss:4.4707, latent MSE loss:0.00034576, KL loss:0.00075609\n",
      "Pretrain epoch [20/366], ZINB loss:0.3901, NB loss:4.4531, latent MSE loss:0.00032954, KL loss:0.00082482\n",
      "Pretrain epoch [21/366], ZINB loss:0.4068, NB loss:4.4313, latent MSE loss:0.00038876, KL loss:0.00085472\n",
      "Pretrain epoch [22/366], ZINB loss:0.4176, NB loss:4.5323, latent MSE loss:0.00030911, KL loss:0.00120380\n",
      "Pretrain epoch [23/366], ZINB loss:0.4026, NB loss:4.4800, latent MSE loss:0.00042133, KL loss:0.00114903\n",
      "Pretrain epoch [24/366], ZINB loss:0.3933, NB loss:4.4388, latent MSE loss:0.00035760, KL loss:0.00114276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [25/366], ZINB loss:0.3807, NB loss:4.4635, latent MSE loss:0.00023744, KL loss:0.00114729\n",
      "Pretrain epoch [26/366], ZINB loss:0.3926, NB loss:4.4685, latent MSE loss:0.00030445, KL loss:0.00092148\n",
      "Pretrain epoch [27/366], ZINB loss:0.3034, NB loss:4.6453, latent MSE loss:0.00082599, KL loss:0.00004047\n",
      "Pretrain epoch [1/367], ZINB loss:0.4287, NB loss:4.4595, latent MSE loss:0.00085929, KL loss:0.00122969\n",
      "Pretrain epoch [2/367], ZINB loss:0.3993, NB loss:4.5105, latent MSE loss:0.00043063, KL loss:0.00093311\n",
      "Pretrain epoch [3/367], ZINB loss:0.4150, NB loss:4.4767, latent MSE loss:0.00051645, KL loss:0.00084167\n",
      "Pretrain epoch [4/367], ZINB loss:0.4002, NB loss:4.4729, latent MSE loss:0.00052879, KL loss:0.00083547\n",
      "Pretrain epoch [5/367], ZINB loss:0.3876, NB loss:4.4398, latent MSE loss:0.00050882, KL loss:0.00071678\n",
      "Pretrain epoch [6/367], ZINB loss:0.4096, NB loss:4.5255, latent MSE loss:0.00075383, KL loss:0.00083350\n",
      "Pretrain epoch [7/367], ZINB loss:0.3988, NB loss:4.5263, latent MSE loss:0.00049894, KL loss:0.00117441\n",
      "Pretrain epoch [8/367], ZINB loss:0.4127, NB loss:4.4695, latent MSE loss:0.00066596, KL loss:0.00138115\n",
      "Pretrain epoch [9/367], ZINB loss:0.3836, NB loss:4.5036, latent MSE loss:0.00035259, KL loss:0.00087693\n",
      "Pretrain epoch [10/367], ZINB loss:0.3929, NB loss:4.5454, latent MSE loss:0.00056362, KL loss:0.00091346\n",
      "Pretrain epoch [11/367], ZINB loss:0.3901, NB loss:4.4992, latent MSE loss:0.00041802, KL loss:0.00092384\n",
      "Pretrain epoch [12/367], ZINB loss:0.3887, NB loss:4.4775, latent MSE loss:0.00048029, KL loss:0.00094182\n",
      "Pretrain epoch [13/367], ZINB loss:0.4033, NB loss:4.4505, latent MSE loss:0.00039238, KL loss:0.00078524\n",
      "Pretrain epoch [14/367], ZINB loss:0.3807, NB loss:4.4633, latent MSE loss:0.00034142, KL loss:0.00111223\n",
      "Pretrain epoch [15/367], ZINB loss:0.3924, NB loss:4.5125, latent MSE loss:0.00048003, KL loss:0.00131700\n",
      "Pretrain epoch [16/367], ZINB loss:0.3948, NB loss:4.3896, latent MSE loss:0.00033894, KL loss:0.00078914\n",
      "Pretrain epoch [17/367], ZINB loss:0.3891, NB loss:4.5040, latent MSE loss:0.00042489, KL loss:0.00086820\n",
      "Pretrain epoch [18/367], ZINB loss:0.3820, NB loss:4.5327, latent MSE loss:0.00031710, KL loss:0.00085747\n",
      "Pretrain epoch [19/367], ZINB loss:0.3783, NB loss:4.4458, latent MSE loss:0.00036168, KL loss:0.00114182\n",
      "Pretrain epoch [20/367], ZINB loss:0.4078, NB loss:4.5175, latent MSE loss:0.00045501, KL loss:0.00096418\n",
      "Pretrain epoch [21/367], ZINB loss:0.4132, NB loss:4.4837, latent MSE loss:0.00037806, KL loss:0.00088727\n",
      "Pretrain epoch [22/367], ZINB loss:0.3995, NB loss:4.4103, latent MSE loss:0.00038098, KL loss:0.00086863\n",
      "Pretrain epoch [23/367], ZINB loss:0.3849, NB loss:4.4189, latent MSE loss:0.00031883, KL loss:0.00108679\n",
      "Pretrain epoch [24/367], ZINB loss:0.3834, NB loss:4.4692, latent MSE loss:0.00031381, KL loss:0.00097831\n",
      "Pretrain epoch [25/367], ZINB loss:0.4006, NB loss:4.4845, latent MSE loss:0.00039498, KL loss:0.00083406\n",
      "Pretrain epoch [26/367], ZINB loss:0.3960, NB loss:4.5193, latent MSE loss:0.00035324, KL loss:0.00096345\n",
      "Pretrain epoch [27/367], ZINB loss:0.3737, NB loss:4.4700, latent MSE loss:0.00025398, KL loss:0.00003819\n",
      "Pretrain epoch [1/368], ZINB loss:0.3917, NB loss:4.4770, latent MSE loss:0.00043776, KL loss:0.00094675\n",
      "Pretrain epoch [2/368], ZINB loss:0.4051, NB loss:4.4944, latent MSE loss:0.00031934, KL loss:0.00101241\n",
      "Pretrain epoch [3/368], ZINB loss:0.3945, NB loss:4.4419, latent MSE loss:0.00038373, KL loss:0.00084624\n",
      "Pretrain epoch [4/368], ZINB loss:0.3895, NB loss:4.4346, latent MSE loss:0.00033993, KL loss:0.00079250\n",
      "Pretrain epoch [5/368], ZINB loss:0.3926, NB loss:4.5269, latent MSE loss:0.00038924, KL loss:0.00120915\n",
      "Pretrain epoch [6/368], ZINB loss:0.3981, NB loss:4.4978, latent MSE loss:0.00029421, KL loss:0.00073777\n",
      "Pretrain epoch [7/368], ZINB loss:0.3820, NB loss:4.5135, latent MSE loss:0.00025557, KL loss:0.00072255\n",
      "Pretrain epoch [8/368], ZINB loss:0.3918, NB loss:4.4558, latent MSE loss:0.00028811, KL loss:0.00081229\n",
      "Pretrain epoch [9/368], ZINB loss:0.3764, NB loss:4.4677, latent MSE loss:0.00030218, KL loss:0.00086086\n",
      "Pretrain epoch [10/368], ZINB loss:0.3975, NB loss:4.5135, latent MSE loss:0.00035236, KL loss:0.00090532\n",
      "Pretrain epoch [11/368], ZINB loss:0.3833, NB loss:4.4908, latent MSE loss:0.00043262, KL loss:0.00096752\n",
      "Pretrain epoch [12/368], ZINB loss:0.4039, NB loss:4.5313, latent MSE loss:0.00044071, KL loss:0.00141078\n",
      "Pretrain epoch [13/368], ZINB loss:0.4093, NB loss:4.4881, latent MSE loss:0.00034641, KL loss:0.00104245\n",
      "Pretrain epoch [14/368], ZINB loss:0.3892, NB loss:4.4110, latent MSE loss:0.00031060, KL loss:0.00095835\n",
      "Pretrain epoch [15/368], ZINB loss:0.4095, NB loss:4.4858, latent MSE loss:0.00026773, KL loss:0.00089226\n",
      "Pretrain epoch [16/368], ZINB loss:0.3924, NB loss:4.4794, latent MSE loss:0.00024668, KL loss:0.00101506\n",
      "Pretrain epoch [17/368], ZINB loss:0.3961, NB loss:4.4676, latent MSE loss:0.00027848, KL loss:0.00086143\n",
      "Pretrain epoch [18/368], ZINB loss:0.3909, NB loss:4.5087, latent MSE loss:0.00029754, KL loss:0.00086080\n",
      "Pretrain epoch [19/368], ZINB loss:0.3841, NB loss:4.4679, latent MSE loss:0.00027609, KL loss:0.00075754\n",
      "Pretrain epoch [20/368], ZINB loss:0.3983, NB loss:4.4729, latent MSE loss:0.00029990, KL loss:0.00080492\n",
      "Pretrain epoch [21/368], ZINB loss:0.4319, NB loss:4.4476, latent MSE loss:0.00028307, KL loss:0.00109034\n",
      "Pretrain epoch [22/368], ZINB loss:0.3872, NB loss:4.4481, latent MSE loss:0.00021835, KL loss:0.00119290\n",
      "Pretrain epoch [23/368], ZINB loss:0.3905, NB loss:4.4299, latent MSE loss:0.00022679, KL loss:0.00089025\n",
      "Pretrain epoch [24/368], ZINB loss:0.3984, NB loss:4.4988, latent MSE loss:0.00034569, KL loss:0.00136086\n",
      "Pretrain epoch [25/368], ZINB loss:0.3958, NB loss:4.5408, latent MSE loss:0.00026836, KL loss:0.00080807\n",
      "Pretrain epoch [26/368], ZINB loss:0.4124, NB loss:4.4894, latent MSE loss:0.00028403, KL loss:0.00090089\n",
      "Pretrain epoch [27/368], ZINB loss:0.4158, NB loss:4.3256, latent MSE loss:0.00012846, KL loss:0.00007739\n",
      "Pretrain epoch [1/369], ZINB loss:0.3909, NB loss:4.4219, latent MSE loss:0.00031958, KL loss:0.00071236\n",
      "Pretrain epoch [2/369], ZINB loss:0.3961, NB loss:4.4295, latent MSE loss:0.00024920, KL loss:0.00081871\n",
      "Pretrain epoch [3/369], ZINB loss:0.3887, NB loss:4.4737, latent MSE loss:0.00030647, KL loss:0.00076776\n",
      "Pretrain epoch [4/369], ZINB loss:0.3822, NB loss:4.4835, latent MSE loss:0.00023171, KL loss:0.00078644\n",
      "Pretrain epoch [5/369], ZINB loss:0.3833, NB loss:4.5383, latent MSE loss:0.00033144, KL loss:0.00123463\n",
      "Pretrain epoch [6/369], ZINB loss:0.4087, NB loss:4.5140, latent MSE loss:0.00030137, KL loss:0.00108789\n",
      "Pretrain epoch [7/369], ZINB loss:0.4031, NB loss:4.4748, latent MSE loss:0.00035366, KL loss:0.00137609\n",
      "Pretrain epoch [8/369], ZINB loss:0.3797, NB loss:4.4716, latent MSE loss:0.00029045, KL loss:0.00078971\n",
      "Pretrain epoch [9/369], ZINB loss:0.4072, NB loss:4.4254, latent MSE loss:0.00024577, KL loss:0.00092032\n",
      "Pretrain epoch [10/369], ZINB loss:0.4246, NB loss:4.4864, latent MSE loss:0.00020372, KL loss:0.00117786\n",
      "Pretrain epoch [11/369], ZINB loss:0.4084, NB loss:4.4463, latent MSE loss:0.00026948, KL loss:0.00110854\n",
      "Pretrain epoch [12/369], ZINB loss:0.4116, NB loss:4.5367, latent MSE loss:0.00025907, KL loss:0.00117228\n",
      "Pretrain epoch [13/369], ZINB loss:0.3974, NB loss:4.4723, latent MSE loss:0.00033785, KL loss:0.00098643\n",
      "Pretrain epoch [14/369], ZINB loss:0.3933, NB loss:4.4256, latent MSE loss:0.00021929, KL loss:0.00087430\n",
      "Pretrain epoch [15/369], ZINB loss:0.3749, NB loss:4.4681, latent MSE loss:0.00027508, KL loss:0.00090657\n",
      "Pretrain epoch [16/369], ZINB loss:0.4002, NB loss:4.4767, latent MSE loss:0.00026805, KL loss:0.00094170\n",
      "Pretrain epoch [17/369], ZINB loss:0.3933, NB loss:4.4488, latent MSE loss:0.00024939, KL loss:0.00078036\n",
      "Pretrain epoch [18/369], ZINB loss:0.4068, NB loss:4.4758, latent MSE loss:0.00022620, KL loss:0.00086302\n",
      "Pretrain epoch [19/369], ZINB loss:0.3709, NB loss:4.4239, latent MSE loss:0.00015904, KL loss:0.00077417\n",
      "Pretrain epoch [20/369], ZINB loss:0.3829, NB loss:4.4689, latent MSE loss:0.00020920, KL loss:0.00100044\n",
      "Pretrain epoch [21/369], ZINB loss:0.4083, NB loss:4.5476, latent MSE loss:0.00023790, KL loss:0.00137697\n",
      "Pretrain epoch [22/369], ZINB loss:0.3843, NB loss:4.5133, latent MSE loss:0.00017303, KL loss:0.00074747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [23/369], ZINB loss:0.3901, NB loss:4.4628, latent MSE loss:0.00020493, KL loss:0.00077002\n",
      "Pretrain epoch [24/369], ZINB loss:0.3924, NB loss:4.5045, latent MSE loss:0.00026402, KL loss:0.00078873\n",
      "Pretrain epoch [25/369], ZINB loss:0.4158, NB loss:4.4956, latent MSE loss:0.00019841, KL loss:0.00076758\n",
      "Pretrain epoch [26/369], ZINB loss:0.3939, NB loss:4.5843, latent MSE loss:0.00021660, KL loss:0.00085428\n",
      "Pretrain epoch [27/369], ZINB loss:0.2722, NB loss:4.4340, latent MSE loss:0.00005852, KL loss:0.00000080\n",
      "Pretrain epoch [1/370], ZINB loss:0.3840, NB loss:4.4686, latent MSE loss:0.00023906, KL loss:0.00089010\n",
      "Pretrain epoch [2/370], ZINB loss:0.3943, NB loss:4.4793, latent MSE loss:0.00020213, KL loss:0.00064751\n",
      "Pretrain epoch [3/370], ZINB loss:0.3940, NB loss:4.5683, latent MSE loss:0.00023821, KL loss:0.00124036\n",
      "Pretrain epoch [4/370], ZINB loss:0.3829, NB loss:4.5013, latent MSE loss:0.00020382, KL loss:0.00074937\n",
      "Pretrain epoch [5/370], ZINB loss:0.3702, NB loss:4.4614, latent MSE loss:0.00020918, KL loss:0.00088898\n",
      "Pretrain epoch [6/370], ZINB loss:0.3960, NB loss:4.4756, latent MSE loss:0.00021894, KL loss:0.00097477\n",
      "Pretrain epoch [7/370], ZINB loss:0.3795, NB loss:4.4276, latent MSE loss:0.00015625, KL loss:0.00071771\n",
      "Pretrain epoch [8/370], ZINB loss:0.3899, NB loss:4.4823, latent MSE loss:0.00015458, KL loss:0.00077893\n",
      "Pretrain epoch [9/370], ZINB loss:0.4009, NB loss:4.4686, latent MSE loss:0.00022117, KL loss:0.00088907\n",
      "Pretrain epoch [10/370], ZINB loss:0.3773, NB loss:4.4982, latent MSE loss:0.00018950, KL loss:0.00077776\n",
      "Pretrain epoch [11/370], ZINB loss:0.4065, NB loss:4.4940, latent MSE loss:0.00025928, KL loss:0.00125994\n",
      "Pretrain epoch [12/370], ZINB loss:0.3945, NB loss:4.4824, latent MSE loss:0.00019588, KL loss:0.00074891\n",
      "Pretrain epoch [13/370], ZINB loss:0.3919, NB loss:4.4636, latent MSE loss:0.00017576, KL loss:0.00074357\n",
      "Pretrain epoch [14/370], ZINB loss:0.4298, NB loss:4.4448, latent MSE loss:0.00026654, KL loss:0.00095861\n",
      "Pretrain epoch [15/370], ZINB loss:0.4148, NB loss:4.4691, latent MSE loss:0.00029054, KL loss:0.00111947\n",
      "Pretrain epoch [16/370], ZINB loss:0.4064, NB loss:4.5005, latent MSE loss:0.00021195, KL loss:0.00079304\n",
      "Pretrain epoch [17/370], ZINB loss:0.3891, NB loss:4.4796, latent MSE loss:0.00022783, KL loss:0.00085498\n",
      "Pretrain epoch [18/370], ZINB loss:0.4134, NB loss:4.4550, latent MSE loss:0.00022685, KL loss:0.00105276\n",
      "Pretrain epoch [19/370], ZINB loss:0.3877, NB loss:4.4505, latent MSE loss:0.00015282, KL loss:0.00077020\n",
      "Pretrain epoch [20/370], ZINB loss:0.4034, NB loss:4.5131, latent MSE loss:0.00023605, KL loss:0.00094449\n",
      "Pretrain epoch [21/370], ZINB loss:0.3931, NB loss:4.4197, latent MSE loss:0.00021759, KL loss:0.00079346\n",
      "Pretrain epoch [22/370], ZINB loss:0.4066, NB loss:4.4522, latent MSE loss:0.00024301, KL loss:0.00081727\n",
      "Pretrain epoch [23/370], ZINB loss:0.4004, NB loss:4.4951, latent MSE loss:0.00022777, KL loss:0.00100023\n",
      "Pretrain epoch [24/370], ZINB loss:0.3891, NB loss:4.4888, latent MSE loss:0.00022676, KL loss:0.00102966\n",
      "Pretrain epoch [25/370], ZINB loss:0.3892, NB loss:4.5026, latent MSE loss:0.00025892, KL loss:0.00101418\n",
      "Pretrain epoch [26/370], ZINB loss:0.3959, NB loss:4.4951, latent MSE loss:0.00021651, KL loss:0.00099053\n",
      "Pretrain epoch [27/370], ZINB loss:0.5360, NB loss:5.0886, latent MSE loss:0.00070570, KL loss:0.00000854\n",
      "Pretrain epoch [1/371], ZINB loss:0.3892, NB loss:4.4232, latent MSE loss:0.00108048, KL loss:0.00071521\n",
      "Pretrain epoch [2/371], ZINB loss:0.4211, NB loss:4.5140, latent MSE loss:0.00078611, KL loss:0.00138740\n",
      "Pretrain epoch [3/371], ZINB loss:0.3959, NB loss:4.4735, latent MSE loss:0.00099537, KL loss:0.00096077\n",
      "Pretrain epoch [4/371], ZINB loss:0.3862, NB loss:4.4649, latent MSE loss:0.00080824, KL loss:0.00081642\n",
      "Pretrain epoch [5/371], ZINB loss:0.3830, NB loss:4.4640, latent MSE loss:0.00079972, KL loss:0.00080942\n",
      "Pretrain epoch [6/371], ZINB loss:0.4033, NB loss:4.4243, latent MSE loss:0.00099645, KL loss:0.00083328\n",
      "Pretrain epoch [7/371], ZINB loss:0.3867, NB loss:4.4969, latent MSE loss:0.00092127, KL loss:0.00118517\n",
      "Pretrain epoch [8/371], ZINB loss:0.4167, NB loss:4.5280, latent MSE loss:0.00106098, KL loss:0.00154766\n",
      "Pretrain epoch [9/371], ZINB loss:0.4071, NB loss:4.4396, latent MSE loss:0.00079414, KL loss:0.00110416\n",
      "Pretrain epoch [10/371], ZINB loss:0.3992, NB loss:4.4400, latent MSE loss:0.00079642, KL loss:0.00124154\n",
      "Pretrain epoch [11/371], ZINB loss:0.4001, NB loss:4.4791, latent MSE loss:0.00071775, KL loss:0.00104730\n",
      "Pretrain epoch [12/371], ZINB loss:0.3954, NB loss:4.5039, latent MSE loss:0.00079433, KL loss:0.00079827\n",
      "Pretrain epoch [13/371], ZINB loss:0.3927, NB loss:4.4966, latent MSE loss:0.00073146, KL loss:0.00081350\n",
      "Pretrain epoch [14/371], ZINB loss:0.4259, NB loss:4.4398, latent MSE loss:0.00080941, KL loss:0.00096893\n",
      "Pretrain epoch [15/371], ZINB loss:0.3872, NB loss:4.4501, latent MSE loss:0.00068152, KL loss:0.00107172\n",
      "Pretrain epoch [16/371], ZINB loss:0.3727, NB loss:4.4684, latent MSE loss:0.00045456, KL loss:0.00085463\n",
      "Pretrain epoch [17/371], ZINB loss:0.4113, NB loss:4.4978, latent MSE loss:0.00057983, KL loss:0.00100826\n",
      "Pretrain epoch [18/371], ZINB loss:0.3747, NB loss:4.5005, latent MSE loss:0.00044005, KL loss:0.00074308\n",
      "Pretrain epoch [19/371], ZINB loss:0.3874, NB loss:4.5395, latent MSE loss:0.00045927, KL loss:0.00093053\n",
      "Pretrain epoch [20/371], ZINB loss:0.4026, NB loss:4.4972, latent MSE loss:0.00047714, KL loss:0.00086307\n",
      "Pretrain epoch [21/371], ZINB loss:0.4016, NB loss:4.4538, latent MSE loss:0.00043835, KL loss:0.00073722\n",
      "Pretrain epoch [22/371], ZINB loss:0.4060, NB loss:4.4755, latent MSE loss:0.00043936, KL loss:0.00087929\n",
      "Pretrain epoch [23/371], ZINB loss:0.4020, NB loss:4.5159, latent MSE loss:0.00036395, KL loss:0.00083157\n",
      "Pretrain epoch [24/371], ZINB loss:0.3870, NB loss:4.5077, latent MSE loss:0.00037335, KL loss:0.00083608\n",
      "Pretrain epoch [25/371], ZINB loss:0.4006, NB loss:4.4784, latent MSE loss:0.00040179, KL loss:0.00072783\n",
      "Pretrain epoch [26/371], ZINB loss:0.3891, NB loss:4.4831, latent MSE loss:0.00035313, KL loss:0.00093078\n",
      "Pretrain epoch [27/371], ZINB loss:0.3641, NB loss:4.2776, latent MSE loss:0.00027071, KL loss:0.00006303\n",
      "Pretrain epoch [1/372], ZINB loss:0.3864, NB loss:4.5284, latent MSE loss:0.00042292, KL loss:0.00082382\n",
      "Pretrain epoch [2/372], ZINB loss:0.4073, NB loss:4.4848, latent MSE loss:0.00044106, KL loss:0.00100362\n",
      "Pretrain epoch [3/372], ZINB loss:0.4034, NB loss:4.4811, latent MSE loss:0.00044759, KL loss:0.00140658\n",
      "Pretrain epoch [4/372], ZINB loss:0.3929, NB loss:4.4503, latent MSE loss:0.00034128, KL loss:0.00102902\n",
      "Pretrain epoch [5/372], ZINB loss:0.4197, NB loss:4.4838, latent MSE loss:0.00037172, KL loss:0.00115492\n",
      "Pretrain epoch [6/372], ZINB loss:0.3946, NB loss:4.4686, latent MSE loss:0.00035098, KL loss:0.00081379\n",
      "Pretrain epoch [7/372], ZINB loss:0.3965, NB loss:4.4807, latent MSE loss:0.00040155, KL loss:0.00082379\n",
      "Pretrain epoch [8/372], ZINB loss:0.3921, NB loss:4.4436, latent MSE loss:0.00040000, KL loss:0.00083156\n",
      "Pretrain epoch [9/372], ZINB loss:0.3801, NB loss:4.4383, latent MSE loss:0.00031345, KL loss:0.00083789\n",
      "Pretrain epoch [10/372], ZINB loss:0.4036, NB loss:4.4914, latent MSE loss:0.00024118, KL loss:0.00075714\n",
      "Pretrain epoch [11/372], ZINB loss:0.3924, NB loss:4.4140, latent MSE loss:0.00034985, KL loss:0.00128618\n",
      "Pretrain epoch [12/372], ZINB loss:0.3927, NB loss:4.5162, latent MSE loss:0.00027071, KL loss:0.00081044\n",
      "Pretrain epoch [13/372], ZINB loss:0.4047, NB loss:4.4953, latent MSE loss:0.00029342, KL loss:0.00107602\n",
      "Pretrain epoch [14/372], ZINB loss:0.3849, NB loss:4.4922, latent MSE loss:0.00025505, KL loss:0.00103488\n",
      "Pretrain epoch [15/372], ZINB loss:0.3919, NB loss:4.4382, latent MSE loss:0.00029427, KL loss:0.00107622\n",
      "Pretrain epoch [16/372], ZINB loss:0.4060, NB loss:4.5215, latent MSE loss:0.00027733, KL loss:0.00082113\n",
      "Pretrain epoch [17/372], ZINB loss:0.3758, NB loss:4.4953, latent MSE loss:0.00023821, KL loss:0.00075000\n",
      "Pretrain epoch [18/372], ZINB loss:0.3872, NB loss:4.4741, latent MSE loss:0.00025806, KL loss:0.00070160\n",
      "Pretrain epoch [19/372], ZINB loss:0.3932, NB loss:4.4285, latent MSE loss:0.00025090, KL loss:0.00074294\n",
      "Pretrain epoch [20/372], ZINB loss:0.3947, NB loss:4.5179, latent MSE loss:0.00023493, KL loss:0.00104093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [21/372], ZINB loss:0.3976, NB loss:4.5123, latent MSE loss:0.00020105, KL loss:0.00078538\n",
      "Pretrain epoch [22/372], ZINB loss:0.4105, NB loss:4.4924, latent MSE loss:0.00022590, KL loss:0.00076959\n",
      "Pretrain epoch [23/372], ZINB loss:0.4088, NB loss:4.3963, latent MSE loss:0.00025888, KL loss:0.00083499\n",
      "Pretrain epoch [24/372], ZINB loss:0.4017, NB loss:4.4762, latent MSE loss:0.00021873, KL loss:0.00074968\n",
      "Pretrain epoch [25/372], ZINB loss:0.3785, NB loss:4.4645, latent MSE loss:0.00017705, KL loss:0.00077617\n",
      "Pretrain epoch [26/372], ZINB loss:0.3892, NB loss:4.5127, latent MSE loss:0.00022087, KL loss:0.00086345\n",
      "Pretrain epoch [27/372], ZINB loss:0.3433, NB loss:4.6588, latent MSE loss:0.00013185, KL loss:0.00004630\n",
      "Pretrain epoch [1/373], ZINB loss:0.3914, NB loss:4.4725, latent MSE loss:0.00027859, KL loss:0.00079608\n",
      "Pretrain epoch [2/373], ZINB loss:0.3916, NB loss:4.4352, latent MSE loss:0.00016503, KL loss:0.00066925\n",
      "Pretrain epoch [3/373], ZINB loss:0.4168, NB loss:4.4603, latent MSE loss:0.00035649, KL loss:0.00101302\n",
      "Pretrain epoch [4/373], ZINB loss:0.4007, NB loss:4.5289, latent MSE loss:0.00027328, KL loss:0.00080273\n",
      "Pretrain epoch [5/373], ZINB loss:0.4044, NB loss:4.5377, latent MSE loss:0.00021957, KL loss:0.00087766\n",
      "Pretrain epoch [6/373], ZINB loss:0.3784, NB loss:4.4938, latent MSE loss:0.00018157, KL loss:0.00073851\n",
      "Pretrain epoch [7/373], ZINB loss:0.4013, NB loss:4.5129, latent MSE loss:0.00022219, KL loss:0.00115959\n",
      "Pretrain epoch [8/373], ZINB loss:0.3866, NB loss:4.4687, latent MSE loss:0.00020897, KL loss:0.00077342\n",
      "Pretrain epoch [9/373], ZINB loss:0.3739, NB loss:4.4653, latent MSE loss:0.00021694, KL loss:0.00069818\n",
      "Pretrain epoch [10/373], ZINB loss:0.4092, NB loss:4.4909, latent MSE loss:0.00025717, KL loss:0.00087169\n",
      "Pretrain epoch [11/373], ZINB loss:0.3966, NB loss:4.5058, latent MSE loss:0.00021856, KL loss:0.00128679\n",
      "Pretrain epoch [12/373], ZINB loss:0.3880, NB loss:4.4749, latent MSE loss:0.00021141, KL loss:0.00074197\n",
      "Pretrain epoch [13/373], ZINB loss:0.3910, NB loss:4.4206, latent MSE loss:0.00014534, KL loss:0.00078015\n",
      "Pretrain epoch [14/373], ZINB loss:0.3908, NB loss:4.4599, latent MSE loss:0.00020344, KL loss:0.00072656\n",
      "Pretrain epoch [15/373], ZINB loss:0.4104, NB loss:4.4920, latent MSE loss:0.00023315, KL loss:0.00100062\n",
      "Pretrain epoch [16/373], ZINB loss:0.3818, NB loss:4.5242, latent MSE loss:0.00017802, KL loss:0.00077675\n",
      "Pretrain epoch [17/373], ZINB loss:0.3817, NB loss:4.4714, latent MSE loss:0.00015736, KL loss:0.00078417\n",
      "Pretrain epoch [18/373], ZINB loss:0.3834, NB loss:4.4795, latent MSE loss:0.00016135, KL loss:0.00085106\n",
      "Pretrain epoch [19/373], ZINB loss:0.3927, NB loss:4.4465, latent MSE loss:0.00015154, KL loss:0.00087826\n",
      "Pretrain epoch [20/373], ZINB loss:0.4046, NB loss:4.4342, latent MSE loss:0.00019842, KL loss:0.00066936\n",
      "Pretrain epoch [21/373], ZINB loss:0.3793, NB loss:4.4370, latent MSE loss:0.00022640, KL loss:0.00068755\n",
      "Pretrain epoch [22/373], ZINB loss:0.3973, NB loss:4.4518, latent MSE loss:0.00029408, KL loss:0.00088481\n",
      "Pretrain epoch [23/373], ZINB loss:0.3958, NB loss:4.4852, latent MSE loss:0.00036156, KL loss:0.00103911\n",
      "Pretrain epoch [24/373], ZINB loss:0.4070, NB loss:4.4986, latent MSE loss:0.00046661, KL loss:0.00101651\n",
      "Pretrain epoch [25/373], ZINB loss:0.4112, NB loss:4.4736, latent MSE loss:0.00067665, KL loss:0.00120282\n",
      "Pretrain epoch [26/373], ZINB loss:0.4115, NB loss:4.5049, latent MSE loss:0.00079634, KL loss:0.00087679\n",
      "Pretrain epoch [27/373], ZINB loss:0.4162, NB loss:4.9102, latent MSE loss:0.00117528, KL loss:0.00006859\n",
      "Pretrain epoch [1/374], ZINB loss:0.3878, NB loss:4.4473, latent MSE loss:0.00673603, KL loss:0.00081670\n",
      "Pretrain epoch [2/374], ZINB loss:0.3883, NB loss:4.4029, latent MSE loss:0.00745846, KL loss:0.00070002\n",
      "Pretrain epoch [3/374], ZINB loss:0.4063, NB loss:4.5091, latent MSE loss:0.00211507, KL loss:0.00104704\n",
      "Pretrain epoch [4/374], ZINB loss:0.3964, NB loss:4.5230, latent MSE loss:0.00289003, KL loss:0.00079865\n",
      "Pretrain epoch [5/374], ZINB loss:0.4089, NB loss:4.5648, latent MSE loss:0.00417026, KL loss:0.00138434\n",
      "Pretrain epoch [6/374], ZINB loss:0.3916, NB loss:4.5056, latent MSE loss:0.00091655, KL loss:0.00086761\n",
      "Pretrain epoch [7/374], ZINB loss:0.4020, NB loss:4.4213, latent MSE loss:0.00314638, KL loss:0.00108093\n",
      "Pretrain epoch [8/374], ZINB loss:0.4004, NB loss:4.4346, latent MSE loss:0.00139506, KL loss:0.00091960\n",
      "Pretrain epoch [9/374], ZINB loss:0.4092, NB loss:4.4512, latent MSE loss:0.00205599, KL loss:0.00112671\n",
      "Pretrain epoch [10/374], ZINB loss:0.3840, NB loss:4.4628, latent MSE loss:0.00101905, KL loss:0.00099535\n",
      "Pretrain epoch [11/374], ZINB loss:0.3882, NB loss:4.5084, latent MSE loss:0.00159415, KL loss:0.00086222\n",
      "Pretrain epoch [12/374], ZINB loss:0.3759, NB loss:4.4484, latent MSE loss:0.00092669, KL loss:0.00090347\n",
      "Pretrain epoch [13/374], ZINB loss:0.3914, NB loss:4.3788, latent MSE loss:0.00136497, KL loss:0.00104155\n",
      "Pretrain epoch [14/374], ZINB loss:0.3861, NB loss:4.5247, latent MSE loss:0.00090282, KL loss:0.00095596\n",
      "Pretrain epoch [15/374], ZINB loss:0.3906, NB loss:4.4328, latent MSE loss:0.00115273, KL loss:0.00101138\n",
      "Pretrain epoch [16/374], ZINB loss:0.3875, NB loss:4.4988, latent MSE loss:0.00085084, KL loss:0.00093542\n",
      "Pretrain epoch [17/374], ZINB loss:0.3985, NB loss:4.4759, latent MSE loss:0.00090439, KL loss:0.00085045\n",
      "Pretrain epoch [18/374], ZINB loss:0.3897, NB loss:4.4690, latent MSE loss:0.00095695, KL loss:0.00107388\n",
      "Pretrain epoch [19/374], ZINB loss:0.4002, NB loss:4.4528, latent MSE loss:0.00076092, KL loss:0.00088156\n",
      "Pretrain epoch [20/374], ZINB loss:0.3990, NB loss:4.4971, latent MSE loss:0.00088736, KL loss:0.00104697\n",
      "Pretrain epoch [21/374], ZINB loss:0.3990, NB loss:4.4714, latent MSE loss:0.00063889, KL loss:0.00099621\n",
      "Pretrain epoch [22/374], ZINB loss:0.4008, NB loss:4.4989, latent MSE loss:0.00065947, KL loss:0.00086381\n",
      "Pretrain epoch [23/374], ZINB loss:0.4053, NB loss:4.5332, latent MSE loss:0.00063732, KL loss:0.00136589\n",
      "Pretrain epoch [24/374], ZINB loss:0.4023, NB loss:4.4938, latent MSE loss:0.00063667, KL loss:0.00097372\n",
      "Pretrain epoch [25/374], ZINB loss:0.3819, NB loss:4.4746, latent MSE loss:0.00043305, KL loss:0.00084940\n",
      "Pretrain epoch [26/374], ZINB loss:0.4180, NB loss:4.5115, latent MSE loss:0.00044992, KL loss:0.00102102\n",
      "Pretrain epoch [27/374], ZINB loss:0.2970, NB loss:4.3081, latent MSE loss:0.00045436, KL loss:0.00004177\n",
      "Pretrain epoch [1/375], ZINB loss:0.4077, NB loss:4.4655, latent MSE loss:0.00067826, KL loss:0.00086945\n",
      "Pretrain epoch [2/375], ZINB loss:0.3859, NB loss:4.4750, latent MSE loss:0.00045126, KL loss:0.00084003\n",
      "Pretrain epoch [3/375], ZINB loss:0.3849, NB loss:4.5043, latent MSE loss:0.00053793, KL loss:0.00092378\n",
      "Pretrain epoch [4/375], ZINB loss:0.4035, NB loss:4.5493, latent MSE loss:0.00046844, KL loss:0.00095835\n",
      "Pretrain epoch [5/375], ZINB loss:0.4016, NB loss:4.4594, latent MSE loss:0.00057085, KL loss:0.00092868\n",
      "Pretrain epoch [6/375], ZINB loss:0.3856, NB loss:4.4014, latent MSE loss:0.00043097, KL loss:0.00091746\n",
      "Pretrain epoch [7/375], ZINB loss:0.4031, NB loss:4.4740, latent MSE loss:0.00055408, KL loss:0.00113966\n",
      "Pretrain epoch [8/375], ZINB loss:0.3879, NB loss:4.4375, latent MSE loss:0.00043117, KL loss:0.00091102\n",
      "Pretrain epoch [9/375], ZINB loss:0.4020, NB loss:4.5012, latent MSE loss:0.00040082, KL loss:0.00105892\n",
      "Pretrain epoch [10/375], ZINB loss:0.3938, NB loss:4.4328, latent MSE loss:0.00038201, KL loss:0.00121785\n",
      "Pretrain epoch [11/375], ZINB loss:0.4038, NB loss:4.4781, latent MSE loss:0.00042813, KL loss:0.00103135\n",
      "Pretrain epoch [12/375], ZINB loss:0.3897, NB loss:4.4959, latent MSE loss:0.00048394, KL loss:0.00106167\n",
      "Pretrain epoch [13/375], ZINB loss:0.4020, NB loss:4.5151, latent MSE loss:0.00052933, KL loss:0.00116607\n",
      "Pretrain epoch [14/375], ZINB loss:0.4088, NB loss:4.4633, latent MSE loss:0.00049285, KL loss:0.00109803\n",
      "Pretrain epoch [15/375], ZINB loss:0.3947, NB loss:4.5906, latent MSE loss:0.00038093, KL loss:0.00118112\n",
      "Pretrain epoch [16/375], ZINB loss:0.3877, NB loss:4.4614, latent MSE loss:0.00037122, KL loss:0.00114718\n",
      "Pretrain epoch [17/375], ZINB loss:0.4088, NB loss:4.4487, latent MSE loss:0.00031827, KL loss:0.00095058\n",
      "Pretrain epoch [18/375], ZINB loss:0.3829, NB loss:4.3918, latent MSE loss:0.00032232, KL loss:0.00093043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [19/375], ZINB loss:0.4005, NB loss:4.5121, latent MSE loss:0.00030765, KL loss:0.00085265\n",
      "Pretrain epoch [20/375], ZINB loss:0.3900, NB loss:4.4523, latent MSE loss:0.00038189, KL loss:0.00098982\n",
      "Pretrain epoch [21/375], ZINB loss:0.3980, NB loss:4.5348, latent MSE loss:0.00035324, KL loss:0.00109403\n",
      "Pretrain epoch [22/375], ZINB loss:0.3860, NB loss:4.4713, latent MSE loss:0.00034459, KL loss:0.00084109\n",
      "Pretrain epoch [23/375], ZINB loss:0.3950, NB loss:4.4768, latent MSE loss:0.00027408, KL loss:0.00080046\n",
      "Pretrain epoch [24/375], ZINB loss:0.4087, NB loss:4.4764, latent MSE loss:0.00028447, KL loss:0.00086293\n",
      "Pretrain epoch [25/375], ZINB loss:0.3818, NB loss:4.4304, latent MSE loss:0.00028485, KL loss:0.00084988\n",
      "Pretrain epoch [26/375], ZINB loss:0.4063, NB loss:4.4550, latent MSE loss:0.00033385, KL loss:0.00117560\n",
      "Pretrain epoch [27/375], ZINB loss:0.4107, NB loss:4.5882, latent MSE loss:0.00102192, KL loss:0.00005093\n",
      "Pretrain epoch [1/376], ZINB loss:0.3874, NB loss:4.4424, latent MSE loss:0.00108628, KL loss:0.00072020\n",
      "Pretrain epoch [2/376], ZINB loss:0.4084, NB loss:4.4763, latent MSE loss:0.00057381, KL loss:0.00097958\n",
      "Pretrain epoch [3/376], ZINB loss:0.3872, NB loss:4.5354, latent MSE loss:0.00098244, KL loss:0.00103179\n",
      "Pretrain epoch [4/376], ZINB loss:0.3987, NB loss:4.4807, latent MSE loss:0.00072047, KL loss:0.00118820\n",
      "Pretrain epoch [5/376], ZINB loss:0.4013, NB loss:4.4572, latent MSE loss:0.00187681, KL loss:0.00089187\n",
      "Pretrain epoch [6/376], ZINB loss:0.4060, NB loss:4.4733, latent MSE loss:0.00035751, KL loss:0.00111259\n",
      "Pretrain epoch [7/376], ZINB loss:0.3751, NB loss:4.4571, latent MSE loss:0.00041392, KL loss:0.00080233\n",
      "Pretrain epoch [8/376], ZINB loss:0.3935, NB loss:4.4599, latent MSE loss:0.00056225, KL loss:0.00085967\n",
      "Pretrain epoch [9/376], ZINB loss:0.3844, NB loss:4.5083, latent MSE loss:0.00119972, KL loss:0.00089775\n",
      "Pretrain epoch [10/376], ZINB loss:0.3872, NB loss:4.4565, latent MSE loss:0.00047103, KL loss:0.00076201\n",
      "Pretrain epoch [11/376], ZINB loss:0.3935, NB loss:4.4175, latent MSE loss:0.00053656, KL loss:0.00115196\n",
      "Pretrain epoch [12/376], ZINB loss:0.4035, NB loss:4.4698, latent MSE loss:0.00077206, KL loss:0.00089486\n",
      "Pretrain epoch [13/376], ZINB loss:0.3948, NB loss:4.4188, latent MSE loss:0.00096034, KL loss:0.00102517\n",
      "Pretrain epoch [14/376], ZINB loss:0.3881, NB loss:4.4735, latent MSE loss:0.00047853, KL loss:0.00077396\n",
      "Pretrain epoch [15/376], ZINB loss:0.3994, NB loss:4.5294, latent MSE loss:0.00044909, KL loss:0.00100555\n",
      "Pretrain epoch [16/376], ZINB loss:0.3683, NB loss:4.4995, latent MSE loss:0.00060979, KL loss:0.00087735\n",
      "Pretrain epoch [17/376], ZINB loss:0.4178, NB loss:4.5247, latent MSE loss:0.00048373, KL loss:0.00147984\n",
      "Pretrain epoch [18/376], ZINB loss:0.3901, NB loss:4.4412, latent MSE loss:0.00041505, KL loss:0.00072311\n",
      "Pretrain epoch [19/376], ZINB loss:0.3928, NB loss:4.4795, latent MSE loss:0.00047147, KL loss:0.00110762\n",
      "Pretrain epoch [20/376], ZINB loss:0.3864, NB loss:4.4718, latent MSE loss:0.00034481, KL loss:0.00076265\n",
      "Pretrain epoch [21/376], ZINB loss:0.4055, NB loss:4.4193, latent MSE loss:0.00035229, KL loss:0.00108405\n",
      "Pretrain epoch [22/376], ZINB loss:0.4019, NB loss:4.4818, latent MSE loss:0.00033389, KL loss:0.00078367\n",
      "Pretrain epoch [23/376], ZINB loss:0.4121, NB loss:4.4685, latent MSE loss:0.00043758, KL loss:0.00108154\n",
      "Pretrain epoch [24/376], ZINB loss:0.4260, NB loss:4.4994, latent MSE loss:0.00038818, KL loss:0.00110839\n",
      "Pretrain epoch [25/376], ZINB loss:0.3939, NB loss:4.5733, latent MSE loss:0.00033732, KL loss:0.00083223\n",
      "Pretrain epoch [26/376], ZINB loss:0.3907, NB loss:4.4424, latent MSE loss:0.00030073, KL loss:0.00102866\n",
      "Pretrain epoch [27/376], ZINB loss:0.3690, NB loss:4.1607, latent MSE loss:0.00042601, KL loss:0.00004154\n",
      "Pretrain epoch [1/377], ZINB loss:0.3915, NB loss:4.4494, latent MSE loss:0.00101695, KL loss:0.00117345\n",
      "Pretrain epoch [2/377], ZINB loss:0.4058, NB loss:4.4800, latent MSE loss:0.00069335, KL loss:0.00078118\n",
      "Pretrain epoch [3/377], ZINB loss:0.3916, NB loss:4.4508, latent MSE loss:0.00103819, KL loss:0.00105371\n",
      "Pretrain epoch [4/377], ZINB loss:0.4149, NB loss:4.4667, latent MSE loss:0.00086698, KL loss:0.00090333\n",
      "Pretrain epoch [5/377], ZINB loss:0.3990, NB loss:4.4653, latent MSE loss:0.00084762, KL loss:0.00077744\n",
      "Pretrain epoch [6/377], ZINB loss:0.3979, NB loss:4.4479, latent MSE loss:0.00059287, KL loss:0.00081783\n",
      "Pretrain epoch [7/377], ZINB loss:0.3970, NB loss:4.5013, latent MSE loss:0.00046635, KL loss:0.00086786\n",
      "Pretrain epoch [8/377], ZINB loss:0.4101, NB loss:4.4530, latent MSE loss:0.00089670, KL loss:0.00121981\n",
      "Pretrain epoch [9/377], ZINB loss:0.3982, NB loss:4.4990, latent MSE loss:0.00048478, KL loss:0.00115146\n",
      "Pretrain epoch [10/377], ZINB loss:0.4184, NB loss:4.4687, latent MSE loss:0.00053369, KL loss:0.00085764\n",
      "Pretrain epoch [11/377], ZINB loss:0.3898, NB loss:4.4264, latent MSE loss:0.00045207, KL loss:0.00087517\n",
      "Pretrain epoch [12/377], ZINB loss:0.3908, NB loss:4.4598, latent MSE loss:0.00042897, KL loss:0.00093717\n",
      "Pretrain epoch [13/377], ZINB loss:0.3742, NB loss:4.4689, latent MSE loss:0.00031356, KL loss:0.00074080\n",
      "Pretrain epoch [14/377], ZINB loss:0.3688, NB loss:4.5411, latent MSE loss:0.00039315, KL loss:0.00106742\n",
      "Pretrain epoch [15/377], ZINB loss:0.3862, NB loss:4.4871, latent MSE loss:0.00041342, KL loss:0.00107277\n",
      "Pretrain epoch [16/377], ZINB loss:0.3858, NB loss:4.4304, latent MSE loss:0.00030313, KL loss:0.00089937\n",
      "Pretrain epoch [17/377], ZINB loss:0.3823, NB loss:4.4929, latent MSE loss:0.00034876, KL loss:0.00080349\n",
      "Pretrain epoch [18/377], ZINB loss:0.4101, NB loss:4.4709, latent MSE loss:0.00029860, KL loss:0.00087375\n",
      "Pretrain epoch [19/377], ZINB loss:0.3882, NB loss:4.4581, latent MSE loss:0.00030340, KL loss:0.00125223\n",
      "Pretrain epoch [20/377], ZINB loss:0.4149, NB loss:4.4974, latent MSE loss:0.00037512, KL loss:0.00111725\n",
      "Pretrain epoch [21/377], ZINB loss:0.3917, NB loss:4.4815, latent MSE loss:0.00031785, KL loss:0.00086093\n",
      "Pretrain epoch [22/377], ZINB loss:0.3995, NB loss:4.4978, latent MSE loss:0.00031905, KL loss:0.00084438\n",
      "Pretrain epoch [23/377], ZINB loss:0.4040, NB loss:4.4888, latent MSE loss:0.00029593, KL loss:0.00111532\n",
      "Pretrain epoch [24/377], ZINB loss:0.3939, NB loss:4.4257, latent MSE loss:0.00024391, KL loss:0.00075601\n",
      "Pretrain epoch [25/377], ZINB loss:0.3974, NB loss:4.5176, latent MSE loss:0.00028930, KL loss:0.00089440\n",
      "Pretrain epoch [26/377], ZINB loss:0.3837, NB loss:4.4965, latent MSE loss:0.00027870, KL loss:0.00080848\n",
      "Pretrain epoch [27/377], ZINB loss:0.4412, NB loss:4.3073, latent MSE loss:0.00052030, KL loss:0.00000160\n",
      "Pretrain epoch [1/378], ZINB loss:0.3966, NB loss:4.4990, latent MSE loss:0.00090323, KL loss:0.00078650\n",
      "Pretrain epoch [2/378], ZINB loss:0.3930, NB loss:4.4449, latent MSE loss:0.00108315, KL loss:0.00072460\n",
      "Pretrain epoch [3/378], ZINB loss:0.3955, NB loss:4.4826, latent MSE loss:0.00064171, KL loss:0.00085316\n",
      "Pretrain epoch [4/378], ZINB loss:0.4152, NB loss:4.4423, latent MSE loss:0.00086794, KL loss:0.00083743\n",
      "Pretrain epoch [5/378], ZINB loss:0.3910, NB loss:4.5057, latent MSE loss:0.00102105, KL loss:0.00091694\n",
      "Pretrain epoch [6/378], ZINB loss:0.3988, NB loss:4.4617, latent MSE loss:0.00068660, KL loss:0.00079399\n",
      "Pretrain epoch [7/378], ZINB loss:0.3899, NB loss:4.4523, latent MSE loss:0.00077486, KL loss:0.00096189\n",
      "Pretrain epoch [8/378], ZINB loss:0.3975, NB loss:4.4634, latent MSE loss:0.00084287, KL loss:0.00083734\n",
      "Pretrain epoch [9/378], ZINB loss:0.4089, NB loss:4.5057, latent MSE loss:0.00078322, KL loss:0.00136609\n",
      "Pretrain epoch [10/378], ZINB loss:0.3855, NB loss:4.4399, latent MSE loss:0.00071729, KL loss:0.00073910\n",
      "Pretrain epoch [11/378], ZINB loss:0.3946, NB loss:4.4592, latent MSE loss:0.00053166, KL loss:0.00095369\n",
      "Pretrain epoch [12/378], ZINB loss:0.3868, NB loss:4.4946, latent MSE loss:0.00078900, KL loss:0.00087219\n",
      "Pretrain epoch [13/378], ZINB loss:0.4059, NB loss:4.4339, latent MSE loss:0.00069489, KL loss:0.00103160\n",
      "Pretrain epoch [14/378], ZINB loss:0.3753, NB loss:4.4512, latent MSE loss:0.00057829, KL loss:0.00112072\n",
      "Pretrain epoch [15/378], ZINB loss:0.3913, NB loss:4.5073, latent MSE loss:0.00041921, KL loss:0.00081903\n",
      "Pretrain epoch [16/378], ZINB loss:0.3792, NB loss:4.4367, latent MSE loss:0.00045112, KL loss:0.00072887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [17/378], ZINB loss:0.3836, NB loss:4.4916, latent MSE loss:0.00053762, KL loss:0.00076555\n",
      "Pretrain epoch [18/378], ZINB loss:0.3843, NB loss:4.5077, latent MSE loss:0.00049272, KL loss:0.00077626\n",
      "Pretrain epoch [19/378], ZINB loss:0.4029, NB loss:4.4825, latent MSE loss:0.00042660, KL loss:0.00085513\n",
      "Pretrain epoch [20/378], ZINB loss:0.4079, NB loss:4.4533, latent MSE loss:0.00040057, KL loss:0.00089921\n",
      "Pretrain epoch [21/378], ZINB loss:0.4009, NB loss:4.4570, latent MSE loss:0.00041353, KL loss:0.00085048\n",
      "Pretrain epoch [22/378], ZINB loss:0.3911, NB loss:4.4576, latent MSE loss:0.00043804, KL loss:0.00120050\n",
      "Pretrain epoch [23/378], ZINB loss:0.4068, NB loss:4.4423, latent MSE loss:0.00042348, KL loss:0.00119940\n",
      "Pretrain epoch [24/378], ZINB loss:0.3921, NB loss:4.4712, latent MSE loss:0.00033266, KL loss:0.00103816\n",
      "Pretrain epoch [25/378], ZINB loss:0.4053, NB loss:4.5579, latent MSE loss:0.00035538, KL loss:0.00101194\n",
      "Pretrain epoch [26/378], ZINB loss:0.4108, NB loss:4.5154, latent MSE loss:0.00034705, KL loss:0.00093845\n",
      "Pretrain epoch [27/378], ZINB loss:0.3207, NB loss:4.3129, latent MSE loss:0.00024181, KL loss:0.00004156\n",
      "Pretrain epoch [1/379], ZINB loss:0.4164, NB loss:4.4202, latent MSE loss:0.00041391, KL loss:0.00108896\n",
      "Pretrain epoch [2/379], ZINB loss:0.3779, NB loss:4.4655, latent MSE loss:0.00035328, KL loss:0.00082899\n",
      "Pretrain epoch [3/379], ZINB loss:0.3768, NB loss:4.4229, latent MSE loss:0.00032163, KL loss:0.00075562\n",
      "Pretrain epoch [4/379], ZINB loss:0.4089, NB loss:4.4530, latent MSE loss:0.00036154, KL loss:0.00117094\n",
      "Pretrain epoch [5/379], ZINB loss:0.4018, NB loss:4.5262, latent MSE loss:0.00035298, KL loss:0.00104567\n",
      "Pretrain epoch [6/379], ZINB loss:0.3963, NB loss:4.4956, latent MSE loss:0.00037578, KL loss:0.00122653\n",
      "Pretrain epoch [7/379], ZINB loss:0.3811, NB loss:4.4509, latent MSE loss:0.00036264, KL loss:0.00094534\n",
      "Pretrain epoch [8/379], ZINB loss:0.3819, NB loss:4.4387, latent MSE loss:0.00032962, KL loss:0.00079327\n",
      "Pretrain epoch [9/379], ZINB loss:0.3895, NB loss:4.4063, latent MSE loss:0.00033880, KL loss:0.00118311\n",
      "Pretrain epoch [10/379], ZINB loss:0.4006, NB loss:4.4750, latent MSE loss:0.00021905, KL loss:0.00099495\n",
      "Pretrain epoch [11/379], ZINB loss:0.4076, NB loss:4.4943, latent MSE loss:0.00031466, KL loss:0.00088115\n",
      "Pretrain epoch [12/379], ZINB loss:0.3931, NB loss:4.5388, latent MSE loss:0.00028812, KL loss:0.00141116\n",
      "Pretrain epoch [13/379], ZINB loss:0.3966, NB loss:4.3962, latent MSE loss:0.00032280, KL loss:0.00068927\n",
      "Pretrain epoch [14/379], ZINB loss:0.3961, NB loss:4.5209, latent MSE loss:0.00028381, KL loss:0.00123380\n",
      "Pretrain epoch [15/379], ZINB loss:0.4075, NB loss:4.4819, latent MSE loss:0.00029273, KL loss:0.00078193\n",
      "Pretrain epoch [16/379], ZINB loss:0.3880, NB loss:4.4828, latent MSE loss:0.00028887, KL loss:0.00073948\n",
      "Pretrain epoch [17/379], ZINB loss:0.4115, NB loss:4.4825, latent MSE loss:0.00025370, KL loss:0.00080630\n",
      "Pretrain epoch [18/379], ZINB loss:0.3895, NB loss:4.4648, latent MSE loss:0.00028525, KL loss:0.00117137\n",
      "Pretrain epoch [19/379], ZINB loss:0.3836, NB loss:4.4341, latent MSE loss:0.00024565, KL loss:0.00072880\n",
      "Pretrain epoch [20/379], ZINB loss:0.4103, NB loss:4.5422, latent MSE loss:0.00025390, KL loss:0.00095816\n",
      "Pretrain epoch [21/379], ZINB loss:0.3897, NB loss:4.5038, latent MSE loss:0.00020110, KL loss:0.00080925\n",
      "Pretrain epoch [22/379], ZINB loss:0.3963, NB loss:4.4437, latent MSE loss:0.00018527, KL loss:0.00073792\n",
      "Pretrain epoch [23/379], ZINB loss:0.3898, NB loss:4.4524, latent MSE loss:0.00020446, KL loss:0.00071904\n",
      "Pretrain epoch [24/379], ZINB loss:0.3966, NB loss:4.4886, latent MSE loss:0.00029586, KL loss:0.00090195\n",
      "Pretrain epoch [25/379], ZINB loss:0.4032, NB loss:4.5006, latent MSE loss:0.00022446, KL loss:0.00079130\n",
      "Pretrain epoch [26/379], ZINB loss:0.3874, NB loss:4.4982, latent MSE loss:0.00018350, KL loss:0.00089956\n",
      "Pretrain epoch [27/379], ZINB loss:0.3156, NB loss:4.5555, latent MSE loss:0.00007411, KL loss:0.00000132\n",
      "Pretrain epoch [1/380], ZINB loss:0.3865, NB loss:4.4705, latent MSE loss:0.00022586, KL loss:0.00107043\n",
      "Pretrain epoch [2/380], ZINB loss:0.3968, NB loss:4.4883, latent MSE loss:0.00021838, KL loss:0.00080181\n",
      "Pretrain epoch [3/380], ZINB loss:0.4141, NB loss:4.4702, latent MSE loss:0.00024884, KL loss:0.00096037\n",
      "Pretrain epoch [4/380], ZINB loss:0.4138, NB loss:4.4831, latent MSE loss:0.00020416, KL loss:0.00088466\n",
      "Pretrain epoch [5/380], ZINB loss:0.3786, NB loss:4.4441, latent MSE loss:0.00015677, KL loss:0.00089384\n",
      "Pretrain epoch [6/380], ZINB loss:0.3897, NB loss:4.4265, latent MSE loss:0.00018216, KL loss:0.00071118\n",
      "Pretrain epoch [7/380], ZINB loss:0.3848, NB loss:4.4539, latent MSE loss:0.00023715, KL loss:0.00094014\n",
      "Pretrain epoch [8/380], ZINB loss:0.3997, NB loss:4.5573, latent MSE loss:0.00020295, KL loss:0.00094839\n",
      "Pretrain epoch [9/380], ZINB loss:0.3956, NB loss:4.4601, latent MSE loss:0.00025552, KL loss:0.00089118\n",
      "Pretrain epoch [10/380], ZINB loss:0.3893, NB loss:4.4263, latent MSE loss:0.00020816, KL loss:0.00102725\n",
      "Pretrain epoch [11/380], ZINB loss:0.3992, NB loss:4.4932, latent MSE loss:0.00024145, KL loss:0.00079744\n",
      "Pretrain epoch [12/380], ZINB loss:0.3933, NB loss:4.5025, latent MSE loss:0.00023593, KL loss:0.00080381\n",
      "Pretrain epoch [13/380], ZINB loss:0.3753, NB loss:4.4889, latent MSE loss:0.00022792, KL loss:0.00086179\n",
      "Pretrain epoch [14/380], ZINB loss:0.4082, NB loss:4.4954, latent MSE loss:0.00021104, KL loss:0.00086897\n",
      "Pretrain epoch [15/380], ZINB loss:0.4031, NB loss:4.4877, latent MSE loss:0.00024251, KL loss:0.00074894\n",
      "Pretrain epoch [16/380], ZINB loss:0.4010, NB loss:4.4554, latent MSE loss:0.00020772, KL loss:0.00086520\n",
      "Pretrain epoch [17/380], ZINB loss:0.3981, NB loss:4.5435, latent MSE loss:0.00023740, KL loss:0.00083379\n",
      "Pretrain epoch [18/380], ZINB loss:0.4003, NB loss:4.4776, latent MSE loss:0.00018905, KL loss:0.00080092\n",
      "Pretrain epoch [19/380], ZINB loss:0.4047, NB loss:4.4419, latent MSE loss:0.00020844, KL loss:0.00099446\n",
      "Pretrain epoch [20/380], ZINB loss:0.3819, NB loss:4.4865, latent MSE loss:0.00016692, KL loss:0.00071722\n",
      "Pretrain epoch [21/380], ZINB loss:0.3934, NB loss:4.4281, latent MSE loss:0.00017151, KL loss:0.00070768\n",
      "Pretrain epoch [22/380], ZINB loss:0.3843, NB loss:4.4881, latent MSE loss:0.00016761, KL loss:0.00075856\n",
      "Pretrain epoch [23/380], ZINB loss:0.4004, NB loss:4.4462, latent MSE loss:0.00019482, KL loss:0.00072707\n",
      "Pretrain epoch [24/380], ZINB loss:0.3892, NB loss:4.4473, latent MSE loss:0.00019194, KL loss:0.00070686\n",
      "Pretrain epoch [25/380], ZINB loss:0.3962, NB loss:4.4063, latent MSE loss:0.00018041, KL loss:0.00087979\n",
      "Pretrain epoch [26/380], ZINB loss:0.3922, NB loss:4.4954, latent MSE loss:0.00019273, KL loss:0.00089397\n",
      "Pretrain epoch [27/380], ZINB loss:0.3537, NB loss:4.3977, latent MSE loss:0.00013934, KL loss:0.00004967\n",
      "Pretrain epoch [1/381], ZINB loss:0.4052, NB loss:4.5136, latent MSE loss:0.00033935, KL loss:0.00097524\n",
      "Pretrain epoch [2/381], ZINB loss:0.4185, NB loss:4.5085, latent MSE loss:0.00035725, KL loss:0.00106697\n",
      "Pretrain epoch [3/381], ZINB loss:0.4101, NB loss:4.4712, latent MSE loss:0.00036016, KL loss:0.00072068\n",
      "Pretrain epoch [4/381], ZINB loss:0.3986, NB loss:4.4381, latent MSE loss:0.00040660, KL loss:0.00091099\n",
      "Pretrain epoch [5/381], ZINB loss:0.3948, NB loss:4.4167, latent MSE loss:0.00029684, KL loss:0.00075206\n",
      "Pretrain epoch [6/381], ZINB loss:0.3931, NB loss:4.5000, latent MSE loss:0.00035355, KL loss:0.00092377\n",
      "Pretrain epoch [7/381], ZINB loss:0.3838, NB loss:4.5199, latent MSE loss:0.00032421, KL loss:0.00117944\n",
      "Pretrain epoch [8/381], ZINB loss:0.4018, NB loss:4.4790, latent MSE loss:0.00036952, KL loss:0.00078875\n",
      "Pretrain epoch [9/381], ZINB loss:0.3997, NB loss:4.4935, latent MSE loss:0.00044411, KL loss:0.00078433\n",
      "Pretrain epoch [10/381], ZINB loss:0.3892, NB loss:4.4848, latent MSE loss:0.00028117, KL loss:0.00107487\n",
      "Pretrain epoch [11/381], ZINB loss:0.3863, NB loss:4.4563, latent MSE loss:0.00037417, KL loss:0.00103572\n",
      "Pretrain epoch [12/381], ZINB loss:0.4004, NB loss:4.5269, latent MSE loss:0.00034977, KL loss:0.00079196\n",
      "Pretrain epoch [13/381], ZINB loss:0.4020, NB loss:4.4506, latent MSE loss:0.00034846, KL loss:0.00097688\n",
      "Pretrain epoch [14/381], ZINB loss:0.3809, NB loss:4.4038, latent MSE loss:0.00030350, KL loss:0.00077996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [15/381], ZINB loss:0.4021, NB loss:4.4414, latent MSE loss:0.00029585, KL loss:0.00088346\n",
      "Pretrain epoch [16/381], ZINB loss:0.3786, NB loss:4.4740, latent MSE loss:0.00023850, KL loss:0.00096393\n",
      "Pretrain epoch [17/381], ZINB loss:0.3870, NB loss:4.4034, latent MSE loss:0.00024980, KL loss:0.00094896\n",
      "Pretrain epoch [18/381], ZINB loss:0.4203, NB loss:4.4144, latent MSE loss:0.00028024, KL loss:0.00084257\n",
      "Pretrain epoch [19/381], ZINB loss:0.4058, NB loss:4.5133, latent MSE loss:0.00031179, KL loss:0.00129113\n",
      "Pretrain epoch [20/381], ZINB loss:0.3750, NB loss:4.4552, latent MSE loss:0.00026439, KL loss:0.00077406\n",
      "Pretrain epoch [21/381], ZINB loss:0.3812, NB loss:4.5108, latent MSE loss:0.00022825, KL loss:0.00080865\n",
      "Pretrain epoch [22/381], ZINB loss:0.3899, NB loss:4.4955, latent MSE loss:0.00033673, KL loss:0.00107830\n",
      "Pretrain epoch [23/381], ZINB loss:0.3919, NB loss:4.5382, latent MSE loss:0.00025032, KL loss:0.00079319\n",
      "Pretrain epoch [24/381], ZINB loss:0.3993, NB loss:4.4238, latent MSE loss:0.00027422, KL loss:0.00079669\n",
      "Pretrain epoch [25/381], ZINB loss:0.3961, NB loss:4.4811, latent MSE loss:0.00023156, KL loss:0.00076405\n",
      "Pretrain epoch [26/381], ZINB loss:0.3820, NB loss:4.4464, latent MSE loss:0.00018951, KL loss:0.00068265\n",
      "Pretrain epoch [27/381], ZINB loss:0.5328, NB loss:4.4299, latent MSE loss:0.00022796, KL loss:0.00006624\n",
      "Pretrain epoch [1/382], ZINB loss:0.3978, NB loss:4.5154, latent MSE loss:0.00041160, KL loss:0.00093231\n",
      "Pretrain epoch [2/382], ZINB loss:0.4083, NB loss:4.5198, latent MSE loss:0.00044047, KL loss:0.00136904\n",
      "Pretrain epoch [3/382], ZINB loss:0.4164, NB loss:4.5375, latent MSE loss:0.00026963, KL loss:0.00087257\n",
      "Pretrain epoch [4/382], ZINB loss:0.3964, NB loss:4.4355, latent MSE loss:0.00038234, KL loss:0.00103549\n",
      "Pretrain epoch [5/382], ZINB loss:0.3838, NB loss:4.4413, latent MSE loss:0.00034848, KL loss:0.00094318\n",
      "Pretrain epoch [6/382], ZINB loss:0.3869, NB loss:4.4232, latent MSE loss:0.00026455, KL loss:0.00071849\n",
      "Pretrain epoch [7/382], ZINB loss:0.3867, NB loss:4.4192, latent MSE loss:0.00025569, KL loss:0.00108229\n",
      "Pretrain epoch [8/382], ZINB loss:0.4041, NB loss:4.4330, latent MSE loss:0.00028775, KL loss:0.00077441\n",
      "Pretrain epoch [9/382], ZINB loss:0.3970, NB loss:4.3731, latent MSE loss:0.00028215, KL loss:0.00071215\n",
      "Pretrain epoch [10/382], ZINB loss:0.3827, NB loss:4.4623, latent MSE loss:0.00027900, KL loss:0.00074218\n",
      "Pretrain epoch [11/382], ZINB loss:0.3938, NB loss:4.5092, latent MSE loss:0.00019934, KL loss:0.00086910\n",
      "Pretrain epoch [12/382], ZINB loss:0.3833, NB loss:4.5142, latent MSE loss:0.00024548, KL loss:0.00073652\n",
      "Pretrain epoch [13/382], ZINB loss:0.3803, NB loss:4.4530, latent MSE loss:0.00017775, KL loss:0.00066637\n",
      "Pretrain epoch [14/382], ZINB loss:0.3952, NB loss:4.4341, latent MSE loss:0.00020375, KL loss:0.00064618\n",
      "Pretrain epoch [15/382], ZINB loss:0.3925, NB loss:4.4547, latent MSE loss:0.00021423, KL loss:0.00081223\n",
      "Pretrain epoch [16/382], ZINB loss:0.3963, NB loss:4.4802, latent MSE loss:0.00019695, KL loss:0.00080372\n",
      "Pretrain epoch [17/382], ZINB loss:0.3814, NB loss:4.4606, latent MSE loss:0.00022589, KL loss:0.00073961\n",
      "Pretrain epoch [18/382], ZINB loss:0.3899, NB loss:4.4640, latent MSE loss:0.00019254, KL loss:0.00074082\n",
      "Pretrain epoch [19/382], ZINB loss:0.3899, NB loss:4.4655, latent MSE loss:0.00020564, KL loss:0.00092665\n",
      "Pretrain epoch [20/382], ZINB loss:0.4104, NB loss:4.5052, latent MSE loss:0.00024015, KL loss:0.00080410\n",
      "Pretrain epoch [21/382], ZINB loss:0.3935, NB loss:4.4870, latent MSE loss:0.00023779, KL loss:0.00095031\n",
      "Pretrain epoch [22/382], ZINB loss:0.3955, NB loss:4.5081, latent MSE loss:0.00021587, KL loss:0.00068059\n",
      "Pretrain epoch [23/382], ZINB loss:0.3979, NB loss:4.4552, latent MSE loss:0.00021021, KL loss:0.00101296\n",
      "Pretrain epoch [24/382], ZINB loss:0.4018, NB loss:4.5540, latent MSE loss:0.00019622, KL loss:0.00099451\n",
      "Pretrain epoch [25/382], ZINB loss:0.4147, NB loss:4.4722, latent MSE loss:0.00022982, KL loss:0.00092540\n",
      "Pretrain epoch [26/382], ZINB loss:0.3928, NB loss:4.4614, latent MSE loss:0.00014809, KL loss:0.00075265\n",
      "Pretrain epoch [27/382], ZINB loss:0.4063, NB loss:4.0476, latent MSE loss:0.00027492, KL loss:0.00000707\n",
      "Pretrain epoch [1/383], ZINB loss:0.3823, NB loss:4.4208, latent MSE loss:0.00031424, KL loss:0.00069465\n",
      "Pretrain epoch [2/383], ZINB loss:0.3960, NB loss:4.5043, latent MSE loss:0.00024338, KL loss:0.00084624\n",
      "Pretrain epoch [3/383], ZINB loss:0.4093, NB loss:4.5034, latent MSE loss:0.00026501, KL loss:0.00091901\n",
      "Pretrain epoch [4/383], ZINB loss:0.3892, NB loss:4.4497, latent MSE loss:0.00027348, KL loss:0.00065208\n",
      "Pretrain epoch [5/383], ZINB loss:0.4103, NB loss:4.4958, latent MSE loss:0.00030731, KL loss:0.00109646\n",
      "Pretrain epoch [6/383], ZINB loss:0.3825, NB loss:4.5041, latent MSE loss:0.00022779, KL loss:0.00077216\n",
      "Pretrain epoch [7/383], ZINB loss:0.4251, NB loss:4.4742, latent MSE loss:0.00029967, KL loss:0.00125925\n",
      "Pretrain epoch [8/383], ZINB loss:0.3871, NB loss:4.4058, latent MSE loss:0.00030497, KL loss:0.00097584\n",
      "Pretrain epoch [9/383], ZINB loss:0.4083, NB loss:4.5128, latent MSE loss:0.00027240, KL loss:0.00082620\n",
      "Pretrain epoch [10/383], ZINB loss:0.3905, NB loss:4.4303, latent MSE loss:0.00028202, KL loss:0.00073485\n",
      "Pretrain epoch [11/383], ZINB loss:0.4082, NB loss:4.4418, latent MSE loss:0.00027297, KL loss:0.00101061\n",
      "Pretrain epoch [12/383], ZINB loss:0.3854, NB loss:4.3895, latent MSE loss:0.00037623, KL loss:0.00072544\n",
      "Pretrain epoch [13/383], ZINB loss:0.4097, NB loss:4.4439, latent MSE loss:0.00028883, KL loss:0.00099357\n",
      "Pretrain epoch [14/383], ZINB loss:0.3906, NB loss:4.5170, latent MSE loss:0.00030786, KL loss:0.00081396\n",
      "Pretrain epoch [15/383], ZINB loss:0.3903, NB loss:4.5276, latent MSE loss:0.00028526, KL loss:0.00099264\n",
      "Pretrain epoch [16/383], ZINB loss:0.3827, NB loss:4.4729, latent MSE loss:0.00025227, KL loss:0.00073638\n",
      "Pretrain epoch [17/383], ZINB loss:0.3836, NB loss:4.4237, latent MSE loss:0.00018983, KL loss:0.00101195\n",
      "Pretrain epoch [18/383], ZINB loss:0.3979, NB loss:4.4918, latent MSE loss:0.00020907, KL loss:0.00079539\n",
      "Pretrain epoch [19/383], ZINB loss:0.3898, NB loss:4.4531, latent MSE loss:0.00021584, KL loss:0.00081699\n",
      "Pretrain epoch [20/383], ZINB loss:0.3981, NB loss:4.4400, latent MSE loss:0.00023981, KL loss:0.00085179\n",
      "Pretrain epoch [21/383], ZINB loss:0.4005, NB loss:4.4591, latent MSE loss:0.00026394, KL loss:0.00072676\n",
      "Pretrain epoch [22/383], ZINB loss:0.3843, NB loss:4.4162, latent MSE loss:0.00032561, KL loss:0.00072067\n",
      "Pretrain epoch [23/383], ZINB loss:0.3977, NB loss:4.4754, latent MSE loss:0.00023173, KL loss:0.00093269\n",
      "Pretrain epoch [24/383], ZINB loss:0.3798, NB loss:4.5170, latent MSE loss:0.00016443, KL loss:0.00068843\n",
      "Pretrain epoch [25/383], ZINB loss:0.3877, NB loss:4.5496, latent MSE loss:0.00025203, KL loss:0.00081935\n",
      "Pretrain epoch [26/383], ZINB loss:0.4034, NB loss:4.4905, latent MSE loss:0.00023669, KL loss:0.00158787\n",
      "Pretrain epoch [27/383], ZINB loss:0.3327, NB loss:4.6880, latent MSE loss:0.00009239, KL loss:0.00000094\n",
      "Pretrain epoch [1/384], ZINB loss:0.3922, NB loss:4.4688, latent MSE loss:0.00040047, KL loss:0.00092951\n",
      "Pretrain epoch [2/384], ZINB loss:0.3785, NB loss:4.4541, latent MSE loss:0.00025896, KL loss:0.00074899\n",
      "Pretrain epoch [3/384], ZINB loss:0.3877, NB loss:4.4554, latent MSE loss:0.00025503, KL loss:0.00120055\n",
      "Pretrain epoch [4/384], ZINB loss:0.3946, NB loss:4.4527, latent MSE loss:0.00026223, KL loss:0.00091261\n",
      "Pretrain epoch [5/384], ZINB loss:0.3830, NB loss:4.4806, latent MSE loss:0.00026414, KL loss:0.00081217\n",
      "Pretrain epoch [6/384], ZINB loss:0.3957, NB loss:4.4847, latent MSE loss:0.00030889, KL loss:0.00084733\n",
      "Pretrain epoch [7/384], ZINB loss:0.3993, NB loss:4.4861, latent MSE loss:0.00033067, KL loss:0.00080809\n",
      "Pretrain epoch [8/384], ZINB loss:0.3821, NB loss:4.4763, latent MSE loss:0.00030920, KL loss:0.00075562\n",
      "Pretrain epoch [9/384], ZINB loss:0.3971, NB loss:4.4740, latent MSE loss:0.00032816, KL loss:0.00079178\n",
      "Pretrain epoch [10/384], ZINB loss:0.4185, NB loss:4.4585, latent MSE loss:0.00029018, KL loss:0.00073733\n",
      "Pretrain epoch [11/384], ZINB loss:0.3924, NB loss:4.4486, latent MSE loss:0.00028554, KL loss:0.00068044\n",
      "Pretrain epoch [12/384], ZINB loss:0.3992, NB loss:4.4705, latent MSE loss:0.00029279, KL loss:0.00066025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [13/384], ZINB loss:0.3942, NB loss:4.4547, latent MSE loss:0.00031829, KL loss:0.00077348\n",
      "Pretrain epoch [14/384], ZINB loss:0.4131, NB loss:4.4762, latent MSE loss:0.00029441, KL loss:0.00094352\n",
      "Pretrain epoch [15/384], ZINB loss:0.3898, NB loss:4.4907, latent MSE loss:0.00030494, KL loss:0.00085948\n",
      "Pretrain epoch [16/384], ZINB loss:0.3870, NB loss:4.4776, latent MSE loss:0.00025778, KL loss:0.00095780\n",
      "Pretrain epoch [17/384], ZINB loss:0.3853, NB loss:4.4691, latent MSE loss:0.00022247, KL loss:0.00069424\n",
      "Pretrain epoch [18/384], ZINB loss:0.3989, NB loss:4.4270, latent MSE loss:0.00029505, KL loss:0.00072288\n",
      "Pretrain epoch [19/384], ZINB loss:0.3989, NB loss:4.4071, latent MSE loss:0.00045672, KL loss:0.00076958\n",
      "Pretrain epoch [20/384], ZINB loss:0.3968, NB loss:4.4833, latent MSE loss:0.00054232, KL loss:0.00079445\n",
      "Pretrain epoch [21/384], ZINB loss:0.3931, NB loss:4.4783, latent MSE loss:0.00025543, KL loss:0.00071244\n",
      "Pretrain epoch [22/384], ZINB loss:0.3931, NB loss:4.5440, latent MSE loss:0.00027843, KL loss:0.00099636\n",
      "Pretrain epoch [23/384], ZINB loss:0.3812, NB loss:4.4777, latent MSE loss:0.00038074, KL loss:0.00076656\n",
      "Pretrain epoch [24/384], ZINB loss:0.3990, NB loss:4.4808, latent MSE loss:0.00029032, KL loss:0.00098605\n",
      "Pretrain epoch [25/384], ZINB loss:0.4148, NB loss:4.4556, latent MSE loss:0.00027196, KL loss:0.00086018\n",
      "Pretrain epoch [26/384], ZINB loss:0.3950, NB loss:4.4773, latent MSE loss:0.00028726, KL loss:0.00089699\n",
      "Pretrain epoch [27/384], ZINB loss:0.3925, NB loss:4.1053, latent MSE loss:0.00021154, KL loss:0.00000547\n",
      "Pretrain epoch [1/385], ZINB loss:0.3928, NB loss:4.4985, latent MSE loss:0.00034997, KL loss:0.00086041\n",
      "Pretrain epoch [2/385], ZINB loss:0.4377, NB loss:4.4417, latent MSE loss:0.00050532, KL loss:0.00126442\n",
      "Pretrain epoch [3/385], ZINB loss:0.4035, NB loss:4.4903, latent MSE loss:0.00037073, KL loss:0.00083605\n",
      "Pretrain epoch [4/385], ZINB loss:0.3845, NB loss:4.4607, latent MSE loss:0.00030799, KL loss:0.00075780\n",
      "Pretrain epoch [5/385], ZINB loss:0.3915, NB loss:4.4385, latent MSE loss:0.00037633, KL loss:0.00072047\n",
      "Pretrain epoch [6/385], ZINB loss:0.3923, NB loss:4.4098, latent MSE loss:0.00043580, KL loss:0.00076071\n",
      "Pretrain epoch [7/385], ZINB loss:0.3973, NB loss:4.4821, latent MSE loss:0.00039702, KL loss:0.00089417\n",
      "Pretrain epoch [8/385], ZINB loss:0.3915, NB loss:4.4920, latent MSE loss:0.00039104, KL loss:0.00076228\n",
      "Pretrain epoch [9/385], ZINB loss:0.3731, NB loss:4.5013, latent MSE loss:0.00027269, KL loss:0.00094968\n",
      "Pretrain epoch [10/385], ZINB loss:0.4164, NB loss:4.5391, latent MSE loss:0.00042500, KL loss:0.00128575\n",
      "Pretrain epoch [11/385], ZINB loss:0.3776, NB loss:4.4849, latent MSE loss:0.00033888, KL loss:0.00123408\n",
      "Pretrain epoch [12/385], ZINB loss:0.4068, NB loss:4.4691, latent MSE loss:0.00037106, KL loss:0.00080757\n",
      "Pretrain epoch [13/385], ZINB loss:0.4018, NB loss:4.5571, latent MSE loss:0.00041930, KL loss:0.00089539\n",
      "Pretrain epoch [14/385], ZINB loss:0.3946, NB loss:4.4887, latent MSE loss:0.00050810, KL loss:0.00095730\n",
      "Pretrain epoch [15/385], ZINB loss:0.3759, NB loss:4.4272, latent MSE loss:0.00040798, KL loss:0.00065603\n",
      "Pretrain epoch [16/385], ZINB loss:0.4113, NB loss:4.5029, latent MSE loss:0.00029798, KL loss:0.00079132\n",
      "Pretrain epoch [17/385], ZINB loss:0.3974, NB loss:4.4489, latent MSE loss:0.00030903, KL loss:0.00078296\n",
      "Pretrain epoch [18/385], ZINB loss:0.3761, NB loss:4.4301, latent MSE loss:0.00028124, KL loss:0.00076538\n",
      "Pretrain epoch [19/385], ZINB loss:0.3840, NB loss:4.4483, latent MSE loss:0.00025332, KL loss:0.00078185\n",
      "Pretrain epoch [20/385], ZINB loss:0.4000, NB loss:4.4616, latent MSE loss:0.00028579, KL loss:0.00080605\n",
      "Pretrain epoch [21/385], ZINB loss:0.3987, NB loss:4.4517, latent MSE loss:0.00031028, KL loss:0.00087656\n",
      "Pretrain epoch [22/385], ZINB loss:0.3993, NB loss:4.4586, latent MSE loss:0.00025066, KL loss:0.00086736\n",
      "Pretrain epoch [23/385], ZINB loss:0.3920, NB loss:4.3752, latent MSE loss:0.00020483, KL loss:0.00062028\n",
      "Pretrain epoch [24/385], ZINB loss:0.3954, NB loss:4.4671, latent MSE loss:0.00019285, KL loss:0.00077445\n",
      "Pretrain epoch [25/385], ZINB loss:0.4050, NB loss:4.4221, latent MSE loss:0.00021449, KL loss:0.00085491\n",
      "Pretrain epoch [26/385], ZINB loss:0.3898, NB loss:4.5409, latent MSE loss:0.00019203, KL loss:0.00086105\n",
      "Pretrain epoch [27/385], ZINB loss:0.2832, NB loss:4.2228, latent MSE loss:0.00010807, KL loss:0.00000256\n",
      "Pretrain epoch [1/386], ZINB loss:0.3894, NB loss:4.4910, latent MSE loss:0.00037282, KL loss:0.00073096\n",
      "Pretrain epoch [2/386], ZINB loss:0.3929, NB loss:4.5264, latent MSE loss:0.00043496, KL loss:0.00072187\n",
      "Pretrain epoch [3/386], ZINB loss:0.4054, NB loss:4.4264, latent MSE loss:0.00031314, KL loss:0.00108698\n",
      "Pretrain epoch [4/386], ZINB loss:0.3841, NB loss:4.4468, latent MSE loss:0.00022012, KL loss:0.00083444\n",
      "Pretrain epoch [5/386], ZINB loss:0.3931, NB loss:4.5550, latent MSE loss:0.00030583, KL loss:0.00078456\n",
      "Pretrain epoch [6/386], ZINB loss:0.3824, NB loss:4.4681, latent MSE loss:0.00037807, KL loss:0.00074595\n",
      "Pretrain epoch [7/386], ZINB loss:0.3780, NB loss:4.3833, latent MSE loss:0.00030554, KL loss:0.00088352\n",
      "Pretrain epoch [8/386], ZINB loss:0.4011, NB loss:4.5000, latent MSE loss:0.00027589, KL loss:0.00069703\n",
      "Pretrain epoch [9/386], ZINB loss:0.4038, NB loss:4.4996, latent MSE loss:0.00032422, KL loss:0.00127162\n",
      "Pretrain epoch [10/386], ZINB loss:0.3868, NB loss:4.4723, latent MSE loss:0.00029016, KL loss:0.00085427\n",
      "Pretrain epoch [11/386], ZINB loss:0.3937, NB loss:4.4610, latent MSE loss:0.00024157, KL loss:0.00079581\n",
      "Pretrain epoch [12/386], ZINB loss:0.4121, NB loss:4.4920, latent MSE loss:0.00030296, KL loss:0.00091287\n",
      "Pretrain epoch [13/386], ZINB loss:0.4113, NB loss:4.4750, latent MSE loss:0.00027365, KL loss:0.00072493\n",
      "Pretrain epoch [14/386], ZINB loss:0.4071, NB loss:4.4965, latent MSE loss:0.00025200, KL loss:0.00073501\n",
      "Pretrain epoch [15/386], ZINB loss:0.3952, NB loss:4.4604, latent MSE loss:0.00021771, KL loss:0.00103359\n",
      "Pretrain epoch [16/386], ZINB loss:0.3846, NB loss:4.4158, latent MSE loss:0.00024409, KL loss:0.00080407\n",
      "Pretrain epoch [17/386], ZINB loss:0.4031, NB loss:4.4198, latent MSE loss:0.00025348, KL loss:0.00101925\n",
      "Pretrain epoch [18/386], ZINB loss:0.3798, NB loss:4.4856, latent MSE loss:0.00016247, KL loss:0.00071487\n",
      "Pretrain epoch [19/386], ZINB loss:0.3922, NB loss:4.4854, latent MSE loss:0.00016612, KL loss:0.00087058\n",
      "Pretrain epoch [20/386], ZINB loss:0.3865, NB loss:4.5175, latent MSE loss:0.00018434, KL loss:0.00078569\n",
      "Pretrain epoch [21/386], ZINB loss:0.4073, NB loss:4.5275, latent MSE loss:0.00022276, KL loss:0.00141684\n",
      "Pretrain epoch [22/386], ZINB loss:0.3947, NB loss:4.4264, latent MSE loss:0.00019395, KL loss:0.00088152\n",
      "Pretrain epoch [23/386], ZINB loss:0.3786, NB loss:4.4253, latent MSE loss:0.00018565, KL loss:0.00072908\n",
      "Pretrain epoch [24/386], ZINB loss:0.3936, NB loss:4.4111, latent MSE loss:0.00015619, KL loss:0.00072655\n",
      "Pretrain epoch [25/386], ZINB loss:0.4103, NB loss:4.4527, latent MSE loss:0.00021428, KL loss:0.00076033\n",
      "Pretrain epoch [26/386], ZINB loss:0.3953, NB loss:4.4335, latent MSE loss:0.00022018, KL loss:0.00106325\n",
      "Pretrain epoch [27/386], ZINB loss:0.3569, NB loss:5.0875, latent MSE loss:0.00010812, KL loss:0.00007173\n",
      "Pretrain epoch [1/387], ZINB loss:0.3742, NB loss:4.5338, latent MSE loss:0.00034269, KL loss:0.00107089\n",
      "Pretrain epoch [2/387], ZINB loss:0.4068, NB loss:4.4470, latent MSE loss:0.00044438, KL loss:0.00066543\n",
      "Pretrain epoch [3/387], ZINB loss:0.4162, NB loss:4.5175, latent MSE loss:0.00039325, KL loss:0.00085354\n",
      "Pretrain epoch [4/387], ZINB loss:0.3860, NB loss:4.4353, latent MSE loss:0.00031562, KL loss:0.00088138\n",
      "Pretrain epoch [5/387], ZINB loss:0.4021, NB loss:4.4742, latent MSE loss:0.00027153, KL loss:0.00088733\n",
      "Pretrain epoch [6/387], ZINB loss:0.3967, NB loss:4.4630, latent MSE loss:0.00047233, KL loss:0.00121921\n",
      "Pretrain epoch [7/387], ZINB loss:0.3938, NB loss:4.5009, latent MSE loss:0.00034057, KL loss:0.00072235\n",
      "Pretrain epoch [8/387], ZINB loss:0.3974, NB loss:4.4541, latent MSE loss:0.00029898, KL loss:0.00079473\n",
      "Pretrain epoch [9/387], ZINB loss:0.3837, NB loss:4.4501, latent MSE loss:0.00024159, KL loss:0.00073666\n",
      "Pretrain epoch [10/387], ZINB loss:0.4032, NB loss:4.4211, latent MSE loss:0.00040614, KL loss:0.00085461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [11/387], ZINB loss:0.4018, NB loss:4.4861, latent MSE loss:0.00033515, KL loss:0.00077458\n",
      "Pretrain epoch [12/387], ZINB loss:0.3954, NB loss:4.4778, latent MSE loss:0.00028918, KL loss:0.00090135\n",
      "Pretrain epoch [13/387], ZINB loss:0.3838, NB loss:4.4974, latent MSE loss:0.00027357, KL loss:0.00075640\n",
      "Pretrain epoch [14/387], ZINB loss:0.3872, NB loss:4.4329, latent MSE loss:0.00029223, KL loss:0.00073909\n",
      "Pretrain epoch [15/387], ZINB loss:0.3914, NB loss:4.5178, latent MSE loss:0.00030429, KL loss:0.00073527\n",
      "Pretrain epoch [16/387], ZINB loss:0.3994, NB loss:4.4837, latent MSE loss:0.00026220, KL loss:0.00079508\n",
      "Pretrain epoch [17/387], ZINB loss:0.3798, NB loss:4.4954, latent MSE loss:0.00028466, KL loss:0.00069666\n",
      "Pretrain epoch [18/387], ZINB loss:0.3916, NB loss:4.4545, latent MSE loss:0.00023136, KL loss:0.00069886\n",
      "Pretrain epoch [19/387], ZINB loss:0.3815, NB loss:4.4617, latent MSE loss:0.00022676, KL loss:0.00072047\n",
      "Pretrain epoch [20/387], ZINB loss:0.4084, NB loss:4.4165, latent MSE loss:0.00024036, KL loss:0.00095972\n",
      "Pretrain epoch [21/387], ZINB loss:0.3909, NB loss:4.4636, latent MSE loss:0.00021853, KL loss:0.00093329\n",
      "Pretrain epoch [22/387], ZINB loss:0.3995, NB loss:4.3815, latent MSE loss:0.00025920, KL loss:0.00068215\n",
      "Pretrain epoch [23/387], ZINB loss:0.4008, NB loss:4.4370, latent MSE loss:0.00030054, KL loss:0.00094355\n",
      "Pretrain epoch [24/387], ZINB loss:0.4054, NB loss:4.5040, latent MSE loss:0.00033275, KL loss:0.00088833\n",
      "Pretrain epoch [25/387], ZINB loss:0.3947, NB loss:4.5108, latent MSE loss:0.00023423, KL loss:0.00067416\n",
      "Pretrain epoch [26/387], ZINB loss:0.4077, NB loss:4.4700, latent MSE loss:0.00026430, KL loss:0.00086446\n",
      "Pretrain epoch [27/387], ZINB loss:0.2915, NB loss:4.3281, latent MSE loss:0.00015166, KL loss:0.00005904\n",
      "Pretrain epoch [1/388], ZINB loss:0.3950, NB loss:4.4052, latent MSE loss:0.00086400, KL loss:0.00075439\n",
      "Pretrain epoch [2/388], ZINB loss:0.3968, NB loss:4.4477, latent MSE loss:0.00070448, KL loss:0.00075891\n",
      "Pretrain epoch [3/388], ZINB loss:0.3950, NB loss:4.5136, latent MSE loss:0.00108989, KL loss:0.00078226\n",
      "Pretrain epoch [4/388], ZINB loss:0.3914, NB loss:4.4653, latent MSE loss:0.00063720, KL loss:0.00074866\n",
      "Pretrain epoch [5/388], ZINB loss:0.4211, NB loss:4.4437, latent MSE loss:0.00057306, KL loss:0.00090648\n",
      "Pretrain epoch [6/388], ZINB loss:0.3800, NB loss:4.5514, latent MSE loss:0.00086602, KL loss:0.00070723\n",
      "Pretrain epoch [7/388], ZINB loss:0.3925, NB loss:4.4404, latent MSE loss:0.00054898, KL loss:0.00073489\n",
      "Pretrain epoch [8/388], ZINB loss:0.3900, NB loss:4.4489, latent MSE loss:0.00049627, KL loss:0.00093856\n",
      "Pretrain epoch [9/388], ZINB loss:0.4030, NB loss:4.4359, latent MSE loss:0.00047696, KL loss:0.00087711\n",
      "Pretrain epoch [10/388], ZINB loss:0.3989, NB loss:4.4386, latent MSE loss:0.00055768, KL loss:0.00077222\n",
      "Pretrain epoch [11/388], ZINB loss:0.3903, NB loss:4.4608, latent MSE loss:0.00038097, KL loss:0.00090479\n",
      "Pretrain epoch [12/388], ZINB loss:0.3942, NB loss:4.4882, latent MSE loss:0.00044013, KL loss:0.00072347\n",
      "Pretrain epoch [13/388], ZINB loss:0.3859, NB loss:4.4597, latent MSE loss:0.00030533, KL loss:0.00071161\n",
      "Pretrain epoch [14/388], ZINB loss:0.4018, NB loss:4.4800, latent MSE loss:0.00032928, KL loss:0.00076605\n",
      "Pretrain epoch [15/388], ZINB loss:0.3803, NB loss:4.5180, latent MSE loss:0.00023369, KL loss:0.00080472\n",
      "Pretrain epoch [16/388], ZINB loss:0.3819, NB loss:4.4550, latent MSE loss:0.00038705, KL loss:0.00083339\n",
      "Pretrain epoch [17/388], ZINB loss:0.3878, NB loss:4.4994, latent MSE loss:0.00026146, KL loss:0.00079086\n",
      "Pretrain epoch [18/388], ZINB loss:0.3781, NB loss:4.4681, latent MSE loss:0.00033290, KL loss:0.00080426\n",
      "Pretrain epoch [19/388], ZINB loss:0.3766, NB loss:4.4851, latent MSE loss:0.00030304, KL loss:0.00106157\n",
      "Pretrain epoch [20/388], ZINB loss:0.4042, NB loss:4.4589, latent MSE loss:0.00028020, KL loss:0.00075256\n",
      "Pretrain epoch [21/388], ZINB loss:0.4131, NB loss:4.4471, latent MSE loss:0.00025150, KL loss:0.00077244\n",
      "Pretrain epoch [22/388], ZINB loss:0.3935, NB loss:4.4367, latent MSE loss:0.00030264, KL loss:0.00067080\n",
      "Pretrain epoch [23/388], ZINB loss:0.4128, NB loss:4.5376, latent MSE loss:0.00036868, KL loss:0.00158165\n",
      "Pretrain epoch [24/388], ZINB loss:0.3914, NB loss:4.4403, latent MSE loss:0.00026685, KL loss:0.00071962\n",
      "Pretrain epoch [25/388], ZINB loss:0.4148, NB loss:4.4620, latent MSE loss:0.00030693, KL loss:0.00139724\n",
      "Pretrain epoch [26/388], ZINB loss:0.4016, NB loss:4.4401, latent MSE loss:0.00026665, KL loss:0.00104443\n",
      "Pretrain epoch [27/388], ZINB loss:0.3745, NB loss:4.4055, latent MSE loss:0.00026388, KL loss:0.00006730\n",
      "Pretrain epoch [1/389], ZINB loss:0.3850, NB loss:4.4041, latent MSE loss:0.00053439, KL loss:0.00064052\n",
      "Pretrain epoch [2/389], ZINB loss:0.3783, NB loss:4.4985, latent MSE loss:0.00040358, KL loss:0.00081396\n",
      "Pretrain epoch [3/389], ZINB loss:0.3832, NB loss:4.4601, latent MSE loss:0.00033717, KL loss:0.00087576\n",
      "Pretrain epoch [4/389], ZINB loss:0.3891, NB loss:4.4748, latent MSE loss:0.00048839, KL loss:0.00121864\n",
      "Pretrain epoch [5/389], ZINB loss:0.4174, NB loss:4.4526, latent MSE loss:0.00044754, KL loss:0.00083947\n",
      "Pretrain epoch [6/389], ZINB loss:0.4018, NB loss:4.4386, latent MSE loss:0.00032991, KL loss:0.00085316\n",
      "Pretrain epoch [7/389], ZINB loss:0.3786, NB loss:4.4618, latent MSE loss:0.00036225, KL loss:0.00094114\n",
      "Pretrain epoch [8/389], ZINB loss:0.3817, NB loss:4.5317, latent MSE loss:0.00036269, KL loss:0.00101729\n",
      "Pretrain epoch [9/389], ZINB loss:0.3808, NB loss:4.4864, latent MSE loss:0.00037328, KL loss:0.00099445\n",
      "Pretrain epoch [10/389], ZINB loss:0.4168, NB loss:4.3928, latent MSE loss:0.00034040, KL loss:0.00097509\n",
      "Pretrain epoch [11/389], ZINB loss:0.3883, NB loss:4.4734, latent MSE loss:0.00030703, KL loss:0.00084898\n",
      "Pretrain epoch [12/389], ZINB loss:0.4081, NB loss:4.4845, latent MSE loss:0.00035453, KL loss:0.00130260\n",
      "Pretrain epoch [13/389], ZINB loss:0.3964, NB loss:4.4959, latent MSE loss:0.00035881, KL loss:0.00110426\n",
      "Pretrain epoch [14/389], ZINB loss:0.3726, NB loss:4.5072, latent MSE loss:0.00029323, KL loss:0.00073989\n",
      "Pretrain epoch [15/389], ZINB loss:0.4179, NB loss:4.5257, latent MSE loss:0.00028834, KL loss:0.00088306\n",
      "Pretrain epoch [16/389], ZINB loss:0.4160, NB loss:4.4606, latent MSE loss:0.00034282, KL loss:0.00131292\n",
      "Pretrain epoch [17/389], ZINB loss:0.3927, NB loss:4.4893, latent MSE loss:0.00023980, KL loss:0.00083088\n",
      "Pretrain epoch [18/389], ZINB loss:0.4084, NB loss:4.4805, latent MSE loss:0.00030924, KL loss:0.00071560\n",
      "Pretrain epoch [19/389], ZINB loss:0.3857, NB loss:4.4668, latent MSE loss:0.00027744, KL loss:0.00102194\n",
      "Pretrain epoch [20/389], ZINB loss:0.3951, NB loss:4.4006, latent MSE loss:0.00033227, KL loss:0.00079323\n",
      "Pretrain epoch [21/389], ZINB loss:0.4027, NB loss:4.4912, latent MSE loss:0.00033370, KL loss:0.00075498\n",
      "Pretrain epoch [22/389], ZINB loss:0.3907, NB loss:4.4667, latent MSE loss:0.00029480, KL loss:0.00081366\n",
      "Pretrain epoch [23/389], ZINB loss:0.4133, NB loss:4.4409, latent MSE loss:0.00033486, KL loss:0.00102714\n",
      "Pretrain epoch [24/389], ZINB loss:0.3977, NB loss:4.4187, latent MSE loss:0.00021126, KL loss:0.00073471\n",
      "Pretrain epoch [25/389], ZINB loss:0.3951, NB loss:4.4296, latent MSE loss:0.00024738, KL loss:0.00090190\n",
      "Pretrain epoch [26/389], ZINB loss:0.3850, NB loss:4.4759, latent MSE loss:0.00028502, KL loss:0.00096765\n",
      "Pretrain epoch [27/389], ZINB loss:0.4330, NB loss:4.3783, latent MSE loss:0.00010424, KL loss:0.00004345\n",
      "Pretrain epoch [1/390], ZINB loss:0.3963, NB loss:4.5723, latent MSE loss:0.00025861, KL loss:0.00073448\n",
      "Pretrain epoch [2/390], ZINB loss:0.3844, NB loss:4.4886, latent MSE loss:0.00027144, KL loss:0.00072050\n",
      "Pretrain epoch [3/390], ZINB loss:0.3753, NB loss:4.4770, latent MSE loss:0.00036512, KL loss:0.00085563\n",
      "Pretrain epoch [4/390], ZINB loss:0.4112, NB loss:4.4384, latent MSE loss:0.00028659, KL loss:0.00111754\n",
      "Pretrain epoch [5/390], ZINB loss:0.3938, NB loss:4.4355, latent MSE loss:0.00030983, KL loss:0.00072975\n",
      "Pretrain epoch [6/390], ZINB loss:0.4079, NB loss:4.4402, latent MSE loss:0.00030444, KL loss:0.00089088\n",
      "Pretrain epoch [7/390], ZINB loss:0.4025, NB loss:4.4542, latent MSE loss:0.00025847, KL loss:0.00086697\n",
      "Pretrain epoch [8/390], ZINB loss:0.4012, NB loss:4.4003, latent MSE loss:0.00022669, KL loss:0.00074436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [9/390], ZINB loss:0.3834, NB loss:4.4895, latent MSE loss:0.00021450, KL loss:0.00078818\n",
      "Pretrain epoch [10/390], ZINB loss:0.4099, NB loss:4.4413, latent MSE loss:0.00028444, KL loss:0.00080093\n",
      "Pretrain epoch [11/390], ZINB loss:0.4089, NB loss:4.4847, latent MSE loss:0.00030687, KL loss:0.00098911\n",
      "Pretrain epoch [12/390], ZINB loss:0.3891, NB loss:4.4753, latent MSE loss:0.00023073, KL loss:0.00074354\n",
      "Pretrain epoch [13/390], ZINB loss:0.4066, NB loss:4.4292, latent MSE loss:0.00024257, KL loss:0.00083262\n",
      "Pretrain epoch [14/390], ZINB loss:0.3992, NB loss:4.4969, latent MSE loss:0.00027434, KL loss:0.00116926\n",
      "Pretrain epoch [15/390], ZINB loss:0.3726, NB loss:4.4353, latent MSE loss:0.00025704, KL loss:0.00072312\n",
      "Pretrain epoch [16/390], ZINB loss:0.3939, NB loss:4.4964, latent MSE loss:0.00021355, KL loss:0.00077183\n",
      "Pretrain epoch [17/390], ZINB loss:0.3814, NB loss:4.5375, latent MSE loss:0.00023977, KL loss:0.00077935\n",
      "Pretrain epoch [18/390], ZINB loss:0.4024, NB loss:4.4790, latent MSE loss:0.00022780, KL loss:0.00081508\n",
      "Pretrain epoch [19/390], ZINB loss:0.3775, NB loss:4.4668, latent MSE loss:0.00022023, KL loss:0.00074871\n",
      "Pretrain epoch [20/390], ZINB loss:0.4079, NB loss:4.5012, latent MSE loss:0.00028634, KL loss:0.00086835\n",
      "Pretrain epoch [21/390], ZINB loss:0.4129, NB loss:4.4135, latent MSE loss:0.00021118, KL loss:0.00076074\n",
      "Pretrain epoch [22/390], ZINB loss:0.3820, NB loss:4.4247, latent MSE loss:0.00019349, KL loss:0.00085656\n",
      "Pretrain epoch [23/390], ZINB loss:0.3887, NB loss:4.4820, latent MSE loss:0.00028125, KL loss:0.00080408\n",
      "Pretrain epoch [24/390], ZINB loss:0.3885, NB loss:4.3878, latent MSE loss:0.00027857, KL loss:0.00086262\n",
      "Pretrain epoch [25/390], ZINB loss:0.3822, NB loss:4.4858, latent MSE loss:0.00025472, KL loss:0.00116783\n",
      "Pretrain epoch [26/390], ZINB loss:0.4001, NB loss:4.4529, latent MSE loss:0.00018798, KL loss:0.00067657\n",
      "Pretrain epoch [27/390], ZINB loss:0.3635, NB loss:4.6900, latent MSE loss:0.00016998, KL loss:0.00006726\n",
      "Pretrain epoch [1/391], ZINB loss:0.4101, NB loss:4.4949, latent MSE loss:0.00052054, KL loss:0.00077183\n",
      "Pretrain epoch [2/391], ZINB loss:0.3932, NB loss:4.5357, latent MSE loss:0.00034233, KL loss:0.00128879\n",
      "Pretrain epoch [3/391], ZINB loss:0.3786, NB loss:4.4229, latent MSE loss:0.00034521, KL loss:0.00069837\n",
      "Pretrain epoch [4/391], ZINB loss:0.3932, NB loss:4.4587, latent MSE loss:0.00047140, KL loss:0.00068718\n",
      "Pretrain epoch [5/391], ZINB loss:0.4057, NB loss:4.4888, latent MSE loss:0.00050046, KL loss:0.00086107\n",
      "Pretrain epoch [6/391], ZINB loss:0.4131, NB loss:4.4666, latent MSE loss:0.00046101, KL loss:0.00081997\n",
      "Pretrain epoch [7/391], ZINB loss:0.3928, NB loss:4.4161, latent MSE loss:0.00039010, KL loss:0.00069478\n",
      "Pretrain epoch [8/391], ZINB loss:0.4213, NB loss:4.5161, latent MSE loss:0.00042148, KL loss:0.00091939\n",
      "Pretrain epoch [9/391], ZINB loss:0.3760, NB loss:4.5058, latent MSE loss:0.00028326, KL loss:0.00077257\n",
      "Pretrain epoch [10/391], ZINB loss:0.3882, NB loss:4.3907, latent MSE loss:0.00035363, KL loss:0.00067806\n",
      "Pretrain epoch [11/391], ZINB loss:0.3827, NB loss:4.4731, latent MSE loss:0.00035674, KL loss:0.00079474\n",
      "Pretrain epoch [12/391], ZINB loss:0.3805, NB loss:4.4540, latent MSE loss:0.00035941, KL loss:0.00074137\n",
      "Pretrain epoch [13/391], ZINB loss:0.4028, NB loss:4.5044, latent MSE loss:0.00031893, KL loss:0.00079053\n",
      "Pretrain epoch [14/391], ZINB loss:0.3854, NB loss:4.4427, latent MSE loss:0.00024694, KL loss:0.00074945\n",
      "Pretrain epoch [15/391], ZINB loss:0.3942, NB loss:4.4732, latent MSE loss:0.00036444, KL loss:0.00079351\n",
      "Pretrain epoch [16/391], ZINB loss:0.3941, NB loss:4.4730, latent MSE loss:0.00041344, KL loss:0.00076383\n",
      "Pretrain epoch [17/391], ZINB loss:0.4102, NB loss:4.4925, latent MSE loss:0.00033905, KL loss:0.00089282\n",
      "Pretrain epoch [18/391], ZINB loss:0.3878, NB loss:4.4601, latent MSE loss:0.00023801, KL loss:0.00094786\n",
      "Pretrain epoch [19/391], ZINB loss:0.3910, NB loss:4.4697, latent MSE loss:0.00021937, KL loss:0.00073856\n",
      "Pretrain epoch [20/391], ZINB loss:0.3761, NB loss:4.4411, latent MSE loss:0.00030628, KL loss:0.00081970\n",
      "Pretrain epoch [21/391], ZINB loss:0.3935, NB loss:4.4535, latent MSE loss:0.00031639, KL loss:0.00072759\n",
      "Pretrain epoch [22/391], ZINB loss:0.4210, NB loss:4.4786, latent MSE loss:0.00035872, KL loss:0.00099787\n",
      "Pretrain epoch [23/391], ZINB loss:0.4061, NB loss:4.4401, latent MSE loss:0.00032474, KL loss:0.00093113\n",
      "Pretrain epoch [24/391], ZINB loss:0.3897, NB loss:4.4280, latent MSE loss:0.00025837, KL loss:0.00085481\n",
      "Pretrain epoch [25/391], ZINB loss:0.3929, NB loss:4.4517, latent MSE loss:0.00027842, KL loss:0.00106239\n",
      "Pretrain epoch [26/391], ZINB loss:0.3897, NB loss:4.4405, latent MSE loss:0.00030808, KL loss:0.00099299\n",
      "Pretrain epoch [27/391], ZINB loss:0.3097, NB loss:4.4949, latent MSE loss:0.00019376, KL loss:0.00006560\n",
      "Pretrain epoch [1/392], ZINB loss:0.4208, NB loss:4.3887, latent MSE loss:0.00043848, KL loss:0.00080610\n",
      "Pretrain epoch [2/392], ZINB loss:0.3947, NB loss:4.5184, latent MSE loss:0.00066402, KL loss:0.00091884\n",
      "Pretrain epoch [3/392], ZINB loss:0.3874, NB loss:4.4233, latent MSE loss:0.00044558, KL loss:0.00080204\n",
      "Pretrain epoch [4/392], ZINB loss:0.3968, NB loss:4.4723, latent MSE loss:0.00038392, KL loss:0.00082007\n",
      "Pretrain epoch [5/392], ZINB loss:0.3890, NB loss:4.4343, latent MSE loss:0.00034455, KL loss:0.00072839\n",
      "Pretrain epoch [6/392], ZINB loss:0.4047, NB loss:4.5024, latent MSE loss:0.00044399, KL loss:0.00077212\n",
      "Pretrain epoch [7/392], ZINB loss:0.4061, NB loss:4.4394, latent MSE loss:0.00031245, KL loss:0.00076276\n",
      "Pretrain epoch [8/392], ZINB loss:0.3797, NB loss:4.4838, latent MSE loss:0.00027889, KL loss:0.00069159\n",
      "Pretrain epoch [9/392], ZINB loss:0.3931, NB loss:4.5103, latent MSE loss:0.00028243, KL loss:0.00090701\n",
      "Pretrain epoch [10/392], ZINB loss:0.3925, NB loss:4.3974, latent MSE loss:0.00032557, KL loss:0.00071306\n",
      "Pretrain epoch [11/392], ZINB loss:0.3878, NB loss:4.5230, latent MSE loss:0.00025828, KL loss:0.00087114\n",
      "Pretrain epoch [12/392], ZINB loss:0.4047, NB loss:4.4588, latent MSE loss:0.00034385, KL loss:0.00077770\n",
      "Pretrain epoch [13/392], ZINB loss:0.4009, NB loss:4.4865, latent MSE loss:0.00032240, KL loss:0.00085793\n",
      "Pretrain epoch [14/392], ZINB loss:0.3960, NB loss:4.5252, latent MSE loss:0.00021453, KL loss:0.00076660\n",
      "Pretrain epoch [15/392], ZINB loss:0.3892, NB loss:4.4168, latent MSE loss:0.00026778, KL loss:0.00127229\n",
      "Pretrain epoch [16/392], ZINB loss:0.3925, NB loss:4.5104, latent MSE loss:0.00031643, KL loss:0.00107134\n",
      "Pretrain epoch [17/392], ZINB loss:0.3972, NB loss:4.4708, latent MSE loss:0.00034573, KL loss:0.00080707\n",
      "Pretrain epoch [18/392], ZINB loss:0.3888, NB loss:4.4368, latent MSE loss:0.00037400, KL loss:0.00068700\n",
      "Pretrain epoch [19/392], ZINB loss:0.3824, NB loss:4.4683, latent MSE loss:0.00031618, KL loss:0.00077794\n",
      "Pretrain epoch [20/392], ZINB loss:0.3981, NB loss:4.4633, latent MSE loss:0.00022041, KL loss:0.00098502\n",
      "Pretrain epoch [21/392], ZINB loss:0.3979, NB loss:4.4481, latent MSE loss:0.00030387, KL loss:0.00090859\n",
      "Pretrain epoch [22/392], ZINB loss:0.3911, NB loss:4.4602, latent MSE loss:0.00032360, KL loss:0.00089436\n",
      "Pretrain epoch [23/392], ZINB loss:0.3890, NB loss:4.4731, latent MSE loss:0.00040325, KL loss:0.00078580\n",
      "Pretrain epoch [24/392], ZINB loss:0.3944, NB loss:4.4455, latent MSE loss:0.00045174, KL loss:0.00098397\n",
      "Pretrain epoch [25/392], ZINB loss:0.3982, NB loss:4.4679, latent MSE loss:0.00028970, KL loss:0.00121304\n",
      "Pretrain epoch [26/392], ZINB loss:0.3933, NB loss:4.4334, latent MSE loss:0.00030562, KL loss:0.00080071\n",
      "Pretrain epoch [27/392], ZINB loss:0.4217, NB loss:4.4336, latent MSE loss:0.00050461, KL loss:0.00000759\n",
      "Pretrain epoch [1/393], ZINB loss:0.4083, NB loss:4.4556, latent MSE loss:0.00110634, KL loss:0.00086098\n",
      "Pretrain epoch [2/393], ZINB loss:0.4071, NB loss:4.4771, latent MSE loss:0.00089655, KL loss:0.00113994\n",
      "Pretrain epoch [3/393], ZINB loss:0.4095, NB loss:4.4763, latent MSE loss:0.00081129, KL loss:0.00107891\n",
      "Pretrain epoch [4/393], ZINB loss:0.3824, NB loss:4.4491, latent MSE loss:0.00072075, KL loss:0.00089124\n",
      "Pretrain epoch [5/393], ZINB loss:0.3988, NB loss:4.3937, latent MSE loss:0.00081882, KL loss:0.00091924\n",
      "Pretrain epoch [6/393], ZINB loss:0.4171, NB loss:4.4855, latent MSE loss:0.00093900, KL loss:0.00099379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [7/393], ZINB loss:0.3864, NB loss:4.4830, latent MSE loss:0.00078177, KL loss:0.00081906\n",
      "Pretrain epoch [8/393], ZINB loss:0.3922, NB loss:4.4269, latent MSE loss:0.00072826, KL loss:0.00119887\n",
      "Pretrain epoch [9/393], ZINB loss:0.3687, NB loss:4.5159, latent MSE loss:0.00069540, KL loss:0.00078109\n",
      "Pretrain epoch [10/393], ZINB loss:0.3945, NB loss:4.4662, latent MSE loss:0.00074935, KL loss:0.00084440\n",
      "Pretrain epoch [11/393], ZINB loss:0.3902, NB loss:4.4382, latent MSE loss:0.00079315, KL loss:0.00084853\n",
      "Pretrain epoch [12/393], ZINB loss:0.3877, NB loss:4.4860, latent MSE loss:0.00070466, KL loss:0.00092271\n",
      "Pretrain epoch [13/393], ZINB loss:0.4029, NB loss:4.4224, latent MSE loss:0.00067502, KL loss:0.00105961\n",
      "Pretrain epoch [14/393], ZINB loss:0.4106, NB loss:4.4409, latent MSE loss:0.00067609, KL loss:0.00085322\n",
      "Pretrain epoch [15/393], ZINB loss:0.4071, NB loss:4.4879, latent MSE loss:0.00067822, KL loss:0.00089524\n",
      "Pretrain epoch [16/393], ZINB loss:0.4114, NB loss:4.4911, latent MSE loss:0.00049573, KL loss:0.00091947\n",
      "Pretrain epoch [17/393], ZINB loss:0.4027, NB loss:4.4438, latent MSE loss:0.00045565, KL loss:0.00082899\n",
      "Pretrain epoch [18/393], ZINB loss:0.3912, NB loss:4.4298, latent MSE loss:0.00058647, KL loss:0.00087732\n",
      "Pretrain epoch [19/393], ZINB loss:0.3998, NB loss:4.4580, latent MSE loss:0.00065178, KL loss:0.00121042\n",
      "Pretrain epoch [20/393], ZINB loss:0.3952, NB loss:4.4558, latent MSE loss:0.00059571, KL loss:0.00086769\n",
      "Pretrain epoch [21/393], ZINB loss:0.3783, NB loss:4.4726, latent MSE loss:0.00032465, KL loss:0.00081166\n",
      "Pretrain epoch [22/393], ZINB loss:0.4053, NB loss:4.5100, latent MSE loss:0.00059198, KL loss:0.00122000\n",
      "Pretrain epoch [23/393], ZINB loss:0.3635, NB loss:4.4555, latent MSE loss:0.00043447, KL loss:0.00087534\n",
      "Pretrain epoch [24/393], ZINB loss:0.3859, NB loss:4.4815, latent MSE loss:0.00039102, KL loss:0.00122654\n",
      "Pretrain epoch [25/393], ZINB loss:0.3936, NB loss:4.4684, latent MSE loss:0.00063126, KL loss:0.00079746\n",
      "Pretrain epoch [26/393], ZINB loss:0.3841, NB loss:4.4966, latent MSE loss:0.00043578, KL loss:0.00075077\n",
      "Pretrain epoch [27/393], ZINB loss:0.3493, NB loss:4.4255, latent MSE loss:0.00069996, KL loss:0.00004359\n",
      "Pretrain epoch [1/394], ZINB loss:0.3776, NB loss:4.4180, latent MSE loss:0.00324178, KL loss:0.00093109\n",
      "Pretrain epoch [2/394], ZINB loss:0.3916, NB loss:4.4127, latent MSE loss:0.00111049, KL loss:0.00066372\n",
      "Pretrain epoch [3/394], ZINB loss:0.4028, NB loss:4.4504, latent MSE loss:0.00162109, KL loss:0.00082918\n",
      "Pretrain epoch [4/394], ZINB loss:0.4006, NB loss:4.4827, latent MSE loss:0.00121129, KL loss:0.00076689\n",
      "Pretrain epoch [5/394], ZINB loss:0.3771, NB loss:4.4802, latent MSE loss:0.00176730, KL loss:0.00072004\n",
      "Pretrain epoch [6/394], ZINB loss:0.3960, NB loss:4.4795, latent MSE loss:0.00147030, KL loss:0.00065498\n",
      "Pretrain epoch [7/394], ZINB loss:0.3964, NB loss:4.4818, latent MSE loss:0.00161328, KL loss:0.00082074\n",
      "Pretrain epoch [8/394], ZINB loss:0.3898, NB loss:4.4977, latent MSE loss:0.00182798, KL loss:0.00099001\n",
      "Pretrain epoch [9/394], ZINB loss:0.4006, NB loss:4.4738, latent MSE loss:0.00093723, KL loss:0.00111008\n",
      "Pretrain epoch [10/394], ZINB loss:0.4254, NB loss:4.4808, latent MSE loss:0.00167301, KL loss:0.00147440\n",
      "Pretrain epoch [11/394], ZINB loss:0.3908, NB loss:4.5156, latent MSE loss:0.00101960, KL loss:0.00113446\n",
      "Pretrain epoch [12/394], ZINB loss:0.3849, NB loss:4.4830, latent MSE loss:0.00152188, KL loss:0.00087496\n",
      "Pretrain epoch [13/394], ZINB loss:0.4117, NB loss:4.4037, latent MSE loss:0.00148073, KL loss:0.00104617\n",
      "Pretrain epoch [14/394], ZINB loss:0.4106, NB loss:4.5193, latent MSE loss:0.00095218, KL loss:0.00115403\n",
      "Pretrain epoch [15/394], ZINB loss:0.3926, NB loss:4.5492, latent MSE loss:0.00118940, KL loss:0.00096229\n",
      "Pretrain epoch [16/394], ZINB loss:0.3803, NB loss:4.4819, latent MSE loss:0.00061659, KL loss:0.00084125\n",
      "Pretrain epoch [17/394], ZINB loss:0.3965, NB loss:4.4434, latent MSE loss:0.00101669, KL loss:0.00109626\n",
      "Pretrain epoch [18/394], ZINB loss:0.3918, NB loss:4.3740, latent MSE loss:0.00076788, KL loss:0.00090935\n",
      "Pretrain epoch [19/394], ZINB loss:0.4022, NB loss:4.4144, latent MSE loss:0.00069082, KL loss:0.00097806\n",
      "Pretrain epoch [20/394], ZINB loss:0.3796, NB loss:4.4118, latent MSE loss:0.00084551, KL loss:0.00075858\n",
      "Pretrain epoch [21/394], ZINB loss:0.3934, NB loss:4.4807, latent MSE loss:0.00086352, KL loss:0.00090825\n",
      "Pretrain epoch [22/394], ZINB loss:0.3895, NB loss:4.4431, latent MSE loss:0.00047602, KL loss:0.00090085\n",
      "Pretrain epoch [23/394], ZINB loss:0.3935, NB loss:4.4076, latent MSE loss:0.00078861, KL loss:0.00074191\n",
      "Pretrain epoch [24/394], ZINB loss:0.3894, NB loss:4.4857, latent MSE loss:0.00072330, KL loss:0.00085178\n",
      "Pretrain epoch [25/394], ZINB loss:0.3928, NB loss:4.5366, latent MSE loss:0.00052698, KL loss:0.00120052\n",
      "Pretrain epoch [26/394], ZINB loss:0.4082, NB loss:4.4267, latent MSE loss:0.00068131, KL loss:0.00089181\n",
      "Pretrain epoch [27/394], ZINB loss:0.4912, NB loss:4.2802, latent MSE loss:0.00041533, KL loss:0.00006541\n",
      "Pretrain epoch [1/395], ZINB loss:0.3894, NB loss:4.4633, latent MSE loss:0.00092887, KL loss:0.00078899\n",
      "Pretrain epoch [2/395], ZINB loss:0.4001, NB loss:4.4369, latent MSE loss:0.00071119, KL loss:0.00093308\n",
      "Pretrain epoch [3/395], ZINB loss:0.4077, NB loss:4.4599, latent MSE loss:0.00078728, KL loss:0.00081489\n",
      "Pretrain epoch [4/395], ZINB loss:0.4078, NB loss:4.5227, latent MSE loss:0.00069666, KL loss:0.00112629\n",
      "Pretrain epoch [5/395], ZINB loss:0.3880, NB loss:4.4150, latent MSE loss:0.00064888, KL loss:0.00081962\n",
      "Pretrain epoch [6/395], ZINB loss:0.3974, NB loss:4.4126, latent MSE loss:0.00048347, KL loss:0.00083005\n",
      "Pretrain epoch [7/395], ZINB loss:0.3959, NB loss:4.4152, latent MSE loss:0.00051187, KL loss:0.00077413\n",
      "Pretrain epoch [8/395], ZINB loss:0.3967, NB loss:4.5146, latent MSE loss:0.00052903, KL loss:0.00087488\n",
      "Pretrain epoch [9/395], ZINB loss:0.4050, NB loss:4.4253, latent MSE loss:0.00042858, KL loss:0.00086530\n",
      "Pretrain epoch [10/395], ZINB loss:0.3788, NB loss:4.5435, latent MSE loss:0.00037279, KL loss:0.00075867\n",
      "Pretrain epoch [11/395], ZINB loss:0.4046, NB loss:4.4664, latent MSE loss:0.00035108, KL loss:0.00079822\n",
      "Pretrain epoch [12/395], ZINB loss:0.3864, NB loss:4.4583, latent MSE loss:0.00037995, KL loss:0.00138072\n",
      "Pretrain epoch [13/395], ZINB loss:0.3839, NB loss:4.3912, latent MSE loss:0.00041056, KL loss:0.00085709\n",
      "Pretrain epoch [14/395], ZINB loss:0.4010, NB loss:4.5231, latent MSE loss:0.00043485, KL loss:0.00082968\n",
      "Pretrain epoch [15/395], ZINB loss:0.3936, NB loss:4.4954, latent MSE loss:0.00034136, KL loss:0.00098779\n",
      "Pretrain epoch [16/395], ZINB loss:0.3949, NB loss:4.4624, latent MSE loss:0.00042185, KL loss:0.00081338\n",
      "Pretrain epoch [17/395], ZINB loss:0.4022, NB loss:4.5004, latent MSE loss:0.00031528, KL loss:0.00107279\n",
      "Pretrain epoch [18/395], ZINB loss:0.3886, NB loss:4.4349, latent MSE loss:0.00047855, KL loss:0.00086993\n",
      "Pretrain epoch [19/395], ZINB loss:0.4032, NB loss:4.5831, latent MSE loss:0.00034584, KL loss:0.00142366\n",
      "Pretrain epoch [20/395], ZINB loss:0.3893, NB loss:4.4884, latent MSE loss:0.00034634, KL loss:0.00077297\n",
      "Pretrain epoch [21/395], ZINB loss:0.3855, NB loss:4.4339, latent MSE loss:0.00024565, KL loss:0.00080616\n",
      "Pretrain epoch [22/395], ZINB loss:0.3895, NB loss:4.4090, latent MSE loss:0.00031031, KL loss:0.00084236\n",
      "Pretrain epoch [23/395], ZINB loss:0.3860, NB loss:4.4447, latent MSE loss:0.00031170, KL loss:0.00092517\n",
      "Pretrain epoch [24/395], ZINB loss:0.3952, NB loss:4.4092, latent MSE loss:0.00031037, KL loss:0.00078015\n",
      "Pretrain epoch [25/395], ZINB loss:0.3916, NB loss:4.4171, latent MSE loss:0.00020095, KL loss:0.00077981\n",
      "Pretrain epoch [26/395], ZINB loss:0.3934, NB loss:4.4868, latent MSE loss:0.00035214, KL loss:0.00089037\n",
      "Pretrain epoch [27/395], ZINB loss:0.3313, NB loss:4.3487, latent MSE loss:0.00011878, KL loss:0.00006753\n",
      "Pretrain epoch [1/396], ZINB loss:0.3711, NB loss:4.4564, latent MSE loss:0.00044302, KL loss:0.00078328\n",
      "Pretrain epoch [2/396], ZINB loss:0.4000, NB loss:4.4802, latent MSE loss:0.00028013, KL loss:0.00098107\n",
      "Pretrain epoch [3/396], ZINB loss:0.3957, NB loss:4.4072, latent MSE loss:0.00039593, KL loss:0.00084879\n",
      "Pretrain epoch [4/396], ZINB loss:0.3880, NB loss:4.3978, latent MSE loss:0.00019179, KL loss:0.00079338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [5/396], ZINB loss:0.3817, NB loss:4.4713, latent MSE loss:0.00030490, KL loss:0.00108132\n",
      "Pretrain epoch [6/396], ZINB loss:0.4015, NB loss:4.4533, latent MSE loss:0.00025933, KL loss:0.00076624\n",
      "Pretrain epoch [7/396], ZINB loss:0.4057, NB loss:4.4919, latent MSE loss:0.00034363, KL loss:0.00089915\n",
      "Pretrain epoch [8/396], ZINB loss:0.3939, NB loss:4.4323, latent MSE loss:0.00020799, KL loss:0.00074393\n",
      "Pretrain epoch [9/396], ZINB loss:0.3906, NB loss:4.4038, latent MSE loss:0.00029061, KL loss:0.00071624\n",
      "Pretrain epoch [10/396], ZINB loss:0.4025, NB loss:4.4770, latent MSE loss:0.00020271, KL loss:0.00133975\n",
      "Pretrain epoch [11/396], ZINB loss:0.3986, NB loss:4.4698, latent MSE loss:0.00025373, KL loss:0.00071064\n",
      "Pretrain epoch [12/396], ZINB loss:0.3945, NB loss:4.5209, latent MSE loss:0.00019901, KL loss:0.00096835\n",
      "Pretrain epoch [13/396], ZINB loss:0.3813, NB loss:4.5383, latent MSE loss:0.00024891, KL loss:0.00084810\n",
      "Pretrain epoch [14/396], ZINB loss:0.3999, NB loss:4.4296, latent MSE loss:0.00023687, KL loss:0.00075073\n",
      "Pretrain epoch [15/396], ZINB loss:0.3832, NB loss:4.5053, latent MSE loss:0.00034981, KL loss:0.00082658\n",
      "Pretrain epoch [16/396], ZINB loss:0.4029, NB loss:4.4164, latent MSE loss:0.00025674, KL loss:0.00084680\n",
      "Pretrain epoch [17/396], ZINB loss:0.3889, NB loss:4.4552, latent MSE loss:0.00027471, KL loss:0.00077883\n",
      "Pretrain epoch [18/396], ZINB loss:0.3938, NB loss:4.4422, latent MSE loss:0.00024254, KL loss:0.00075966\n",
      "Pretrain epoch [19/396], ZINB loss:0.4017, NB loss:4.4371, latent MSE loss:0.00025489, KL loss:0.00082493\n",
      "Pretrain epoch [20/396], ZINB loss:0.3900, NB loss:4.4431, latent MSE loss:0.00028540, KL loss:0.00108614\n",
      "Pretrain epoch [21/396], ZINB loss:0.3982, NB loss:4.5003, latent MSE loss:0.00019661, KL loss:0.00070210\n",
      "Pretrain epoch [22/396], ZINB loss:0.3911, NB loss:4.5053, latent MSE loss:0.00018978, KL loss:0.00107066\n",
      "Pretrain epoch [23/396], ZINB loss:0.4050, NB loss:4.4103, latent MSE loss:0.00025424, KL loss:0.00087612\n",
      "Pretrain epoch [24/396], ZINB loss:0.4091, NB loss:4.4575, latent MSE loss:0.00023980, KL loss:0.00081287\n",
      "Pretrain epoch [25/396], ZINB loss:0.3816, NB loss:4.4929, latent MSE loss:0.00022087, KL loss:0.00104868\n",
      "Pretrain epoch [26/396], ZINB loss:0.3973, NB loss:4.4888, latent MSE loss:0.00022073, KL loss:0.00076934\n",
      "Pretrain epoch [27/396], ZINB loss:0.3295, NB loss:4.8261, latent MSE loss:0.00025716, KL loss:0.00000582\n",
      "Pretrain epoch [1/397], ZINB loss:0.3966, NB loss:4.4797, latent MSE loss:0.00041095, KL loss:0.00105129\n",
      "Pretrain epoch [2/397], ZINB loss:0.3951, NB loss:4.4216, latent MSE loss:0.00033599, KL loss:0.00073297\n",
      "Pretrain epoch [3/397], ZINB loss:0.3833, NB loss:4.4834, latent MSE loss:0.00032666, KL loss:0.00095550\n",
      "Pretrain epoch [4/397], ZINB loss:0.3887, NB loss:4.4664, latent MSE loss:0.00032751, KL loss:0.00075687\n",
      "Pretrain epoch [5/397], ZINB loss:0.3929, NB loss:4.4745, latent MSE loss:0.00030761, KL loss:0.00081266\n",
      "Pretrain epoch [6/397], ZINB loss:0.3926, NB loss:4.4716, latent MSE loss:0.00028451, KL loss:0.00108856\n",
      "Pretrain epoch [7/397], ZINB loss:0.4085, NB loss:4.4388, latent MSE loss:0.00028201, KL loss:0.00083483\n",
      "Pretrain epoch [8/397], ZINB loss:0.3920, NB loss:4.4784, latent MSE loss:0.00028103, KL loss:0.00084805\n",
      "Pretrain epoch [9/397], ZINB loss:0.3944, NB loss:4.4708, latent MSE loss:0.00027877, KL loss:0.00081828\n",
      "Pretrain epoch [10/397], ZINB loss:0.4032, NB loss:4.3824, latent MSE loss:0.00027466, KL loss:0.00074315\n",
      "Pretrain epoch [11/397], ZINB loss:0.3914, NB loss:4.4271, latent MSE loss:0.00025836, KL loss:0.00069243\n",
      "Pretrain epoch [12/397], ZINB loss:0.4029, NB loss:4.4073, latent MSE loss:0.00035333, KL loss:0.00086592\n",
      "Pretrain epoch [13/397], ZINB loss:0.3944, NB loss:4.4633, latent MSE loss:0.00027153, KL loss:0.00089482\n",
      "Pretrain epoch [14/397], ZINB loss:0.3898, NB loss:4.4414, latent MSE loss:0.00023298, KL loss:0.00082695\n",
      "Pretrain epoch [15/397], ZINB loss:0.3858, NB loss:4.4705, latent MSE loss:0.00024690, KL loss:0.00072965\n",
      "Pretrain epoch [16/397], ZINB loss:0.4017, NB loss:4.4640, latent MSE loss:0.00030081, KL loss:0.00084506\n",
      "Pretrain epoch [17/397], ZINB loss:0.3885, NB loss:4.4892, latent MSE loss:0.00026802, KL loss:0.00114263\n",
      "Pretrain epoch [18/397], ZINB loss:0.3933, NB loss:4.4480, latent MSE loss:0.00018856, KL loss:0.00075951\n",
      "Pretrain epoch [19/397], ZINB loss:0.4055, NB loss:4.5219, latent MSE loss:0.00031110, KL loss:0.00078898\n",
      "Pretrain epoch [20/397], ZINB loss:0.3714, NB loss:4.4599, latent MSE loss:0.00022503, KL loss:0.00100124\n",
      "Pretrain epoch [21/397], ZINB loss:0.3908, NB loss:4.5168, latent MSE loss:0.00025565, KL loss:0.00077936\n",
      "Pretrain epoch [22/397], ZINB loss:0.4005, NB loss:4.4806, latent MSE loss:0.00022605, KL loss:0.00079921\n",
      "Pretrain epoch [23/397], ZINB loss:0.3956, NB loss:4.4791, latent MSE loss:0.00022792, KL loss:0.00078299\n",
      "Pretrain epoch [24/397], ZINB loss:0.3901, NB loss:4.4488, latent MSE loss:0.00022512, KL loss:0.00104879\n",
      "Pretrain epoch [25/397], ZINB loss:0.4028, NB loss:4.4931, latent MSE loss:0.00023086, KL loss:0.00094623\n",
      "Pretrain epoch [26/397], ZINB loss:0.3995, NB loss:4.4064, latent MSE loss:0.00028179, KL loss:0.00105930\n",
      "Pretrain epoch [27/397], ZINB loss:0.4078, NB loss:4.3175, latent MSE loss:0.00024020, KL loss:0.00004913\n",
      "Pretrain epoch [1/398], ZINB loss:0.4045, NB loss:4.4522, latent MSE loss:0.00127489, KL loss:0.00081126\n",
      "Pretrain epoch [2/398], ZINB loss:0.3949, NB loss:4.4391, latent MSE loss:0.00142283, KL loss:0.00111671\n",
      "Pretrain epoch [3/398], ZINB loss:0.4067, NB loss:4.4919, latent MSE loss:0.00055447, KL loss:0.00110618\n",
      "Pretrain epoch [4/398], ZINB loss:0.3993, NB loss:4.4806, latent MSE loss:0.00064898, KL loss:0.00086055\n",
      "Pretrain epoch [5/398], ZINB loss:0.4094, NB loss:4.4454, latent MSE loss:0.00050343, KL loss:0.00082404\n",
      "Pretrain epoch [6/398], ZINB loss:0.3821, NB loss:4.4630, latent MSE loss:0.00100142, KL loss:0.00100011\n",
      "Pretrain epoch [7/398], ZINB loss:0.3745, NB loss:4.4794, latent MSE loss:0.00078819, KL loss:0.00083740\n",
      "Pretrain epoch [8/398], ZINB loss:0.4008, NB loss:4.4542, latent MSE loss:0.00102450, KL loss:0.00079167\n",
      "Pretrain epoch [9/398], ZINB loss:0.3988, NB loss:4.4262, latent MSE loss:0.00096266, KL loss:0.00082912\n",
      "Pretrain epoch [10/398], ZINB loss:0.3972, NB loss:4.4915, latent MSE loss:0.00065085, KL loss:0.00109395\n",
      "Pretrain epoch [11/398], ZINB loss:0.3967, NB loss:4.4415, latent MSE loss:0.00072199, KL loss:0.00083122\n",
      "Pretrain epoch [12/398], ZINB loss:0.4027, NB loss:4.4639, latent MSE loss:0.00054998, KL loss:0.00078252\n",
      "Pretrain epoch [13/398], ZINB loss:0.3918, NB loss:4.4284, latent MSE loss:0.00064043, KL loss:0.00093697\n",
      "Pretrain epoch [14/398], ZINB loss:0.3878, NB loss:4.4724, latent MSE loss:0.00046237, KL loss:0.00067830\n",
      "Pretrain epoch [15/398], ZINB loss:0.4086, NB loss:4.4395, latent MSE loss:0.00044071, KL loss:0.00075120\n",
      "Pretrain epoch [16/398], ZINB loss:0.4036, NB loss:4.4467, latent MSE loss:0.00041314, KL loss:0.00067827\n",
      "Pretrain epoch [17/398], ZINB loss:0.3851, NB loss:4.4759, latent MSE loss:0.00047218, KL loss:0.00077356\n",
      "Pretrain epoch [18/398], ZINB loss:0.4002, NB loss:4.4573, latent MSE loss:0.00048341, KL loss:0.00091473\n",
      "Pretrain epoch [19/398], ZINB loss:0.3944, NB loss:4.5242, latent MSE loss:0.00041602, KL loss:0.00095003\n",
      "Pretrain epoch [20/398], ZINB loss:0.3867, NB loss:4.4284, latent MSE loss:0.00038036, KL loss:0.00082312\n",
      "Pretrain epoch [21/398], ZINB loss:0.3841, NB loss:4.4397, latent MSE loss:0.00031529, KL loss:0.00072701\n",
      "Pretrain epoch [22/398], ZINB loss:0.3958, NB loss:4.4423, latent MSE loss:0.00050406, KL loss:0.00084255\n",
      "Pretrain epoch [23/398], ZINB loss:0.3877, NB loss:4.4470, latent MSE loss:0.00035151, KL loss:0.00113428\n",
      "Pretrain epoch [24/398], ZINB loss:0.3844, NB loss:4.4940, latent MSE loss:0.00029986, KL loss:0.00083185\n",
      "Pretrain epoch [25/398], ZINB loss:0.3904, NB loss:4.4759, latent MSE loss:0.00029261, KL loss:0.00094802\n",
      "Pretrain epoch [26/398], ZINB loss:0.4011, NB loss:4.4624, latent MSE loss:0.00028512, KL loss:0.00082047\n",
      "Pretrain epoch [27/398], ZINB loss:0.3433, NB loss:4.3609, latent MSE loss:0.00020575, KL loss:0.00004073\n",
      "Pretrain epoch [1/399], ZINB loss:0.3815, NB loss:4.4803, latent MSE loss:0.00045903, KL loss:0.00087277\n",
      "Pretrain epoch [2/399], ZINB loss:0.3811, NB loss:4.4975, latent MSE loss:0.00055110, KL loss:0.00068923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrain epoch [3/399], ZINB loss:0.4022, NB loss:4.4887, latent MSE loss:0.00041145, KL loss:0.00073374\n",
      "Pretrain epoch [4/399], ZINB loss:0.4099, NB loss:4.4659, latent MSE loss:0.00037325, KL loss:0.00078762\n",
      "Pretrain epoch [5/399], ZINB loss:0.4104, NB loss:4.4534, latent MSE loss:0.00041327, KL loss:0.00082999\n",
      "Pretrain epoch [6/399], ZINB loss:0.3887, NB loss:4.5102, latent MSE loss:0.00041612, KL loss:0.00066837\n",
      "Pretrain epoch [7/399], ZINB loss:0.4036, NB loss:4.5286, latent MSE loss:0.00033993, KL loss:0.00114525\n",
      "Pretrain epoch [8/399], ZINB loss:0.3800, NB loss:4.4345, latent MSE loss:0.00033332, KL loss:0.00068893\n",
      "Pretrain epoch [9/399], ZINB loss:0.3921, NB loss:4.3842, latent MSE loss:0.00047299, KL loss:0.00103625\n",
      "Pretrain epoch [10/399], ZINB loss:0.3974, NB loss:4.4292, latent MSE loss:0.00029465, KL loss:0.00081653\n",
      "Pretrain epoch [11/399], ZINB loss:0.4012, NB loss:4.4544, latent MSE loss:0.00036789, KL loss:0.00090803\n",
      "Pretrain epoch [12/399], ZINB loss:0.3955, NB loss:4.4798, latent MSE loss:0.00027362, KL loss:0.00072692\n",
      "Pretrain epoch [13/399], ZINB loss:0.4020, NB loss:4.5121, latent MSE loss:0.00039663, KL loss:0.00120599\n",
      "Pretrain epoch [14/399], ZINB loss:0.3837, NB loss:4.4083, latent MSE loss:0.00027226, KL loss:0.00066693\n",
      "Pretrain epoch [15/399], ZINB loss:0.3852, NB loss:4.4783, latent MSE loss:0.00021738, KL loss:0.00069824\n",
      "Pretrain epoch [16/399], ZINB loss:0.3893, NB loss:4.4314, latent MSE loss:0.00033439, KL loss:0.00099668\n",
      "Pretrain epoch [17/399], ZINB loss:0.3945, NB loss:4.3625, latent MSE loss:0.00029560, KL loss:0.00086708\n",
      "Pretrain epoch [18/399], ZINB loss:0.4084, NB loss:4.4916, latent MSE loss:0.00037531, KL loss:0.00124163\n",
      "Pretrain epoch [19/399], ZINB loss:0.3893, NB loss:4.3790, latent MSE loss:0.00031423, KL loss:0.00083889\n",
      "Pretrain epoch [20/399], ZINB loss:0.3910, NB loss:4.4135, latent MSE loss:0.00023882, KL loss:0.00070349\n",
      "Pretrain epoch [21/399], ZINB loss:0.3918, NB loss:4.4911, latent MSE loss:0.00027789, KL loss:0.00105995\n",
      "Pretrain epoch [22/399], ZINB loss:0.4039, NB loss:4.5360, latent MSE loss:0.00019324, KL loss:0.00076642\n",
      "Pretrain epoch [23/399], ZINB loss:0.3994, NB loss:4.4321, latent MSE loss:0.00026633, KL loss:0.00080352\n",
      "Pretrain epoch [24/399], ZINB loss:0.3886, NB loss:4.4741, latent MSE loss:0.00025731, KL loss:0.00090825\n",
      "Pretrain epoch [25/399], ZINB loss:0.3865, NB loss:4.4686, latent MSE loss:0.00021313, KL loss:0.00074432\n",
      "Pretrain epoch [26/399], ZINB loss:0.3894, NB loss:4.4571, latent MSE loss:0.00020924, KL loss:0.00081642\n",
      "Pretrain epoch [27/399], ZINB loss:0.4385, NB loss:4.1209, latent MSE loss:0.00014602, KL loss:0.00000447\n",
      "Pretrain epoch [1/400], ZINB loss:0.4008, NB loss:4.4999, latent MSE loss:0.00042834, KL loss:0.00077472\n",
      "Pretrain epoch [2/400], ZINB loss:0.3928, NB loss:4.4724, latent MSE loss:0.00061054, KL loss:0.00077393\n",
      "Pretrain epoch [3/400], ZINB loss:0.3868, NB loss:4.4135, latent MSE loss:0.00048882, KL loss:0.00094313\n",
      "Pretrain epoch [4/400], ZINB loss:0.4001, NB loss:4.4493, latent MSE loss:0.00038899, KL loss:0.00094164\n",
      "Pretrain epoch [5/400], ZINB loss:0.3986, NB loss:4.4380, latent MSE loss:0.00033274, KL loss:0.00071423\n",
      "Pretrain epoch [6/400], ZINB loss:0.3848, NB loss:4.4995, latent MSE loss:0.00054134, KL loss:0.00077619\n",
      "Pretrain epoch [7/400], ZINB loss:0.3778, NB loss:4.4704, latent MSE loss:0.00038209, KL loss:0.00085280\n",
      "Pretrain epoch [8/400], ZINB loss:0.3789, NB loss:4.4329, latent MSE loss:0.00043215, KL loss:0.00104885\n",
      "Pretrain epoch [9/400], ZINB loss:0.4036, NB loss:4.4524, latent MSE loss:0.00049895, KL loss:0.00083904\n",
      "Pretrain epoch [10/400], ZINB loss:0.3747, NB loss:4.4266, latent MSE loss:0.00027434, KL loss:0.00086365\n",
      "Pretrain epoch [11/400], ZINB loss:0.4043, NB loss:4.3637, latent MSE loss:0.00033417, KL loss:0.00072654\n",
      "Pretrain epoch [12/400], ZINB loss:0.3918, NB loss:4.4458, latent MSE loss:0.00048883, KL loss:0.00097643\n",
      "Pretrain epoch [13/400], ZINB loss:0.4149, NB loss:4.5200, latent MSE loss:0.00046558, KL loss:0.00105781\n",
      "Pretrain epoch [14/400], ZINB loss:0.3899, NB loss:4.4638, latent MSE loss:0.00031187, KL loss:0.00080306\n",
      "Pretrain epoch [15/400], ZINB loss:0.3799, NB loss:4.4438, latent MSE loss:0.00031706, KL loss:0.00079451\n",
      "Pretrain epoch [16/400], ZINB loss:0.3865, NB loss:4.4456, latent MSE loss:0.00036670, KL loss:0.00098406\n",
      "Pretrain epoch [17/400], ZINB loss:0.3845, NB loss:4.4541, latent MSE loss:0.00031537, KL loss:0.00080269\n",
      "Pretrain epoch [18/400], ZINB loss:0.4008, NB loss:4.5046, latent MSE loss:0.00027357, KL loss:0.00082980\n",
      "Pretrain epoch [19/400], ZINB loss:0.3941, NB loss:4.4121, latent MSE loss:0.00034204, KL loss:0.00072717\n",
      "Pretrain epoch [20/400], ZINB loss:0.4046, NB loss:4.4894, latent MSE loss:0.00028427, KL loss:0.00081826\n",
      "Pretrain epoch [21/400], ZINB loss:0.3931, NB loss:4.4442, latent MSE loss:0.00029637, KL loss:0.00074864\n",
      "Pretrain epoch [22/400], ZINB loss:0.3931, NB loss:4.4471, latent MSE loss:0.00030827, KL loss:0.00069117\n",
      "Pretrain epoch [23/400], ZINB loss:0.4002, NB loss:4.5519, latent MSE loss:0.00024141, KL loss:0.00081989\n",
      "Pretrain epoch [24/400], ZINB loss:0.4053, NB loss:4.4414, latent MSE loss:0.00031374, KL loss:0.00076225\n",
      "Pretrain epoch [25/400], ZINB loss:0.4055, NB loss:4.4581, latent MSE loss:0.00021289, KL loss:0.00074468\n",
      "Pretrain epoch [26/400], ZINB loss:0.4024, NB loss:4.4722, latent MSE loss:0.00039471, KL loss:0.00106132\n",
      "Pretrain epoch [27/400], ZINB loss:0.3237, NB loss:4.4740, latent MSE loss:0.00010056, KL loss:0.00007024\n",
      "Pretraining time: 1403 seconds.\n"
     ]
    }
   ],
   "source": [
    "#pretraing stage\n",
    "t0 = time()\n",
    "\n",
    "model.pretrain_autoencoder(X1=adata1.X, X_raw1=adata1.raw.X, sf1=adata1.obs.size_factors, X2=adata2.X, X_raw2=adata2.raw.X, sf2=adata2.obs.size_factors, batch_size=256, epochs=400, ae_weights='AE_weights_1.pth.tar')\n",
    "\n",
    "print('Pretraining time: %d seconds.' % int(time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Estimate the number of clusters on latent features by Louvain algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated n_clusters is:  5\n",
      "Estimated number of clusters: 5\n"
     ]
    }
   ],
   "source": [
    "#estimate k\n",
    "latent = model.encodeBatch(torch.tensor(adata1.X), torch.tensor(adata2.X)).cpu().numpy()\n",
    "n_clusters = GetCluster(latent, res=0.2, n=30)\n",
    "print(\"Estimated number of clusters:\", n_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Clustering stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering stage\n",
      "Initializing cluster centers with kmeans.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiantian/miniconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:22: FutureWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n",
      "/Users/tiantian/miniconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing k-means: ACC= 0.9707, NMI= 0.9194, ARI= 0.9353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiantian/miniconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustering   1: ACC= 0.9707, NMI= 0.9194, ARI= 0.9353\n",
      "#Epoch   1: Total: 15.7939 Clustering Loss: 0.02671068 ZINB Loss: 0.3940 NB Loss: 4.4879 Latent MSE Loss: 0.1198 KL Loss: 10.7654\n",
      "Clustering   2: ACC= 0.9710, NMI= 0.9199, ARI= 0.9360\n",
      "delta_label  0.0006005104338687885 < tol  0.001\n",
      "Reach tolerance threshold. Stopping training.\n",
      "Total time: 1521 seconds.\n",
      "Final: ACC= 0.9710, NMI= 0.9199, ARI= 0.9360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tiantian/miniconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n",
      "/Users/tiantian/miniconda3/lib/python3.7/site-packages/sklearn/utils/linear_assignment_.py:128: FutureWarning: The linear_assignment function is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y_pred, _, _, _, _ = model.fit(X1=adata1.X, X_raw1=adata1.raw.X, sf1=adata1.obs.size_factors, X2=adata2.X, X_raw2=adata2.raw.X, sf2=adata2.obs.size_factors, y=y, n_clusters=n_clusters, batch_size=256, num_epochs=2000, update_interval=1, tol=0.001, lr=1., save_dir='results/')\n",
    "print('Total time: %d seconds.' % int(time() - t0))\n",
    "\n",
    "acc = np.round(cluster_acc(y, y_pred), 5)\n",
    "nmi = np.round(metrics.normalized_mutual_info_score(y, y_pred), 5)\n",
    "ari = np.round(metrics.adjusted_rand_score(y, y_pred), 5)\n",
    "print('Final: ACC= %.4f, NMI= %.4f, ARI= %.4f' % (acc, nmi, ari))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 minicoda",
   "language": "python",
   "name": "python3m"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
